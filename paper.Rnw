% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% TODO: 
%  - check tense: we are is have has  use/used find/found
% Sweave/Knitr init
<<setup, include=FALSE, cache=FALSE>>=
library(knitr)
opts_chunk$set(echo = FALSE, 
               message = FALSE, 
               warning = FALSE, 
               fig.align = 'center', 
               tidy = FALSE, 
               comment = NA, 
               cache = TRUE,
               fig.width = 6, 
               fig.height = 6)
library(ggplot2)
library(Hmisc)
library(reshape2)
library(ADNIMERGE)
library(plyr)
options(digits=3)
theme_set(theme_bw(base_size = 12))

lm_eqn = function(m) {
  l <- list(a = format(coef(m)[1], digits = 2),
      b = format(abs(coef(m)[2]), digits = 2),
      r2 = format(summary(m)$r.squared, digits = 3));
  if (coef(m)[2] >= 0)  {
    eq <- substitute(italic(y) == a + b %.% italic(x)*","~~italic(r)^2~"="~r2,l)
  } else {
    eq <- substitute(italic(y) == a - b %.% italic(x)*","~~italic(r)^2~"="~r2,l)    
  }

  as.character(as.expression(eq))
}
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass{article}
\usepackage[margin=1in]{geometry}
\usepackage{algorithm, color, algpseudocode, amsmath, url, geometry, ctable}
\usepackage{titlesec, siunitx, graphicx}
\usepackage[round,authoryear]{natbib}
\usepackage[section]{placeins}   % keep floats in their place.
\usepackage{authblk}             % Listing Author affiliations
\usepackage{rotating}            % rotating figures
\usepackage[hypcap]{caption}


%draft mode
\usepackage[colorinlistoftodos, textwidth=4cm, shadow]{todonotes}
\usepackage[displaymath, tightpage]{preview}
\setlength{\marginparwidth}{1.2in}
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhead[RO,RE]{draft - f9776d7 - September, 2013}

% styling
\newcommand{\subsubsubsection}[1]{\paragraph{#1}}
\renewcommand\Affilfont{\itshape\small}  %authblk
\linespread{1.3} % one and a half line spacing

% shortcuts 
\newcommand{\mb}{MAGeT-Brain}
\newcommand{\ants}{ANTS}
\newcommand{\animal}{ANIMAL}
\newcommand{\adnidataset}{ADNI1:Complete 1Yr 1.5T}
\newcommand{\FEPdataset}{SZ-FEP}
\newcommand{\gs}{Gold Standard}
\newcommand{\fsl}{FSL}
\newcommand{\freesurfer}{FreeSurfer}
\newcommand{\maper}{MAPER}


% title and authors
%\title{Bootstrapping Multi-atlas Hippocampal Subfield Segmentation by using
%Multiple Automatically Generated Templates}
\title{Bootstrapping Multi-atlas Segmentation Using Multiple Automatically
Generated Templates for the Segmentation of the Whole Hippocampus and
Subfields}
\author[1]{Jon Pipitone}
\author[1]{Matt Min Tae Park}
\author[1]{Julie Winterburn}
\author[1,9]{Tristram A. Lett}
\author[2,3]{Jason P. Lerch}
\author[4]{Jens C. Pruessner}
\author[4,5]{Martin Lepage}
\author[1,6,9]{Aristotle N. Voineskos}
\author[1,6,7,8]{M. Mallar Chakravarty}
\author[ ]{the Alzheimer's Disease Neuroimaging Initiative\footnote{Data
used in preparation of this article were obtained from the Alzheimer's Disease
Neuroimaging Initiative (ADNI) database (adni.loni.ucla.edu). As such, the
investigators within the ADNI contributed to the design and implementation of
ADNI and/or provided data but did not participate in analysis or writing of this
report. A complete listing of ADNI investigators can be found at:
http://adni.loni.ucla.edu/wp-content/uploads/how\_to\_apply/ADNI\_Acknowledgement\_List.pdf}}
\affil[1]{Kimel Family Translational Imaging-Genetics Lab, Centre for Addiction and
Mental Health, Toronto, ON, Canada}
\affil[2]{Neurosciences and Mental Health Laboratory, Hospital for Sick
Children, Toronto, ON, Canada}
\affil[3]{Department of Medical Biophysics, University of Toronto, Toronto, ON,
Canada}
\affil[4]{Douglas Mental Health University Institute, Verdun, QC, Canada}
\affil[5]{Department of Psychiatry, McGill University, Montreal, QC, Canada}
\affil[6]{Department of Psychiatry, University of Toronto, Toronto, ON, Canada}
\affil[7]{Institute of Biomaterials and Biomedical Engineering, University of
Toronto, Toronto, ON, Canada}
\affil[8]{Rotman Research Institute, Baycrest, Toronto, ON, Canada}
\affil[9]{Institute of Medical Science, University of Toronto, Toronto, ON, Canada}

\renewcommand\Authands{ and }

\date{}

\begin{document}
\maketitle

\begin{abstract}

\textbf{Introduction:} 
Advances in image segmentation of magnetic resonance images (MRI) have
demonstrated that multi-atlas approaches improve segmentation accuracy and
precision over regular atlas-based approaches.  These approaches often rely on
a large number of such manually segmented atlases (e.g.  30-80) that take
significant time and expertise to produce. We present an algorithm, \mb{} (
({\textbf M}ultiple {\textbf A}utomatically {\textbf Ge}nerated {\textbf
T}emplates), for the automatic segmentation of the hippocampus that minimizes
the number of atlases needed while still achieving similar accuracy to
multi-atlas approaches. Thus, our method acts as an accurate multi-atlas
approach when using special, hard-to-define atlases that are laborious to
construct. \\
\textbf{Method:} \mb{} works by propagating atlas segmentations to a template library,
formed from a subset of target images, via transformations estimated by non-linear
image registration. The resultant segmentations are then propagated to each
target image and fused using a label fusion method. We conduct a 10-fold Monte
Carlo cross-validation of whole hippocampal segmentation on a pool of 69 ADNI
subjects over a range of parameter settings, and a leave-one-out
cross-validation (LOOCV) of hippocampal subfield segmentation using five
high-resolution atlases. Two final experiments assess \mb{} when applied to
first episode psychosis and Alzheimer's disease populations, and \mb{}
segmentations are compared with existing automated methods (\fsl{}, \freesurfer{},
\maper{}) and biases are explored.\\
\textbf{Results:} Using nine atlases and 19 template images, \mb{} achieves a
mean Dice's Similarity Coefficient (DSC) of 0.84 over 10-folds of Monte Carlo
cross-validation on 69 subjects relative to semi-automated \gs{} segmentations,
and shows significantly lower variability in DSC than multi-atlas segmentation.
In a LOOCV, \mb{} reproduces the volumes of the cornu ammonis (CA) 1; CA4/dentate
gyrus (DG); and strata radiatum (SR), strata lacunosum (SL), and strata
moleculare (SM) hippocampal subregions with a percent error in volume that is
at or lower than that produced by image resampling. \mb{} produces hippocampal
volumes in a first episode psychosis patient population that are highly
correlated with expert manual segmentation volumes (Pearson $r = 0.877, t =
16.244, p < 0.001$). Compared to \fsl{} and \freesurfer{}, \mb{} shows much smaller
fixed volume bias (within $250 mm^3$ on average) to \gs{} segmentations available
from ADNI, as well as a conservative, rather than exaggerated, proportional
volume bias.\\ \textbf{Conclusion:} We demonstrate that \mb{} produces accurate
hippocampal segmentations using only 5 atlases over different hippocampal
definitions, disease populations, and acquisition types, as well as showing
that accurate identification of the hippocampal subfields is possible.
\end{abstract}

\parbox{4in}{
\textbf{Contact:} \\
Jon Pipitone and M. Mallar Chakravarty \\
Kimel Family Translation Imaging-Genetics Research Laboratory \\
Research Imaging Centre \\
Centre for Addiction and Mental Health \\
250 College St. \\
Toronto, Canada   M5T 1R8 \\
jon.pipitone@camh.ca; mallar.chakravarty@camh.ca}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                               INTRODUCTION
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

The hippocampus is a brain structure situated in the medial temporal
lobe, and has long been associated with learning and memory
\citep{DenHeijer2012,Scoville2000}. The hippocampus is of interest to
clinical neuroscientists because it is implicated in many forms of brain
dysfunction, including Alzheimer's disease \citep{Sabuncu2011} and
schizophrenia \citep{Narr2004,Karnik-Henry2012}. In neuroimaging studies,
structural magnetic resonance images (MRI) are often used for the volumetric
assessment of the hippocampus.  As such, accurate segmentation of the
hippocampus and its subregions in MRI is a necessary first step to better
understand the inter-individual variability of subject neuroanatomy. 

The gold standard for neuroanatomical segmentation is manual delineation by an
expert human rater.  However, with the availability of increasingly large MRI
datasets, the time and expertise required for manual segmentation becomes
prohibitive \citep{Mazziotta1995,Mazziotta2001,Mazziotta,Pausova2007}. This
effort is complicated by the fact that there is significant variation between
segmentation protocols with respect to specific anatomical boundaries of the
hippocampus \citep{Geuze2004} and this has led to efforts to create an unified
hippocampal segmentation protocol \citep{Jack2011}.  In addition, there is
controversy over the appropriate manual segmentation protocol to use in a
particular imaging study \citep{Nestor2012}.  Thus, a segmentation algorithm
that can easily adapt to different manual segmentation definitions would be of
significant benefit to the neuroimaging community.

Automated segmentation techniques that are reliable, objective, and reproducible
can be considered complementary to manual segmentation. In the case of classical
model-based segmentation methods \citep{Haller1997,Csernansky1998}, an MRI atlas
that was previously manually labelled by an expert rater is matched to target
images using nonlinear registration methods. The resulting nonlinear
transformation is applied to the manual labels (i.e. {\em label propagation}) to
move them into the target image space. While this methodology has been used
successfully in several contexts
\citep{Chakravarty2008,Chakravarty2009,Collins1995,Haller1997}, it is limited in
accuracy due to error in the estimated nonlinear transformation itself, partial
volume effects in label resampling, and irreconcilable differences between the
neuroanatomy represented within the atlas and target images.
 
One methodology that can be used to mitigate these sources of errors involves
the use of multiple manually segmented atlases and probabilistic segmentation
techniques, such as those found in the \freesurfer{} package \citep{Fischl2002}.
\freesurfer{} uses a probabilistic atlas of anatomical and tissue classes along
with spatial constraints for class labels encoded using a Markov random field
model to segment the entire brain. 

More recently, many groups have used multiple atlases to improve overall
segmentation accuracy (i.e. multi-atlas segmentation) over model-based approaches
\citep{Heckemann2006,Heckemann2011,Collins2010,Lotjonen2010,Aljabar2009,Leung2010,Wolz2010}.
Each atlas image is registered to a target image, and label propagation is
performed to produce several labellings of the target image (one from each
atlas). A {\it label fusion} technique, such as voxel-wise voting, is used to
merge these labels into the definitive segmentation for the target. In addition,
weighted voting procedures that use {\em atlas selection} techniques are often
used to exclude atlases from label fusion that are dissimilar to a target image
in order to reduce error from unrepresentative anatomy \citep{Aljabar2009}.
This involves the selection of a subset of atlases using a similarity metric
such as cross-correlation \citep{Aljabar2009} or normalized mutual information.
Such selection has the added benefit of significantly reducing the number of
nonlinear registrations. For example \citet{Collins2010} demonstrated that only
14 atlases, selected based on highest similarity between medial temporal lobe
neuroanatomy as evaluated by normalized mutual information \citep{Studholme1999}
from a library of 80 atlases, were required to achieve accurate segmentations of
the hippocampus. Additionally, several methods have been explored for label
fusion, including the STAPLE algorithm (Simultaneous Truth And Performance Level
Estimation; \citet{Warfield2004}) that computes a probabilistic segmentation
using an expectation-maximization framework from an set of competing
segmentations, or others where a subset of segmentations can be estimated using
metrics such as the sum of squared differences in the regions of interest to be
segmented \citep{Coupe2011}.

However, many of these methods require significant investment of time and
resources for the creation of the atlas library ranging between 30
\citep{Heckemann2006} and 80 \citep{Collins2010} manually segmented atlases.
This strategy has the main drawback of being inflexible as it does not easily
accommodate varying the definition of the hippocampal anatomy (such as the
commonly used heuristic of subdividing the hippocampus into head, body, and tail
\citep{Poppenk2011,Pruessner2000}). Furthermore, none of these methods have
demonstrated sufficient flexibility to accommodate atlases that are somehow
exceptional such as those derived from serial histological data
\citep{Chakravarty2006,Yelnik2007} or high-resolution MRI data that enables
robust identification of hippocampal subfields
\citep{Winterburn2013,Yushkevich2009,Mueller2009,VanLeemput2009,Wisse2012}. Due
to the recent availability of the latter, there has been increased interest in
the use of probabilistic methods for the identification of the hippocampal
subfields on standard T1-weighted images. Our group recently demonstrated that
through use of an intermediary automated segmentation stage, robust and accurate
segmentation of the striatum, pallidum, and thalamus using a single atlas
derived from serial histological data is possible \citep{MallarChakravarty2012}.
The novelty of this manuscript is the extension of our multi-atlas methodology
to the hippocampus using more than a single input atlas, while simultaneously
limiting the number of inputs used during segmentation, and demonstrating that
accurate identification of the hippocampal subfields is indeed possible using
this methodology.

Of special relevance to the present work is the LEAP algorithm (Learning
Embeddings for Atlas Propagation; \citet{Wolz2010}) because of its focus on
performing multi-atlas segmentation with a limited number of input atlases.  The
LEAP algorithm is a clever modification to the basic multi-atlas strategy in
which an atlas library is grown, beginning with a set of manually labelled
atlases, by successively incorporating unlabelled target images once they
themselves have been labelled using multi-atlas techniques. The sequence in
which target images are labelled is chosen so that the similarity between the
atlas images and the target images is minimised at each step, effectively
allowing for deformations between very dissimilar images to be broken up into
sequences of smaller deformations. Although \citet{Wolz2010} begin with an atlas
library of 30 MR images, this method could theoretically work using a much
smaller atlas library.  In their validation, LEAP was used to segment the whole
hippocampus in the ADNI-1 baseline dataset, achieving a mean Dice score of 0.85
against \gs{} segmentations.

Also of interest to this manuscript are methods that attempt to define
hippocampal subfields using standard T1-weighted data.  To the best of our
knowledge, there are only two automated segmentation algorithms that attempt
this problem. The first is included with the \freesurfer{} package
\citep{VanLeemput2009}. This work is limited as it omits the tail of the
hippocampus and the segmentation protocol has yet to be fully validated.
Nonetheless, it demonstrates that the applicability of hippocampal subfield
segmentation using data from 10 subjects. In the second method,
\citet{Yushkevich2009} hippocampal subfields were acquired and labelled on
high-resolution MRI data from post-mortem medial temporal lobe samples. Using
nonlinear registration guided by manually derived hippocampus masks and
specific landmarks, the authors demonstrated accurate parcellation of
hippocampal subfields in unlabelled MRI volumes. 

In this paper we have describe a thorough validation of the \mb{} algorithm for
segmentation of the hippocampus and its subfields. First, we addressed the feasibility and
accuracy of whole hippocampus segmentation with a limited number of input
atlases \citep{MallarChakravarty2012} by performing a multi-fold experiment
using a subset of the Alzheimer's Disease Neuroimaging Initiative (ADNI)
dataset over a range of parameters.  We then performed a leave-one-out
validation to determine if hippocampal subfields can be accurately identified
using our multi-atlas framework.  To ensure that we have not over-fit our
parameters to the aging or neurodegenerative brain, we also applied our
segmentations to a dataset of individuals suffering from first episode
psychosis.  Finally, validated our algorithm using all of the data available in
the \adnidataset{} sample and compare our segmentations to the other
segmentations available through the ADNI informatics portal. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                               METHODS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Methods}

%%%%%                     MAGeT Brain Algorithm                            %%%%%

\subsection{The \mb{} Algorithm}
In this paper, we use the term {\em label} to mean any segmentation (manual or
derived) of an MR image. {\em Label propagation} is the process by which two
images are registered and the resulting transformation is applied to the labels
from one image to bring them into alignment with the other image. We use the
term {\em atlas} to mean a manually segmented image, and the term {\em template}
to mean an automatically segmented image (i.e.  via label propagation). The
terms {\em atlas library} and {\em template library} describe any set of such
images. Additionally, we use the term {\em target} to refer to an unlabelled
image that is undergoing segmentation.

The simplest form of multi-atlas segmentation, which we call {\em basic 
multi-atlas segmentation}, involves three steps. First, each labelled 
input image (i.e. atlas or template) is registered to an unlabelled target image.
Second, the labels from each image are propagated to the target image space. 
Third, the labels are combined into a single label by label fusion
\citep{Heckemann2006, Heckemann2011}. The basic multi-atlas segmentation method
is described in detail in other publications
\citep{Collins2010,Heckemann2011,Aljabar2009}. When only a single atlas is used,
basic multi-atlas segmentation degenerates into model-based segmentation: labels
are propagated from the atlas to a target, and no label fusion is needed.

\mb{} ({\textbf M}ultiple {\textbf A}utomatically {\textbf Ge}nerated {\textbf
T}emplates) bootstraps the creation of a large template library given a limited
input atlas library, and then uses the template library in basic multi-atlas
segmentation.  Images for the template library are selected from a set of input
target images, either arbitrarily or so as to reflect the neuroanatomy or
demographics of the target set as a whole (for instance, by sampling equally
from cases and controls).  The template library images are automatically
labelled by each of the atlases via label propagation.  Basic multi-atlas
segmentation is then conducted using the template library to segment the entire
set of target images (including the target images used in the construction of
the template library).  Since each template library image has multiple labels
(one from each atlas), the final number of labels to be fused for each target
may be quite large (i.e. \# of atlas $\times$ \# of templates).

Figure \ref{fig:MAGeT} illustrates the \mb{} algorithm graphically. Source code
for \mb{} can be found at \url{http://github.com/pipitone/MAGeTbrain}.

\begin{figure}
  \begin{centering}
    \includegraphics[width=\textwidth]{figure/MA-MAGeTBrain-Schematic}
  \end{centering}
  \caption{A schematic illustration of basic multi-atlas segmentation and \mb{}
  segmentation \label{fig:MAGeT}}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                            Experiments                              %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Experiments}

The following section describes for experiments conducted to assess the
segmentation quality of the \mb{} algorithm. The first two experiments assess the
validity of \mb{} using a cross-validation design. Experiment 1 investigates the
accuracy of \mb{} whole hippocampus segmentation over a wide range of parameter
settings. The results of this experiment enable us to choose the parameter
settings offering the best performance for use in subsequent experiments.
Experiment 2 assesses hippocampal subfield segmentation quality in a
leave-one-out cross-validation design. The last two experiments assess the
validity of the \mb{} algorithm when applied to different diseases: first episode
schizophrenia (Experiment 3), and Alzheimer's disease (Experiment 4).
Additionally, in Experiment 4, we compared \mb{} segmentations with those of
well-known automated methods and assessed segmentation bias. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                                                                     %%%%%
%%%%%         Experiment 1: Whole Hippocampus Cross-Validation            %%%%%
%%%%%                                                                     %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Experiment 1: Whole Hippocampus Cross-Validation}

Monte Carlo Cross-Validation (MCCV) \citep{Shao1993} was performed using a pool
of images and SNT \gs{} segmentations from the ADNI dataset \citep{Hsu2002}. This
form of cross-validation allows us to rigorously validate a large number of
parameter settings of \mb{} (atlas and template library sizes, registration
algorithm, and label fusion method) and select the best parameters to use in
subsequent experiments.

\paragraph{\adnidataset{} dataset} 
Data used in the preparation of this article were obtained from the Alzheimerâs
Disease Neuroimaging Initiative (ADNI) database (adni.loni.ucla.edu). The ADNI
was launched in 2003 by the National Institute on Aging (NIA), the National
Institute of Biomedical Imaging and Bioengineering (NIBIB), the Food and Drug
Administration (FDA), private pharmaceutical companies and non-profit
organizations, as a \$60 million, 5-year public- private partnership. The primary
goal of ADNI has been to test whether serial magnetic resonance imaging (MRI),
positron emission tomography (PET), other biological markers, and clinical and
neuropsychological assessment can be combined to measure the progression of mild
cognitive impairment (MCI) and early Alzheimerâs disease (AD).  Determination of
sensitive and specific markers of very early AD progression is intended to aid
researchers and clinicians to develop new treatments and monitor their
effectiveness, as well as lessen the time and cost of clinical trials.  

The Principal Investigator of this initiative is Michael W. Weiner, MD, VA
Medical Center and University of California â San Francisco. ADNI is the result
of efforts of many co- investigators from a broad range of academic institutions
and private corporations, and subjects have been recruited from over 50 sites
across the U.S. and Canada. The initial goal of ADNI was to recruit 800 subjects
but ADNI has been followed by ADNI-GO and ADNI-2.  To date these three protocols
have recruited over 1500 adults, ages 55 to 90, to participate in the research,
consisting of cognitively normal (CN) older individuals, people with early or
late MCI, and people with early AD. The follow up duration of each group is
specified in the protocols for ADNI-1, ADNI-2 and ADNI-GO. Subjects originally
recruited for ADNI-1 and ADNI-GO had the option to be followed in ADNI-2. For
up-to-date information, see www.adni-info.org.

69 1.5T images were arbitrarily selected from the baseline scans in the {\em
\adnidataset{}} standardized dataset. 23 subjects were chosen from each disease
category: cognitively normal (CN), mild cognitive impairment (MCI) and
Alzheimer's disease (AD). Demographics for this subset are shown in Table
\ref{tab:ADNI1-xvalidation-demographics}.  Semi-automated segmentations of the
left and right whole hippocampi are made available with a subset of ADNI images
\citep{Hsu2002}. These labels have been generated using the SNT tool from
Medtronic Surgical Navigation Technologies, Louisville, CO (see Supplementary
Materials for detailed discussion of the segmentation process used). Throughout
this paper, we use these segmentations as the \gs{} for comparison. 

Clinical, demographic and pre-processed T1-weighted MRI were downloaded by the
authors from the ADNI database (adni.loni.ucla.edu) between March 2012 and
August 2012. The image dataset used was the "\adnidataset{}" standardized dataset
available from ADNI \footnote{
\url{http://adni.loni.ucla.edu/methods/mri-analysis/adni-standardized-data/}}
\citep{Wyman2012}. This image collection contains uniformly pre-processed images
which have been designated to be the "best" after quality control.  All images
were acquired using 1.5T scanners (General Electric Healthcare, Philips Medical
Systems or Siemens Medical Solutions) at multiple sites using the protocol
described in \citep{Jack2008}.  Representative 1.5T imaging parameters were TR =
2400ms, TI = 1000ms, TE = 3.5ms, flip angle = $8^{\circ}$, field of view = 240 x
240mm, a $192 \times 192 \times 166$ matrix ($x$, $y$, and $z$ directions)
yielding a voxel dimensions of $1.25mm \times 1.25mm \times 1.2mm$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% ADNI1 X-Validation Dataset Demographics Table
%
<<ADNI-Xval-demographics, echo=F, results="asis",cache=FALSE>>=
jens_RIDs = read.csv('data/jens_RID.csv')

adni_69_RIDs = c(295,413,619,685,729,782,938,954,1018,1155,907,981,222,324,448,
                 546,553,572,602,610,814,1341,675,681,731,1130,41,68,70,101,
                 249,293,316,414,698,1206,1222,1339,751,1030,3,5,10,16,22,53,
                 168,183,241,1205,328,1095,991,213,159,337,343,642,753,1109,
                 1217,29,56,1188,1293,149,382,431,1202)

tab <- summary(DX.bl ~ AGE + PTGENDER + PTEDUCAT + CDRSB + ADAS13 +
               MMSE, data = adnimerge, subset = VISCODE == 'bl' & RID %in%
               jens_RIDs$RID, method = "reverse", test=FALSE, overall=TRUE)
caption = 
  "\\textbf{ADNI-1 cross-validation subset demographics.} 
  CN     - Cognitively Normal. 
  LMCI   - Late-onset Mild Cognitive Impairment. 
  AD     - Alzheimer's Disease.  
  Hisp   - Hispanic. 
  CDR-SB - Clinical Dementia Rating-Sum of Boxes.  
  ADAS   - Alzheimer's Disease Assessment Scale.  
  MMSE   - Mini-Mental State Examination."
latex(tab, file="", size="scriptsize",landscape=FALSE, ctable=FALSE,
      caption=caption, caption.loc = c("top"),
      label="tab:ADNI1-xvalidation-demographics")
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\paragraph{Experiment details} 

Monte Carlo Cross-Validation (MCCV), also known as repeated random sub-sampling
cross-validation, consists of repeated rounds of validation conducted on a fixed
dataset \citep{Shao1993}. In each round, the dataset is randomly partitioned into
a training set and a validation set. The method to be validated is then given
the training data, and its output is compared with the validation set.

In this experiment, our dataset consists of 69 1.5T images and corresponding \gs{}
segmentations. In each validation round, the dataset is partitioned into a
training set consisting of images and \gs{} segmentations used as an atlas
library, and a validation set consisting of the remaining images segmented by
both \mb{} and multi-atlas. The computed segmentations were compared to the \gs{}
segmentations (see below). 

A total of ten validation rounds were performed on each subject in the dataset,
over each combination of parameter settings. The parameter settings
explored are: atlas library size (1-9), template library size (1-20),
registration method (\ants{} or \animal{}, described below), and label fusion method (majority vote,
cross-correlation weighted majority vote, and normalized mutual information
weighted majority vote, described below).  A total of $10 \times 69 \times 9
\times 20 \times 2 \times 3 = \num{7452000}$ validation rounds were conducted,
resulting in a total of $\num{1490400}$ segmentations analysed. 

Before registration, all images underwent preprocessing with the N3 algorithm
\citep{Sled1998} to minimize intensity nonuniformity. In this experiment we
compared two non-linear image registration methods:

\subparagraph{Automatic Normalization and Image Matching and Anatomical
Labeling (\animal{})}

The \animal{} algorithm carries out image registration in two phases. In the
first, a 12-parameter linear transformation (3 translations, rotations, scales,
shears) is estimated between images using an algorithm that maximizes the
correlation between blurred MR intensities and gradient magnitude over the whole
brain \citep{Collins}. In the second phase, nonlinear registration is completed
using the \animal{} algorithm \citep{Collins1995}: an iterative procedure that
estimates a 3D deformation field between two MR images. At first, large
deformations are estimated using a blurred version of the input data. These larger
deformations are then input to subsequent steps where the fit is refined by
estimating smaller deformations on data blurred with a Gaussian kernel with a
smaller full width at half maximum (FWHM). The final transformation is a set of
local translations defined on a bed of equally spaced nodes that were estimated
through the optimization of the correlation coefficient.  For the purposes of
this work we used the regularization parameters optimized in
\citet{Robbins2004}, displayed in Table \ref{tab:ANIMAL-params}. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ANIMAL parameters                    
%                                     
\begin{table*}[!tbp]
\scriptsize
\caption{\textbf{\animal{} registration parameters.} \label{tab:ANIMAL-params}}
\begin{center}
\begin{tabular}{l | c c c}
\hline 
Parameters        & Stage 1 & Stage 2 & Stage 3  \tabularnewline
\hline 
Model Blur (FWHM) &   8     &    8    &   4      \tabularnewline
Input Blur (FWHM) &   8     &    8    &   4      \tabularnewline
Iterations        &   30    &    30   &   10     \tabularnewline
Step              &   8x8x8 &  4x4x4  &   2x2x2  \tabularnewline
Sub-Lattice       &   6     &    6    &   6      \tabularnewline
Lattice Diameter  &24x24x24 &12x12x12 & 6x6x6    \tabularnewline
\hline
\end{tabular}
\end{center}
\end{table*}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subparagraph{Automatic Normalization Tools (\ants{})}

\ants{} is a diffeomorphic registration algorithm which provides great flexibility
over the choice of transformation model, objective function, and the consistency
of the final transformation \citep{Avants2008}. The transformation is estimated in a
hierarchical fashion where the MRI data is subsampled, allowing large
deformations to be estimated and successively refined at later hierarchical
stages (where the data is subsampled to a finer grid). The deformation field and
the objective function are regularized with a Gaussian kernel at each level of
the hierarchy. The \ants{} algorithm is freely available
\url{http://www.picsl.upenn.edu/ANTS/}. We used an implementation of the \ants{}
algorithm compatible with the MINC data format, mincANTS
\url{https://github.com/vfonov/mincANTS}.

We used the following command line when running \ants{}:
{\small
\begin{verbatim}
  mincANTS 3 -m PR[target_file.mnc,source_file.mnc,1,4] 
   --number-of-affine-iterations 10000x10000x10000x10000x10000 
   --affine-gradient-descent-option 0.5x0.95x1.e-4x1.e-4
   --use-Histogram-Matching --MI-option 32x16000
   -r Gauss[3,0] -t SyN[0.5] -i 100x100x100x20
   -o transformation.xfm
 \end{verbatim}
}
These settings were adapted from the "reasonable starting point" given in the
\ants{} manual 
\footnote{\url{https://sourceforge.net/projects/advants/files/Documentation/}}.

\paragraph{Label fusion methods}
Label fusion is a term given to the process of combining the information from
several candidate labels for an image into a single labelling.  In this
experiment we explore three fusion methods: 
\begin{description}
  \item[Voxel-wise Majority Vote]
  Labels are propagated from all template library images to a target.  Each
  output voxel is given the most frequent label at that voxel location amongst
  all candidate labels.

  \item[Cross-correlation Weighted Majority Vote]
  An optimal combination of targets from the template library has previously been
  shown to improve segmentation accuracy \citep{Aljabar2009,Collins2010}.  In this
  method, each template library image is ranked in similarity to each unlabelled 
  image by the normalized cross-correlation (CC) of image intensities after linear
  registration, over a region of interest (ROI) generously encompassing the 
  hippocampus.  Only the top ranked template library image labels are used in a
  voxel-wise majority vote. The ROI is heuristically defined as the extent of all
  atlas labels after linear registration to the template, dilated by three voxels
  \citep{MallarChakravarty2012}.  The number of top ranked template library image labels
  is a configurable parameter and displayed as the size of the template library
  in the rest of the paper. 

  The {\tt xcorr\_vol} utility from the \animal{} toolkit is used to calculate the
  cross-correlation similarity measure.  
 
  \item[Normalised Mutual Information Weighted Majority Vote]
  This method is similar to cross-correlation weighted voting except that image
  similarity is calculated by the normalised mutual information score over the
  region of interest\citep{Studholme2001}.  The {\tt itk\_similarity} utility
  from the EZMinc toolkit\footnote{\url{https://github.com/vfonov/EZminc}} is
  used to calculate the normalised mutual information measure between two images.
\end{description}

\paragraph{Evaluation method}  
The Dice similarity coefficient (DSC), also known as Dice's Kappa, assesses the
agreement between two segmentations. It is one of the most widely used measures
of segmentation accuracy, and we use it as the basis of comparison in this
experiment.
%Additionally, we report the Jaccard index, another commonly used similarity
%measure:

 \[\text{Dice's coefficient (DSC)} = \frac{2|A \cap B|}{|A| + |B|}\]

% \[\text{Jaccard (J)} = \frac{|A \cap B|}{|A \cup B|} = \frac{DSC}{(2-DSC)}\]

where $A$ and $B$ are the regions being compared, and the cardinality is the
volume measured in voxels. 

The automatically produces labels are compared to the \gs{} SNT labels provided by
ADNI. The segmentation accuracy reported for a parameter setting is the average
over ten validation rounds. 

In order to investigate the performance of \mb{} in a real world setting in which 
only one size of atlas and template libraries are used, we explore the
variability in label agreement at fixed parameter settings under varying  
atlas and template library compositions. This is achieved by first computing the
standard deviation and variance of DSC scores in each block of ten validation
rounds per subject. The distribution of these statistics across all subjects is
then compared between \mb{} and multi-atlas using a Student's t-test. A
significant difference between distributions is taken to show either a larger or
smaller level of variability between methods. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                                                                     %%%%%
%%%%%        Experiment 2: Hippocampal Subfield Cross-Validation          %%%%%
%%%%%                                                                     %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Experiment 2: Hippocampal Subfield Cross-Validation}
In this experiment, the accuracy of the \mb{} algorithm on hippocampal subregion
segmentation is tested using a leave-one-out cross-validation (LOOCV) design on
two image sets. The optimal parameter settings for \mb{} found in Experiment 1 are
used in this experiment.

\paragraph{Winterburn Atlases dataset} 
The Winterburn atlases \citep{Winterburn2013} are digital hippocampal
segmentations of five in-vivo $300\mu$ isotropic T1-weighted MR images. The
segmentations include subfield segmentations for the cornu ammonis (CA) 1; CA2
and CA3; CA4 and dentate gyrus; subiculum; and strata radiatum (SR), strata
lacunosum (SL), and strata moleculare (SM). Subjects in the Winterburn atlases
range in age from 29-57 years (mean age of 37), and include two males and three
females.  

In addition to the high-resolution scans distributed as part of the Winterburn
atlases, we also obtained separate 3T T1 BRAVO acquisitions (0.9mm-isotropic
voxels) of four of the five Winterburn atlas subjects.  Images were acquired on
a 3T GE Discovery MR 750 system (General Electric, Milwaukee, WI) using an
8-channel head coil with the enhanced fast gradient recalled echo 3-dimensional
acquisition protocol, EFGRE-BRAVO, with the following parameters: $TE/TR/TI =
3.0ms/6.7ms/650ms$, flip angle $=8^\circ$, $FOV=15.8cm$, slice
thickness$=0.9mm$, 176 in-plane steps for an approximate isotropic resolution
of 0.9mm dimension voxels.

\paragraph{Experiment details} 
Leave-one-out cross-validation (LOOCV) is an approach in which the method to be
validated is given all but one item in a dataset as training data (in our case,
atlas library images and labels), and the output accuracy is measured on the
left-out item. This is done, in turn, for each item in the dataset. 

\begin{figure}
  \begin{centering}
    \includegraphics[width=\textwidth]{figure/WinterburnSubfieldLOOCVSchematic}
  \end{centering}
  \caption{A schematic illustration of the experimental set up of the
  leave-one-out cross-validation (LOOCV) subfield experiment.}
  \label{fig:LOOCV-schematic}
\end{figure}

In part 2a of this experiment, we have modified the LOOCV experimental
design in order to compare \mb{} segmentation accuracy with the accuracy of image
resampling error. The five $0.3mm$-isotropic voxel Winterburn atlas images and
labels are used as the atlas library, and LOOCV is conducted using the five Winterburn
atlas images subsampled (using trilinear interpolation) to
0.9mm-isotropic voxel resolution (referred to as the {\em Subsampled} dataset)
as input subjects. Subsampling the target images allows us to assess \mb{} in a
typical segmentation scenario (high-resolution atlases and lower-resolution
subjects).  The template library is composed of all five subject images, plus
an additional set of 16 of healthy subjects 3T T1 images acquired separately
(Table \ref{tab:WAval-healthy-demographics}).  Images were acquired on a 3T GE
Discovery MR 750 system (General Electric, Milwaukee, WI) using an 8-channel
head coil with the enhanced fast gradient recalled echo 3-dimensional
acquisition protocol, EFGRE-BRAVO, with the following parameters: $TE/TR/TI =
3.0ms/6.7ms/650ms$, flip angle=$8^\circ$ , $FOV = 15.3cm$, slice
thickness$=0.9mm$, 170 in-plane steps for an approximate isotropic resolution
of 0.9mm dimension voxels.

The optimal size of template library, registration method, and label fusion
method found in Experiment 1 are used.  As with traditional LOOCV, each subject
image is segmented by \mb{} with that subject's image excluded from the atlas
library.  In part 2b of this experiment, we carry out a similar validation in
which the subject images are separately acquired T1 BRAVO images of four of the
five Winterburn atlas subjects (referred to as the {\em T1 BRAVO} dataset).
Figure \ref{fig:LOOCV-schematic} illustrates the experimental set up of both
parts of this experiment. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Subfield Validation Template library demographics (healthy controls)
%                                     
<<WAval-healthy-demographics, echo=F, results="asis",cache=FALSE>>=
master = read.csv('data/DT_study.csv')
tab <- summary( Diagnosis ~ Age + Sex + Education + Handedness, data = master,
    method="reverse", na.rm = TRUE, test=FALSE)
caption = 
  "\\textbf{Demographics for the hippocampal subfield cross-validation healthy
control subject sample.} Education is shown in years."
latex(tab, file="", size="scriptsize",landscape=FALSE, ctable=FALSE,
      caption=caption, caption.loc = c("top"),
      title="tab:WAval-healthy-demographics")
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\paragraph{Evaluation method}  
To assess the \mb{} LOOCV segmentations we compute the relative percent error in 
hippocampal volume with respect to the full resolution Winterburn atlas 
segmentations. In addition, by computing the relative error in volume of the
Winterburn atlas labels resampled (with nearest-neighbour interpolation) to
0.9mm-isotropic voxels, we obtain a baseline error against which to assess \mb{}
segmentations.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                                                                     %%%%%
%%%%%         Experiment 3: Application of \mb{} to the segmentation        %%%%%
%%%%%                       of schizophrenia patients                     %%%%%
%%%%%                                                                     %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Experiment 3: Application to the segmentation of first episode
schizophrenia patients}
 
To validate that the \mb{} works effectively in the context of other neurological
disorders, in this experiment we use the Winterburn atlases to derive 
whole hippocampal segmentations of a dataset of patients with Schizophrenia. The
resulting segmentations are assessed for quality by comparison with expert
manual segmentations.

\paragraph{\FEPdataset{} dataset}
All patients were recruited and treated through the Prevention and Early
Intervention Program for Psychoses (PEPP-Montreal), a specialized early
intervention service at the Douglas Mental Health University Institute in
Montreal, Canada. People aged 14 to 35 years from the local catchment area
suffering from either affective or non-affective psychosis who had not taken
antipsychotic medication for more than one month with an IQ above 70 were
consecutively admitted as either in- or out-patients. Of those treated at PEPP,
only patients aged 18 to 30 years with no previous history of neurological
disease or head trauma causing loss of consciousness were eligible for the
neuroimaging study; only those suffering from schizophrenia spectrum disorders
were considered for this analysis.  For complete program details see
\citet{Malla2003}. 

Scanning of 81 subjects was carried out at the Montreal Neurological Institute
on a 1.5-T Siemens whole body MRI system.  Structural T1 volumes were acquired
for each participant using a three-dimensional (3D) gradient echo pulse sequence
with sagittal volume excitation (repetition time=22ms, echo time=9.2ms, flip
angle=$30^{\circ}$, 180 1mm contiguous sagittal slices). The rectangular
field-of-view for the images was 256mm (SI)$\times$204mm (AP).  Subject
demographics are shown in Table \ref{tab:SZFEP-Demographics}. 

Manual segmentation of each subject whole hippocampus is produced following a
validated segmentation protocol \citep{Pruessner2000}. 

\paragraph{Experiment details} 
\mb{} is configured with an atlas library composed of the Winterburn T1 atlases
(see Experiment 2) ignoring subfield delineations.  All images from the
\FEPdataset{} dataset are segmented by \mb{}.  The optimal size of template library,
registration method, and label fusion method found in Experiment 1 are used. 

\paragraph{Evaluation method}
The Pruessner and Winterburn hippocampal segmentation protocols differ slightly in
the neuroanatomical features that are delineated \citep{Winterburn2013}. This
difference poses a problem for evaluation by measuring overlap.  That is, since
different protocols will necessarily produce segmentations that do not perfectly
overlap, the degree of overlap cannot be solely used to compare segmentation
methods using different protocols. In place of an overlap metric, we can assess
the degree of (Pearson) correlation in average bilateral hippocampal volume of the
subjects produced by each method. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% First Episode SZ Demographics Table
%
<<FEP-SZ-demographics, echo=F, results="asis",cache=FALSE>>=
caption = 
  "\\textbf{Schizophrenia First Episode Patient Demographics.}
  ambi - ambidextrous. 
  SES  - Socioeconomic Status score. 
  FSIQ - Full Scale IQ.
"
fep_sz_demographics = read.csv("data/SZ_demographics.csv", na.strings=c("","."))
fep_sz_demographics = subset(fep_sz_demographics, Anon <= 81)
tab <- summary(DX ~ Age + Gender + Handedness + Education + SES + FSIQ,
               data=fep_sz_demographics, method = "reverse", test = FALSE)
latex(tab, file="", size="scriptsize",landscape=FALSE, ctable=FALSE,
      caption=caption, caption.loc = c("top"),
      title="tab:SZFEP-Demographics")
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                                                                     %%%%%
%%%%%         EXPERIMENT 4: Application of \mb{} to the segmentation      %%%%%
%%%%%                       of ADNI subjects                              %%%%%
%%%%%                                                                     %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Experiment 4: Application to the segmentation of Alzheimer's
disease patients}

To validate \mb{} segmentation quality with respect to other established automated
hippocampal segmentation methods, \mb{} was applied to large dataset from the ADNI
project and the resulting segmentations were compared to those determined by
\freesurfer{}, \fsl{}, \maper{} and the SNT \gs{} segmentation.

\paragraph{ADNI1 dataset revisited} 
The {\em \adnidataset{}} standardized dataset contains $1919$ images in total.
SNT, \maper, \freesurfer{} hippocampal volumes for a subset of images were
provided by ADNI, along with quality control data for each \freesurfer{}
segmentation (guidelines described in \citep{Hartig2010}).  Clinical and
demographic data for the entire \adnidataset{} dataset are shown in Table
\ref{tab:ADNI1-Dataset-Demographics}.

\paragraph{Experiment details} 
\mb{} was configured with an atlas library composed of the five Winterburn T1
atlases (described in Experiment 2), and size of template library,
registration method, and label fusion method were determined by the optimal
settings found in Experiment 1.  The \fsl{} segmentation method was used via
the \verb+run_first_all+ script according to the FIRST user guide
\footnote{http://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FIRST/UserGuide}.  All images
in the \adnidataset{} dataset were segmented by both methods. 

One author (MP) performed visual quality inspection for \mb{} and \freesurfer{} 
segmentations using similar quality control guidelines (if either hippocampus
was under or over segmented by $10mm$ or greater in three or more slices then
the segmentation did not pass).  Only images meeting the conditions of having
segmentations from all methods (SNT, \maper{}, \freesurfer{}, \fsl{}, and \mb{}) and also
passing quality control inspection were included in the analysis.  

\paragraph{Evaluation method}
As in Experiment 3, the SNT \gs{} and Winterburn hippocampal segmentation
protocols differ in the neuroanatomical features delineated, and so we 
assessed \mb{} by the degree of (Pearson) correlation of average hippocampal volume
across subjects. We also computed the correlation in hippocampal volume between
existing, established automated segmentation methods -- \fsl{}, \freesurfer{}, and
\maper{}, and SNT semi-automated segmentations. Additionally, we evaluate the
volume-related fixed and proportional biases in all segmentation methods using
Bland-Altman plots \citep{Bland1986}.  

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ADNI1-COMPLETE
% Prepares the data in the form needed for plotting.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
<<ADNI-volumes-prep,echo=F,cache=T>>=
means.complete   <- read.csv('data/cache/ADNI1:qc.csv')
package_totals   <- read.csv('data/cache/ADNI1:package_totals.csv')
@


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                                             
% ADNI1 Complete 1Yr Dataset Demographics Table 
%                                                                             
<<ADNI1-Dataset-Demographics, echo=F, results="asis",cache=FALSE>>=
# RID < 2000 ensures only ADNI1 patients
yr1 = read.csv("data/ADNI_baseline_volumes/ADNI1_Complete_1Yr_1.5T_11_15_2012.csv")
yr1$VISCODE <- factor(yr1$Visit, levels = c(1,2,3,4), labels=c("bl","m03","m06","m12"))
yr1 = subset(yr1, !grepl("Scaled_2", Description))
yr1 = yr1[,c("RID","VISCODE")]
yr1 = 
adnimerge.yr1 = merge(adnimerge, yr1) 
tab <- summary(DX.bl ~ AGE + PTGENDER + PTEDUCAT + CDRSB + ADAS13 +
               MMSE, data = adnimerge.yr1, 
               #subset = RID %in% yr1$RID & VISCODE %in% c('bl','m06','m12'),   
               method = "reverse", test=FALSE, overall=TRUE)
caption = 
  "\\textbf{ADNI1 1.5T Complete 1Yr dataset demographics.} 
  CN     - Cognitively Normal. 
  LMCI   - Late-onset Mild Cognitive Impairment. 
  AD     - Alzheimer's Disease.  
  Hisp   - Hispanic. 
  CDR-SB - Clinical Dementia Rating-Sum of Boxes.  
  ADAS   - Alzheimer's Disease Assessment Scale.  
  MMSE   - Mini-Mental State Examination."
latex(tab, file="", size="scriptsize",landscape=FALSE, ctable=FALSE,
    caption=caption, caption.loc = c("top"),
    title="tab:ADNI1-Dataset-Demographics",
    label="tab:ADNI1-Dataset-Demographics")
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                               RESULTS                                        %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Results}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                                                                     %%%%%
%%%%%     RESULTS: Experiment 1: Whole Hippocampus Cross-Validation       %%%%%
%%%%%                                                                     %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Experiment 1 Results: Whole Hippocampus Cross-Validation}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ADNI1-XVAL: prep
% Prepares the data in a the form needed for plotting.
<<ADNI1-xval-prep,dependson='ADNI1-xval-load',include=FALSE,cache=TRUE>>=
jens_xval_data  <- read.csv(gzfile('data/cache/ADNI-JENS-XVAL:all_data.csv.gz'))
jens_xval_mean  <- read.csv(gzfile('data/cache/ADNI-JENS-XVAL:all_data_mean.csv.gz'))

mb.best.kappa = mean(subset(jens_xval_mean, reg_method   == "ANTS" & 
                                  method.mb    == "Majority Vote" &
                                  templates.mb == 19 & 
                                  atlases      == 9)$k.mb)
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


In this experiment we conducted 10 rounds of \mb{} and multi-atlas segmentation of
of 69 subjects using atlas and template library sizes varying from 1-9 and 1-20
images respectively, two registration algorithms (\ants{} or \animal{}), and three
label fusion techniques (unweighted, cross-correlation, and normalised mutual
information weighted majority vote).  Hippocampal \mb{}-based segmentations using
both \animal{} and \ants{} registration algorithms demonstrate good overlap with SNT
\gs{} segmentations (maximum mean DSC of \Sexpr{round(mb.best.kappa, digits=2)}
when using 9 atlases, 19 templates, ANTS registration, and majority vote label
fusion); Figure \ref{fig:ADNI1-xval-k-mean}).  Qualitatively, both \animal{} and
\ants{}-based segmentations demonstrate trend overlap accuracy that increases with
the size of atlas library and template library. Improvement in accuracy plateaus
with template libraries larger than ten images. 

The use of \mb{} with \ants{} registration shows a pronounced increase
in segmentation accuracy over \mb{} with \animal{} registration, across all
other variable settings we tested. Additionally, by itself, using a weighted
voting strategy did not significantly improve segmentation accuracy, contrary to
the findings of \citet{Aljabar2009} in basic multi-atlas segmentation. Given
these findings, in the remainder of this section only results using the \ants{}
registration algorithm and majority vote fusion will be shown.

With an increasing number of templates, \mb{} shows improvement over
multi-atlas-based segmentation in overlap accuracy when using the same number of
atlases and voting method (Figure \ref{fig:ADNI1-xval-k-diff}). The two methods
converge in accuracy when using seven atlases.  Peak improvement in \mb{} accuracy
(~0.02 DSC) is found when one atlas is used with a template library of 19
images.

In addition to an improvement in accuracy over multi-atlas-based segmentation,
\mb{} also shows a decrease in the variability of segmentation accuracy 
(Figure \ref{ADNI1-xval-variability}).  The size of template library 
necessary to reach a decrease ($p < 0.05$) in variance and standard deviation
grows with the size of atlas library used.  A template library of 19 images is
sufficient to show significant decrease in variance and standard deviation for
3-7 atlases. 

We have omitted results obtained when using an even number of atlases or
templates since with this configuration we found significantly decreased
performance. We believe this is as a result of an inherent bias in the majority
vote fusion method used (see Discussion).  


% \begin{figure}
% <<ADN1-library-composition, cache=TRUE, dependson='ADNI1-Xval-prep'>>=
% # These composition datasheets describe the subjects and subject DX in the 
% # template and atlas libraries for each voting run
% atlas_comp = read.csv('data/a2a_ants/atlas_library_composition.csv')
% templ_comp = read.csv('data/a2a_ants/template_library_composition.csv')
% a2a.best = subset(all_data, atlases == 9 &
%                     templates.mb == 19 &
%                     reg_method=='ANTS' &
%                     method.mb =='Majority Vote')
% 
% cumulative_dist = 
%   ggplot(a2a.best, aes(x=k.mb)) + stat_ecdf() + scale_y_continuous(breaks=seq(0,1,0.1))
% 
% a2a.best = subset(a2a.best, k.mb > 0.75) # drop the guys that suck
% 
% a2a.best = merge(a2a.best, atlas_comp, by=c("timestamp","atlases"))
% a2a.best = merge(a2a.best, templ_comp, by.x=c("timestamp","templates.mb"), by.y=c("timestamp","templates"))
% a2a.best$templates_AD_percent = (a2a.best$templates_AD / 19) * 100
% a2a.best$templates_MCI_percent = (a2a.best$templates_MCI / 19) * 100
% a2a.best.melted = melt(a2a.best, measure.vars=c("templates_AD_percent", "templates_MCI_percent"))
% 
% k_by_composition = 
%   ggplot(a2a.best.melted, aes(x=value, y=k.mb, colour=DX)) + facet_grid(variable ~ DX) + 
%   geom_boxplot(aes(group=as.factor(value), colour=DX)) +  geom_smooth(method="lm") 
% 
% snt.unilateral.vols = read.csv('data/a2a_snt_volumes.csv')
% a2a.best = merge(a2a.best, snt.unilateral.vols)
% 
% # bland-altman plots
% bland_mb_overall = with(a2a.best, bland_altman_plot(volume.snt, volume.mb, DX) + 
%   geom_smooth(method="lm") + 
%   scale_y_continuous(breaks=seq(-500, 500, 50)))
% 
% bland_ma_overall = with(a2a.best, bland_altman_plot(volume.snt, volume.ma, DX) + 
%   geom_smooth(method="lm") + 
%   scale_y_continuous(breaks=seq(-500, 500, 50)))
% 
% # just the trials with a high percentage of MCI in the template library
% a2a.best.highMCI = subset(a2a.best, templates_MCI_percent > 50)
% 
% bland_mb_highMCI = with(a2a.best.highMCI, bland_altman_plot(volume.snt, volume.ma, DX) + 
%   geom_smooth(method="lm") + 
%   scale_y_continuous(breaks=seq(-500, 500, 50)))
% 
%   
% @
% \end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ADNI1-XVAL: mean Kappa plot by atlases, templates, reg and voting method. 
\begin{figure}
<<fig:ADNI1-xval-k-mean, cache=TRUE, dependson='ADNI1-xval-prep', fig.width=7, fig.height=7>>=
stderr <- function(x) sqrt(var(x)/length(x))
ggplot(subset(jens_xval_mean, (templates.mb*atlases) %% 2 == 1),
       aes(x=templates.mb,y=k.mb, colour=as.factor(atlases))) + #as.factor((atlases*templates.mb) %% 2 ))) + 
  facet_grid(reg_method~method.mb) + 
  stat_summary(fun.y=mean,geom='line',
               aes(y=k.mb, weight=1, group=as.factor(atlases))) + 
  stat_summary(fun.y=mean,
               fun.ymin=function (x) mean(x) - stderr(x),
               fun.ymax=function (x) mean(x) + stderr(x), 
               geom='errorbar',
               aes(y=k.mb, weight=1, group=as.factor(atlases)), width=0.5) + 
  #stat_smooth(method='lm', formula=y~log(x)) + 
  scale_y_continuous(breaks=seq(0,1,0.05)) + 
  scale_colour_hue(name="Number of Atlases") +
  xlab( "Number of Templates" ) + 
  ylab( "Mean DSC" ) + 
  theme(legend.direction = "horizontal", legend.position = "bottom", 
        axis.text = element_text(size = 8))
@
  \caption{Mean Dice's Similarity Coefficient of \mb{} segmentations relative to
  SNT \gs{} segmentations for 69 ADNI subjects vs. atlas and template library
  size, registration algorithm, and label fusion method. Error bars indicate
  standard error.
  \label{fig:ADNI1-xval-k-mean}}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ADNI1-XVAL: "increase" in mean kappa over multi-atlas
\begin{figure}
<<fig:ADN11-xval-k-diff,cache=TRUE,dependson='ADNI1-xval-prep'>>=
ggplot(subset(jens_xval_mean, reg_method=="ANTS" & 
                method.mb=="Majority Vote" & (templates.mb*atlases) %% 2 == 1), 
       aes(x=templates.mb, y=k_diff, colour=as.factor(atlases))) + 
  #facet_grid(reg_method~method.y) + 
  stat_summary(fun.data=mean_cl_boot,geom='errorbar',
               aes(y=k_diff,colour=as.factor(atlases), width=0.2)) +
  stat_summary(fun.y=mean, geom="point", 
               aes(y=k_diff,colour=as.factor(atlases))) + 
  stat_summary(fun.y=mean, geom="line", 
               aes(y=k_diff,colour=as.factor(atlases))) + 
  #stat_smooth(method=lm, formula=y~log(x)) + 
  geom_hline(aes(alpha=0.5, yintercept=0), linetype='dashed') + 
  scale_x_continuous(breaks=seq(1,20,2)) + scale_y_continuous(breaks=seq(-1,1,by=0.01)) + 
  scale_colour_hue(name="Number of Atlases") +
  scale_alpha_continuous(guide = "none") + 
  scale_linetype_discrete(guide = "none") + 
  xlab( "Number of Templates" ) + 
  ylab( "Difference in mean DSC" ) +
  theme(legend.direction = "horizontal", legend.position = "bottom")
@
  \caption{Difference in mean Dice's Similarity Coefficient between \mb{} and
  multi-atlas segmentations relative to \gs{} (SNT) segmentations vs. atlas and
  template library size when using the \ants{} registration method, and
  majority-vote label fusion. Error bars indicate standard error.
  \label{fig:ADNI1-xval-k-diff}}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ADNI1-XVAL: show variability of MAGeT over parameters
\begin{figure}
<<ADN1-Xval-variability, cache=TRUE, dependson='ADNI1-Xval-prep'>>=
ants = subset(jens_xval_data, 
                     reg_method=="ANTS" & 
                     method.mb=="Majority Vote" &
                    templates.mb %in% seq(1,20,2))

ants.stats = ddply(ants, c("subject", "label", "atlases","templates.mb"), 
                   function (df) {
                     data.frame(
                       MA.sd  =  sd(df$k.ma),
                       MB.sd  =  sd(df$k.mb),
                       MA.var = var(df$k.ma),
                       MB.var = var(df$k.mb)
                       )
                   })

stats.tests = ddply(ants.stats, c("atlases","templates.mb"), function (df) {
  t.var = t.test(df$MA.var, df$MB.var)
  t.sd  = t.test(df$MA.sd , df$MB.sd)
  diff_mean_var = mean(df$MA.var - df$MB.var)
  diff_mean_sd  = mean(df$MA.sd -  df$MB.sd)
  
  # test statistic is positive if MA mean is larger than MB
  # i.e. that MA has a greater mean of variances/SDs
  # i.e. that MB has a smaller mean, and so is doing "better"
  data.frame(
    stat      = c("Variance", "Standard Deviation"),
    statistic = c(t.var$statistic, t.sd$statistic),
    p.value   = c(t.var$p.value, t.sd$p.value),
    direction = c(diff_mean_var, diff_mean_sd)
  )
})

ggplot(subset(stats.tests, direction > 0 & stat == "Variance"), 
  aes(x=templates.mb, y=p.value, colour=as.factor(atlases))) + 
  #facet_grid( . ~ stat) + 
  geom_line(size=1) +
  geom_point(size=3) + 
  geom_hline(aes(yintercept=0.05, alpha=0.5), linetype='dashed') + 
  geom_hline(aes(yintercept=0.01, alpha=0.5), linetype='dashed') + 
  scale_x_continuous(breaks=seq(1,20,by=2)) + 
  scale_y_log10(limits=c(0.001,1), breaks=c(0.01,0.05,0.1,1.0)) + 
  xlab( "Number of Templates" ) + 
  ylab( "Difference of variance during validation (p-value)") +
  scale_colour_hue(name="Atlases") +
  scale_alpha_continuous(guide='none') + 
  scale_linetype_discrete(guide='none') + 
  scale_size_continuous(guide='none') + 
  theme(legend.direction = "horizontal", legend.position = "bottom")
@
  \caption{{\bf Difference in variability of \mb{} vs. multi-atlas segmentation 
  accuracy.}
  Variance of segmentation accuracy between \mb{} and multi-atlas segmentation is
  computed for each subject across all ten rounds of validation. Shown on the
  y-axis (scaled logarithmically) is the  p-value resulting from a t-test
  comparing the distribution of variances at each parameter setting
  (atlas/template library size). Only points where \mb{} mean variability is lower
  than multi-atlas are shown. Dashed lines indicate a p-value of 0.05 and 0.01.}
  \label{ADNI1-xval-variability}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\FloatBarrier

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                                                                     %%%%%
%%%%%    RESULTS: Experiment 2: Hippocampal Subfield Cross-Validation     %%%%%
%%%%%                                                                     %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Experiment 2 Results: Winterburn Atlases Cross-Validation}
This experiment explores \mb{} segmentation of hippocampal subfields. To achieve
this, a leave-one-out validation was conducted in which lower-resolution images
($0.9mm^3$ voxels) of each Winterburn atlas subject were segmented using the
remaining high-resolution Winterburn atlas subjects' images. 

In general, across hippocampal subregions the percent error in volume of \mb{}
segmentations (relative to the full-resolution Winterburn atlas segmentation)
compares favourably to the error resulting from image resampling (Figure
\ref{fig:WAval-vol-boxplot}). In particular, the CA1, CA4/DG, and SR/SL/SM
subregions all show a percent error in volume that is at or lower than
resampling error. The Subiculum and CA2/CA3 subregions show distinctly larger
percent error in volume than is found through resampling.  

Figure \ref{fig:subfield-montage} shows a qualitative comparison of \mb{} subfield
segmentations for a single subject.  


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Winterburn-XVAL: compare resampling
\begin{figure}[h!]
<<WAval-vol-boxplot,cache=T,fig.width=6,fig.height=4>>=
data = subset(read.csv('data/WAval.csv'))
casted = dcast(melt(data, id.vars=c("file","version")), file + variable ~ version)
casted = rename(casted, c("variable"="region"))

error = ddply(casted, c("file", "region"), function(df) {
  with(df, 
  data.frame(
    resampled = (gold_0.9mm - gold_0.3mm) / gold_0.3mm * 100, 
    mb_bravo  = (mb_bravo   - gold_0.3mm) / gold_0.3mm * 100, 
    mb_0.9mm  = (mb_0.9mm   - gold_0.3mm) / gold_0.3mm * 100))})

levels(error$region) <-list("CA1"="X1", "CA1"="X101", 
                            "Subiculum"="X2","Subiculum"="X102", 
                            "CA4/DG"="X4","CA4/DG"="X104", 
                            "CA2/CA3"="X5","CA2/CA3"="X105", 
                            "SR/SL/SM"="X6","SR/SL/SM"="X106")
melted = melt(error,id.vars=c("file", "region"))
melted = rename(melted, c("variable"="measure", "value"="percenterr"))
levels(melted$measure) <- list("Subsampled"="resampled",
                               "MAGeT on Subsampled" = "mb_0.9mm",
                               "MAGeT on T1 BRAVO"="mb_bravo")

ggplot(melted, aes(y=percenterr,x=region,colour=measure)) +
  geom_hline(aes(yintercept=0), colour="grey", size=1) + 
  geom_boxplot() +
  labs(y="Percent error in volume", x="Subfield") +
  scale_colour_discrete("") + 
  opts(legend.direction = "horizontal", legend.position = "bottom")
@
  \caption{{\bf Average percent error in hemispheric subfield volume.} 
  Percent error is measured against the volumes of the unmodified Winterburn
  atlas subfield segmentations.
  {\bf Subsampled} are volumes of the manual segmentations of the Winterburn
  atlases after resampling to $0.9mm^3$ voxels.  
  {\bf MAGeT on Subsampled} volumes are \mb{} segmentations of the Winterburn atlas
  images after resampling to $0.9mm^3$ voxels.
  {\bf MAGeT on T1 BRAVO} volumes are \mb{} segmentations of T1 BRAVO images
  ($0.9mm^3$ voxels) acquired separately of four of the five Winterburn atlas
  subjects.} 
  \label{fig:WAval-vol-boxplot}
\end{figure}

\begin{sidewaysfigure}
    \begin{centering}
      \includegraphics[width=\linewidth]{figure/winterburn-atlas-montage/figure.pdf}
    \end{centering}
    \caption{Detailed subfield segmentation results for a single subject. In
    the upper left corner is the original high-resolution Winterburn atlas manual
    subfield segmentation; in the upper right corner is the Winterburn atlas
    segmentation resampled from 0.3mm- to 0.9mm-isotropic voxels; in the lower left
    corner is the \mb{} segmentation of the resampled Winterburn atlas images; in the
    lower right corner is the \mb{} segmentation of a separately acquired T1 BRAVO
    image of the same subject. In each segmentation, slices from the left
    hemisphere are shown in Talairach-like ICBM152 space: the first row shows axial
    slices from inferior to superior; the second row shows sagittal slices from
    lateral to medial; the third row shows coronal slices from anterior to
    posterior.  \label{fig:subfield-montage}}
\end{sidewaysfigure}

\FloatBarrier
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                                                                     %%%%%
%%%%%    RESULTS: Experiment 3, Application of \mb{} to the segmentation  %%%%%
%%%%%                       of schizophrenia patients                     %%%%%
%%%%%                                                                     %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Experiment 3 Results: Application to the segmentation of first
episode schizophrenia patients}
 
In this experiment \mb{} is applied to a dataset of images of first episode
schizophrenia patients, using the Winterburn atlases and a template library of
21 subject images selected at random.  Expert manual whole hippocampal
segmentations are used as a gold standard. 

\begin{figure}
<<FEP-volumes,cache=FALSE,dependson="setup",width=5,height=5>>=
SZ_volumes=read.csv("data/SZ_volumes_by_method.csv", sep="\t")
mean_sz_vols = ddply(SZ_volumes, c('Subject', 'Method'), function (df) {
  data.frame(Volume = mean(df$Volume))})
    
casted = dcast(mean_sz_vols, Subject ~ Method, value.var = "Volume")
lm = lm(MAGeT ~ Manual, casted)
ggplot(data=casted, aes(x = Manual, y = MAGeT)) + 
  geom_smooth(method="lm", formula=y~x) + 
  geom_point() + 
  geom_text(aes(x=3500, y=5000, label=lm_eqn(lm),hjust=0,size=1), parse=TRUE, data=data.frame()) +
  xlab(expression("Mean bilateral manual hippocampus volume " (mm^3))) + 
  ylab(expression("Mean bilateral MAGeT hippocampus volume "  (mm^3))) + 
  scale_size_continuous(guide="none") 
@
  \caption{Mean bilateral hippocampus volume as measured by \mb{}  vs. manually
  segmented volumes from the First Episode Patients with Schizophrenia dataset.
  A linear fit line is shown, with shaded region showing standard error. 
  \label{fig:SZ-volumes}}
\end{figure}

<<FEP-t-test,cache=TRUE,dependson="FEP-volumes">>=
  fep.cor.test = cor.test(casted$Manual, casted$MAGeT)
@
\mb{} produces hippocampal volumes that are highly correlated with 
manual segmentation volumes (Pearson $r = \Sexpr{fep.cor.test$estimate}$, 
$t = \Sexpr{fep.cor.test$statistic}$, $p < \Sexpr{max(0.001, fep.cor.test$p.value)}$; 
Figure \ref{fig:SZ-volumes}). 


\FloatBarrier
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                                                                     %%%%%
%%%%%                           RESULTS                                   %%%%%
%%%%%                                                                     %%%%%
%%%%%         EXPERIMENT 4: Application of \mb{} to the segmentation      %%%%%
%%%%%                       of ADNI subjects                              %%%%%
%%%%%                                                                     %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Experiment 4 Results: Application to the segmentation of Alzheimer's
disease patients}

Based on the results from Experiment 1, in this experiment \mb{} was configured
with a template library of 21 randomly chosen subject images (7 from each
disease class) and majority vote label fusion.  The entire \adnidataset{} dataset
was segmented by \mb{}, and the resulting volumes compared with those obtained by
expert semi-automated segmentation (SNT), and three other automated segmentation
techniques: \maper{}, \freesurfer{}, and \fsl{}. Table
\ref{tab:ADNI1-1.5T-Complete-1Yr-Dataset-Method-Totals} shows the total count of
segmentations available, including a count of those which have failed a quality
control inspection.  A total of \Sexpr{length(means.complete$RID)} images are
included in the following analysis, having met quality criteria and having
segmentations from every method. 
 
We found a close relationship in total bilateral hippocampal volume between all
methods and SNT \gs{} volumes (Figure \ref{fig:ADNI-volumes-plot}).  Volumes are
correlated with Pearson $r > 0.78$ for all methods across disease categories.
Within disease categories (Figure \ref{fig:ADNI-volumes-boxplot}), \mb{} is
consistently well correlated to manual volumes (Pearson $r > 0.85$), but appears
to slightly over-estimate the volume of the AD hippocampus. 

To investigate the level of agreement with SNT \gs{} hippocampal
volumes, we constructed Bland-Altman plots for each method (Figure
\ref{fig:ADNI-Bland-Altman}).  As \citet{Bland1986} noted, high correlation
amongst measures of the same quantity does not necessarily imply agreement (as
correlation can be driven by a large range in true values, for instance).  All
methods show an obvious proportional bias: \freesurfer{} and \fsl{} markedly
under-estimate smaller hippocampi and over-estimate large hippocampi, whereas
\maper{} and \mb{} show a reverse, conservative bias (Figure
\ref{fig:ADNI-Bland-Altman}).  Additionally, all methods show a fixed volume
bias, with \freesurfer{} and \fsl{} most dramatically over-estimating hippocampal
volume by $2600 mm^3$ and $2800 mm^3$ on average, respectively, and \maper{} and
\mb{} within $250 mm^3$ on average. 

Figure \ref{fig:ADNI-segmentations} shows a qualitative comparison of \mb{} and 
SNT \gs{} hippocampal segmentations for 10 randomly selected subjects in 
each disease category, and illustrates some of the common errors found during 
visual inspection. Mostly frequently, we found \mb{} improperly includes the vestigial
hippocampal sulcus and, although not anatomically incorrect, \mb{} under-estimates 
the hippocampal body in comparison to the SNT \gs{} segmentation.  

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ADNI1 1yr Complete Dataset Package Totals & Failures
%                        
<<ADNI-seg-package-totals, echo=F, results="asis",cache=FALSE>>=
package_totals$Total <- NULL
latex(package_totals, file="", size="scriptsize",landscape=FALSE, ctable=TRUE,
    caption="\\textbf{Number of segmented images and quality control failures of 
             \\adnidataset{} dataset by method.}", 
    caption.loc = c("top"), rowname=NULL, 
    label="tab:ADNI1-1.5T-Complete-1Yr-Dataset-Method-Totals")
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{figure}[h]
<<ADNI-volumes-boxplot,dependson='ADNI-volumes-prep',cache=T,fig.width=7,fig.height=4>>=
melted = melt(means.complete,measure.vars=c("FS", "FSL", "MAPER","MAGeT"),
              variable.name="Method", value.name="Volume")
correlations = ddply(melted, c("DX","Method"), function (df) {
  data.frame(
    pearson = cor(df$SNT, df$Volume)
  )
})
m2 = melt(means.complete,measure.vars=c("FS", "FSL", "MAPER","MAGeT","SNT"), variable.name="Method")
levels(m2$Method) = c("FS"    = "FreeSurfer", 
                      "FSL"   = "FSL", 
                      "MAPER" = "MAPER", 
                      "MAGeT" = "MAGeT", 
                      "SNT"   = "SNT \\gs{}")
m2$DX = factor(m2$DX, levels(m2$DX)[c(2,3,1)])

qplot(DX,value,data=m2,
      colour=Method,geom="boxplot") + 
      #geom_text(aes(y=-Inf,x=c(.7,.85,1,1.15, 1.7,1.85,2,2.15, 2.7,2.85,3,3.15), vjust=-5, label=round(pearson,2)), 
      #          colour = 'black', size=3, data=correlations) +
      xlab("Diagnosis") + 
      ylab(expression(paste("Hippocampal volume (", mm^3, ")"))) + 
      opts(legend.direction = "horizontal", legend.position = "bottom")
@
  \caption{Subject mean hippocampal volume as measured in the \adnidataset{}
dataset by \freesurfer{}, \fsl{}, \maper{}, \mb{}, and SNT \gs{} vs. disease
category.}
  \label{fig:ADNI-volumes-boxplot}
\end{figure}

\begin{figure}[h]
<<ADNI-volumes-plot,dependson='ADNI-volumes-prep',cache=T,fig.width=6,fig.height=4>>=
melted=melt(means.complete, measure.vars=c("FS", "FSL", "MAPER","MAGeT"), 
            variable.name = "Method", value.name = "volume")

df = means.complete

levels(melted$Method) = c("FS"    = "FreeSurfer", 
                          "FSL"   = "FSL", 
                          "MAPER" = "MAPER", 
                          "MAGeT" = "MAGeT")

ggplot(data=melted, aes(x=SNT, y=volume, colour=Method)) + 
    geom_point(size=1) + 
    geom_smooth(method="lm") + 
    xlab(expression("SNT \\gs{} mean hippocampus volume " (mm^3))) + 
    ylab(expression("Automated mean hippocampal volume " (mm^3))) +
    annotate("text", y = c(2000,1500,1000,500), x=Inf-100, size=2.5,
              label = c(paste("FS r =", round(cor(df$SNT, df$FS),2)),
                        paste("FSL r =", round(cor(df$SNT, df$FSL),2)),
                        paste("MAPER r =", round(cor(df$SNT, df$MAPER),2)),
                        paste("MAGeT r =", round(cor(df$SNT, df$MAGeT),2))),
              hjust=1.1,vjust=1.5) +
    opts(legend.direction = "horizontal", legend.position = "bottom")
@
  \caption{Subject mean hippocampal volume as measured in the \adnidataset{}
dataset by each of the four automated methods investigated (\freesurfer{} (FS), \fsl{},
\maper{}, \mb{}) vs. SNT \gs{}. Linear fit lines and Pearson correlations are shown
for each method.}
  \label{fig:ADNI-volumes-plot}
\end{figure}
 
\begin{figure}
<<ADNI-Bland-Altman, cache=TRUE, dependson='ADNI-volumes-prep', fig.width=7, fig.height=7>>=
names(means.complete)[8] = "FreeSurfer"
melted=melt(means.complete, measure.vars=c("FreeSurfer", "FSL", "MAPER","MAGeT"), 
            variable.name = "method", value.name = "volume")

melted$diff = melted$SNT - melted$volume
melted = subset(melted, (method == "FreeSurfer") | 
                        (method == "FSL"  ) | # & diff > -5000 & diff < 900) | 
                        (method == "MAPER") | # & diff > -500 & diff < 1000) | 
                        (method == "MAGeT"))  # & diff > -1100))
#melted = subset(melted, method == "MAGeT")
melted$DX = factor(melted$DX, levels(melted$DX)[c(2,3,1)])
melted$mean = ( melted$SNT + melted$volume ) / 2
limits = ddply(melted, c("method"), function (df) { 
  data.frame(
    y = mean(df$diff) + c(-1.96,0,2) * sd(df$diff) 
)}) 

names(melted)[4] = "Diagnosis"
ggplot(melted, aes(x= mean, y = diff, colour=Diagnosis)) + 
  facet_wrap( ~ method, nrow=2, scales="fixed") + 
  geom_smooth(method="lm", formula=y~x, fullrange=T, se=F) + 
  geom_point(size=1) +  
  geom_hline(aes(yintercept = y), linetype="dashed", colour="brown",
             data=limits, size=0.3, alpha=0.5) + 
  geom_text(aes(y = y, x=Inf, label=round(y,0)), colour="black", data = limits,
            hjust=1.1,vjust=-0.8, size=2.5) + 
  xlab(expression('Mean of SNT \\gs{} and automated hippocampal volume ' (mm^3))) + 
  ylab(expression('Difference in manual and automated hippocampal volume ' (mm^3))) + 
  scale_y_continuous(breaks=seq(-10000,4000, 1000)) + 
  scale_x_continuous(breaks=seq(0,10000, 1000)) + 
  theme(legend.direction = "horizontal", legend.position = "bottom", 
        axis.text.y = element_text(angle = 90, hjust=0.5), 
        axis.text = element_text(size = 8))
@
  \caption{Bland-Altman plots comparing subject mean hippocampal volume as
measured in the \adnidataset{} dataset by SNT \gs{} segmentation and each of the
four automated methods investigated (\freesurfer{}, \fsl{}, \maper{}, \mb{}). The overall
mean difference in volume, and limits of agreement ($\pm 1.96SD$) are shown by
dashed horizontal lines. Linear fit lines are shown for each diagnosis group.
Note, points below the mean difference indicate overestimation of the volume
with respect to the \gs{} rating, and vice versa. }

  \label{fig:ADNI-Bland-Altman}
\end{figure}




\begin{figure}
  \begin{centering}
    \includegraphics[width=6in]{figure/ADNI1_SNT_MB_montage/montage.pdf}
  \end{centering}
  \caption{SNT \gs{} and \mb{} segmentations for 30 ADNI subjects (10
  subjects randomly selected from each disease category in the subject pool used
  in Experiment 1). Sagittal slices are shown for each unlabelled T1-weighted
  anatomical image. SNT \gs{} labels appear in green, and \mb{} labels appear in
  blue. Noted are examples of common segmentation idiosyncrasies: 
  {\em (a)} over-estimation of hippocampal head and  
  {\em (b)} translated SNT \gs{} segmentation; 
  {\em (c)} under-estimation of hippocampal body and
  {\em (d)} improper inclusion of the vestigial hippocampal sulcus by \mb{}.}
  \label{fig:ADNI-segmentations}
\end{figure}

\FloatBarrier

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                Discussion
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Discussion}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Tabulation of segmentation accuracies of existing methods (ADNI)
%
<<ADNI1-literature, echo=F, results="asis",cache=FALSE>>=
# caption = 
#   "\\textbf{Automated segmentation accuracy (overlap with manual labels) of the 
#    ADNI dataset.} For each method, the number of manually labelled atlases used for 
#    training, the best Dice's overlap measure, the disease classes measured, and 
#    the validation procedure are shown. LOOCV = Leave-one-out cross-validation. 
#    Some studies of automated segmentation of ADNI images are excluded because they 
#    do not not provide overlap measures for the hippocampus \\cite{Heckemann2011, Chupin2009}.
#   "
# 
# tab = read.csv("data/ADNI-existing-work.csv")
# tab$Notes <- NULL
# 
# adni_lit = subset(tab, Dataset=="ADNI")
# adni_lit$Dataset <- NULL
# 
# 
# latex(adni_lit, #file="", 
#       size="scriptsize",
#       caption=caption, 
#       rowname=NULL,
#       col.just=c("p{2in}","p{1in}","p{1in}","p{1in}","p{1in}"),
#       title="")
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Tabulation of segmentation accuracies of existing methods (ADNI)
%
%
\begin{table}[!tbp]
\scriptsize
\caption{\textbf{Automated segmentation accuracy (overlap with SNT \gs{} labels)
of the ADNI dataset.} For each method, the number of labelled atlases
used for training, the best Dice's overlap measure, the disease classes
measured, and the validation procedure are shown. Unless specified, validation
datasets are composed equally of subjects diagnosed with Alzheimer's Disease
(AD), Mild Cognitive Impairment (MCI), and Cognitively Normal (CN). LOOCV =
Leave-one-out cross-validation. 
   Some studies of automated segmentation of ADNI images are excluded because they 
   do not not provide overlap measures for the hippocampus \citep{Heckemann2011,Chupin2009}.
  \label{tab:other-methods}} 
\begin{center}
\begin{tabular}{ l  c  p{1in}  l  p{2in}  }
\hline\hline
Method & Atlases & DSC & Reference & Validation \tabularnewline
\hline
\mb{}                     &9 & \Sexpr{round(mb.best.kappa, digits=3)} & & 10 rounds of Monte Carlo CV on a pool of 69 subjects \tabularnewline
LEAP                    &30&0.848                 &\cite{Wolz2010}  &Segmentation of 60 subjects\tabularnewline
ACM (AdaBoost-based)    &21&0.862                 &\cite{Morra2008} &LOOCV on atlases\tabularnewline
Patch-based label fusion&16&0.883 (CN) \newline 0.838 (AD)&\cite{Coupe2011e}&LOOCV on atlases\tabularnewline
Multi-atlas             &30&0.885                 &\cite{Lotjonen2010}&Segmentation of 60 subjects\tabularnewline
Multi-atlas + weighted fusion&20&0.898 (CN) \newline 0.798 (left HC, MCI) &\cite{Wang2011}  &10 rounds of Monte Carlo CV on 20 subjects, pool of 139 (CN/MCI)\tabularnewline
Multi-atlas (MAPS)    &55&0.890                   &\cite{Leung2010}&Segmentation of 30 subjects (10 AD, MCI, and CN)\tabularnewline
\hline
\end{tabular}
\end{center}
\end{table}

In this manuscript we have presented the implementation and validation of the
\mb{} framework -- a methodology that requires very few input atlases in
order to provide accurate and reliable segmentations.  Experiment 1 establishes
\mb{} as effective and as comparable to multi-atlas segmentation. This experiment
also rigorously characterizes the behaviour of \mb{} whole hippocampal
segmentation under various parameter settings, allowing us to choose an optimal
setting for subsequent experiments. Experiment 2 demonstrates the accuracy of
\mb{} hippocampal subfield identification despite contrast and resolution
limitations in standard T1-weighted image volumes.  Experiments 2 and 3 validate
\mb{} whole hippocampal segmentation accuracy and consistency on populations with
different ageing and neuropsychiatric characteristics.  Furthermore, taken
together, these experiments demonstrate that algorithmic performance is not
dependent on a single definition of the hippocampus but is effective with
differing hippocampal definitions \citep{Winterburn2013,Pruessner2000,Hsu2002}.  

Throughout the cross validation in Experiment 1 (10-fold Monte Carlo cross
validation in the \adnidataset{} dataset subsample) we find that two parameter
choices improve segmentation accuracy: increasing the number of atlases, and the
number of templates. However, after setting the parameters to 5 atlases and 15
templates there are diminishing returns with respect to this improvement. 

Previous work on multi-atlas segmentation methods
\citep{Aljabar2009,Collins2010} has found that cross-correlation and normalized
mutual information-based weighted label fusion improves segmentation accuracy
over simple majority vote label fusion. Selectively filtering out atlases with
lower image similarity is believed to reduce sources of error from estimating
deformations via nonlinear registration, partial volume effects from nearest
neighbour image resampling, and neuroanatomical mismatch between atlases and
subjects. That \mb{} does not see the same boost in performance from weighted
voting may suggest that the neuroanatomical variability of a template library
constructed from study subjects more closely matches any particular subject and
thereby leaving less error to filter. From our previous work on the \mb{}
algorithm we have shown that the reduction in error is not simply a smoothing or
averaging effect \citep{MallarChakravarty2012}.

Although, the goal of this manuscript was not to exhaustively test or validate
multiple different voting strategies in the context of our segmentation
algorithm, it is important to note that other strategies for voting are
available.  For example, other groups have used the STAPLE algorithm
\citep{Warfield2004} (or variants of the STAPLE algorithm
\citep{Robitaille2012}) which weights each segmentation based upon its
estimated performance level with respect to the other available candidate
segmentations.  Further, the sensitivity and specificity parameters can also be
tuned to potentially improve segmentation accuracy and reliability.  It is
likely that using more sophisticated voting methods would have a positive effect
on the overall segmentation performance, as demonstrated by the STAPLE
algorithm.  

To this end, more work is required to determine the source of the slight
decrease in segmentation performance when the number of templates are set to an
even number.  Our initial concern was that this dip in performance was a
by-product of the \mb{} algorithm itself.  However, this this pattern is also
found in the results of the multi-atlas segmentations we used in our
experiments.  We believe that our majority voting methodology is biased towards
labels with the lowest numeric values when breaking ties (by way of the
implementation of the \verb+mode+ function used to determine majority), thus
causing the slight bias observed when using an even number of templates. This is
another area where the voting scheme could be used to improve performance.
However, it is worth noting that this limitation was previously identified by
\citet{Heckemann2006a} and, subsequently, other groups have not even considered
the potential pitfalls of an even number of candidate labels (e.g.
\citet{Leung2010}).

Another concern is the moderate-to-small improvement observed in \mb{} in
comparison to multi-atlas segmentation when using the same number of atlases.
The actual benefit in using \mb{} is consistency of the labelling regardless of
atlas or template choice. This is an important consideration that few have
touched on previously. The 10-fold Monte Carlo leave-one-out cross-validation
that we present in Experiment 1 is amongst one of the most stringent performed
in the multi-atlas/segmentation literature. To the best of our knowledge, other
groups using ADNI data for validation do at most a single round of
leave-one-out-validation (Table \ref{tab:other-methods}), aside from
\citep{Wang2011} who perform a similarly rigorous validation as us. The
thoroughness of our validation suggests that our results are reflective of a
true average over the choice of parameter settings and are independent of atlas
or template choice (provided the input atlases are consistently segmented).  

On that note, one author (JW), an expert manual rater, identified regular
inconsistencies in the SNT segmentations: occurrences of over- and
under-estimation, as well as misalignments of the entire segmentation volume
(Figure \ref{fig:ADNI-segmentations}). Although the SNT segmentations are used
as gold standards for validation in many other studies (Table
\ref{tab:other-methods}) providing a benchmark for comparison, their use in
Experiments 1 and 4 presents the possibility that the DSC scores and
correlations we obtained are lower than what would be found with a more
accurate and consistent gold standard.

% Validation of ADNI in other works
% Chupin 2009: LOOCV, 1-fold validation
% Heckemann 2011: QC of segmentations, comparison across field strengths, 
%                 agreement between two different atlas sets
% Coupe 2011e: LOOCV
% Lotjonen 2010: LOOCV, 1-fold validation
% Leung 2010: 1-fold, QC, classification
% Wolz 2010: 1-fold over different leap settings, classification
% Collins 2010: 1-fold validation, QC
% Morra 2008: LOOCV with 21 atlases, 2 manual raters
% Wang 2011: 10 rounds of MCCV with 20 atlases and 20 subjects, chosen from 
%            a pool of 139 images

In comparison to other methodologies in the field \mb{} performs favourably. Table
\ref{tab:other-methods} surveys some of the most recent reported DSC values
reported on ADNI dataset, using SNT segmentations for the atlas library and as
gold standards for evaluation.  While it is difficult to compare segmentation
results across studies, gold standards, evaluation metrics, and algorithms it is
worth noting that the methods summarized require more atlases (between 16-55)
than our \mb{} implementation with the Winterburn atlases \citep{Winterburn2013}.

There are some important differences between our method and these specific
methods. Others have reported the difficulty with mis-registrations in
candidate segmentation (i.e. segmentations generated that are then input in the
voxel-voting procedure \citep{Collins2010}). The work of \citet{Leung2010}
tackles this problem by using an intensity threshold that is estimated
heuristically at the time of segmentation (this work also reports some of the
highest DSC scores for the segmentation of ADNI data). While this method is
effective for the ADNI dataset (which is partially homogenized with respect to
image acquisition and pre-processing), it is unclear if this type of heuristic
is applicable to other datasets. In all cases, these methods require more
atlases than our implementation with the Winterburn atlases.
\citet{Lotjonen2010} achieve highly accurate segmentation but correct their
segmentations using classifications derived using an expectation maximization
framework. In their initial work, \citet{Chupin2009} develop their probabilistic
methodology using a cohort of 8 healthy controls and 15 epilepsy patients, and
then use this method to segment an ADNI sample, with a hierarchical
experimentation protocol. These methods suggest that some post-processing of the
final segmentations would improve accuracy of the segmentation. While that may
be true, there is little consensus regarding how to achieve this.  

To the best of our knowledge, no other groups have validated their work using
multiple atlas segmentation protocols, different acquisitions, and disease
populations in order to demonstrate the robustness of their technique.  This is
one of the clear strengths of this work.  Furthermore, unlike some of the
algorithms mentioned, our implementation does not require retuning for new
populations or datasets as it inherently models the variability of the dataset
through the template library.  However it should be noted that the increased
accuracy that follows increasing the number of atlases and templates comes at an
increased computational cost ($O(log(n))$), as previously mentioned in
other work \citep{Heckemann2006}. 

Among the automated segmentation methods we compared in this paper
(\freesurfer{}, \maper{}, \fsl{}-FIRST), we find extremely variable
performance of all methods.  With the exception of \fsl{} all methods correlate
well with the SNT volumes provided in the ADNI database.  However, \freesurfer{}
and \fsl{} provide radically different definitions of the size of the hippocampus
in comparison to the other methods.  Further, when estimating bias of these
methods relative to SNT \gs{} hippocampal volumes we see that large hippocampi are
over estimated while small hippocampi are under estimated. By comparison, \mb{}
and \maper{} are far more conservative in volume estimation, suggesting these
methods may be better suited for estimating true-positives, especially in
neurodegenerative disease subjects featuring smaller overall hippocampi.
However, in this analysis we have only compared methods by total hippocampal
volume, and so more work is needed to understand the full extent to which these
methods differ.

Finally, we have also demonstrated that our algorithmic framework is
appropriate for the segmentation of hippocampal subfields in standard
T1-weighted data.  Subfield segmentation is a burgeoning topic in the
literature although very few automated methods are available for the
segmentation of 3T data \citep{Yushkevich2009,VanLeemput2009}. While recent
work demonstrates that subfield segmentations can be used for classification of
AD, MCI, and CN, there has been no explicit validation of the methodology based
on accuracy or precision.  Although the initial hippocampal subfield
segmentations from the Yushkevich group have been demonstrated to work on the
ADNI population, there has also been no validation of their work. In addition,
their work requires some manual initialization to properly function.  Our work
demonstrates that we can reliably identify the CA1, subiculum, and CA4/dentate
with only modest amounts of error.  The fact that CA2/CA3 and molecular layers
cannot be reasonably identified should not be surprising as these are extremely
thin and spatially convoluted regions that originally required high-resolution
MRI for identification.  It is likely that the extents of these regions are
well below the resolution offered by standard T1-weighted images and, in fact,
many manual segmentation methodologies do not attempt to parse these regions
either \citep{Wisse2012, Mueller2009}.

In conclusion, we have presented a flexible multi-atlas framework that has
considerable advantages over other methods since only a small number of atlases
is required to initialize the algorithm.  We demonstrate that our method works
robustly over hippocampal definitions, different disease populations, and
different acquisition types. Finally, we also demonstrate that accurate
identification of the hippocampal subfields is possible.



% \begin{verbatim}
% Experiment 1: 
% - address the absence of weighted-voting effects. 
%   - hypothesis: the benefits of weighted voting only outweigh the resampling
%     error effects when choosing from a large library.  In this experiment, the 
%     template library (during weighted voting) consists of only 20 templates, so
%     the most we could hope for is a "squashing" upwards of the curve towards 
%     the 20-template limit (which is the same across all cases in this experiment).
%   - we do see a slight "squashing" effect, with XCORR more strongly than NMI. 
%     Perhaps in future experiments with larger template libraries, this could be
%     explored further.
% - Why don't we use STAPLE? What would we expect from STAPLE or other fusion methods? 
%   - couldn't get STAPLE to work with our image formats
%   - Idea: expect smoothness across range of templates (no even # dips, below)
%   - perhaps more sophisticated fusion methods would boost results over majority 
%     vote based techniques.
% 
% - why does MAGeT brain show a dip in average Kappa when using an even number
%   templates. Does MA show this same pattern? (yes)
%   - Hypothesis: our voting method is biased when breaking ties to choose the 
%     label with the lowest numeric value.
%   - If we compute the total number of labels fused (atlases * templates) then 
%     both MB/MA perform worse when fusing an even number of labels. 
% 
% - we only show a +0.02 increase in mean Kappa over multi-atlas, and this is when
%   using 1 atlas (which we know from Figure 2, is when we perform worst). Why does
%   this increase justify the extra effort involved in MB? 
%   - decrease in variability
%   - we are comparing "true" averages (see above)... does this make our criteria 
%     for a worthy improvement less strict? 
%     
% 
% - how does MAGeT stack up, Kappa-wise, to other methods, in an absolute sense.
% - because of the extensive cross-validation in experiment 1, we are very likely
%   showing results that approach the true average of MB and MA on that dataset
%   (i.e. our mid 0.8 range result is a mean across 69 subjects and 10 repetitions
%   each).
% - even with this caveat, do we think we do well enough?  i.e. other than parameter 
%   tuning, to what extent does this experiment tell us about how MB would do in 
%   practice. 
% 
% - effects we are seeing is not only averaging effects (Chakravarty et al. 2012). 
% 
% - take aways: as in other studies (Aljabar, Heckemann) we find that performance
%   scales with the number of inputs (approx. log(n)), and that a large enough
%   template library can boost performance with a small number of atlases. The use 
%   of templates /can/ have a negative impact on performance (Figure 2), that is 
%   balanced by the improvement of growing the template library.  Likely the negative
%   impact on peformance is as a result of resampling/mislabelling error. In other 
%   words, tuning MAGeT brain involves balancing the tension between an improvement 
%   in peformance due to increase neuroanatomical capture and decreased peformance
%   due to resampling error. 
% 
% Experiment 2: 
% - describe resampling error during downsampling (essentially partial volume effect 
%   due to averaging/majority vote in nearest neighbour selection)
% - Why would some structures have greater downsampling error than others? (i.e. what
%   is it about a structure that would make it especially prone to resampling error)
%   - since error is discretised to whole voxels, smaller regions will show larger
%     percent error
%   - average unilateral volume (approx; mm3): 
%      region   volume   downsampling error
%      CA1      800            2%
%      CA4/DG   600          -30%
%      SR/SL/SM 700           30%
%      Sibculum 350            0%
%      CA2/3    200           15%
% 
% - observation: when downsampling error is small (<10 percent), MB error is larger, 
%   and vice versa when downsampling error is large.  Could this a case where the 
%   inevitable MAGeT resampling error outweighs the small downsampling error?
% - observation: MAGeT produces similar volumes for the downsampled and BRAVO images
%   which demonstrates reliability. Additionally, MB's error is in the same *direction*
%   as the downsampling error except for SR/SL/SM
% - for MB to show less error than resampling means that voting across templates is 
%   in aggregate performing better than local nearest neighbour fitting. presumably 
%   we'd see the same improvement with basic multiatlas as well.
% 
% - take away: MB produces subregion volumes that are comparable or better than
%   resampling error, except for the CA2/3 where error is near 25 percent (but 
%   even then resampling error is ~15%)
% 
% Experiment 3: 
% - what is an "acceptable" r^2 value? 
% - take away: MB has proven to be robust with atlases derived from three different
%   segmentation protocols (SNT, Winterburn, and now Pruessner) on three different
%   populations (older with AD progression; young and healthy; young and SZ). 
%   
% Experiment 4: 
% - address the smaller difference in mean volume across disease classes. smaller 
%   than every other method. 
%   
% - address the segmentation bias towards over-estimating smaller hippocampi, and 
%   underestimating larger HC
%   
% - visual inspection/QC reveals MB segmentations are satisfactory (failure rate 
%   is lower than the other methods (but we may be biased. :-). 
%   
% - take away: MB, with the Winterburn atlases, produces HC volumes more inline with
%   SNT than FSL/FS.  Comparable to MAPER but with far fewer atlases required. 
% 
% \end{verbatim}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                               Conclusion 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Acknowledgements}
We wish acknowledge support from the CAMH Foundation, thanks to Michael and
Sonja Koerner, the Kimel Family, and the Paul E. Garfinkel New Investigator
Catalyst Award. MMC is funded by the W. Garfield Weston Foundation and ANV is
funded by the Canadian Institutes of Health Research, Ontario Mental Health
Foundation, NARSAD, and the National Institute of Mental Health (R01MH099167).

Computations were performed on the gpc supercomputer at the SciNet HPC
Consortium. SciNet is funded by: the Canada Foundation for Innovation under the
auspices of Compute Canada; the Government of Ontario; Ontario Research Fund -
Research Excellence; and the University of Toronto.

In addition, computations were performed on the CAMH Specialized Computing 
Cluster. The SCC is funded by: The Canada Foundation for Innovation, Research 
Hospital Fund.

ADNI Acknowledgements: Data collection and sharing for this project was funded
by the Alzheimer's Disease Neuroimaging Initiative (ADNI) (National Institutes
of Health Grant U01 AG024904). ADNI is funded by the National Institute on
Aging, the National Institute of Biomedical Imaging and Bioengineering, and
through generous contributions from the following: Abbott; Alzheimer's
Association; Alzheimer's Drug Discovery Foundation; Amorfix Life Sciences Ltd.;
AstraZeneca; Bayer HealthCare; BioClinica, Inc.; Biogen Idec Inc.;
Bristol-Myers Squibb Company; Eisai Inc.; Elan Pharmaceuticals Inc.; Eli Lilly
and Company; F. Hoffmann-La Roche Ltd and its affiliated company Genentech,
Inc.; GE Healthcare; Innogenetics, N.V.; IXICO Ltd.; Janssen Alzheimer
Immunotherapy Research  Development, LLC.; Johnson \& Johnson Pharmaceutical
Research  Development LLC.; Medpace, Inc.; Merck \& Co., Inc.; Meso Scale
Diagnostics, LLC.; Novartis Pharmaceuticals Corporation; Pfizer Inc.; Servier;
Synarc Inc.; and Takeda Pharmaceutical Company. The Canadian Institutes of
Health Research is providing funds to support ADNI clinical sites in Canada.
Private sector contributions are facilitated by the Foundation for the National
Institutes of Health (www.fnih.org). The grantee organization is the Northern
California Institute for Research and Education, and the study is Rev March 26,
2012 coordinated by the Alzheimer's disease Cooperative Study at the University
of California, San Diego. ADNI data are disseminated by the Laboratory for
NeuroImaging at the University of California, Los Angeles. This research was
also supported by NIH grants P30 AG010129 and K01 AG030514.

We would also like to thank G. Clinton, E. Hazel, and B. Worrell for inspiring
this work.

\section{Supplementary Materials}

\subsection{ADNI SNT Hippocampal Labels}
% The following blurb is taken (except for the first sentence) verbatim 
Semi-automated hippocampal volumetry was carried out using a commercially
available high dimensional brain mapping tool (Medtronic Surgical Navigation
Technologies, Louisville, CO), that has previously been validated and compared
to manual tracing of the hippocampus \citep{Hsu2002}. Measurement of hippocampal
volume is achieved first by placing manually 22 control points as local
landmarks for the hippocampus on the individual brain MRI data: one landmark at
the hippocampal head, one at the tail, and four per image (i.e., at the
superior, inferior, medial and lateral boundaries) on five equally spaced images
perpendicular to the long axis of the hippocampus. Second, fluid image
transformation is used to match the individual brains to a template brain
\citep{Christensen1997}. The pixels corresponding to the hippocampus are then
labeled and counted to obtain volumes. This method of hippocampal voluming has a
documented reliability of an intraclass coefficient better than .94
\citep{Hsu2002}.

\subsection{Experiment 1a: Whole Hippocampus Cross-Validation with SNT 
\gs Segmentations }


Monte Carlo Cross-Validation (MCCV) \citep{Shao1993} was performed using a pool
of images and SNT \gs{} segmentations from the ADNI dataset \citep{Hsu2002}. This
form of cross-validation allows us to rigorously validate a large number of
parameter settings of \mb{} (atlas and template library sizes, registration
algorithm, and label fusion method) and select the best parameters to use in
subsequent experiments.

\subsubsection{Methods}
\paragraph{\adnidataset{} dataset} 
69 1.5T images were arbitrarily selected from the baseline scans in the {\em
\adnidataset{}} standardized dataset. 23 subjects were chosen from each disease
category: cognitively normal (CN), mild cognitive impairment (MCI) and
Alzheimer's disease (AD). Demographics for this subset are shown in Table
\ref{tab:ADNI1-xvalidation-demographics}.  Semi-automated segmentations of the
left and right whole hippocampi are made available with a subset of ADNI images
\citep{Hsu2002}. These labels have been generated using the SNT tool from
Medtronic Surgical Navigation Technologies, Louisville, CO (see Supplementary
Materials for detailed discussion of the segmentation process used). Throughout
this paper, we use these segmentations as the \gs{} for comparison. 

Clinical, demographic and pre-processed T1-weighted MRI were downloaded by the
authors from the ADNI database (adni.loni.ucla.edu) between March 2012 and
August 2012. The image dataset used was the "\adnidataset{}" standardized dataset
available from ADNI \footnote{
\url{http://adni.loni.ucla.edu/methods/mri-analysis/adni-standardized-data/}}
\citep{Wyman2012}. This image collection contains uniformly pre-processed images
which have been designated to be the "best" after quality control.  All images
were acquired using 1.5T scanners (General Electric Healthcare, Philips Medical
Systems or Siemens Medical Solutions) at multiple sites using the protocol
described in \citep{Jack2008}.  Representative 1.5T imaging parameters were TR =
2400ms, TI = 1000ms, TE = 3.5ms, flip angle = $8^{\circ}$, field of view = 240 x
240mm, a $192 \times 192 \times 166$ matrix ($x$, $y$, and $z$ directions)
yielding a voxel dimensions of $1.25mm \times 1.25mm \times 1.2mm$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% ADNI1 X-Validation Dataset Demographics Table
%
<<ADNI-SNT-Xval-demographics, echo=F, results="asis",cache=FALSE>>=
adni_69_RIDs = c(295,413,619,685,729,782,938,954,1018,1155,907,981,222,324,448,
                 546,553,572,602,610,814,1341,675,681,731,1130,41,68,70,101,
                 249,293,316,414,698,1206,1222,1339,751,1030,3,5,10,16,22,53,
                 168,183,241,1205,328,1095,991,213,159,337,343,642,753,1109,
                 1217,29,56,1188,1293,149,382,431,1202)

tab <- summary(DX.bl ~ AGE + PTGENDER + PTEDUCAT + CDRSB + ADAS13 +
               MMSE, data = adnimerge, subset = VISCODE == 'bl' & RID %in%
               adni_69_RIDs, method = "reverse", test=FALSE, overall=TRUE)
caption = 
  "\\textbf{ADNI1 SNT cross-validation subset demographics.} 
  CN     - Cognitively Normal. 
  LMCI   - Late-onset Mild Cognitive Impairment. 
  AD     - Alzheimer's Disease.  
  Hisp   - Hispanic. 
  CDR-SB - Clinical Dementia Rating-Sum of Boxes.  
  ADAS   - Alzheimer's Disease Assessment Scale.  
  MMSE   - Mini-Mental State Examination."
latex(tab, file="", size="scriptsize",landscape=FALSE, ctable=FALSE,
      caption=caption, caption.loc = c("top"),
      label="tab:ADNI1-SNT-xvalidation-demographics")
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\paragraph{Experiment details} 

Monte Carlo Cross-Validation (MCCV), also known as repeated random sub-sampling
cross-validation, consists of repeated rounds of validation conducted on a fixed
dataset \citep{Shao1993}. In each round, the dataset is randomly partitioned into
a training set and a validation set. The method to be validated is then given
the training data, and its output is compared with the validation set.

In this experiment, our dataset consists of 69 1.5T images and corresponding \gs{}
segmentations. In each validation round, the dataset is partitioned into a
training set consisting of images and \gs{} segmentations used as an atlas
library, and a validation set consisting of the remaining images segmented by
both \mb{} and multi-atlas. The computed segmentations were compared to the \gs{}
segmentations (see below). 

A total of ten validation rounds were performed on each subject in the dataset,
over each combination of parameter settings. The parameter settings
explored are: atlas library size (1-9), template library size (1-20),
registration method (\ants{} or \animal{}, described below), and label fusion method (majority vote,
cross-correlation weighted majority vote, and normalized mutual information
weighted majority vote, described below).  A total of $10 \times 69 \times 9
\times 20 \times 2 \times 3 = \num{7452000}$ validation rounds were conducted,
resulting in a total of $\num{1490400}$ segmentations analysed. 

Before registration, all images underwent preprocessing with the N3 algorithm
\citep{Sled1998} to minimize intensity nonuniformity. In this experiment we
compared two non-linear image registration methods, three label fusion methods. 

The automatically produces labels are compared to the \gs{} SNT labels provided by
ADNI. The segmentation accuracy reported for a parameter setting is the average
over ten validation rounds. 


% ######################
\subsubsection{Results}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ADNI1-XVAL: prep
% Prepares the data in a the form needed for plotting.
<<ADNI1-SNT-xval-prep,dependson='ADNI1-xval-load',include=FALSE,cache=TRUE>>=
snt_xval_data  <- read.csv(gzfile('data/cache/ADNI-SNT-XVAL:all_data.csv.gz'))
snt_xval_mean  <- read.csv(gzfile('data/cache/ADNI-SNT-XVAL:all_data_mean.csv.gz'))

snt_xval_mb.best = mean(subset(snt_xval_data, reg_method   == "ANTS" & 
                                  method.mb    == "Majority Vote" &
                                  templates.mb == 19 & 
                                  atlases      == 9)$k.mb)
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


In this experiment we conducted 10 rounds of \mb{} and multi-atlas segmentation of
of 69 subjects using atlas and template library sizes varying from 1-9 and 1-20
images respectively, two registration algorithms (\ants{} or \animal{}), and three
label fusion techniques (unweighted, cross-correlation, and normalised mutual
information weighted majority vote).  Hippocampal \mb{}-based segmentations using
both \animal{} and \ants{} registration algorithms demonstrate good overlap with SNT
\gs{} segmentations (maximum mean DSC of \Sexpr{round(snt_xval_mb.best, digits=2)}
when using 9 atlases, 19 templates, ANTS registration, and majority vote label
fusion); Figure \ref{fig:ADNI1-xval-k-mean}).  Qualitatively, both \animal{} and
\ants{}-based segmentations demonstrate trend overlap accuracy that increases with
the size of atlas library and template library. Improvement in accuracy plateaus
with template libraries larger than ten images. 

The use of \mb{} with \ants{} registration shows a pronounced increase
in segmentation accuracy over \mb{} with \animal{} registration, across all
other variable settings we tested. Additionally, by itself, using a weighted
voting strategy did not significantly improve segmentation accuracy, contrary to
the findings of \citet{Aljabar2009} in basic multi-atlas segmentation. Given
these findings, in the remainder of this section only results using the \ants{}
registration algorithm and majority vote fusion will be shown.

With an increasing number of templates, \mb{} shows improvement over
multi-atlas-based segmentation in overlap accuracy when using the same number of
atlases and voting method (Figure \ref{fig:ADNI1-SNT-xval-k-diff}). The two methods
converge in accuracy when using seven atlases.  Peak improvement in \mb{} accuracy
(~0.02 DSC) is found when one atlas is used with a template library of 19
images.

In addition to an improvement in accuracy over multi-atlas-based segmentation,
\mb{} also shows a decrease in the variability of segmentation accuracy 
(Figure \ref{ADNI1-SNT-xval-variability}).  The size of template library 
necessary to reach a decrease ($p < 0.05$) in variance and standard deviation
grows with the size of atlas library used.  A template library of 19 images is
sufficient to show significant decrease in variance and standard deviation for
3-7 atlases. 

We have omitted results obtained when using an even number of atlases or
templates since with this configuration we found significantly decreased
performance. We believe this is as a result of an inherent bias in the majority
vote fusion method used (see Discussion).  

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ADNI1-XVAL: mean Kappa plot by atlases, templates, reg and voting method. 
\begin{figure}
<<fig:ADNI1-SNT-xval-k-mean, cache=TRUE, dependson='ADNI1-xval-prep', fig.width=5, fig.height=5>>=
stderr <- function(x) sqrt(var(x)/length(x))
ggplot(subset(snt_xval_mean, (templates.mb*atlases) %% 2 == 1),
       aes(x=templates.mb,y=k.mb, colour=as.factor(atlases))) + #as.factor((atlases*templates.mb) %% 2 ))) + 
  facet_grid(reg_method~method.mb) + 
  stat_summary(fun.y=mean,geom='line',
               aes(y=k.mb, weight=1, group=as.factor(atlases))) + 
  stat_summary(fun.y=mean,
               fun.ymin=function (x) mean(x) - stderr(x),
               fun.ymax=function (x) mean(x) + stderr(x), 
               geom='errorbar',
               aes(y=k.mb, weight=1, group=as.factor(atlases)), width=0.5) + 
  #stat_smooth(method='lm', formula=y~log(x)) + 
  scale_y_continuous(breaks=seq(0,1,0.05)) + 
  scale_colour_hue(name="Number of Atlases") +
  xlab( "Number of Templates" ) + 
  ylab( "Mean DSC" ) + 
  theme(legend.direction = "horizontal", legend.position = "bottom", 
        axis.text = element_text(size = 8))
@
  \caption{Mean Dice's Similarity Coefficient of \mb{} segmentations relative to
  SNT \gs{} segmentations for 69 ADNI subjects vs. atlas and template library
  size, registration algorithm, and label fusion method. Error bars indicate
  standard error.
  \label{fig:ADNI1-SNT-xval-k-mean}}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ADNI1-XVAL: "increase" in mean kappa over multi-atlas
\begin{figure}
<<fig:ADN11-SNT-xval-k-diff,cache=TRUE,dependson='ADNI1-xval-prep', fig.width=5, fig.height=5>>=
ggplot(subset(snt_xval_mean, reg_method=="ANTS" & 
                method.mb=="Majority Vote" & (templates.mb*atlases) %% 2 == 1), 
       aes(x=templates.mb, y=k_diff, colour=as.factor(atlases))) + 
  #facet_grid(reg_method~method.y) + 
  stat_summary(fun.data=mean_cl_boot,geom='errorbar',
               aes(y=k_diff,colour=as.factor(atlases), width=0.2)) +
  stat_summary(fun.y=mean, geom="point", 
               aes(y=k_diff,colour=as.factor(atlases))) + 
  stat_summary(fun.y=mean, geom="line", 
               aes(y=k_diff,colour=as.factor(atlases))) + 
  #stat_smooth(method=lm, formula=y~log(x)) + 
  geom_hline(aes(alpha=0.5, yintercept=0), linetype='dashed') + 
  scale_x_continuous(breaks=seq(1,20,2)) + scale_y_continuous(breaks=seq(-1,1,by=0.01)) + 
  scale_colour_hue(name="Number of Atlases") +
  scale_alpha_continuous(guide = "none") + 
  scale_linetype_discrete(guide = "none") + 
  xlab( "Number of Templates" ) + 
  ylab( "Difference in mean DSC" ) +
  theme(legend.direction = "horizontal", legend.position = "bottom")
@
  \caption{Difference in mean Dice's Similarity Coefficient between \mb{} and
  multi-atlas segmentations relative to \gs{} (SNT) segmentations vs. atlas and
  template library size when using the \ants{} registration method, and
  majority-vote label fusion. Error bars indicate standard error.
  \label{fig:ADNI1-SNT-xval-k-diff}}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ADNI1-SNT-XVAL: show variability of MAGeT over parameters
\begin{figure}
<<ADN1-SNT-Xval-variability, cache=TRUE, dependson='ADNI1-Xval-prep', fig.width=5, fig.width=5>>=
ants = subset(snt_xval_data, 
                     reg_method=="ANTS" & 
                     method.mb=="Majority Vote" &
                    templates.mb %in% seq(1,20,2))

ants.stats = ddply(ants, c("subject", "label", "atlases","templates.mb"), 
                   function (df) {
                     data.frame(
                       MA.sd  =  sd(df$k.ma),
                       MB.sd  =  sd(df$k.mb),
                       MA.var = var(df$k.ma),
                       MB.var = var(df$k.mb)
                       )
                   })

stats.tests = ddply(ants.stats, c("atlases","templates.mb"), function (df) {
  t.var = t.test(df$MA.var, df$MB.var)
  t.sd  = t.test(df$MA.sd , df$MB.sd)
  diff_mean_var = mean(df$MA.var - df$MB.var)
  diff_mean_sd  = mean(df$MA.sd -  df$MB.sd)
  
  # test statistic is positive if MA mean is larger than MB
  # i.e. that MA has a greater mean of variances/SDs
  # i.e. that MB has a smaller mean, and so is doing "better"
  data.frame(
    stat      = c("Variance", "Standard Deviation"),
    statistic = c(t.var$statistic, t.sd$statistic),
    p.value   = c(t.var$p.value, t.sd$p.value),
    direction = c(diff_mean_var, diff_mean_sd)
  )
})

ggplot(subset(stats.tests, direction > 0 & stat == "Variance"), 
  aes(x=templates.mb, y=p.value, colour=as.factor(atlases))) + 
  #facet_grid( . ~ stat) + 
  geom_line(size=1) +
  geom_point(size=3) + 
  geom_hline(aes(yintercept=0.05, alpha=0.5), linetype='dashed') + 
  geom_hline(aes(yintercept=0.01, alpha=0.5), linetype='dashed') + 
  scale_x_continuous(breaks=seq(1,20,by=2)) + 
  scale_y_log10(limits=c(0.001,1), breaks=c(0.01,0.05,0.1,1.0)) + 
  xlab( "Number of Templates" ) + 
  ylab( "Difference of variance during validation (p-value)") +
  scale_colour_hue(name="Atlases") +
  scale_alpha_continuous(guide='none') + 
  scale_linetype_discrete(guide='none') + 
  scale_size_continuous(guide='none') + 
  theme(legend.direction = "horizontal", legend.position = "bottom")
@
  \caption{{\bf Difference in variability of \mb{} vs. multi-atlas segmentation 
  accuracy using SNT \gs.}
  Variance of segmentation accuracy between \mb{} and multi-atlas segmentation is
  computed for each subject across all ten rounds of validation. Shown on the
  y-axis (scaled logarithmically) is the  p-value resulting from a t-test
  comparing the distribution of variances at each parameter setting
  (atlas/template library size). Only points where \mb{} mean variability is lower
  than multi-atlas are shown. Dashed lines indicate a p-value of 0.05 and 0.01.}
  \label{ADNI1-SNT-xval-variability}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




\bibliographystyle{abbrvnat}
\bibliography{references}

% \section*{R Session Information}
% <<results = "asis">>=
% toLatex(sessionInfo(), locale=FALSE)
% @
\end{document}
