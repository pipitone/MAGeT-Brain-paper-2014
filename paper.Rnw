%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Sweave/Knitr init
<<setup, include=FALSE, cache=FALSE>>=
library(knitr)
opts_chunk$set(echo = FALSE, 
               message = FALSE, 
               warning = FALSE, 
               fig.align = 'center', 
               tidy = FALSE, 
               comment = NA, 
               cache = TRUE,
               fig.width = 6, 
               fig.height = 6)
library(ggplot2)
library(Hmisc)
library(reshape2)
library(ADNIMERGE)
library(plyr)
options(digits=3)
theme_set(theme_bw())

bland_altman_plot <- function(x, y) {
  data = data.frame(x=x,y=y,diff=x-y)
  return(ggplot(data, aes(x= x, y = diff)) + 
    geom_hline(yintercept = mean(data$diff) + c(-2, 0, 2) * sd(data$diff), 
               linetype=2, color='brown') + 
    geom_point())
}

lm_eqn = function(m) {
  l <- list(a = format(coef(m)[1], digits = 2),
      b = format(abs(coef(m)[2]), digits = 2),
      r2 = format(summary(m)$r.squared, digits = 3));
  if (coef(m)[2] >= 0)  {
    eq <- substitute(italic(y) == a + b %.% italic(x)*","~~italic(r)^2~"="~r2,l)
  } else {
    eq <- substitute(italic(y) == a - b %.% italic(x)*","~~italic(r)^2~"="~r2,l)    
  }

  as.character(as.expression(eq))
}
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass{article}
\usepackage[margin=1in]{geometry}
\usepackage{algorithm, color, algpseudocode, amsmath, url, geometry, ctable}
\usepackage{titlesec}
\usepackage[round,authoryear]{natbib}

%draft mode
\usepackage[colorlinks]{hyperref}
\usepackage[colorinlistoftodos, textwidth=4cm, shadow]{todonotes}
\usepackage[displaymath, tightpage]{preview}
\setlength{\marginparwidth}{1.2in}

% add \subsubsubsection
\setcounter{secnumdepth}{4}  
\titleformat{\paragraph}
{\normalfont\normalsize\bfseries}{\theparagraph}{1em}{}
\titlespacing*{\paragraph}
{0pt}{3.25ex plus 1ex minus .2ex}{1.5ex plus .2ex}
\newcommand{\subsubsubsection}[1]{\paragraph{#1}}

% shortcuts 
\newcommand{\mb}{MAGeT-Brain }
\newcommand{\ants}{ANTS }
\newcommand{\animal}{ANIMAL }

%notes and TODO formatting
%\newcommand{\marginnote}[1]{\-\marginpar[\raggedleft\footnotesize #1]{\raggedright\footnotesize #1}}
%\newcommand{\comment}[1]{\begin{kframe}{\textcolor{red}{#1}}\end{kframe}}
%\newcommand{\todo}[1]{\comment{TODO #1}}
%\newcommand{\mc}[1]{\comment{MC: #1}}
\begin{document}

\title{Bootstrapping Multi-atlas Hippocampal Segmentation with \mb}
\author{Pipitone J., Winterburn J., Lerch J., Pruessner J., Lepage M., \\ 
Voineskos A., Chakravarty M.M., and \\ 
the Alzheimer's Disease Neuroimaging Initiative}
\maketitle

\begin{abstract}
Neuroimaging research often relies on automated anatomical segmentations of MR
images of the brain. Current multi-atlas based approaches provide accurate
segmentations of brain images by propagating manually derived segmentations of
specific neuroanatomical structures to unlabelled data. These approaches often
rely on a large number of such manually segmented atlases that take significant
time and expertise to produce. We present an algorithm for the automatic
segmentation of the hippocampus that minimizes the number of atlases needed
while still achieving similar accuracy to multi-atlas approaches.
\todo[inline]{finish}
\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                               INTRODUCTION
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

The hippocampus is of particular interest to many researchers because it is
implicated in forms of brain dysfunction such as Alzheimer's
disease\citep{Sabuncu2011} and schizophrenia\citep{Narr2004,Karnik-Henry2012},
and has functional significance in cognitive processes such as learning and
memory\citep{DenHeijer2012,Scoville2000}.  For many research questions
involving magnetic resonance imaging (MRI) data accurate identification of the
hippocampus and its subregions is a necessary first step to better understand
the individual neuroanatomy of subjects.  

Currently, the gold standard for neuroanatomical segmentation is manual
delineation by an expert human rater.  This is problematic for hippocampal
segmentation for several reasons.  First, manual segmentation takes a
significant investment of time and expertise \citep{Hammers2003} which may not
be readily available to researchers or clinicians.  Second, the amount of data
produced in neuroimaging experiments increasingly exceeds the capacity for
identification of specific neuroanatomical structures by an expert manual
rater.  Third, the true definition of hippocampal anatomy in MR images is
disputed \citep{Geuze2004}, as evidenced by efforts to create an unified
segmentation protocol \citep{Jack2011}.  

Compounding each of these problems is the significant neuroanatomical
variability in the hippocampus throughout the course of aging, maturation, and
neuropsychiatric disorders
\citep{Mouiha2011b,Sabuncu2011,Giedd1998,Gogtay2006,Narr2002}.  The result is that
existing hippocampal atlases available to a researcher may not accurately
represent neuroanatomy of a specific population under study.  Additionally, in
the course of a research or clinical study, it may be necessary to make
adjustments to hippocampal definition as a means of hypothesis testing.  For
example, Poppenk \citep{Poppenk2011} found that subdividing the hippocampus
into anterior and posterior regions resulted in a predictive relationship
between volume difference of those regions and recollection memory performance.
Making such modifications to a set of MRI data segmentations requires additional
manual effort. 

Automated segmentation techniques do not require human intervention but do
require {\it a priori} anatomical information to guide segmentations.  In this
paper we focus on methods that use manually segmented MRI atlases as anatomical
priors, as these methods achieve some of the best automated hippocampal
segmentation accuracies to-date. This technique was first developed using a
single atlas prior (known as single-atlas, or model-based,
segmentation)\citep{Haller1997,Csernansky1998}.  Volumetric image registration
is used to estimate a fit between the neuroanatomy of an atlas and target
images.  Labelling of the target image is achieved by applying the resulting
transformation to the atlas labels to bring them into the target image space
({\em label propagation}). This method is limited in accuracy by the
introduction of estimation errors in registration and partial volume effects in
label resampling, and errors introduced when the anatomy of the atlas is
unrepresentative of the target anatomy.

Multi-atlas segmentation techniques address these limitations by combining
segmentation information from a series of expertly segmented atlases
\citep{Heckemann2006,Heckemann2011,Collins2010,Lotjonen2012,Aljabar2009,Leung2010,Wolz2010}.
Each atlas image is registered to a target image, and label propagation is
performed to produce several labellings of the target image (one from each
atlas). A {\it label fusion} technique, such as voxel-wise voting, is used merge
these labels into a definitive segmentation for the target.  In addition, {\em
atlas selection} techniques are often used to exclude atlases from label fusion
that are dissimilar to a target image in order to reduce error from
unrepresentative anatomy \citep{Aljabar2009}. Cross-correlation or normalised
mutual information of image intensities are common measures of image similarity
used in atlas selection.

Multi-atlas methods have been very successfully applied to hippocampal
segmentation. Collins et al. found near-manual segmentation performance using an
atlas library of 80 T1-weighted atlas images from the ICBM152 dataset, the
\animal nonlinear registration algorithm, normalised mutual information as an
atlas selection similarity metric, and majority vote for label fusion
\citep{Collins2010}.  The Alzheimer's Disease Neuroimaging Initiative (ADNI) is
a commonly used benchmarking dataset of MR images of controls and patients with
MCI or Alzheimer's (see Methods for more information on the ADNI dataset).
Leung et al. tuned parameters for registration and label fusion to the
segmentation of ADNI1 1 year dataset of images with an atlas library of 55
images \citep{Leung2010}.  The MAPER whole brain segmentation algorithm
\citep{Heckemann2006,Heckemann2011}, using 30 atlases, on all ADNI1 baseline
images \citep{Heckemann2011}.  Lotjonen et al. use images from the ADNI1
baseline dataset and 30 atlases with a proprietary non-linear registration
method based on intensity differences, and post-processing step using a graph
cuts algorithm to optimise fused segmentations against a spatial intensity prior
\citep{Lotjonen2012}.  
\todo{No story here}

The LEAP algorithm is an elegant modification to the basic multi-atlas strategy
\citep{Wolz2010}. The atlas library is grown, beginning with a set of manually
labelled atlases, and successively incorporats unlabelled target images after
being labelling using multi-atlas techniques. The sequence in which target
images are labelled is chosen so that the similarity between the atlas images
and the target images is minimised at each step, effectively allowing for
deformations between very dissimilar images to be broken up into sequences of
smaller deformations.  With an atlas library of 30 MR images, LEAP was used to
segment the ADNI1 baseline dataset, achieving a mean Dice score of 0.85 with
manual segmentations.

%- TODO: "probablistic methods?"

While not purely nulti-atlas techniques, there are several important algorithms
for hippocampal segmentation that inform our approach. The popular FreeSurfer
application's whole brain segmentation algoritm uses a probabilistic atlas of
anatomical and tissue classes along with spatial constraints for class labels
encoded using a Markov random field model \citep{Fischl2002}. When segmenting
hippocampal subfields, FreeSurfer employs a Bayesian inference algorithm using a
probabilistic atlas of anatomical classes as a prior, and a likelihood model of
how those classes translate into MR image intensities, both trained on manual
segmentations of high resolution MR images \citep{Fischl2009}. Yushkevitch et
al. describe a semi-automated method for hippocampal subfield segmentation of
focal T2 images\citep{Yushkevitch2010}.  The unlabelled MR image must be
manually partitioned into 'head', 'body' and 'tail', and then multi-atlas
methods are used to segment the image.  Finally, an AdaBoost-based bias
correction classifier is trained on texture, spatial location, and intensities
of manual segmentations and is applied to fix mislabelled voxels.  

%  Chupin's use of shape-based priors 
%   - Mouiha2011b - Hippocampal atrophy rates in AD: compare SNT vs FreeSurfer
%     on ADNI
%

Aside from the algorithmic choices used in multi-atlas segmentation, it is
natural to ask about how the features of the atlases themselves impact the
resulting segmentations. As noted, by choosing atlases ranked most similar to a
target image by voxel intensity profile, segmentation accuracy is improved,
suggesting that neuroanatomical similarity plays a strong role
\citep{Aljabar2009}.  Carmichael et al. explored this directly and found that
when using only one atlas the important factors leading to improved accuracy are
that the atlas have neuroanatomical features that match the target, and that the
atlas segmentation use the same protocol as the gold-standard
\citep{Carmichael2005}. Nestor et al.  found that hippocampal segmentation
protocols that include more dorsal white-matter and posterior anatomy tended to
produce higher overlap and better accuracy at distinguishing disease classes in
the ADNI1 1 year dataset \citep{Nestor2012}. These results suggest both atlas
library neuroanatomy and delineation protocol play a significant role in the
resulting segmentation.

Considered along with our earlier discussion on the difficulty of producing
manual segmentations of MR images and the need for adaptable segmentation
definitions in order to conduct research, this presents a real problem of labour
and expertise when using existing multi-atlas segmentation methods which rely on
relatively large atlas libraries (typically between 30 and 80 atlases). Indeed,
it may be especially prohibitive to use these methods in situations where
producing a single atlas is challenging (e.g. histology-based atlases, or
atlases from very high resolution images). In this paper we address the problem
of producing accurate segmentations using small numbers of manually segmented
atlases. 

% MAGeT bootstrapping: tune the template library to your dataset, reduce the
% number of input atlases you need, with the upshot that with fewer atlases it's
% that much easier to change definitions in order to test hypothesis

Our algorith, called \mb ({\em M}ultiple {\em A}utomatically {\em
Ge}nerated {\em T}emplates), is an extension to the basic multi-atlas-based
segmentation schema\citep{Chakravarty2012}. Principally, we explore the
possibility of using a small atlas library to bootstrap a much larger
\emph{template library} composed of images taken from the target population.
The template library is then used to segment the targets in a similar fashion
to basic multi-atlas segmentation: by label propagation and label fusion. The
intuition driving this approach is that by generating a template library we
leverage the unique neuroanatomy of target population on hand to initialize the
segmentation process and improve accuracy over direct propagation from the atlas
library to unlabelled targets while also using fewer manually segmented
atlases. 

The insight of generating a template library is not new.  Heckemann et al.
compared ``indirect'' segmentation -- taking a single atlas and propagating the
labels to intermediate targets before fusing them in a target image space -- to
multi-atlas segmentation and found that the indirect approach performed worse
\citep{Heckemann2006}. In this paper we continue the same line of investigation
but explore the performance when using multiple atlases as well as the effect of
different registration and fusion methods.

The LEAP algorithm \citep{Wolz2010}, described above, is another example of
indirect segmentation previously explored.  LEAP proceeds by iteratively
segmenting unlabelled images most similar to the atlas library images and then
incorporating the labelled images into the atlas library for future iterations.
The novelty explored in our current work is to demonstrate the viability of
achieving comparable segmentation accuracy using the basic multi-atlas schema
and using significantly fewer manually created atlases.

In previous work \citep{Chakravarty2012}, we applied \mb to segmentation
of the human striatum, globus pallidus, and thalamus using a single
histologically-derived atlas. The contribution of the present work is to extend
our approach to the human hippocampus and perform a series of experiments to
rigorous validate the method. First, we conduct an extensive cross-validation of
\mb and basic multi-atlas segmentation on a subset of the ADNI1 dataset to
assess the accuracy of \mb under various parameter settings (number of
atlases and templates, registration and fusion methods). With the best
performing parameter configuration discovered above, we estimate \mb
intra-rater reliability by segmenting separately acquired T1 images of the
atlas subjects. For this experiment, we use the Winterburn atlases: digital
hippocampal subfield segmentations of five {\em in vivo} high-resolution (300$\mu$
isotropic) T1-weighted MR scans\citep{Winterburn2013}. To validate \mb in a
real world situation, we segment the entire ADNI1 Complete 1Yr dataset and compare
our segmentations to established automated and manual segmentations.
Additionally, to ensure \mb accuracy across disease categories, we also
compare \mb segmentations to manual segmentations of 139 first episode
schizophrenic patients. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                               METHODS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Methods}

%%%%%                     MAGeT Brain Algorithm                            %%%%%

\subsection{The \mb Algorithm}
In this paper we will be making a distinction between an atlas and a template --
typically these terms are used roughly interchangeably. The term {\it atlas} is
taken to refer to two image volumes: an intensity image ({\it atlas image}) and
a corresponding manual segmentation image ({\it atlas labels}). {\it Template}
refers more generically to any image and corresponding labelling, manual or
computed, when it is {\it used as} as a model in the segmentation of another
image.  The terms {\it atlas library} and {\it template library} mean a set of
such images. Additionally, we will use the terms {\it target} to refer to an
intensity image for which we would like an segmentation.

The simplest form of multi-atlas segmentation combines labellings derived from
several atlases by way of label fusion \citep{Heckemann2006,Heckemann2011}. We
will refer to this as {\em basic multi-atlas segmentation}. The schema as for
this method is as follows: 
\begin{enumerate}
\item   An atlas library and set of target images are given as input. The atlas
        library is used as a template library in the following steps; 
\item   Each atlas intensity image is nonlinearly registered to each target 
        intensity image; 
\item   Label images from each atlas are propagated via the resulting
        transformations to the target image space; and 
\item   the resulting labels are fused to produce a single, definitive
        segmentation. 
\end{enumerate}       
The particular registration and voting method used are left unspecified.

\mb is best understood as an extension of the basic multi-atlas
segmentation schema. Instead of using the atlas library to directly label the
target images, a subset of the input images are selected as template images and
then labelled.  The choice of targets used in the template library can be made
to reflect the neuroanatomy or demographics of the target set as a whole (for
instance, by sampling equally from cases and controls). Once the template
library images have been chosen, a truncated version of basic multi-atlas
segmentation is used to label the template library images without performing
label fusion. Instead, each template image receives multiple labellings: one
from each atlas image. A second round of basic multi-atlas segmentation uses the
template library to segment the entire set of target images (including those
images used in the template library). Label fusion in this final step fuses all
labels from all templates. To summarize, figure \ref{alg:MAGeT} describes the
\mb algorithm in pseudocode.  

Source code for \mb can be found at
\url{http://github.com/pipitone/MAGeTbrain}.

\begin{algorithm}
  \scriptsize
  \caption{Pseudocode for the \mb algorithm}
  \label{alg:MAGeT}
  \begin{algorithmic}
    \Function{BasicMultiAtlasSegmentation}{Templates, Subjects}
      \ForAll{$target$}
        \ForAll{$template$}
          \State propagate all labels for template to target space
          \State store target labels
        \EndFor
        \State fuse target labels
      \EndFor
    \EndFunction
    \\
    \Function {MAGeTBrain}{Subjects, Atlases, n}
      \For{$i = 1 \to n$}
        \State choose a target to be used as a template
        \State propagate labels from each atlas to template space
        \State store the template with all of its labels
      \EndFor
      \State MultiAtlas(Templates, Subjects)
    \EndFunction
  \end{algorithmic}
\end{algorithm}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                       Registration Methods                          %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Registration Methods}

Before registration, all images underwent preprocessing with the N3 algorithm
\citep{Sled1998} to minimize intensity nonuniformity. In our experiments we use
one of two non-linear image registration methods.

\subsubsection{Automatic Normalization and Image Matching and Anatomical
Labeling (\animal)}

The \animal algorithm carries out image registration is in two phases. In the
first, a 12-parameter linear transformation (3 translations, rotations, scales,
shears) is estimated between images using an algorithm that maximizes the
correlation between blurred MR intensities and gradient magnitude over the whole
brain \citep{Collins}. In the second phase, nonlinear registration is completed
using the \animal algorithm \citep{Collins1995}: an iterative procedure that
estimates a 3D deformation field between two MR images. At first, large
deformations are estimated using blurred version of the input data. These larger
deformations are then input to subsequent steps where the fit is refined by
estimating smaller deformations on data blurred with a Gaussian kernel with a
smaller FWHM. The final transformation is a set of local translations defined on
a bed of equally spaced nodes that were estimated through the optimization of
the correlation coefficient.  For the purposes of this work we used the
regularization parameters optimized in Robbins et al. \citep{Robbins2004},
displayed in table \ref{tab:ANIMAL-params}. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ANIMAL parameters                    
%                                     
\begin{table}[!tbp]
\begin{center}
\caption{\animal  registration parameters}
\begin{tabular}{l | c c c}
\hline 
Parameters        & Stage 1 & Stage 2 & Stage 3  \tabularnewline
\hline 
Model Blur (FWHM) &   8     &    8    &   4      \tabularnewline
Input Blur (FWHM) &   8     &    8    &   4      \tabularnewline
Iterations        &   30    &    30   &   10     \tabularnewline
Step              &   8x8x8 &  4x4x4  &   2x2x2  \tabularnewline
Sub-Lattice       &   6     &    6    &   6      \tabularnewline
Lattice Diameter  &24x24x24 &12x12x12 & 6x6x6    \tabularnewline
\hline
\end{tabular}
\end{center}
\label{tab:ANIMAL-params}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Automatic Normalization Tools (\ants)}

\ants is a diffeomorphic registration algorithm which provides great flexibility
over the choice of transformation model, objective function, and the consistency
of the final transformation. The transformation is estimated in a hierarchical
fashion where the MRI data is subsampled, allowing large deformations to be
estimated and successively refined at later hierarchical stages (where the data
is subsampled to a finer grid). The deformation field and the objective function
are regularized with a Gaussian kernel at each level of the hierarchy. The \ants
algorithm is freely available \url{http://www.picsl.upenn.edu/ANTS/}. We used an
implementation of the \ants algorithm compatible with the MINC data format,
mincANTS \url{https://github.com/vfonov/mincANTS}.

We used the following command line when running \ants:
{\small
\begin{verbatim}
  mincANTS 3 -m PR[target_file.mnc,source_file.mnc,1,4] 
   --number-of-affine-iterations 10000x10000x10000x10000x10000 
   --affine-gradient-descent-option 0.5x0.95x1.e-4x1.e-4
   --use-Histogram-Matching --MI-option 32x16000
   -r Gauss[3,0] -t SyN[0.5] -i 100x100x100x20
   -o transformation.xfm
 \end{verbatim}
}
These settings were adapted from the "reasonable starting point" given in the
\ants manual 
\footnote{\url{https://sourceforge.net/projects/advants/files/Documentation/}}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                           Label Fusion                              %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Label fusion methods}
Label fusion is a term given to the process of combining the information from
several candidate labellings for an intensity image into a single labelling.  In
this paper we explore three fusion methods. 

\begin{description}
  \item[Voxel-wise Majority Vote] \hfill \\
  Labels are propagated from all template library images to a target.  Each
  output voxel is given the most frequent label at that voxel location amongst
  all candidate labellings.  Ties are broken arbitrarily.

  \item[Cross-correlation Weighted Majority Vote] \hfill \\
  An optimal combination of targets from the template library has previously been
  shown to improve segmentation accuracy \citep{Aljabar2009,Collins2010}.  In this
  method, each template library image is ranked in similarity to each unlabelled 
  image by the normalized cross-correlation (CC) of image intensities after linear
  registration, over a region of interest (ROI) generously encompassing the 
  hippocampus.  Only the top ranked template library image labels are used in a
  voxel-wise majority vote. The ROI is heuristically defined as the extent of all
  atlas labels after linear registration to the template, dilated by three voxels
  \citep{Chakravarty2012}.  The number of top ranked template library image labels
  is a configurable parameter.

  The {\tt xcorr\_vol} utility from the \animal toolkit is used to calculate the
  cross-correlation similarity measure.  
 
  \item[Normalised Mutual Information Weighted Majority Vote] \hfill \\
  This method is similar to cross-correlation weighted voting except that image
  similarity is calculated by the normalised mutual information score over the
  region of interest\citep{Studholme2001}.  The {\tt itk\_similarity} utility
  from the EZMinc toolkit\footnote{\url{https://github.com/vfonov/EZminc}} is
  used to calculate the normalised mutual information measure between to images.
\end{description}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                            Experiments                              %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Experiments}

The following section describes the experiments we conducted to assess the
segmentation quality of the \mb algorithm. The first two experiments assess the
validity of \mb using a cross-validation design. Experiment 1 investigates the
accuracy of \mb whole hippocampus segmentation over a wide range of parameter
settings. This enables us to choose the parameter settings offering the best
performance for use in subsequent experiments. Experiment 2 tests hippocampal
subfield segmentation quality. The last two experiments assess the validity of
the \mb algorithm when applied to different diseases: Alzheimer's disease
(Experiment 3) and first episode schizophrenia patients (Experiment 4). 


%The ADNI experiment includes comparison of volumes with other automated
%segmentation methods. Evaluation is done by correlating volumes b/c overlap
%metrics assume identical segmentation protocol. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                                                                     %%%%%
%%%%%         Experiment 1: Whole Hippocampus Cross-Validation            %%%%%
%%%%%                                                                     %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection*{Experiment 1: Whole Hippocampus Cross-Validation}

To test the effect of parameter settings on the \mb algorithm, Monte
Carlo Cross-Validation (MCCV) \citep{Shao1993} was performed using a subset of
the ADNI1 dataset for validation (see below).  This form of cross-validation
allows us to validate \mb with various atlas and template library sizes,
registration and label fusion methods.

Monte Carlo Cross-Validation (MCCV), also known as repeated random sub-sampling
cross-validation, consists of repeated rounds of validation in which items from
the dataset are randomly sampled (without replacement) and assigned to a
training set or validation set \cite{Shao1993}.  

In this experiment, each validation round consists of the following steps. First, 
an atlas library is selected (the training set) and, from the remaining images, 
a template library and subject to be segmented is chosen (the validation set). 
Second, \mb and basic multi-atlas segmentation are performed on the subject using the 
selected atlas and template libraries. Third, the accuracy of the resulting 
segmentations are measured against the SNT labels. 

A total of ten validation rounds are perfomed on each subject in the dataset,
for each combination of parameter settings. Reported subject segmentation
accuracy is the averaged over the ten validation rounds. The parameter settings
we explore are: atlas library size (1-9), template library size (1-20),
registration method (\ants vs.  \animal), and label fusion method (MV, XC-WV,
NMI-WV). A total of $10*69*9*20*2*3 = 7452000$ validation rounds were conducted,
resulting in a total of 1'490'400 segmentations analysed. 

\subsubsubsection{Dataset evaluated.} 

69 1.5T images were arbitrarily selected from the {\em ADNI1:Complete 1Yr 1.5T}
standardized dataset. 23 subjects were chosen from each disease category
(cognitively normal (CN), MCI and AD). Demographics for this subset are shown in
Table \ref{tab:ADNI1-xvalidation-demographics}. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% ADNI1 X-Validation Dataset Demographics Table
%
<<ADNI-Xval-demographics, echo=F, results="asis",cache=FALSE>>=
adni_69_RIDs = c(295,413,619,685,729,782,938,954,1018,1155,907,981,222,324,448,
                 546,553,572,602,610,814,1341,675,681,731,1130,41,68,70,101,
                 249,293,316,414,698,1206,1222,1339,751,1030,3,5,10,16,22,53,
                 168,183,241,1205,328,1095,991,213,159,337,343,642,753,1109,
                 1217,29,56,1188,1293,149,382,431,1202)
tab <- summary(DX.bl ~ AGE + PTGENDER + PTEDUCAT + PTETHCAT + CDRSB + ADAS13 +
               MMSE, data = adnimerge, subset = VISCODE == 'bl' & RID %in%
               adni_69_RIDs, method = "reverse", test=FALSE, overall=TRUE)

latex(tab, file="", size="scriptsize",landscape=FALSE, ctable=FALSE,
      caption="ADNI-1 cross-validation subset demographics", 
      title="tab:ADNI1-xvalidation-demographics")
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The atlas and template libraries are selected from the dataset evaluated.
Atlases consist of images taken from the dataset, with corresponding manual
labels provided by SNT. Template library images were selected at random from
remaining images not used as atlases. The atlas library size ranged from 1 to 9
images. Template library size ranged from 1 to 20 images. 

Both the \ants and \animal registration methods were used. 

Majority vote, cross-correlation weighted majority vote, and
Normalized Mutual Information weighted majority vote were used. With the
weighted majority vote fusion methods, the number of top labels used in the
fusion was varied from 1 to 20 images.

\subsubsubsection{Evaluation method}  

The Dice similarity coefficient (DSC) assesses the agreement between two
segmentations.  It is one of the most widely used measures of segmentation
performance, and we use it as the basis of comparison throughout this paper.
Additionally, we report the Jaccard index, another commonly used similarity
measure:

 \[\text{Dice's coefficient (DSC)} = \frac{2|A \cap B|}{|A| + |B|}\]

 \[\text{Jaccard (J)} = \frac{|A \cap B|}{|A \cup B|} = \frac{DSC}{(2-DSC)}\]

where $A$ and $B$ are the regions being compared, and the cardinality is the
volume measured in voxels. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                                                                     %%%%%
%%%%%        Experiment 2: Hippocampal Subfield Cross-Validation          %%%%%
%%%%%                                                                     %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Winterburn Atlases Cross-Validation}
In this experiment, the accuracy of the \mb algorithm on hippocampal subregion
segmentation is tested using a leave-one-out cross-validation (LOOCV) design.
Leave-one-out-cross-validation (LOOCV) is performed separately for each dataset
evaluated (WA-BRAVO, and WA-Resampled) as follows. Each subject in the dataset
is segmented by \mb using an atlas library in which that subject's image is
excluded. 

The atlas library is composed of the Winterburn T1 atlas images and hippocampal
subregion segmentations. The template library consists of 15 3T T1 images
(0.9mm-isotropic voxels) of healthy subjects as well as all of the images from
the dataset being evaluated.  

- note registration and fusion method were chosen 
\todo{reference, demographics for health control images}.

\subsubsubsection{Dataset evaluated} 
\mb segmentations are evaluated on two datasets. The WA-BRAVO dataset consists
of separately acquired 3T T1 BRAVO images (0.9mm-isotropic voxel) of four of the
five Winterburn atlas subjects.  The WA-Resampled dataset consists of the
Winterburn atlas images and segmentations downsampled to 0.9mm-isotropic voxel
resolution.


\subsubsubsection{Evaluation method}  
The segmentation volumes of each hippocampal subregion are compared to
the expert manual segmentations of the unmodified Winterburn atlases.  As a
point of comparison, we also calculate the subregion volumes from the Winterburn
atlas segmentations after downsampling to 0.9mm-isotropic voxels. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                                                                     %%%%%
%%%%%         Experiment 3: Application of \mb to the segmentation        %%%%%
%%%%%                       of schizophrenia patients                     %%%%%
%%%%%                                                                     %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{SZ First Episode Patient Validation}
To validate that \mb algorithm works effectively with diseased brain images the
performance of \mb is measured on a Schizophrenia dataset.

The atlas library is composed of the Winterburn T1 atlas images, with whole
hippocampus segmentations (no subregions). The template library is composed of
21 images selected at random from the SZFEP dataset. 

- note registration and fusion method were chosen 
\subsubsubsection{Dataset Evaluated}

\subsubsubsection{Evaluation method}
The manual segmentation protocol used to segment the Winterburn atlases is
similar to, but different from, the protocol used to segment the SZFEP dataset.
Therefore, rather than use an overlap metric, \mb hippocampal volumes are
compared to the corresponding manual segmentation volumes. 



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                                                                     %%%%%
%%%%%         EXPERIMENT 3: Application of \mb to the segmentation        %%%%%
%%%%%                       of ADNI subjects                              %%%%%
%%%%%                                                                     %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Experiment 4: Segmentation of Alzheimer's Disease Patients}

To test the accuracy of \mb on a real-world task we segment the entire
ADNI-1 dataset using an atlas set that is not representative of the target set.

The Winterburn atlases were used as the atlas
library.  The template library consisted of 21 randomly selected images from the
ADNI1 data dataset (7 healthy, MCI and AD subjects). 

- note registration and fusion method were chosen 

\ref{tab:ADNI1-scr-tmpllib-demographics}.

\subsubsubsection{Dataset evaluated} 
All images from the {\em ADNI1:Complete 1Yr 1.5T}
standardized dataset.


\subsubsubsection{Evaluation method}
Since the hippocampal segmentation protocols differ between the ADNI labels and
Winterburn atlases, this poses a problem for direct evaluation between labels
produced by \mb and the ADNI labels in terms of overlap; we would not expect
different segmentation protocols to have a high degree of overlap.  Instead, to
evaluate the performance of \mb we compare the correlation of \mb segmentation
volumes with manual segmentation (SNT) volumes.  Additionally, we correlate the
hippocampal volumes of established automated segmentation methods to \mb
segmentations.  

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% ADNI1 Complete 1Yr Template Library Demographics Table
%
%
% <<ADNI1-scr-tmpllib-demographics, echo=F, results="asis",cache=FALSE>>=
% scr_tmpllib_RIDs = c(0295, 0413, 0619, 0685, 0729, 0782, 0938, 0954, 1018, 1155,
%                  0907, 0981, 0448, 0553, 0814, 1130, 0698, 1339, 1095, 0991,
%                  0159)
% tab <- summary(DX.bl ~ AGE + PTGENDER + PTEDUCAT + PTETHCAT + CDRSB + ADAS13 +
%                MMSE, data = adnimerge, subset = VISCODE == 'bl' & RID %in%
%                scr_tmpllib_RIDs, method = "reverse", test=FALSE, overall=TRUE)
% 
% latex(tab, landscape=FALSE, ctable=FALSE, file="", size="scriptsize",
%       caption="ADNI1 Complete 1Yr Template Library demographics", 
%       title="tab:ADNI1-scr-tmpllib-demographics")
% @
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%                             Subjects                                 %%%%%
\subsection{Subjects}

\subsubsection{Winterburn Atlases}
The Winterburn atlases \citep{Winterburn2013} are digital hippocampal segmentations
of of five in-vivo 300u isotropic T1-weighted MR images. The segmentations
include subfield segmentations for the cornus ammonis (CA) 1, CA4, dentate
gyrus, subiculum, and CA 2 and 3 combined. Subjects in the Winterburn atlases
range in age from 29-57 years (mean age of 37), and include two males and three
females.  

In addition to the high-resolution scans distributed as part of the Winterburn
atlases, we also obtained additional T1 BRAVO scans of four of the five
subjects.  \todo{demographics?}\todo{explain scan parameters in more detail..}

\subsubsubsection{FEP dataset}
All patients were recruited and treated through the Prevention and Early
Intervention Program for Psychoses (PEPP-Montreal), a specialized early
intervention service at the Douglas Mental Health University Institute in
Montreal, Canada. People aged 15–30 years from the local catchment area
suffering from either affective or non-affective psychosis who had not taken
antipsychotic medication for more than one month with an IQ above 70 were
consecutively admitted as either in- or out-patients. Of those treated at PEPP,
only patients aged 18 to 30 years with no previous history of neurological
disease or head trauma causing loss of consciousness were eligible for the
neuroimaging study; only those suffering from schizophrenia spectrum disorders
were considered for this analysis.  For complete program details see Malla et
al. \citep{Malla2003}. 

Scanning was carried out at the Montreal Neurological Institute on a 1.5-T
Siemens whole body MRI system.  Structural T1 volumes were acquired for each
participant using a three-dimensional (3D) gradient echo pulse sequence with
sagittal volume excitation (repetition time=22ms, echo time=9.2ms, flip
angle=$30{\circ}$, 180 1mm contiguous sagittal slices). The rectangular
field-of-view for the images was 256mm (SI)×204mm (AP).  Subject demographics
are shown in table \ref{tab:SZFEP-Demographics}. 

The hippocampus were traced following a validated protocol developed by Dr Jens
Pruessner \todo{cite: (Pruessner et al., 2000)}. A recent update to this
protocol by Dr J Pruessner in 2006 allows to accurately and consistently
subdivide the hippocampus into three different subregions: head, body, and tail.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% First Episode SZ Demographics Table
%
<<FEP-SZ-demographics, echo=F, results="asis",cache=FALSE>>=
fep_sz_demographics = read.csv("data/SZ_demographics.csv", na.strings=c("","."))
fep_sz_demographics = subset(fep_sz_demographics, Anon <= 81)
tab <- summary(DX ~ Age + Gender + Handedness + Education + SES + FSIQ,
               data=fep_sz_demographics, method = "reverse", test = FALSE)
latex(tab, file="", ctable=FALSE,
      caption="Schizophrenia First Episode Patient Demographics",
      title="tab:SZFEP-Demographics")
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\subsubsection{ADNI1 1.5T Complete 1Yr Dataset}
Clinical, demographic and pre-processed T1-weighted MRI were downloaded by the
authors from the ADNI1 database (adni.loni.ucla.edu) between March 2012 and
August 2012. The image dataset download was the "ADNI1:Complete 1Yr 1.5T"
standardized dataset available from ADNI \footnote{
\url{http://adni.loni.ucla.edu/methods/mri-analysis/adni-standardized-data/}}
\citep{Wyman2012}. This image collection contains uniformly preprocessed images
which have been designated to be the "best" after quality control.  All images
were acquired using 1.5T scanners (General Electric Healthcare, Philips Medical
Systems or Siemens Medical Solutions) at multiple sites using the protocol
described in \citep{Jack2008a}.  Representative 1.5T imaging parameters were TR
= 2400ms, TI = 1000ms, TE = 3.5ms, flip angle = $8{\circ}$, field of view = 240
x 240mm, a 192 x 192 x 166 matrix (x, y, and z directions) yielding a voxel
resolution of 1.25 x 1.25 x 1.2 $mm^3$. Clinical and demographic data are shown
in table \ref{tab:ADNI1-1.5T-Complete-1Yr-Dataset-Demographics}. 

% The following blurb is taken (except for the first sentence) verbatim 
For a subset of ADNI1 images, labels of the left and right hippocampi are
available (herein refered to as SNT labels).  Semi-automated hippocampal
volumetry was carried out using a commercially available high dimensional brain
mapping tool (Medtronic Surgical Navigation Technologies, Louisville, CO), that
has previously been validated and compared to manual tracing of the hippocampus
\citep{Hsu2002}. Measurement of hippocampal volume is achieved first by placing
manually 22 control points as local landmarks for the hippocampus on the
individual brain MRI data: one landmark at the hippocampal head, one at the
tail, and four per image (i.e., at the superior, inferior, medial and lateral
boundaries) on five equally spaced images perpendicular to the long axis of the
hippocampus. Second, fluid image transformation is used to match the individual
brains to a template brain \citep{Christensen1997}. The pixels corresponding to
the hippocampus are then labeled and counted to obtain volumes. This method of
hippocampal voluming has a documented reliability of an intraclass coefficient
better than .94 \citep{Hsu2002}.

%Representative 3T image parameters were TR = 2300ms, TI = 900ms, TE = 3.0ms,
%flip angle = $8{\circ}$, field of view = 256 x 240mm, a 256 x 256 x 166 matrix
%(x, y, and z directions) yielding a voxel resolution of 1.00 x 1.00 x 1.2
%$mm^3$.

%                                                                             
%                                                                             
% ADNI1 Complete 1Yr Dataset Demographics Table 
%                                                                             
%                                                                             
<<ADNI1-scr-demographics, echo=F, results="asis",cache=FALSE>>=
# RID < 2000 ensures only ADNI1 patients
yr1 = read.csv("data/ADNI_baseline_volumes/ADNI1_Complete_1Yr_1.5T_11_15_2012.csv")
yr1$VISCODE <- factor(yr1$Visit, levels = c(1,2,3,4), labels=c("bl","m03","m06","m12"))
yr1 = subset(yr1, !grepl("Scaled_2", Description))
yr1 = yr1[,c("RID","VISCODE")]

adnimerge_yr1 = merge(adnimerge, yr1) 
tab <- summary(DX.bl ~ AGE + PTGENDER + PTEDUCAT + PTETHCAT + CDRSB + ADAS13 +
               MMSE, data = adnimerge, 
               subset =  adnimerge_yr1, #RID %in% yr1$RID & VISCODE %in% c('bl','m06','m12'),   
               method = "reverse", test=FALSE, overall=TRUE)

latex(tab, file="", size="scriptsize", 
    caption="ADNI1 1.5T Complete 1Yr dataset demographics",
    label="tab:ADN1-1.5T-Complete-1Yr-Dataset-Demographics")
@ %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                               Results
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Results}

%%%%%
%%%%%                  Results: ADNI-1 cross-validationn                   %%%%%
%%%%%
\subsection{ADNI1 Cross-Validation}


%                                                                              %
% ADNI1 Complete 1Yr Validation - results preparation                             %
%                                                                              %
<<ADNI1-xval-load, include=FALSE, cache=TRUE>>=
# all data from the validation trials
a_data       = read.csv(gzfile('data/a2a_ants/results_2013_01_03.csv.gz'))
#t_data       = read.csv(gzfile('data/a2a_tracc/xfmtrials_results_2013-04-01.csv.gz'))
t_data       = read.csv(gzfile('data/a2a_tracc/results_xfmjoin_2013_04_04.csv.gz'))
diagnoses    = read.csv('data/a2a_diagnoses.csv')
@

<<ADNI1-xval-prep,dependson='ADNI1-xval-load',include=FALSE,cache=TRUE>>=
# simplify the data
t_data       = subset(t_data, atlases %in% c(1,3,5,7,9))
a_data       = subset(a_data, atlases %in% c(1,3,5,7,9))
t_data$se    = NULL
t_data$sn    = NULL
t_data$j     = NULL
a_data$se    = NULL
a_data$sn    = NULL
a_data$j     = NULL       

# add registration method column 
t_data       = cbind(t_data, reg_method = "ANIMAL")
a_data       = cbind(a_data, reg_method = "ANTS")

# separate MA majvote from MB so we can compute differences
# we only compare multiatlas using majority vote
t_ma = subset(t_data, approach=="ma" & method=="majvote")
t_ma$approach="multiatlas"
a_ma = subset(a_data, approach=="multiatlas" & method=="majvote")
t_mb = subset(t_data, approach=="mb")
a_mb = subset(a_data, approach=="mb")

ma = rbind(t_ma,a_ma)
mb = rbind(t_mb,a_mb)

# set up a few equivalences for multi-atlas, to make nomenclature simpler
ma$templates =  ma$atlases  # because no template library
mb[mb$method != 'majvote',]$templates = mb[mb$method != 'majvote',]$top_n 

# aggregate over batches
ma_mean = aggregate(k ~ subject + reg_method + approach + method + atlases + templates + top_n + label, data = ma, mean)
mb_mean = aggregate(k ~ subject + reg_method + approach + method + atlases + templates + top_n + label, data = mb, mean)                    

all_data = merge(ma, mb, by=c("timestamp", "atlases", "batch", "label", "reg_method", "subject"), 
                 suffixes=c(".ma", ".mb"))

all_data_mean = merge(ma_mean, mb_mean, by=c("reg_method", "label", "atlases", "subject"), 
                 suffixes=c(".ma", ".mb"))

all_data$k_diff = all_data$k.mb - all_data$k.ma
all_data_mean$k_diff = all_data_mean$k.mb - all_data_mean$k.ma

vote_levels <- list("Majority Vote" = "majvote", 
                      "NMI Vote" = "nmi", 
                      "Cross-correlation Vote" = "xcorr")
levels(all_data$method.mb) <- vote_levels
levels(all_data_mean$method.mb) <- vote_levels

all_data       = merge(all_data, diagnoses)
all_data_mean  = merge(all_data_mean, diagnoses)
remove(t_ma, a_ma, t_mb, a_mb, ma, mb)
@
%                                                                              %
%                                                                              %

%
% synonyms for significant: 
% powerful, suggestive, apparent, definite, evident, large, marked, material, 
% noticeable, plain, pronounced, substantial, substantive, 
%
% antonyms: 
% negligible, minor, no appreciable, scant

In this experiment we conducted 10 rounds of \mb and multi-atlas segmentation of
each of 69 subjects at a range of atlas and template library sizes, registration
algorithm (\ants or \animal), and three label fusion techniques.  Hippocampal
\mb-based segmentations using both \animal and \ants registration algorithm
demonstrate good overlap with manually derived gold-standards (Figure
\ref{fig:ADNI1-xval-k-mean}). Qualitatively, both \animal and \ants-based
segmentations demonstrate trend overlap accuracy that increases with the size of
atlas library and template library. Improvement in accuracy diminishes noticeably
with template libraries larger than ten images. 

No marked difference in segmentation accuracy is seen when either \animal or \ants
registration is used with different label fusion techniques, at any atlas or
template library sizes.  In every parameter configuration, the use of \mb with
\ants registration shows a pronounced increase in segmentation accuracy over \mb with \animal
registration. In the remainder of this section, only results using the \ants
registration algorithm will be shown.

It is interesting to note that with an even number of templates, \mb shows a
small decrease in performance relative to when one fewer template image is used.
See section \todo{ref} for a discussion of this behaviour. In the remainder of
this section, only results from odd-sized template libraries will be shown. 

\begin{figure}
<<ADN1-xval-k-mean, cache=TRUE, dependson='ADNI1-Xval-prep'>>=
ggplot(all_data_mean, 
       aes(x=templates.mb,y=k.mb, colour=as.factor(atlases))) + 
  facet_grid(reg_method~method.mb) + 
  stat_summary(fun.y=mean,geom='line',
               aes(y=k.mb, weight=1)) + 
  #stat_smooth(method='lm', formula=y~log(x)) + 
  scale_colour_hue(name="Atlases") +
  xlab( "Number of Templates" ) + 
  ylab( "Mean DSC" ) + 
  opts(legend.direction = "horizontal", legend.position = "bottom")
@
  \label{fig:ADNI1-xval-k_mean}
  \caption{
  {\bf Mean DSC by atlas and template library size, registration algorithm,
  and label fusion method.} The mean DSC score is calculated over all subjects 
  from the ADNI1 Cross-Validation dataset for each parameter setting.}
\end{figure}

With an increasing number of templates, \mb-based segmentating using \ants
registration and majority vote label fusion shows improvement in overlap
accuracy over multi-atlas-based segmentation, using the same number of atlases
and voting method (Figure \ref{fig:ADNI1-xva-k-diff}). The magnitude of improvement over
multi-atlas-based segmentation decreases with an increasing number of atlases,
with accuracy converging with 7 atlases.  Peak improvement in \mb accuracy (~0.02
DSC) is found when one atlas is used with a template library of 20 images.

\todo{mention failures}

\begin{figure}
<<ADN1-Xval-k-diff, cache=TRUE, dependson='ADNI1-Xval-prep'>>=
ggplot(subset(all_data_mean, reg_method=="ANTS" & method.mb=="Majority Vote" &
                templates.mb %in% seq(1,20,2)), 
       aes(x=templates.mb, y=k_diff, colour=as.factor(atlases))) + 
  #facet_grid(reg_method~method.y) + 
  stat_summary(fun.data=mean_cl_boot,geom='errorbar',
               aes(y=k_diff,colour=as.factor(atlases), width=0.2)) +
  stat_summary(fun.y=mean, geom="point", 
               aes(y=k_diff,colour=as.factor(atlases))) + 
  stat_summary(fun.y=mean, geom="line", 
               aes(y=k_diff,colour=as.factor(atlases))) + 
  #stat_smooth(method=lm, formula=y~log(x)) + 
  geom_hline(aes(alpha=0.5, yintercept=0), linetype='dashed') + 
  scale_x_continuous(breaks=seq(1,20,2)) + scale_y_continuous(breaks=seq(-1,1,by=0.01)) + 
  scale_colour_hue(name="Atlases") +
  scale_alpha_continuous(legend=FALSE) + 
  scale_linetype_discrete(legend=FALSE) + 
  xlab( "Number of Templates" ) + 
  ylab( "Increase in mean DSC between MAGeT brain and multiatlas" ) +
  opts(legend.direction = "horizontal", legend.position = "bottom")
@
  \caption{The difference in mean DSC between \mb and multi-atlas segmentations for 
  a range of parameter settings.}
  \label{ADNI1-xval-k-diff}
\end{figure}


In addition to an improvement in accuracy over multi-atlas-based segmentation,
\mb also shows a decrease in the variability of segmentation accuracy 
(Figure \todo{ADNI1-xval-variability}).  The size of template library 
necessary to reach a significant (p<0.5) decrease in variance and standard 
deviation grows with the size of atlas library used.  A template library of 19
images is sufficient to show significant decrease in variance and standard 
deviation for 3-7 atlases. 

\begin{figure}
<<ADN1-Xval-variability, cache=TRUE, dependson='ADNI1-Xval-prep'>>=
ANTSmajvote = subset(all_data, 
                     reg_method=="ANTS" & 
                     method.mb=="Majority Vote" &
                    templates.mb %in% seq(1,20,2))

data.stats = ddply(ANTSmajvote, c("subject", "label","atlases","templates.mb"), function (df) {
  data.frame(
    MA.sd  =  sd(df$k.ma),
    MB.sd  =  sd(df$k.mb),
    MA.var = var(df$k.ma),
    MB.var = var(df$k.mb)
  )
})

stats.tests = ddply(data.stats, c("atlases","templates.mb"), function (df) {
  t.var = t.test(df$MA.var, df$MB.var)
  t.sd  = t.test(df$MA.sd , df$MB.sd)
  data.frame(
    stat      = c("Variance", "Standard Deviation"),
    statistic = c(t.var$statistic, t.sd$statistic),
    p.value   = c(t.var$p.value, t.sd$p.value),
    direction = c(t.var$statistic < 0, t.sd$statistic < 0)
  )
})

ggplot(stats.tests, 
  aes(x=templates.mb, y=p.value, colour=as.factor(atlases), 
      size = abs(statistic))) + 
  facet_grid( . ~ stat) + 
  geom_line(aes(size=0.1,area=0.1)) + 
  geom_point(aes(shape = factor(direction))) + 
  geom_hline(aes(yintercept=0.05, alpha=0.5), linetype='dashed') + 
  geom_hline(aes(yintercept=0.01, alpha=0.5), linetype='dashed') + 
  scale_shape_discrete("t-statistic sign", labels=c("positive","negative")) + 
  scale_size_area(name="t-statistic magnitude") + 
  scale_x_continuous(breaks=seq(1,20,by=2)) + 
  scale_y_log10(limits=c(0.001,1), breaks=c(0.01,0.05,0.1,1.0)) + 
  xlab( "Number of Templates" ) + 
  ylab( "p-value" ) +
  scale_colour_hue(name="Atlases") +
  scale_alpha_continuous(guide='none') + 
  scale_linetype_discrete(guide='none') + 
  scale_size_continuous(guide='none') + 
  opts(legend.direction = "horizontal", legend.position = "bottom")
@
  \caption{{\bf Difference in variability of \mb vs. multi-atlas segmentation 
  accuracy.}
  Variability of segmentation accuracy within 10 rounds of validation per subject. 
  Standard deviation and variance is computed per subject for both \mb and 
  multi-atlas, and the distribution of these test statistics is compared with a 
  t-test. The p-value of this test, is shown on the y-axis (scaled logarithmically).}
  \label{ADNI1-xval-variability}
\end{figure}

% <<ADNI1-Xval-sd-by-subject, cache=TRUE>>=
% SDs = data.stats[c('subject','label','atlases','templates.mb','MA.sd','MB.sd')]
% SDs = subset(SDs, templates.mb %in% c(5,10,15,20) & atlases == 5)
% 
% melted = melt(SDs, measure.vars=c('MA.sd','MB.sd'))
% ggplot(melted, aes(x=templates.mb, y=value, 
%                    group=interaction(templates.mb, variable), colour=as.factor(variable))) + 
%   scale_x_continuous(breaks=c(5,10,15,20)) + 
%   geom_violin() 
% @
% \begin{figure}
% <<ADN1-Xval-k-diff-ANTS-20tmpls, cache=TRUE, dependson='ADNI1-Xval-prep'>>=
% a_20_tmpls = subset(all_data_mean, 
%                       reg_method  == "ANTS" &
%                       method.mb   == "Majority Vote" &
%                       templates.mb== 20)
% ggplot(a_20_tmpls, aes(x=factor(atlases))) +
%   #geom_point(aes(y=k.mb,group=1,colour="MAGeT"),position="jitter") + 
%   #geom_point(aes(y=k.ma,group=2,colour="MA"),position="jitter") + 
%   geom_violin(aes(y=k.mb,group=factor(atlases),colour="MAGeT")) + 
%   geom_violin(aes(y=k.ma,group=factor(atlases),colour="MA")) + 
%   geom_smooth(aes(y=k.mb,group=1,colour="MAGeT")) +
%   geom_smooth(aes(y=k.ma,group=2,colour="MA")) +
%   
%   #stat_summary(fun.y=mean,geom='point',size=3,colour="red",aes(y=k.ma)) +
%   #stat_summary(fun.y=mean,geom='line',colour="red",aes(y=k.ma,group=1)) +
%   #stat_summary(fun.y=mean,geom='point',size=3,colour="blue",aes(y=k.mb)) +
%   #stat_summary(fun.y=mean,geom='line',colour="blue",aes(y=k.mb,group=1)) +
%   labs(x="Number of Atlases", y = "Kappa", 
%        title="mean Kappa of MA and MAGeT brain (ANTS/20 templates) \nvs\natlas library size") +
%   scale_colour_hue(name="Method") + 
%   coord_cartesian(ylim=c(0.7,0.9))
%   #theme(legend.justification=c(1,0), legend.position=c(1,0))
% @
%   \caption{Change in mean Kappa between multi-atlas and \mb using \ants,
%   20 templates}
%   \label{}
% \end{figure}
% 
% \begin{figure}
% <<ADN1-Xval-ANTS-20tmpls-t-test-sd, cache=TRUE, dependson='ADNI1-Xval-prep'>>=
% a_20_tmpls = subset(all_data, 
%                       reg_method  == "ANTS" &
%                       method.mb    == "Majority Vote" &
%                       templates.mb == 20 &
%                       atlases     == 9 & 
%                       volume.ma < 10000)
% stddev = ddply(a_20_tmpls, c("subject", "label"), function (df) {
%   data.frame(
%     MA = sd(df$k.ma),  #MA
%     MB = sd(df$k.mb)  #MB
%   )
% })
% 
% 
% # TODO: against SNT
% melted = melt(stddev, id.vars=c("subject", "label"))
% ggplot(melted, aes(x=variable, y=value)) + geom_boxplot()
% t.test(stddev$MA, stddev$MB)
% @
%   \caption{}
%   \label{}
% \end{figure}
% 
%

Finally, \mb segmentation volumes show differential agreement with manual (SNT) 
volumes throughout the range of hippocampal volumes (Figure 
\ref{ADNI1-xval-Bland-Altman}). \mb shows a negligble fixed bias towards 
producing smaller segmentations, and shows a slight proportional bias towards 
smaller segmentations with larger hippocampi.
\todo{Note limits of agreement?}

\todo{Include multi-atlas 9-atlas in plot as a comparison} 

\begin{figure}
<<ADN1-xval-Bland-Atlman, cache=TRUE, dependson='ADNI1-Xval-prep', fig.width=8, fig.height=8>>=
df_subset = subset(all_data, 
                      reg_method   == "ANTS" &
                      method.mb    == "Majority Vote" &
                      templates.mb %in% c(1,11,19) &
                      atlases      %in% c(1,5,9) &
                      volume.ma     < 10000)

# get SNT data formatted like 
snt   = read.csv("data/a2a_snt_volumes.csv")
df_merged = merge(df_subset, snt, all.x = TRUE)

hc_vol = ddply(df_merged, c("subject", "label", "atlases", "templates.mb"), function (df) {
  data.frame(
    snt = sum(df$volume.snt),
    ma = sum(df$volume.ma),
    mb = sum(df$volume.mb)
  )
})
hc_vol$diff = hc_vol$snt - hc_vol$mb

group.stats = ddply(hc_vol, c("atlases", "templates.mb"), function (df) {
  data.frame(
    mean = mean(df$diff),
    sd   = sd(df$diff)
  )
})
hc_vol = merge(hc_vol, group.stats)
hc_vol$Atlases = hc_vol$atlases
hc_vol$Templates = hc_vol$templates.mb

ggplot(hc_vol, aes(x=ma, y = diff, group=Atlases)) + 
    geom_hline(aes(yintercept = mean + c(-2, 0, 2) * sd, colour='brown'), 
                linetype=2) + 
    geom_point() + 
    geom_smooth(method="lm") + 
  facet_grid(Atlases~Templates, labeller = label_both) + 
  xlab(expression('Mean manual and MAGeT-Brain total hippocampus volume ' (mm^3))) + 
  ylab(expression('Manual - MAGeT-Brain total hippocampus volume ' (mm^3))) 
@
  \caption{Bland-Altman plots comparing manual and \mb hippocampal volumes 
  when using a varying number of atlases and templates.}
  \label{ADNI1-xval-Bland-Altman}
\end{figure}
% 
% 
% \begin{figure}
% <<ADN1-Xval-k-by-disease, cache=TRUE, dependson='ADNI1-Xval-prep'>>=
% a_20_tmpls = subset(all_data, 
%                       reg_method  == "ANTS" &
%                       method.y    == "Majority Vote" &
%                       templates.y == 20 &
%                       atlases %in% c(1,9))
% template_library = read.csv('data/a2a_ants/template_library_composition.csv')
% template_library$subject = NULL
% a_20_tmpls = merge(a_20_tmpls, template_library,
%                    by.x=c('timestamp', 'templates.y'), 
%                    by.y=c('timestamp', 'templates'))
% ggplot(a_20_tmpls, aes(y=k.y, x=templates_CN,colour=DX)) +  # why does k.x look the same?
%   facet_grid( . ~ atlases) + 
%   geom_smooth(method='lm',fullrange=F) 
%  # add 
% @
%   \caption{Mean kappa vs. proportion of disease category in template library by disease category}
%   \label{}
% \end{figure}
% 
% 
% \todo{show cost (in registrations) / benefit tradec off graph:  show number of
% registrations per Kappa?  or hours of manual labour per Kappa?)}
% discuss run-time for each of MAGet and multi-atlas 

%%%%%
%%%%%                  Results: ADNI-1 Complete 1Yr Validation               %%%%%
%%%%%
\subsection{ADNI1 Complete 1Yr Validation}

<<ADNI-src-volumes-prep,echo=F,cache=T>>=
#bl    = read.csv("data/ADNI_baseline_volumes/ADNI1_Complete_1Yr_1.5T_11_15_2012.csv")
mb    = read.csv("data/ADNI_baseline_volumes/ADNI1_1.5T_MAGeT_volumes.csv")
maper = read.csv("data/ADNI_baseline_volumes/MAPER_volumes.csv")
snt   = read.csv("data/ADNI_baseline_volumes/UCSFSNTVOL.csv")
fs    = read.csv("data/ADNI_baseline_volumes/UCSFFSX_02_15_12.csv")
fsl   = read.csv("data/ADNI_baseline_volumes/ADNI1_1.5T_FSLFIRST_volumes.csv", sep=';')
qc    = read.csv("data/ADNI_baseline_volumes/ADNI1_Complete_1Yr_1.5T_QC_Park.csv", sep="\t")

# Get subjects, and diagnoses
yr1 = read.csv("data/ADNI_baseline_volumes/ADNI1_Complete_1Yr_1.5T_11_15_2012.csv")
yr1 = subset(yr1, !grepl("Scaled_2", Description)) #TODO: remove Scaled_2? 
yr1$VISCODE <- factor(yr1$Visit, levels = c(1,2,3,4), labels=c("bl","m03","m06","m12"))
subjects = yr1[,c("Image.Data.ID", "RID","VISCODE")]  # we only need these fields
dx = unique(adnimerge[c("DX.bl", "RID", "VISCODE")])
subjects = merge(subjects, dx) 

# fetch just the columns we need, and do a little renaming
mb_pruned     = data.frame(MAGeT_L = mb$Left_Hippo, 
                           MAGeT_R = mb$Right_Hippo, Source = mb$SourceImageID)
maper_pruned  = data.frame(MAPER_L = maper$Left_Hippo, 
                           MAPER_R = maper$Right_Hippo, Source = maper$SourceImageID)
snt_pruned    = data.frame(SNT_L = snt$LEFTHIPPO, 
                           SNT_R = snt$RIGHTHIPPO, Source = snt$IMAGEUID)
fs_pruned     = data.frame(TEMPQC =fs$TEMPQC, 
                           FS_L=fs$ST29SV, 
                           FS_R=fs$ST88SV, 
                           Source = fs$IMAGEUID)
fsl_pruned    = data.frame(FSL_L=fsl$X17, 
                           FSL_R=fsl$X53, Source=fsl$Source)



# Now create one data.frame with all the yr1 volume data we have from each datasource
combined = merge(subjects, mb_pruned   , by.x="Image.Data.ID", by.y="Source", all.x=TRUE)
combined = merge(combined, maper_pruned, by.x="Image.Data.ID", by.y="Source", all.x=TRUE)  # only Baseline
combined = merge(combined, snt_pruned  , by.x="Image.Data.ID", by.y="Source", all.x=TRUE)
combined = merge(combined, fs_pruned   , by.x="Image.Data.ID", by.y="Source", all.x=TRUE)
combined = merge(combined, fsl_pruned  , by.x="Image.Data.ID", by.y="Source", all.x=TRUE)
combined = merge(combined, qc          , by=c("Image.Data.ID", "RID"), all.x=TRUE)

# Step 2: Of those, get counts for the numbers that fail QC
package_totals = data.frame(
  Total     = c(length(subjects$VISCODE), 'N/A'),
  SNT        = c(length(which(!is.na(combined$SNT_L)))    , "--"),
  MAGeT      = c(length(which(!is.na(combined$MAGeT_L)))  , length(which(combined$MAGeT_QC==0))), 
  MAPER      = c(length(which(!is.na(combined$MAPER_L)))  , "--"), 
  FSL        = c(length(which(!is.na(combined$FSL_L)))    , length(which(combined$FSL_QC==0))), 
  FS         = c(length(which(!is.na(combined$FS_L)))     , length(which(combined$TEMPQC == "Fail"))),
  row.names  = c("Images", "Failures")
)


all_qc = subset(combined, TEMPQC != "Fail" & MAGeT_QC == 1 | FSL_QC == 1 )

attach(all_qc)
totals = data.frame(RID = RID, VISCODE = VISCODE, DX = factor(DX.bl),
                  MAGeT = MAGeT_L + MAGeT_R, 
                  MAPER = MAPER_L + MAPER_R, 
                  SNT   = SNT_L + SNT_R, 
                  FS    = FS_L + FS_R, 
                  FSL   = FSL_L + FSL_R)
detach(all_qc)
totals.complete = na.omit(totals)
@

Based on the results from the ADNI1 Cross-Validation experiment, in this
experiment \mb was configured with a template library of 21 randomly
chosen subject images (7 from each disease class) and used majority vote label
fusion. The entire ADNI1 Complete 1Yr 1.5T dataset was segmented by \mb and we 
now compare the resulting volumes with those obtained by manual segmentation (SNT), 
and other automated segmentation techniques (MAPER, FreeSurfer, and FSL).  Table
\ref{tab:ADN1-1.5T-Complete-1yr-Dataset-Segmentations} shows the total count of 
segmentations available, including a count of those which have failed a quality 
control inspection. Only those images which had segmentations from every method
are included in the following analysis (a total of
\Sexpr{length(totals.complete$RID)} images; Table 
\ref{tab:ADNI1-1.5T-Complete-1Yr-Dataset-Method-Totals}).
 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ADNI1 1yr Complete Dataset Package Totals & Failures                        %
%                        
%
<<ADNI1-scr-package-totals, echo=F, results="asis",cache=FALSE>>=
caption = paste(
  "Pass/fail quality control indicators were supplied with the FreeSurfer",
  "volumes downloaded from the ADNI website (we used the temporal lobe quality",
  "control indicator, TEMPQC). One of the authors (MP) performed visual",
  "quality inspection for MAGeT and FSL segmentations.", sep=" ")
latex(package_totals, file="", size="scriptsize", 
    caption = caption,
    title = "",
    label="tab:ADNI1-1.5T-Complete-1Yr-Dataset-Method-Totals")
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{figure}[h]
<<ADNI-scr-volumes-boxplot,dependson='ADNI-baseline-volumes-prep',cache=T,fig.width=6,fig.height=4>>=
melted.by.snt = melt(totals.complete, measure.vars=c("MAGeT","FSL", "FS", "MAPER"))
snt.tests <- ddply(melted.by.snt, c("variable", "DX"), function(df) {
  data.frame( c = cor(df$SNT, df$value) ) 
})

qplot(DX,value,data=melt(totals.complete,measure.vars=c("FS", "FSL", "MAPER","MAGeT","SNT")),
      colour=variable,geom="boxplot") + 
      xlab("Diagnosis") + ylab("Total Hippocampal Volume (mm3)")
@
  \caption{Comparison of hippocampus volumes obtained by FreeSurfer (FS), FSL, 
  MAPER, \mb (MAGeT) and manual (SNT).}
  \label{fig:ADNI-scr-volumes-boxplot}
\end{figure}

% paired t-test against SNT to show similarity (should be low) 
% Kruskal-Willis against  (should be high?)
% post-hoc power analysis to say we can detect this change
\begin{figure}[h]
<<ADNI-scr-histogram-prep,cache=T>>=
melted   = melt(totals.complete, measure.vars=c( "SNT","FSL","FS","MAPER","MAGeT"))
binwidth = 250

# prepare the normals
grid <- with(melted, seq(min(value), max(value), length = 100))
normaldf <- ddply(melted, c("variable", "DX"), function(df) {
  data.frame( 
    value = grid,
    density = dnorm(grid, mean(df$value), sd(df$value)),
    freq = length(df$value) * dnorm(grid, mean(df$value), sd(df$value)) * binwidth,
    length = length(df$value)
  )
})

testsdf <- ddply(melted, c("variable", "DX"), function(df) {
  shapiro = shapiro.test(df$value)
  data.frame(
    shapiro.w = shapiro$statistic,
    shapiro.p = shapiro$p.value,
    mean = mean(df$value),
    sd = sd(df$value)
  )
})


melted.by.snt = melt(totals.complete, measure.vars=c("MAGeT","FSL", "FS", "MAPER"))
snt.tests <- ddply(melted.by.snt, c("variable", "DX"), function(df) {
  ks = ks.test(df$SNT, df$value)
  data.frame( 
    ks.D = ks$statistic,
    ks.p = ks$p.value
  )
}) 
@

<<ADNI1-scr-histogram,dependson='ADNI-scr-histogram-prep',cache=T>>=

ggplot(data=melted, aes(x=value)) + 
  geom_histogram(binwidth=binwidth, alpha=0.8) + 
  geom_line(aes(y=freq, colour='red'), data=normaldf) +
  geom_text(aes(y=Inf,x=Inf,hjust=1.1,vjust=1.5,size=1, 
                label=paste("list(W ==",signif(shapiro.w, digits=3), ", p == ", 
                            round(shapiro.p,digits=3), ")")), 
            parse=TRUE, data=testsdf) +
  geom_text(aes(y=Inf,x=Inf,hjust=1.1,vjust=3,size=1, 
                label=paste("list(D ==",signif(ks.D, digits=3), ", p == ", 
                            round(ks.p,digits=3), ")")), 
            parse=TRUE, data=snt.tests) + 
  geom_text(aes(y=Inf,x=Inf,hjust=1.1,vjust=5.5,size=1, 
                label=paste("sigma ==",signif(sd, digits=3))), 
            parse=TRUE, data=testsdf) + 
  geom_text(aes(y=Inf,x=Inf,hjust=1.1,vjust=6,size=1, 
                label=paste("mu ==",signif(mean, digits=3))), 
            parse=TRUE,data=testsdf) + 
  #xlim(0, 10000) + 
  ylim(0,40) + 
  facet_grid(variable ~ DX) + 
  scale_colour_discrete(guide="none") + 
  scale_size_continuous(guide="none") + 
  labs(x=expression(paste("Total hippocampal volume (", mm^3, ")")),
       y="Frequency") + 
  theme(axis.title.x = element_text(vjust=-0.1))
@
  \caption{{\bf ADNI Baseline cohort.} Comparison of total hippocampal volumes
  as measured by SNT, FSL, FreeSurfer (FS), MAPER, and \mb (MAGeT). A
  fitted normal curve is shown in red. $W$ is the Shapiro-Wilkes test statistic
  measuring normality of the data (signficance indicates non-normality). $D$ is
  the Kolmogorov-Smirnov test statistic measuring the goodness-of-fit between
  the distribution of measured volumes and SNT volumes (significance indicates a
  difference).}
  \label{fig:ADNI-scr-histogram}
\end{figure}

Comparing total hippocampal volume, we find close
agreement between manual volumes, MAPER and MAGeT volumes across disease 
categories (Figure \ref{fig:ADNI-scr-volumes-boxplot}, Figure 
\ref{fig:ADNI-scr-histogram}). FSL and FreeSurfer both produce volumes in close 
agreement with each other, but which are consistently larger than manually 
segmented volumes in each disease category.  

\begin{figure}
  \includegraphics[width=6in,height=3in]{figure/ADNI1_MAGeT_montage/figure.pdf}
  \caption{A caption}
  \label{fig:ADNI1-segmentation-montage}
\end{figure}

% show as a plot
<<ADNI-scr-summary-table, echo=F, results="asis",cache=FALSE>>=
# a rather dirty way of computing the pairwise correlations and then forming
# a printable table out of them.  Sorry.
melted = melt(totals.complete, measure.vars=c("MAGeT","FSL", "FS", "MAPER"))
cor_by_dx    = by(melted[c("SNT", "value")], c(melted['variable'], melted['DX']), 
                  function(x) cor(x$SNT,x$value, use="pairwise.complete.obs"))
cor_overall  = by(melted[c("SNT", "value")], melted['variable'], 
                  function(x) cor(x$SNT,x$value, use="pairwise.complete.obs"))
cor_by_dx = t(rbind(cor_by_dx))
cor_overall = rbind(cor_overall)

vol_by_dx = t(rbind(by(totals.complete$MAGeT, totals.complete$DX, mean)))
colnames(vol_by_dx) <- "Mean Volume"
vol_overall = matrix(mean(totals.complete$MAGeT),dimnames=list("Overall"))

dx      = cbind(vol_by_dx, cor_by_dx)
overall = cbind(vol_overall, cor_overall)
df      = format.df(rbind(dx, overall), dec=2)
                    
#latex(df, title="",
#      n.cgroup=c(1,ncol(df)-1),cgroup=c("","Volume Correlation"),
#      file="", size="scriptsize")
@

%%%%%
%%%%%             Results: First Episode Patient Validation          %%%%%
%%%%%
\subsection{First Episode Schizophrenic Patients}
In this experiment we move from an Alzheimer's disease dataset to a dataset of 
first episode schizophrenia parients.  This dataset is segmented using \mb with the
Winterburn atlases, and a template library of 21 subject images selected at random. 
Expert manual whole hippocampal segmentations are used as gold standards. 

\mb produces hippocampus segmentation volumes that are highly correlated with 
manual segmentation volumes (Figure \ref{fig:SZ-volumes}).  Additionally, as we 
saw in the previous experiments, \mb volumes show a fixed bias towards smaller 
volumes (although the bias is negligble), and a proportional bias towards 
producing smaller segmentations for larger hippocampi (Figure \ref{fig:FEP-SZ-Bland-Altman}.

\begin{figure}
<<FEP-volumes,cache=FALSE,dependson="setup">>=
SZ_volumes=read.csv("data/SZ_volumes_by_method.csv", sep="\t")
casted = dcast(SZ_volumes, Subject + Label ~ Method)
lm = lm(MAGeT ~ Manual, casted)
ggplot(data=casted, aes(x = Manual, y = MAGeT)) + 
  geom_smooth(method="lm", formula=y~x) + 
  geom_point() + 
  geom_text(aes(x=3500, y=5000, label=lm_eqn(lm),hjust=0,size=1), parse=TRUE, data=data.frame()) +
  xlab(expression("Manual left / right hippocampus volume " (mm^3))) + 
  ylab(expression("MAGeT left / right hippocampus volume "  (mm^3))) + 
  scale_size_continuous(guide="none") 
@
  \caption{{\bf First Episode Schizophrenic Patients.} Comparison of total
  HC volumes for \mb against manually rated Hippocampal volumes}
  \label{fig:SZ-volumes}
\end{figure}

\begin{figure}
<<ADN1-FEP-Bland-Atlman, cache=TRUE, dependson='FEP-volumes', fig.width=4, fig.height=4>>=
bland_altman_plot <- function(x, y) {
  data = data.frame(x=x,y=y,diff=x-y)
  upper = mean(data$diff) + 2 * sd(data$diff)
  lower = mean(data$diff) - 2 * sd(data$diff)
  return(ggplot(data, aes(x= x, y = diff)) + 
    geom_hline(yintercept = mean(data$diff) + c(-2, 0, 2) * sd(data$diff), 
               linetype=2, color='brown') + 
    annotate("text", y = upper, x=Inf, 
              label=paste("std =",round(upper,0)), 
              hjust=1.1,vjust=1.5) + 
    annotate("text", y = lower, x=Inf, 
              label=paste("-std =",round(lower,0)), 
              hjust=1.1,vjust=1.5) + 
    geom_point())
}

bland_altman_plot(casted$Manual, casted$MAGeT) + 
  xlab('Mean manual and MAGeT Brain total Hippocampus volume') + 
  ylab('Manual - MAGeT Brain volume') + 
  geom_smooth(method="lm", formula = y~x)
@
  \caption{Bland-Altman plot comparing manual and \mb hippocampal volumes 
  when using five Winterburn atlases, and a 21 image template library.}
  \label{fig:FEP-SZ-Bland-Altman}
\end{figure}

%%%%%
%%%%%              Experiments: Winterburn Atlases Validation              %%%%%
%%%%%
\subsection{Winterburn Atlases Cross-Validation}

The final experiment explores \mb segmentations of hippocampal subfields. To
achieve this, a leave-one-out validation is conducted in which lower-resolution
images ($0.9mm^3$ voxels) of each Winterburn atlas subject is segmented using 
the remaining Winterburn atlases. As a point of comparison, volumes of Winterburn 
atlases when downsampled to $0.9mm^3$ voxels are also computed.

In general, across hippocampal subregions the percent error in volume between 
\mb segmentations and the manual Winterburn atlas segmentations compares 
favourably to error when resampling the atlas segmentations (Figure 
\ref{fig:WAval-vol-boxplot}). In particular, the CA1, CA4, and Dentate subregions 
all show near or smaller percent errors. The Sibiculum and CA2/CA3 subregions 
show distinctly larger than resampling error. 

\begin{figure}
<<WAval-vol-boxplot,cache=T>>=
# dirty dirty
data = subset(read.csv('data/WAval.csv'))
casted = dcast(melt(data, id.vars=c("file","version")), file + variable ~ version)
casted = rename(casted, c("variable"="region"))

error = ddply(casted, c("file", "region"), function(df) {
  with(df, 
  data.frame(
    resampled = (gold_0.9mm - gold_0.3mm) / gold_0.3mm * 100, 
    mb_bravo  = (mb_bravo   - gold_0.3mm) / gold_0.3mm * 100, 
    mb_0.9mm  = (mb_0.9mm   - gold_0.3mm) / gold_0.3mm * 100))})

levels(error$region) <-list("CA1"="X1", "CA1"="X101", 
                            "Subiculum"="X2","Subiculum"="X102", 
                            "CA4"="X4","CA4"="X104", 
                            "CA2/CA3"="X5","CA2/CA3"="X105", 
                            "Dentate"="X6","Dentate"="X106")
melted = melt(error,id.vars=c("file", "region"))
melted = rename(melted, c("variable"="measure", "value"="percenterr"))
levels(melted$measure) <- list("Resampled WA"="resampled",
                               "MAGeT-Brain(Resampled WA)" = "mb_0.9mm",
                               "MAGeT-Brain(BRAVO)"="mb_bravo")

ggplot(melted, aes(y=percenterr,x=region,colour=measure)) +
  geom_boxplot() +
  labs(y="Percent error in volume", x="Region") +
  scale_colour_discrete("") + 
  theme(legend.direction = "horizontal", legend.position = "bottom")
@
  \caption{{\bf Percent error in segmentation volume by hippocampus subregion.} 
  {\em Resampled WA} are volumes of the manual segmentations of the Winterburn atlases 
  after resampling to $0.9mm^3$.  {\em \mb(Resampled WA)} volumes are
  \mb segmentations of the Winterburn atlas images after resampling to $0.9mm^3$ voxels.
  {\em \mb(BRAVO) \mb} volumes are \mb segmentations of T1 BRAVO images ($0.9mm^3$ voxels)      
  acquired separately 
  of four of the five Winterburn atlas subjects. Percent error is measured against the volumes of
  of the unmodified Winterburn atlas segmentations.}
  \label{fig:WAval-vol-boxplot}
\end{figure}
% 
% <<WAval-error,cach=T>>=
% # compare % error between MAGeT and resampling
% mb0.9mm_diff_over_gold_diff = cbind(subjects, abs(gold_diff) - abs(mb_0.9mm_diff), res="diffdff")
% names(mb0.9mm_diff_over_gold_diff) <- c("subject", "CA1", "Subiculum", "CA4", "CA2/CA3", "Dentate", "res")
% melted = melt(mb0.9mm_diff_over_gold_diff, id.vars=c("subject", "res"))
% names(melted) <- c("subject","res", "region","voldiff")
% ggplot(melted, aes(y=voldiff,x=region)) +
%   geom_boxplot() +
%   labs(title="Absolute difference in % difference between MAGeT and resampling",
%        y="Absolute difference in % difference in volume", 
%        x="Region")
% @

%<<WAval-kappa,cache=T>>=
%#data = read.csv('data/WAval-kappa.csv')
%ggplot(data, aes(x=label, y=kappa)) + geom_boxplot(y=kappa)
%@

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                Discussion
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Discussion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                               Conclusion 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion}

\bibliographystyle{plainnat}
\bibliography{references}
\end{document}
