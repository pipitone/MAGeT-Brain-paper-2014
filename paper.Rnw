%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Sweave/Knitr init
<<setup, include=FALSE, cache=FALSE>>=
#opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, 
#    fig.align = 'center', tidy = FALSE, comment = NA, cache = TRUE)
library(ggplot2)
library(Hmisc)
library(reshape2)
library(ADNIMERGE)
library(plyr)
options(digits=3)
theme_set(theme_bw())
# bland_altman_plot <- function(dat){
#   dat$diff <- dat$pre - dat$post;
#   
#   return ggplot(dat, aes(pre, diff)) + 
#     geom_hline(yintercept = mean(dat$diff) + c(-2, 0, 2) * sd(dat$diff), 
#                linetype=2, color='brown') + 
#     geom_point() 
# }
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass{article}
\usepackage[margin=1in]{geometry}
\usepackage{algorithm, color, algpseudocode, amsmath, url, geometry, ctable}
\usepackage[round,authoryear]{natbib}

%draft mode
\usepackage[colorlinks]{hyperref}
\usepackage[colorinlistoftodos, textwidth=4cm, shadow]{todonotes}
\usepackage[displaymath, tightpage]{preview}
\setlength{\marginparwidth}{1.2in}

%notes and TODO formatting
%\newcommand{\marginnote}[1]{\-\marginpar[\raggedleft\footnotesize #1]{\raggedright\footnotesize #1}}
%\newcommand{\comment}[1]{\begin{kframe}{\textcolor{red}{#1}}\end{kframe}}
%\newcommand{\todo}[1]{\comment{TODO #1}}
%\newcommand{\mc}[1]{\comment{MC: #1}}
\begin{document}

\title{Bootstrapping Multi-atlas Hippocampal Segmentation with MAGeT}
\author{Pipitone J., Winterburn J., Lerch J., Pruessner J., Lepage M., \\ 
Voineskos A., Chakravarty M.M., and \\ 
the Alzheimer's Disease Neuroimaging Initiative}
\maketitle

\begin{abstract}
Neuroimaging research often relies on automated anatomical segmentations of MR
images of the brain. Current multi-atlas based approaches provide accurate
segmentations of brain images by propagating manually derived segmentations of
specific neuroanatomical structures to unlabelled data. These approaches often
rely on a large number of such manually segmented atlases that take significant
time and expertise to produce. We present an algorithm for the automatic
segmentation of the hippocampus that minimizes the number of atlases needed
while still achieving similar accuracy to multi-atlas approaches.
\todo[inline]{finish}
\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                               INTRODUCTION
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

The hippocampus is of particular interest to many researchers because it is
implicated in forms of brain dysfunction such as Alzheimer's
disease\citep{Sabuncu2011} and schizophrenia\citep{Narr2004,Karnik-Henry2012},
and has functional significance in cognitive processes such as learning and
memory\citep{DenHeijer2012,Scoville2000}.  For many research questions
involving magnetic resonance imaging (MRI) data accurate identification of the
hippocampus and its subregions is a necessary first step to better understand
the individual neuroanatomy of subjects.  

Currently, the gold standard for neuroanatomical segmentation is manual
delineation by an expert human rater.  This is problematic for hippocampal
segmentation for several reasons.  First, manual segmentation takes a
significant investment of time and expertise \citep{Hammers2003} which may not
be readily available to researchers or clinicians.  Second, the amount of data
produced in neuroimaging experiments increasingly exceeds the capacity for
identification of specific neuroanatomical structures by an expert manual
rater.  Third, the true definition of hippocampal anatomy in MR images is
disputed \citep{Geuze2004}, as evidenced by efforts to create an unified
segmentation protocol \citep{Jack2011}.  

Compounding each of these problems is the significant neuroanatomical
variability in the hippocampus throughout the course of aging, maturation, and
neuropsychiatric disorders
\citep{Mouiha2011b,Sabuncu2011,Giedd1998,Gogtay2006,Narr2002}.  The result is that
existing hippocampal atlases available to a researcher may not accurately
represent neuroanatomy of a specific population under study.  Additionally, in
the course of a research or clinical study, it may be necessary to make
adjustments to hippocampal definition as a means of hypothesis testing.  For
example, Poppenk \citep{Poppenk2011} found that subdividing the hippocampus
into anterior and posterior regions resulted in a predictive relationship
between volume difference of those regions and recollection memory performance.
Making such modifications to a set of MRI data segmentations requires additional
manual effort. 

Automated segmentation techniques do not require human intervention but do
require {\it a priori} anatomical information to guide segmentations.  In this
paper we focus on methods that use manually segmented MRI atlases as anatomical
priors, as these methods achieve some of the best automated hippocampal
segmentation accuracies to-date. This technique was first developed using a
single atlas prior (known as single-atlas, or model-based,
segmentation)\citep{Haller1997,Csernansky1998}.  Volumetric image registration
is used to estimate a fit between the neuroanatomy of an atlas and target
images.  Labelling of the target image is achieved by applying the resulting
transformation to the atlas labels to bring them into the target image space
({\em label propagation}). This method is limited in accuracy by the
introduction of estimation errors in registration and partial volume effects in
label resampling, and errors introduced when the anatomy of the atlas is
unrepresentative of the target anatomy.

Multi-atlas segmentation techniques address these limitations by combining
segmentation information from a series of expertly segmented atlases
\citep{Heckemann2006,Heckemann2011,Collins2010,Lotjonen2012,Aljabar2009,Leung2010,Wolz2010}.
Each atlas image is registered to a target image, and label propagation is
performed to produce several labellings of the target image (one from each
atlas). A {\it label fusion} technique, such as voxel-wise voting, is used merge
these labels into a definitive segmentation for the target.  In addition, {\em
atlas selection} techniques are often used to exclude atlases from label fusion
that are dissimilar to a target image in order to reduce error from
unrepresentative anatomy \citep{Aljabar2009}. Cross-correlation or normalised
mutual information of image intensities are common measures of image similarity
used in atlas selection.

Multi-atlas methods have been very successfully applied to hippocampal
segmentation. Collins et al. found near-manual segmentation performance using an
atlas library of 80 T1-weighted atlas images from the ICBM152 dataset, the
ANIMAL nonlinear registration algorithm, normalised mutual information as an
atlas selection similarity metric, and majority vote for label fusion
\citep{Collins2010}.  The Alzheimer's Disease Neuroimaging Initiative (ADNI) is
a commonly used benchmarking dataset of MR images of controls and patients with
MCI or Alzheimer's (see Methods for more information on the ADNI dataset).
Leung et al. tuned parameters for registration and label fusion to the
segmentation of ADNI1 1 year dataset of images with an atlas library of 55
images \citep{Leung2010}.  The MAPER whole brain segmentation algorithm
\citep{Heckemann2006,Heckemann2011}, using 30 atlases, on all ADNI1 baseline
images \citep{Heckemann2011}.  Lotjonen et al. use images from the ADNI1
baseline dataset and 30 atlases with a proprietary non-linear registration
method based on intensity differences, and post-processing step using a graph
cuts algorithm to optimise fused segmentations against a spatial intensity prior
\citep{Lotjonen2012}.  
\todo{No story here}

The LEAP algorithm is an elegant modification to the basic multi-atlas strategy
\citep{Wolz2010}. The atlas library is grown, beginning with a set of manually
labelled atlases, and successively incorporats unlabelled target images after
being labelling using multi-atlas techniques. The sequence in which target
images are labelled is chosen so that the similarity between the atlas images
and the target images is minimised at each step, effectively allowing for
deformations between very dissimilar images to be broken up into sequences of
smaller deformations.  With an atlas library of 30 MR images, LEAP was used to
segment the ADNI1 baseline dataset, achieving a mean Dice score of 0.85 with
manual segmentations.

%- TODO: "probablistic methods?"

While not purely nulti-atlas techniques, there are several important algorithms
for hippocampal segmentation that inform our approach. The popular FreeSurfer
application's whole brain segmentation algoritm uses a probabilistic atlas of
anatomical and tissue classes along with spatial constraints for class labels
encoded using a Markov random field model \citep{Fischl2002}. When segmenting
hippocampal subfields, FreeSurfer employs a Bayesian inference algorithm using a
probabilistic atlas of anatomical classes as a prior, and a likelihood model of
how those classes translate into MR image intensities, both trained on manual
segmentations of high resolution MR images \citep{Fischl2009}. Yushkevitch et
al. describe a semi-automated method for hippocampal subfield segmentation of
focal T2 images\citep{Yushkevitch2010}.  The unlabelled MR image must be
manually partitioned into 'head', 'body' and 'tail', and then multi-atlas
methods are used to segment the image.  Finally, an AdaBoost-based bias
correction classifier is trained on texture, spatial location, and intensities
of manual segmentations and is applied to fix mislabelled voxels.  

%  Chupin's use of shape-based priors 
%   - Mouiha2011b - Hippocampal atrophy rates in AD: compare SNT vs FreeSurfer
%     on ADNI
%

Aside from the algorithmic choices used in multi-atlas segmentation, it is
natural to ask about how the features of the atlases themselves impact the
resulting segmentations. As noted, by choosing atlases ranked most similar to a
target image by voxel intensity profile, segmentation accuracy is improved,
suggesting that neuroanatomical similarity plays a strong role
\citep{Aljabar2009}.  Carmichael et al. explored this directly and found that
when using only one atlas the important factors leading to improved accuracy are
that the atlas have neuroanatomical features that match the target, and that the
atlas segmentation use the same protocol as the gold-standard
\citep{Carmichael2005}. Nestor et al.  found that hippocampal segmentation
protocols that include more dorsal white-matter and posterior anatomy tended to
produce higher overlap and better accuracy at distinguishing disease classes in
the ADNI1 1 year dataset \citep{Nestor2012}. These results suggest both atlas
library neuroanatomy and delineation protocol play a significant role in the
resulting segmentation.

Considered along with our earlier discussion on the difficulty of producing
manual segmentations of MR images and the need for adaptable segmentation
definitions in order to conduct research, this presents a real problem of labour
and expertise when using existing multi-atlas segmentation methods which rely on
relatively large atlas libraries (typically between 30 and 80 atlases). Indeed,
it may be especially prohibitive to use these methods in situations where
producing a single atlas is challenging (e.g. histology-based atlases, or
atlases from very high resolution images). In this paper we address the problem
of producing accurate segmentations using small numbers of manually segmented
atlases. 

% MAGeT bootstrapping: tune the template library to your dataset, reduce the
% number of input atlases you need, with the upshot that with fewer atlases it's
% that much easier to change definitions in order to test hypothesis

Our algorith, called MAGeT brain ({\em M}ultiple {\em A}utomatically {\em
Ge}nerated {\em T}emplates), is an extension to the basic multi-atlas-based
segmentation schema\citep{Chakravarty2012}. Principally, we explore the
possibility of using a small atlas library to bootstrap a much larger
\emph{template library} composed of images taken from the target population.
The template library is then used to segment the targets in a similar fashion
to basic multi-atlas segmentation: by label propagation and label fusion. The
intuition driving this approach is that by generating a template library we
leverage the unique neuroanatomy of target population on hand to initialize the
segmentation process and improve accuracy over direct propagation from the atlas
library to unlabelled targets while also using fewer manually segmented
atlases. 

The insight of generating a template library is not new.  Heckemann et al.
compared ``indirect'' segmentation -- taking a single atlas and propagating the
labels to intermediate targets before fusing them in a target image space -- to
multi-atlas segmentation and found that the indirect approach performed worse
\citep{Heckemann2006}. In this paper we continue the same line of investigation
but explore the performance when using multiple atlases as well as the effect of
different registration and fusion methods.

The LEAP algorithm \citep{Wolz2010}, described above, is another example of
indirect segmentation previously explored.  LEAP proceeds by iteratively
segmenting unlabelled images most similar to the atlas library images and then
incorporating the labelled images into the atlas library for future iterations.
The novelty explored in our current work is to demonstrate the viability of
achieving comparable segmentation accuracy using the basic multi-atlas schema
and using significantly fewer manually created atlases.

In previous work \citep{Chakravarty2012}, we applied MAGeT brain to segmentation
of the human striatum, globus pallidus, and thalamus using a single
histologically-derived atlas. The contribution of the present work is to extend
our approach to the human hippocampus and perform a series of experiments to
rigorous validate the method. First, we conduct an extensive cross-validation of
MAGeT and basic multi-atlas segmentation on a subset of the ADNI1 dataset to
assess the accuracy of MAGeT brain under various parameter settings (number of
atlases and templates, registration and fusion methods). With the best
performing parameter configuration discovered above, we estimate MAGeT
intra-rater reliability by segmenting separately acquired T1 images of the
atlas subjects. For this experiment, we use the Winterburn atlases: digital
hippocampal subfield segmentations of five in-vivo high-resolution (300u
isotropic) T1-weighted MR scans\citep{Winterburn2013}. To validate MAGeT in a
real world situation, we segment the entire ADNI1 screening dataset and compare
our segmentations to established automated and manual segmentations.
Additionally, to ensure MAGeT brain accuracy across disease categories, we also
compare MAGeT segmentations to manual segmentations of 139 first episode
schizophrenic patients. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                               METHODS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Methods}

%%%%%                     MAGeT Brain Algorithm                            %%%%%

\subsection{MAGeT Brain Algorithm}
In this paper we will be making a distinction between an atlas and a template --
typically these terms are used roughly interchangeably. The term {\it atlas} is
taken to refer to two image volumes: an intensity image ({\it atlas image}) and
a corresponding manual segmentation image ({\it atlas labels}). {\it Template}
refers more generically to any image and corresponding labelling, manual or
computed, when it is {\it used as} as a model in the segmentation of another
image.  The terms {\it atlas library} and {\it template library} mean a set of
such images. Additionally, we will use the terms {\it target} to refer to an
intensity image for which we would like an segmentation.

The simplest form of multi-atlas segmentation combines labellings derived from
several atlases by way of label fusion \citep{Heckemann2006,Heckemann2011}. We
will refer to this as {\em basic multi-atlas segmentation}. The schema as for
this method is as follows: 
\begin{enumerate}
\item   An atlas library and set of target images are given as input. The atlas
        library is used as a template library in the following steps; 
\item   Each atlas intensity image is nonlinearly registered to each target 
        intensity image; 
\item   Label images from each atlas are propagated via the resulting
        transformations to the target image space; and 
\item   the resulting labels are fused to produce a single, definitive
        segmentation. 
\end{enumerate}       
The particular registration and voting method used are left unspecified.

MAGeT brain is best understood as an extension of the basic multi-atlas
segmentation schema. Instead of using the atlas library to directly label the
target images, a subset of the input images are selected as template images and
then labelled.  The choice of targets used in the template library can be made
to reflect the neuroanatomy or demographics of the target set as a whole (for
instance, by sampling equally from cases and controls). Once the template
library images have been chosen, a truncated version of basic multi-atlas
segmentation is used to label the template library images without performing
label fusion. Instead, each template image receives multiple labellings: one
from each atlas image. A second round of basic multi-atlas segmentation uses the
template library to segment the entire set of target images (including those
images used in the template library). Label fusion in this final step fuses all
labels from all templates. To summarize, figure \ref{alg:MAGeT} describes the
MAGeT brain algorithm in pseudocode.  

Source code for MAGeT brain can be found at
\url{http://github.com/pipitone/MAGeTbrain}.

\begin{algorithm}
  \scriptsize
  \caption{Pseudocode for the MAGeT Brain algorithm}
  \label{alg:MAGeT}
  \begin{algorithmic}
    \Function{BasicMultiAtlasSegmentation}{Templates, Subjects}
      \ForAll{$target$}
        \ForAll{$template$}
          \State propagate all labels for template to target space
          \State store target labels
        \EndFor
        \State fuse target labels
      \EndFor
    \EndFunction
    \\
    \Function {MAGeTBrain}{Subjects, Atlases, n}
      \For{$i = 1 \to n$}
        \State choose a target to be used as a template
        \State propagate labels from each atlas to template space
        \State store the template with all of its labels
      \EndFor
      \State MultiAtlas(Templates, Subjects)
    \EndFunction
  \end{algorithmic}
\end{algorithm}



%%%%%                             Subjects                                 %%%%%

\subsection{Subjects}
Our experiments use three distinct subject datasets.

\subsubsection{ADNI1 1.5T Screening Dataset}
Clinical, demographic and pre-processed T1-weighted MRI were downloaded by the
authors from the ADNI1 database (adni.loni.ucla.edu) between March 2012 and
August 2012. The image dataset download was the "ADNI1:Screening 1.5T"
standardized dataset available from ADNI \footnote{
\url{http://adni.loni.ucla.edu/methods/mri-analysis/adni-standardized-data/}}
\citep{Wyman2012}. This image collection contains uniformly preprocessed images
which have been designated to be the "best" after quality control.  All images
were acquired using 1.5T scanners (General Electric Healthcare, Philips Medical
Systems or Siemens Medical Solutions) at multiple sites using the protocol
described in \citep{Jack2008a}.  Representative 1.5T imaging parameters were TR
= 2400ms, TI = 1000ms, TE = 3.5ms, flip angle = $8{\circ}$, field of view = 240
x 240mm, a 192 x 192 x 166 matrix (x, y, and z directions) yielding a voxel
resolution of 1.25 x 1.25 x 1.2 $mm^3$. Clinical and demographic data are shown
in table \ref{tab:ADNI1_1.5T_Screening_Dataset_Demographics}. 

For a subset of ADNI1 images, labels of the left and right hippocampi are
available (herein refered to as SNT labels).  Semi-automated hippocampal
volumetry was carried out using a commercially available high dimensional brain
mapping tool (Medtronic Surgical Navigation Technologies, Louisville, CO), that
has previously been validated and compared to manual tracing of the hippocampus
\citep{Hsu2002}. Measurement of hippocampal volume is achieved first by placing
manually 22 control points as local landmarks for the hippocampus on the
individual brain MRI data: one landmark at the hippocampal head, one at the
tail, and four per image (i.e., at the superior, inferior, medial and lateral
boundaries) on five equally spaced images perpendicular to the long axis of the
hippocampus. Second, fluid image transformation is used to match the individual
brains to a template brain \citep{Christensen1997}. The pixels corresponding to
the hippocampus are then labeled and counted to obtain volumes. This method of
hippocampal voluming has a documented reliability of an intraclass coefficient
better than .94 \citep{Hsu2002}.

%Representative 3T image parameters were TR = 2300ms, TI = 900ms, TE = 3.0ms,
%flip angle = $8{\circ}$, field of view = 256 x 240mm, a 256 x 256 x 166 matrix
%(x, y, and z directions) yielding a voxel resolution of 1.00 x 1.00 x 1.2
%$mm^3$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ADNI1 Screening Dataset Demographics Table                                  %
%                                                                             %
<<ADNI1-scr-demographics, echo=F, results="asis",cache=FALSE>>=
# RID < 2000 ensures only ADNI1 patients
tab <- summary(DX.bl ~ AGE + PTGENDER + PTEDUCAT + PTETHCAT + CDRSB + ADAS13 +
               MMSE, data = adnimerge, subset = VISCODE == 'bl' & RID < 2000,   
               method = "reverse", test=FALSE, overall=TRUE)
latex(tab, file="", size="scriptsize", 
    caption="ADNI1 1.5T Screening dataset demographics",
    title="tab:ADN1_1.5T_Screening_Dataset_Demographics")
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Schizophrenic First Episode Patients}
All patients were recruited and treated through the Prevention and Early
Intervention Program for Psychoses (PEPP-Montreal), a specialized early
intervention service at the Douglas Mental Health University Institute in
Montreal, Canada. People aged 15–30 years from the local catchment area
suffering from either affective or non-affective psychosis who had not taken
antipsychotic medication for more than one month with an IQ above 70 were
consecutively admitted as either in- or out-patients. Of those treated at PEPP,
only patients aged 18 to 30 years with no previous history of neurological
disease or head trauma causing loss of consciousness were eligible for the
neuroimaging study; only those suffering from schizophrenia spectrum disorders
were considered for this analysis.  For complete program details see Malla et
al. \citep{Malla2003}. 

Scanning was carried out at the Montreal Neurological Institute on a 1.5-T
Siemens whole body MRI system.  Structural T1 volumes were acquired for each
participant using a three-dimensional (3D) gradient echo pulse sequence with
sagittal volume excitation (repetition time=22ms, echo time=9.2ms, flip
angle=$30{\circ}$, 180 1mm contiguous sagittal slices). The rectangular field-of-view
for the images was 256mm (SI)×204mm (AP).  Subject demographics are shown in
table \ref{tab:SZFEP_Demographics}. 

The hippocampus were traced following a validated protocol developed by Dr Jens
Pruessner (Pruessner et al., 2000). A recent update to this protocol by Dr J
Pruessner in 2006 allows to accurately and consistently subdivide the
hippocampus into three different subregions: head, body, and tail.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% First Episode SZ Demographics Table                                         %
%                                                                             %
<<FEP-SZ-demographics, echo=F, results="asis",cache=FALSE>>=
fep_sz_demographics = read.csv("data/SZ_demographics.csv", na.strings=c("","."))
fep_sz_demographics = subset(fep_sz_demographics, Anon <= 81)
tab <- summary(DX ~ Age + Gender + Handedness + Education + SES + FSIQ,
               data=fep_sz_demographics, method = "reverse", test = FALSE)
latex(tab, file="", size="scriptsize", ctable=FALSE,
      caption="Schizophrenia First Episode Patient Demographics",
      title="tab:SZFEP_Demographics")
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Winterburn Atlases}
The Winterburn atlases \citep{Winterburn2013} are digital hippocampal segmentations
of of five in-vivo 300u isotropic T1-weighted MR images. The segmentations
include subfield segmentations for the cornus ammonis (CA) 1, CA4, dentate
gyrus, subiculum, and CA 2 and 3 combined. Subjects in the Winterburn atlases
range in age from 29-57 years (mean age of 37), and include two males and three
females.  

In addition to the high-resolution scans distributed as part of the Winterburn
atlases, we also obtained additional T1 BRAVO scans of four of the five
subjects.  \todo{demographics?}\todo{explain scan parameters in more detail..}


%%%%%                       Registration Methods                           %%%%%


\subsection{Registration Methods}

Before registration, all images underwent preprocessing with the N3 algorithm
\citep{Sled1998} to minimize intensity nonuniformity. In our experiments we use
one of two non-linear image registration methods.

\subsubsection{Automatic Normalization and Image Matching and Anatomical
Labeling (ANIMAL)}

The ANIMAL algorithm carries out image registration is in two phases. In the
first, a 12-parameter linear transformation (3 translations, rotations, scales,
shears) is estimated between images using an algorithm that maximizes the
correlation between blurred MR intensities and gradient magnitude over the whole
brain \citep{Collins}. In the second phase, nonlinear registration is completed
using the ANIMAL algorithm \citep{Collins1995}: an iterative procedure that
estimates a 3D deformation field between two MR images. At first, large
deformations are estimated using blurred version of the input data. These larger
deformations are then input to subsequent steps where the fit is refined by
estimating smaller deformations on data blurred with a Gaussian kernel with a
smaller FWHM. The final transformation is a set of local translations defined on
a bed of equally spaced nodes that were estimated through the optimization of
the correlation coefficient.  For the purposes of this work we used the
regularization parameters optimized in Robbins et al. \citep{Robbins2004},
displayed in table \ref{tab:ANIMAL_params}. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ANIMAL parameters                                                           %
%                                                                             %
\begin{table*}[!tbp]
\scriptsize
\caption{ANIMAL Registration Parameters\label{tab:ANIMAL_params}} 
\begin{center}
\begin{tabular}{l | c c c}
\hline 
Parameters        & Stage 1 & Stage 2 & Stage 3  \tabularnewline
\hline 
Model Blur (FWHM) &   8     &    8    &   4      \tabularnewline
Input Blur (FWHM) &   8     &    8    &   4      \tabularnewline
Iterations        &   30    &    30   &   10     \tabularnewline
Step              &   8x8x8 &  4x4x4  &   2x2x2  \tabularnewline
Sub-Lattice       &   6     &    6    &   6      \tabularnewline
Lattice Diameter  &24x24x24 &12x12x12 & 6x6x6    \tabularnewline
\hline
\end{tabular}
\end{center}
\end{table*}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Automatic Normalization Tools (ANTS)}

ANTs is a diffeomorphic registration algorithm which provides great flexibility
over the choice of transformation model, objective function, and the consistency
of the final transformation. The transformation is estimated in a hierarchical
fashion where the MRI data is subsampled, allowing large deformations to be
estimated and successively refined at later hierarchical stages (where the data
is subsampled to a finer grid). The deformation field and the objective function
are regularized with a Gaussian kernel at each level of the hierarchy. The ANTs
algorithm is freely available \url{http://www.picsl.upenn.edu/ANTS/}. We used an
implementation of the ANTS algorithm compatible with the MINC data format,
mincANTS \url{https://github.com/vfonov/mincANTS}.

We used the following command line when running ANTS:
{\small
\begin{verbatim}
  mincANTS 3 -m PR[target_file.mnc,source_file.mnc,1,4] 
   --number-of-affine-iterations 10000x10000x10000x10000x10000 
   --affine-gradient-descent-option 0.5x0.95x1.e-4x1.e-4
   --use-Histogram-Matching --MI-option 32x16000
   -r Gauss[3,0] -t SyN[0.5] -i 100x100x100x20
   -o transformation.xfm
 \end{verbatim}
}
These settings were adapted from the "reasonable starting point" given in the
ANTS manual 
\footnote{\url{https://sourceforge.net/projects/advants/files/Documentation/}}.


%%%%%                           Label Fusion                               %%%%%

\subsection{Label Fusion}

Label fusion is a term given to the process of combining the information from
several candidate labellings for an intensity image into a single labelling.  In
this paper we explore three fusion methods. 

\subsubsection{Voxel-wise Majority Vote}

Labels are propagated from all template library images to a target.  Each
output voxel is given the most frequent label at that voxel location amongst
all candidate labellings.  Ties are broken arbitrarily.

\subsubsection{Cross-correlation Weighted Majority Vote}

An optimal combination of targets from the template library has previously been
shown to improve segmentation accuracy \citep{Aljabar2009,Collins2010}.  In this
method, each template library image is ranked in similarity to each unlabelled 
image by the normalized cross-correlation (CC) of image intensities after linear
registration, over a region of interest (ROI) generously encompassing the 
hippocampus.  Only the top ranked template library image labels are used in a
voxel-wise majority vote. The ROI is heuristically defined as the extent of all
atlas labels after linear registration to the template, dilated by three voxels
\citep{Chakravarty2012}.  The number of top ranked template library image labels
is a configurable parameter.

The {\tt xcorr\_vol} utility from the ANIMAL toolkit is used to calculate the
cross-correlation similarity measure.  
 
\subsubsection{Normalised Mutual Information Weighted Majority Vote}
 
This method is similar to cross-correlation weighted voting except that image
similarity is calculated by the normalised mutual information score over the
region of interest\citep{Studholme2001}.  The {\tt itk\_similarity} utility from
the EZMinc toolkit\footnote{\url{https://github.com/vfonov/EZminc}} is used to
calculate the normalised mutual information measure between to images.

%%%%%                        Evaluation Measure                           %%%%%

\subsection{Assessing Segmentation Agreement}

The Dice similarity coefficient (DSC) assesses the agreement between two
segmentations.  It is one of the most widely used measures of segmentation
performance, and we use it as the basis of comparison throughout this paper.
Additionally, we report the Jaccard index, another commonly used similarity
measure:

 \[\text{Dice's coefficient (DSC)} = \frac{2|A \cap B|}{|A| + |B|}\]

 \[\text{Jaccard (J)} = \frac{|A \cap B|}{|A \cup B|} = \frac{DSC}{(2-DSC)}\]

where $A$ and $B$ are the regions being compared, and the cardinality is the
volume measured in voxels. 

%%%%%
%%%%%                            Experiments                               %%%%%
%%%%%
\subsection{Experiments}

The following experiments were performed to assess the performance of MAGeT
brain with various parameter settings as well as on diverse datasets.  In each
experiment we contrast the performance of MAGeT brain with that standard single-
and multi-atlas segmentations derived from the same atlas library. 

%%%%%
%%%%%                 Experiments: ADNI-1 cross-validationn               %%%%%
%%%%%
\subsubsection{ADNI1 cross-validation}
To test the effect of parameter settings on the MAGeT brain algorithm, Monte
Carlo Cross-Validation (MCCV) \citep{Shao1993} was performed using a subset of
the ADNI1 subjects for validation.  This form of cross-validation (described in
detail below) allows us to validate MAGeT with various atlas and template
library sizes, registration and label fusion methods.

{\bf Dataset evaluated.} 69 1.5T images were arbitrarily selected from the {\em
ADNI1:Screening 1.5T} standardized dataset. 23 subjects were chosen from each
disease category (cognitively normal (CN), MCI and AD). Demographics for this
subset are shown in Table \ref{tab:ADNI1_xvalidation_demographics}. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ADNI1 X-Validation Dataset Demographics Table
%
<<ADNI-Xval-demographics, echo=F, results="asis",cache=FALSE>>=
adni_69_RIDs = c(295,413,619,685,729,782,938,954,1018,1155,907,981,222,324,448,
                 546,553,572,602,610,814,1341,675,681,731,1130,41,68,70,101,
                 249,293,316,414,698,1206,1222,1339,751,1030,3,5,10,16,22,53,
                 168,183,241,1205,328,1095,991,213,159,337,343,642,753,1109,
                 1217,29,56,1188,1293,149,382,431,1202)
tab <- summary(DX.bl ~ AGE + PTGENDER + PTEDUCAT + PTETHCAT + CDRSB + ADAS13 +
               MMSE, data = adnimerge, subset = VISCODE == 'bl' & RID %in%
               adni_69_RIDs, method = "reverse", test=FALSE, overall=TRUE)

latex(tab, file="", size="scriptsize",landscape=FALSE, ctable=FALSE,
      caption="ADNI-1 cross-validation subset demographics", 
      title="tab:ADNI1_xvalidation_demographics")
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

{\bf Atlas and template libary.}  Atlases consist of images taken from the
dataset, with corresponding manual labels provided by SNT.  Atlas library size
varied from 3 to 9 images.  The remaining 60-66 target images were segmented
with the template library size varying from 3 to 20 images for each setting of
atlas library size. Template library images were selected at random from the
targets. 

{\bf Registration method.} Both the ANTS and ANIMAL registration methods were
used. 

{\bf Label fusion.} Majority vote, cross-correlation weighted majority vote, and
Normalized Mutual Information weighted majority vote were used. With the
weighted majority vote fusion methods, the number of top labels used in the
fusion was varied from 3 to 20 images.

{\bf Evaluation.}  Monte Carlo Cross-Validation (MCCV), also known as repeated
random sub-sampling cross-validation, consists of repeated trials in which items
from the dataset are randomly sampled (without replacement) and assigned to a
training set or validation set \cite{Shao1993}.  

In each trial, the training set consists of images and SNT labels used as
atlases, and the validation set consists of images to be segmented along with
the corresponding SNT labels used as gold-standard segmentations. Both MAGeT
brain and basic multi-atlas segmentation were performed in each trial, and the
accuracy of the resulting segmentations were measured against the SNT labels. 

We performed 10 trials on each combination of parameters listed above: atlas
library size (1-9), template library size (1-20), registration method (ANTS vs.
ANIMAL), and label fusion method (MV, XC-WV, NMI-WV). A total of 1080 parameter
settings were evaluated over a total of 10800 trials. 

%%%%%
%%%%%               Experiments: ADNI-1 Screening Validation               %%%%%
%%%%%
\subsubsection{ADNI-1 Screening Validation}
To test the accuracy of MAGeT brain on a real-world task we segment the entire
ADNI-1 dataset using an atlas set that is not representative of the target set.

{\bf Dataset evaluated.} All images from the {\em ADNI1:Screening 1.5T}
standardized dataset.

{\bf Atlas and template libary.} The Winterburn atlases were used as the atlas
library.  The template library consisted of 21 randomly selected images from the
ADNI1 data dataset (7 healthy, MCI and AD subjects). Clinical and demographic
data for the template library subjects are shown in Table
\ref{tab:ADNI1_scr_tmpllib_demographics}.

{\bf Registration method.} The ANTS non-linear registration algorithm was used,
as it performed best in the ADNI1 cross-validation experiment (see Results). 

{\bf Label fusion.} Majority vote was used performed equally well in the ADNI1
cross-validation experiment and is the easiest label fusion method to operate. 

{\bf Evaluation.}
Since the hippocampal segmentation protocols differ between the ADNI labels and
Winterburn atlases, this poses a problem for direct similarity comparisons
between labels produced by MAGeT brain and the ADNI labels.  To evaluate the
performance of MAGeT brain, we compare the correlation of MAGeT segmentation
volumes with manual segmentation (SNT) volumes. Additionally, we correlate the
hippocampal volumes of established automated segmentation methods to MAGeT
segmentations.

Additionally, we compared classification accuracy of subjects by diagnosis based
on hippocampal volume using both the SNT labels and our produced labels.  

\todo{explain why we did(n't) resegment the ADNI images with the low-res
protocol and compare directly like that.} 

\todo{Also: group differences, expecting separation}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ADNI1 X-Validation Dataset Demographics Table
%
<<ADNI1-scr-tmpllib-demographics, echo=F, results="asis",cache=FALSE>>=
scr_tmpllib_RIDs = c(0295, 0413, 0619, 0685, 0729, 0782, 0938, 0954, 1018, 1155,
                 0907, 0981, 0448, 0553, 0814, 1130, 0698, 1339, 1095, 0991,
                 0159)
tab <- summary(DX.bl ~ AGE + PTGENDER + PTEDUCAT + PTETHCAT + CDRSB + ADAS13 +
               MMSE, data = adnimerge, subset = VISCODE == 'bl' & RID %in%
               scr_tmpllib_RIDs, method = "reverse", test=FALSE, overall=TRUE)

latex(tab, landscape=FALSE, ctable=FALSE, file="", size="scriptsize",
      caption="ADNI1 Screening Template Library demographics", 
      title="tab:ADNI1_scr_tmpllib_demographics")
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%
%%%%%          Experiments: SZ First Episode Patient Validation           %%%%%
%%%%%
\subsubsection{SZ First Episode Patient Validation}

{\bf Dataset evaluated.} To validate that MAGeT performance generalises to
across disease categories, we measure the performance of MAGeT on the
Schizophrenic First Episode Patient (SFEP) dataset.


{\bf Atlas and template libary.} - two different atlas sets: a manual
hippocampal segmentation of patients, and Winterburn atlas set.  
\todo{complete}

{\bf Registration method.} ANTS.
\todo{complete}

{\bf Label fusion.} Majority vote.
\todo{complete}

{\bf Evaluation.} We validate the FEP-atlas segmentations using Dice's Kappa,
and the Winterburn-atlas segmentations by correlating volumes. 
\todo{complete}


%%%%%
%%%%%              Experiments: Winterburn Atlases Validation              %%%%%
%%%%%
\subsubsection{Winterburn Atlases Validation}
{\bf Dataset evaluated.} - T1 BRAVO scans of the same subjects included in the 
Winterburn atlas set.  These scans are taken within .... weeks of the scans for 
the Winterburn atlases.
\todo{complete}

{\bf Atlas and template libary.} - Atlas library is Winterburn T1 atlases.  
Template library consists of all five T1 BRAVOs, plus 15 T1 healthy control images.
\todo{complete}

{\bf Registration method.} ANTS
\todo{complete}

{\bf Label fusion.} Majority vote.
\todo{complete}

{\bf Evaluation.}  - Leave one out cross-validation (LOOCV) in which all five
subjects are segmented in separate runs of MAGeT brain.  In each run, the subject
to be segmented is excluded from the Atlas library (so only four atlases are used).

Segmentation accuracy is judged by difference in hippocampal volume.
\todo{complete}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                               Results
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Results}

%%%%%
%%%%%                  Results: ADNI-1 cross-validationn                   %%%%%
%%%%%
\subsection{ADNI-1 Cross-Validation}


%                                                                              %
% ADNI1 Screening Validation - results preparation                             %
%                                                                              %
<<ADN1-Xval-prep, include=FALSE, cache=TRUE>>=
# all data from the validation trials
t_data       = read.csv(gzfile('data/a2a_ants/results_2013_01_03.csv.gz'))
t_data       = subset(t_data, atlases %in% c(1,3,5,7,9))
a_data       = t_data[,] #read.csv(gzfile('data/a2a_tracc/results_2013_01_03.csv.gz'))
diagnoses    = read.csv('data/a2a_diagnoses.csv')

# simplifies the table
t_data$se    = NULL
t_data$sn    = NULL
t_data$j     = NULL
a_data$se    = NULL
a_data$sn    = NULL
a_data$j     = NULL       

# add registration method column 
t_data       = cbind(t_data, reg_method = "ANIMAL")
a_data       = cbind(a_data, reg_method = "ANTS")

# separate MA majvote from MB so we can compute differences
t_ma = subset(t_data, approach=="multiatlas" & method=="majvote")
a_ma = subset(a_data, approach=="multiatlas" & method=="majvote")
t_mb = subset(t_data, approach=="mb")
a_mb = subset(a_data, approach=="mb")

ma = rbind(t_ma,a_ma)
mb = rbind(t_mb,a_mb)

# set up a few equivalences for multi-atlas, to make nomenclature simpler
ma$templates =  ma$atlases  # because no template library
mb[mb$method != 'majvote',]$templates = mb[mb$method != 'majvote',]$top_n 

all_data = merge(ma, mb, by=c("timestamp", "atlases", "batch", "label", "reg_method", "subject"))
all_data$k_diff = all_data$k.y - all_data$k.x 
method_labels <- list("Majority Vote" = "majvote", 
                      "NMI Vote" = "nmi", 
                      "Cross-correlation Vote" = "xcorr")
levels(all_data$method.y) <- method_labels
all_data       = merge(all_data, diagnoses)
remove(t_ma, a_ma, t_mb, a_mb, ma, mb)
@
%                                                                              %
%                                                                              %

% TODO: Bland-Altman plot for MA and MAGeT 

Hippocampal MAGeT-based segmentations using both ANIMAL and ANTs registration
algorithm demonstrate good overlap with manually derived gold-standards ( Figure
\ref{fig:ADNI1-xval-k-mean}, \todo{table?}) using each label fusion method.
Qualitatively, both ANIMAL and ANTs-based segmentations demonstrate trend
overlap accuracy that increases with the size of atlas library and template
library, with at least 12 templates needed for optimal results
\todo{quantify?}).  No significant difference in segmentation accuracy is seen
when either ANIMAL or ANTs registration is used with different label fusion
techniques, at any atlas or template library sizes (\todo{lm of interaction?).
In every parameter configuration, the use of MAGeT Brain with ANTs registration
shows increased segmentation accuracy over MAGeT Brain with ANIMAL registration
(\todo{interaction?}).

It is interesting to note that with an even number of templates, MAGeT brain
shows a small decrease in performance relative to when one fewer template image
is used (\todo{show significance of this}). See section (\todo{ref}) for a
discussion of this behaviour. In the remainder of this section, only results
from odd-sized template libraries will be shown. 


\begin{figure}
<<ADN1-xval-k-mean, cache=TRUE, dependson='ADNI1-Xval-prep'>>=

ggplot(subset(all_data, method == 'majvote'), 
       aes(x=templates.y,y=k.y, colour=as.factor(atlases))) + 
  facet_grid(reg_method~method.y) + 
  stat_summary(fun.y=mean,geom='line',
               aes(y=k.y, weight=1)) + 
  #stat_smooth(method='lm', formula=y~log(x)) + 
  scale_colour_hue(name="Atlases") +
  xlab( "Number of Templates" ) + 
  ylab( "Mean DSC" )
@
  \caption{MAGeT brain mean DSC by atlas and template library size}
  \label{fig:ADNI1_xval-k_mean}
\end{figure}


With an increasing number of templates, MAGeT-based segmentating using ANTs
registration and majority vote label fusion shows improvement in overlap
accuracy over multi-atlas-based segmentation, using the same number of atlases
and voting method Figure \todo{ref}. The magnitude of improvement over
multi-atlas-based segmentation decreases with an increasing number of atlases,
with accuracy converging with 7 atlases.  Peak improvement in MAGeT Brain
accuracy (0.02 DSC) is found when one atlas is used with a template library of
20 images. \todo{stats?}

\begin{figure}
<<ADN1-Xval-k-diff, cache=TRUE, dependson='ADNI1-Xval-prep'>>=
ggplot(subset(all_data, reg_method=="ANTS" & method.y=="Majority Vote" &
                templates.y %in% seq(1,20,2)), 
       aes(x=templates.y, y=k_diff, colour=as.factor(atlases))) + 
  #facet_grid(reg_method~method.y) + 
  stat_summary(fun.data=mean_cl_boot,geom='errorbar',
               aes(y=k_diff,colour=as.factor(atlases), width=0.2)) +
  stat_summary(fun.y=mean, geom="point", 
               aes(y=k_diff,colour=as.factor(atlases))) + 
  stat_summary(fun.y=mean, geom="line", 
               aes(y=k_diff,colour=as.factor(atlases))) + 
  #stat_smooth(method=lm, formula=y~log(x)) + 
  geom_hline(aes(alpha=0.5, yintercept=0), linetype='dashed') + 
  coord_cartesian(ylim=c(-0.1,0.05)) + 
  scale_x_continuous(breaks=seq(1,20,2)) + scale_y_continuous(breaks=seq(-1,1,by=0.01)) + 
  scale_colour_hue(name="Atlases") +
  scale_alpha_continuous(legend=FALSE) + 
  scale_linetype_discrete(legend=FALSE) + 
  xlab( "Number of Templates" ) + 
  ylab( "Increase in mean Kappa between MAGeT brain and multiatlas" ) 
@
  \caption{Increase in mean Kappa between MAGeT brain and multi-atlas}
  \label{ADNI1_cross_validation_MA_difference}
\end{figure}


In addition to an improvement in accuracy over multi-atlas-based segmentation,
MAGeT Brain also shows a decrease in the variability of segmentation accuracy
with different input atlases (Figure \todo{ref}).  Additionally, variability
decreases with the size of template library, and is significantly decreased
(p<0.05) when using 3-7 atlases and 17 or more templates. 


\begin{figure}
<<ADN1-Xval-k-sd-t-test-p-plot, cache=TRUE, dependson='ADNI1-Xval-prep'>>=
    ANTSmajvote = subset(all_data, reg_method=="ANTS" & method.y=="Majority Vote")

data.stats = ddply(ANTSmajvote, c("subject", "label","atlases","templates.y"), function (df) {
  data.frame(
    MA.sd  =  sd(df$k.x),
    MB.sd  =  sd(df$k.y),
    MA.var = var(df$k.x),
    MB.var = var(df$k.y)    
  )
})

stats.tests = ddply(data.stats, c("atlases","templates.y"), function (df) {
  t.var = t.test(df$MA.var, df$MB.var)
  t.sd  = t.test(df$MA.sd , df$MB.sd)
  data.frame(
    stat      = c("var", "sd"),
    statistic = c(t.var$statistic, t.sd$statistic),
    p.value   = c(t.var$p.value, t.sd$p.value)
  )
})

ggplot(stats.tests, 
       aes(x=templates.y, y=p.value, colour=as.factor(atlases))) + 
  facet_grid( . ~ stat) + 
  geom_line() + 
  geom_hline(aes(yintercept=0.05), linetype='dashed') + 
  scale_colour_hue(name="Atlases") +
  scale_alpha_continuous(guide='none') + 
  scale_linetype_discrete(guide='none') + 
  scale_x_continuous(breaks=1:20) + scale_y_continuous(breaks=seq(0,1,by=0.05)) + 
  xlab( "Number of Templates" ) + 
  ylab( "p-value" ) 

  
@
\end{figure}

<<ADN1-Xval-sd-by-subject, cache=TRUE, dependson='ADNI1-Xval-prep'>>=
SDs = data.stats[c('subject','label','atlases','templates.y','MA.sd','MB.sd')]
SDs = subset(SDs, templates.y %in% c(5,10,15,20) & atlases == 5)

melted = melt(SDs, measure.vars=c('MA.sd','MB.sd'))
ggplot(melted, aes(x=templates.y, y=value, 
                   group=interaction(templates.y, variable), colour=as.factor(variable))) + 
  scale_x_continuous(breaks=c(5,10,15,20)) + 
  geom_violin() 
@

%- show variance in MAGeT performance by showing nine plots, each with mean multi-atlas performance plotted.

\begin{figure}
<<ADN1-Xval-k-diff-ANTS-20tmpls, cache=TRUE, dependson='ADNI1-Xval-prep'>>=
a_20_tmpls = subset(all_data, 
                      reg_method  == "ANTS" &
                      method.y    == "Majority Vote" &
                      templates.y == 20)
ggplot(a_20_tmpls, aes(x=factor(atlases))) +
  stat_summary(fun.y=mean,geom='point',size=3,colour="red",aes(y=k.x)) +
  stat_summary(fun.y=mean,geom='line',colour="red",aes(y=k.x,group=1)) +
  stat_summary(fun.y=mean,geom='point',size=3,colour="blue",aes(y=k.y)) +
  stat_summary(fun.y=mean,geom='line',colour="blue",aes(y=k.y,group=1)) +
  labs(x="Number of Atlases", y = "Kappa", 
       title="mean Kappa of MA and MAGeT brain (ANTS/20 templates) \nvs\natlas library size") +
  scale_colour_hue(name="Method") + 
  coord_cartesian(ylim=c(0.7,0.9))
  #theme(legend.justification=c(1,0), legend.position=c(1,0))
@
  \caption{Change in mean Kappa between multi-atlas and MAGeT brain using ANTS,
  20 templates}
  \label{}
\end{figure}

\begin{figure}
<<ADN1-Xval-ANTS-20tmpls-t-test-sd, cache=TRUE, dependson='ADNI1-Xval-prep'>>=
a_20_tmpls = subset(all_data, 
                      reg_method  == "ANTS" &
                      method.y    == "Majority Vote" &
                      templates.y == 20 &
                      atlases     == 9 & 
                      volume.x < 10000)
stddev = ddply(a_20_tmpls, c("subject", "label"), function (df) {
  data.frame(
    MA = sd(df$k.x),  #MA
    MB = sd(df$k.y)  #MB
  )
})


# TODO: against SNT
melted = melt(stddev, id.vars=c("subject", "label"))
ggplot(melted, aes(x=variable, y=value)) + geom_boxplot()
t.test(stddev$MA, stddev$MB)
@
  \caption{}
  \label{}
\end{figure}


% \begin{figure}
% <<ADN1-Xval-ANTS-20tmpls-Bland-Atlman, cache=TRUE, dependson='ADNI1-Xval-prep'>>=
% a_20_tmpls = subset(all_data, 
%                       reg_method  == "ANTS" &
%                       method.y    == "Majority Vote" &
%                       templates.y == 20 &
%                       atlases     == 9 &
%                       volume.x < 10000)
% avg = ddply(a_20_tmpls, c("subject", "label"), function (df) {
%   data.frame(
%     pre = mean(df$volume.x),  #MA
%     post = mean(df$volume.y)  #MB
%   )
% })
% # TODO: against SNT
% 
% #df = data.frame(pre=a_20_tmpls$volume.x, post=a_20_tmpls$volume.y)
% bland_altman_plot(avg) + 
%   xlab('Mean of MA and MAGeT HC Left/Right Volumes') + 
%   ylab('MA - MAGeT Volume') + 
%   opts(title = 'Bland-Altman Plot')
% @
%   \caption{Change in mean Kappa between multi-atlas and MAGeT brain using ANTS, 20 templates}
%   \label{}
% \end{figure}
% 
% 
% \begin{figure}
% <<ADN1-Xval-k-by-disease, cache=TRUE, dependson='ADNI1-Xval-prep'>>=
% a_20_tmpls = subset(all_data, 
%                       reg_method  == "ANTS" &
%                       method.y    == "Majority Vote" &
%                       templates.y == 20 &
%                       atlases %in% c(1,9))
% template_library = read.csv('data/a2a_ants/template_library_composition.csv')
% template_library$subject = NULL
% a_20_tmpls = merge(a_20_tmpls, template_library,
%                    by.x=c('timestamp', 'templates.y'), 
%                    by.y=c('timestamp', 'templates'))
% ggplot(a_20_tmpls, aes(y=k.y, x=templates_CN,colour=DX)) +  # why does k.x look the same?
%   facet_grid( . ~ atlases) + 
%   geom_smooth(method='lm',fullrange=F) 
%  # add 
% @
%   \caption{Mean kappa vs. proportion of disease category in template library by disease category}
%   \label{}
% \end{figure}
% 
% 
% \todo{show cost (in registrations) / benefit tradec off graph:  show number of
% registrations per Kappa?  or hours of manual labour per Kappa?)}
% discuss run-time for each of MAGet and multi-atlas 

%%%%%
%%%%%                  Results: ADNI-1 Screening Validation               %%%%%
%%%%%
\subsection{ADNI-1 Screening Validation}


Based on the results from the ADNI1 Cross-Validation experiment, MAGeT Brain was
configured with a template library of 20 subject images and majority vote label
fusion. 

% \begin{itemize}
% \item  A2A shows that if atlas population strongly(?) represents subject set
%        variability, then free choice from atlas population will produce
%        improvements (we know this b/c of extensive validation trials). 
% \item  what about in the case where atlas population doesn???t strongly
%        represent subject set variability (e.g. a priori atlas set)?  then, we
%        can use atlas selection to refine atlas set? 
% \end{itemize}
% 
% \todo{Kappa against our manual rater is low... explain that}

<<ADNI-src-volumes-prep,echo=F,cache=T>>=
bl1.5T= read.csv("data/ADNI_baseline_volumes/ADNI1_Screening_1.5T_11_15_2012.csv")
bl3T  = read.csv("data/ADNI_baseline_volumes/ADNI1_Baseline_3T_11_15_2012.csv")
mb    = read.csv("data/ADNI_baseline_volumes/ADNI1_1.5T_MAGeT_volumes.csv")
maper = read.csv("data/ADNI_baseline_volumes/MAPER_volumes.csv")
snt   = read.csv("data/ADNI_baseline_volumes/UCSFSNTVOL.csv")
ucsd  = read.csv("data/ADNI_baseline_volumes/UCSDVOL.csv")
fs    = read.csv("data/ADNI_baseline_volumes/UCSFFSX_02_15_12.csv")
fsl   = read.csv("data/ADNI_baseline_volumes/ADNI1_1.5T_FSLFIRST_volumes.csv", sep=';')

# recode VISCODE
#viscode_levels = list("bl"=1,"bl"=2, "m06"=3,"m12"=4)
#yr1$VISCODE <- as.factor(yr1$Visit)
#levels(yr1$VISCODE) <-viscode_levels
bl1.5T$VISCODE <- 'bl'
bl1.5T$Scaled_2 <- grepl("Scaled_2", yr1$Description)

#TODO: include Scaled_2? 
subjects = bl1.5T

# fetch just the columns we need, and do a little renaming
mb_pruned     = data.frame(MAGeT_L = mb$Left_Hippo, 
                           MAGeT_R = mb$Right_Hippo, Source = mb$SourceImageID)
maper_pruned  = data.frame(MAPER_L = maper$Left_Hippo, 
                           MAPER_R = maper$Right_Hippo, Source = maper$SourceImageID)
snt_pruned    = data.frame(SNT_L = snt$LEFTHIPPO, 
                           SNT_R = snt$RIGHTHIPPO, Source = snt$IMAGEUID)
ucsd_pruned   = data.frame(RID=ucsd$RID, VISCODE=ucsd$VISCODE, 
                           UCSD_L=ucsd$LHIPPOC, UCSD_R=ucsd$RHIPPOC)
fs_pruned     = subset(fs, TEMPQC != "Fail")
fs_pruned     = data.frame(FS_L=fs_pruned$ST29SV, 
                           FS_R=fs_pruned$ST88SV, Source = fs_pruned$IMAGEUID)
fsl_pruned    = data.frame(FSL_L=fsl$X17, 
                           FSL_R=fsl$X53, Source=fsl$Source)

# diagnoses
dx = adnimerge[c("DX.bl", "RID", "VISCODE")]

# Now create one data.frame with all the yr1 volume data we have from each datasource
combined = merge(subjects, mb_pruned   , by.x="Image.Data.ID", by.y="Source", all.x=TRUE)
combined = merge(combined, maper_pruned, by.x="Image.Data.ID", by.y="Source", all.x=TRUE)  # only Baseline
combined = merge(combined, snt_pruned  , by.x="Image.Data.ID", by.y="Source", all.x=TRUE)
#combined = merge(combined, ucsd_pruned , by=c("RID", "VISCODE"), all.x =TRUE)              # TODO: this a unique key?
combined = merge(combined, fs_pruned   , by.x="Image.Data.ID", by.y="Source", all.x=TRUE)
combined = merge(combined, fsl_pruned  , by.x="Image.Data.ID", by.y="Source", all.x=TRUE)
combined = merge(combined, dx          , by=c("RID","VISCODE"), all.x=TRUE)

attach(combined)
totals = data.frame(RID = RID, VISCODE = VISCODE, DX = factor(DX.bl),
                  MAGeT = MAGeT_L + MAGeT_R, 
                  MAPER = MAPER_L + MAPER_R, 
                  SNT   = SNT_L + SNT_R, 
                  #UCSD  = UCSD_L + UCSD_R,
                  FS    = FS_L + FS_R, 
                  FSL   = FSL_L + FSL_R)

detach(combined)
#complete_totals = subset(totals, !is.na(SNT) & !is.na(FSL) & !is.na(FS) & !is.na(MAPER) & !is.na(MAGeT))
totals.complete = na.omit(totals)
@

\begin{figure}[h]
<<ADNI-scr-volumes-boxplot,dependson='ADNI-baseline-volumes-prep',cache=T>>=
qplot(DX,value,data=melt(totals.complete,measure.vars=c("FS", "FSL", "MAPER","MAGeT","SNT")),
      colour=variable,geom="boxplot") + 
      xlab("Diagnosis") + ylab("Total Hippocampal Volume (mm3)")
@
  \caption{Comparison of HC volumes by FreeSurfer (FSF), MAGeT brain (MAGeT), MAPER, and manual (SNT).}
  \label{ADNI-scr-volumes-boxplot}
\end{figure}

% paired t-test against SNT to show similarity (should be low) 
% Kruskal-Willis against  (should be high?)
% post-hoc power analysis to say we can detect this change
\begin{figure}[h]
<<ADNI-scr-histogram,cache=T>>=
melted   = melt(totals.complete, measure.vars=c( "SNT","FSL","FS","MAPER","MAGeT"))
binwidth = 250

# prepare the normals
grid <- with(melted, seq(min(value), max(value), length = 100))
normaldf <- ddply(melted, c("variable", "DX"), function(df) {
  data.frame( 
    value = grid,
    density = dnorm(grid, mean(df$value), sd(df$value)),
    freq = length(df$value) * dnorm(grid, mean(df$value), sd(df$value)) * binwidth,
    length = length(df$value)
  )
})

testsdf <- ddply(melted, c("variable", "DX"), function(df) {
  shapiro = shapiro.test(df$value)
  data.frame(
    shapiro.w = shapiro$statistic,
    shapiro.p = shapiro$p.value,
    mean = mean(df$value),
    sd = sd(df$value)
  )
})


melted.by.snt = melt(totals.complete, measure.vars=c("MAGeT","FSL", "FS", "MAPER"))
snt.tests <- ddply(melted.by.snt, c("variable", "DX"), function(df) {
  ks = ks.test(df$SNT, df$value)
  data.frame( 
    ks.D = ks$statistic,
    ks.p = ks$p.value
  )
})

label_x_pos = 10000
ggplot(data=melted, aes(x=value)) + 
  geom_histogram(binwidth=binwidth, alpha=0.8) + 
  geom_line(aes(y=freq, colour='red'), data=normaldf) +
  geom_text(aes(y=29,x=label_x_pos,hjust=1,size=1, 
                label=paste("list(W ==",signif(shapiro.w, digits=3), ", p == ", 
                            signif(shapiro.p,digits=3), ")")), 
            parse=TRUE, data=testsdf) +
  geom_text(aes(y=25,x=label_x_pos,hjust=1,size=1, 
                label=paste("list(D ==",signif(ks.D, digits=3), ", p == ", 
                            signif(ks.p,digits=3), ")")), 
            parse=TRUE, data=snt.tests) + 
  geom_text(aes(y=21,x=label_x_pos,hjust=1,size=1, 
                label=paste("sigma ==",signif(sd, digits=3))), 
            parse=TRUE, data=testsdf) + 
  geom_text(aes(y=17,x=label_x_pos,hjust=1,size=1, 
                label=paste("mu ==",signif(mean, digits=3))), 
            parse=TRUE,data=testsdf) + 
  xlim(0, 10000) + ylim(0,30) + 
  facet_grid(variable ~ DX) + 
  scale_colour_discrete(guide="none") + 
  scale_size_continuous(guide="none") + 
  labs(title="Total hippocampus volume by disease and measurement method", 
       x=expression(paste("Total hippocampal volume (", mm^2, ")")),
       y="Frequency") + 
  theme(axis.title.x = element_text(vjust=-0.1))
@
  \caption{{\bf ADNI Baseline cohort.} Comparison of total hippocampal volumes
  as measured by SNT, FSL, FreeSurfer (FS), MAPER, and MAGeT brain (MAGeT). A
  fitted normal curve is shown in red. $W$ is the Shapiro-Wilkes test statistic
  measuring normality of the data (signficance indicates non-normality). $D$ is
  the Kolmogorov-Smirnov test statistic measuring the goodness-of-fit between
  the distribution of measured volumes and SNT volumes (significance indicates a
  difference).}
  \label{ADNI-scr-histogram}
\end{figure}

% 

% show as a plot
<<ADNI-scr-summary-table, echo=F, results="asis",cache=FALSE>>=
# a rather dirty way of computing the pairwise correlations and then forming
# a printable table out of them.  Sorry.
melted = melt(totals.complete, measure.vars=c("MAGeT","FSL", "FS", "MAPER"))
cor_by_dx    = by(melted[c("SNT", "value")], c(melted['variable'], melted['DX']), 
                  function(x) cor(x$SNT,x$value, use="pairwise.complete.obs"))
cor_overall  = by(melted[c("SNT", "value")], melted['variable'], 
                  function(x) cor(x$SNT,x$value, use="pairwise.complete.obs"))
cor_by_dx = t(rbind(cor_by_dx))
cor_overall = rbind(cor_overall)

vol_by_dx = t(rbind(by(totals.complete$MAGeT, totals.complete$DX, mean)))
colnames(vol_by_dx) <- "Mean Volume"
vol_overall = matrix(mean(totals.complete$MAGeT),dimnames=list("Overall"))

dx      = cbind(vol_by_dx, cor_by_dx)
overall = cbind(vol_overall, cor_overall)
df      = format.df(rbind(dx, overall), dec=2)
                    
latex(df, title="",
      n.cgroup=c(1,ncol(df)-1),cgroup=c("","Volume Correlation"),
      file="", size="scriptsize")
@

%%%%%
%%%%%             Results: First Episode Patient Validation          %%%%%
%%%%%
\subsection{First Episode Schizophrenic Patients}
High volume correlation between Winterburn segmentation volumes and ground
truth.  (High-ish?) Kappa when using manual segmentations as Atlases. 

\begin{figure}
<<FEP-volumes,cache=T>>=
SZ_volumes=read.csv("data/SZ_volumes_by_method.csv")
with(SZ_volumes,
qplot(Manual,MAGeT,data=SZ_volumes) + geom_smooth(method="lm") + 
#   geom_text(aes(
#       label=paste("r = ", round(cor(Manual,MAGeT, use="complete.obs"), 2), 
#                   ", p <", round(as.numeric(t.test(Manual, MAGeT, paired=T)["p.value"]), 6))),
#       x=7000,y=10000, hjust=0,vjust=-0.5,size=5,data=data.frame()) +
   xlab("Total Hippocampal Volume (Manual Segmentation)") + 
   ylab("Total Hippocampal Volume (MAGeT Segmentation)")
)
@
  \caption{{\bf First Episode Schizophrenic Patients.} Comparison of total
  HC volumes for MAGeT against manually rated Hippocampal volumes}
  \label{SZ_volumes}
\end{figure}

%%%%%
%%%%%              Experiments: Winterburn Atlases Validation              %%%%%
%%%%%
\subsection{Winterburn Atlases Validation}

<<WAval-vol-boxplot,cache=T>>=
# dirty dirty
data = subset(read.csv('data/WAval.csv'), file != 'anusha')
gold_0.3mm = subset(data, version == "gold_0.3mm")
gold_0.6mm = subset(data, version == "gold_0.6mm")
mb_bravo   = subset(data, version == "mb_bravo")
mb_0.6mm   = subset(data, version == "mb_0.6mm")

gold_0.3mm_total = gold_0.3mm[,2:6] + gold_0.3mm[,7:11]
gold_0.6mm_total = gold_0.6mm[,2:6] + gold_0.6mm[,7:11]
mb_bravo_total   = mb_bravo[,2:6] + mb_bravo[,7:11]
mb_0.6mm_total   = mb_0.6mm[,2:6] + mb_0.6mm[,7:11]

# calculate percent error from the gold standard measured at 0.3mm resolution
pe_gold0.6mm = (gold_0.6mm_total - gold_0.3mm_total)/gold_0.3mm_total * 100
pe_mbbravo   = (mb_bravo_total - gold_0.3mm_total)/gold_0.3mm_total * 100
pe_mb0.6mm   = (mb_0.6mm_total - gold_0.3mm_total)/gold_0.3mm_total * 100

subjects = gold_0.6mm[,1]
pe_gold0.6mm = cbind(subjects,pe_gold0.6mm, res="Resampling to 0.6mm")
pe_mbbravo   = cbind(subjects,pe_mbbravo,   res="MAGeT-on-BRAVO")
pe_mb0.6mm   = cbind(subjects,pe_mb0.6mm,   res="MAGeT-at-0.6mm")


pe = rbind(pe_mbbravo,pe_mb0.6mm, pe_gold0.6mm)
names(pe) <- c("subject", "CA1", "Subiculum", "CA4", "CA2/CA3", "Dentate", "res")

melted = melt(pe, id.vars=c("subject", "res"))
names(melted) <- c("subject","res", "region","percenterr")
ggplot(melted, aes(y=percenterr,x=region)) +
  geom_boxplot(aes(colour=res)) +
  labs(title="Percent error in volumes under different measurement regimes",
       y="Percent error in volume", 
       x="Region") 
@

<<WAval-error,cach=T>>=
# compare % error between MAGeT and resampling
mb0.6mm_diff_over_gold_diff = cbind(subjects, abs(gold_diff) - abs(mb_0.6mm_diff), res="diffdff")
names(mb0.6mm_diff_over_gold_diff) <- c("subject", "CA1", "Subiculum", "CA4", "CA2/CA3", "Dentate", "res")
melted = melt(mb0.6mm_diff_over_gold_diff, id.vars=c("subject", "res"))
names(melted) <- c("subject","res", "region","voldiff")
ggplot(melted, aes(y=voldiff,x=region)) +
  geom_boxplot() +
  labs(title="Absolute difference in % difference between MAGeT and resampling",
       y="Absolute difference in % difference in volume", 
       x="Region")
@
<<WAval-kappa,cache=T>>=
#data = read.csv('data/WAval-kappa.csv')
ggplot(data, aes(x=label, y=kappa)) + geom_boxplot(y=kappa)
@

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                Discussion
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Discussion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                               Conclusion 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion}

\bibliographystyle{plainnat}
\bibliography{references}
\end{document}
