%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% TODO: 
%  - check tense: we are is have has  use/used find/found
%  - remove 'accuracy' unless specifically talking relative to ground truth (and
%    even then, qualify)
%  - overlap/similarity --> agreement? choose one. 
%  - check that chart labels are sensible 
%  - in particular, check that Experiment 5 match Experiment 1
%  - fix figure 2 schematic language for the experiments (not 2a 2b). 
% 
<<setup, include=FALSE, cache=FALSE>>=
library(knitr)
opts_chunk$set(echo = FALSE, 
               message = FALSE, 
               warning = FALSE, 
               fig.align = 'center', 
               tidy = FALSE, 
               comment = NA, 
               cache = TRUE,
               fig.width = 6, 
               fig.height = 6)
library(ggplot2)
library(Hmisc)
library(reshape2)
library(ADNIMERGE)
library(plyr)
options(digits=3)
theme_set(theme_bw(base_size = 12))
lm_eqn = function(m) {
  l <- list(a = format(coef(m)[1], digits = 2),
      b = format(abs(coef(m)[2]), digits = 2),
      pearson = format(sqrt(summary(m)$r.squared), digits = 3));
  if (coef(m)[2] >= 0)  {
    eq <- substitute(italic(y) == a + b %.% italic(x)*","~~italic(r)~"="~pearson,l)
  } else {
    eq <- substitute(italic(y) == a - b %.% italic(x)*","~~italic(r)~"="~pearson,l)    
  }

  as.character(as.expression(eq))
}

@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ADNI1-XVAL: prep
% Prepares the data in a the form needed for plotting.
<<ADNI1-xval-load,include=FALSE,cache=TRUE>>=
jens_atlases = read.csv('data/jens_atlases.csv')
jens_xval_data  <- read.csv(gzfile('data/cache/ADNI-JENS-XVAL:all_data.csv.gz'))
jens_xval_mean  <- read.csv(gzfile('data/cache/ADNI-JENS-XVAL:all_data_mean.csv.gz'))
jens_xval_mean$reg_method = factor(jens_xval_mean$reg_method, c("ANTS", "ANIMAL"))
jens_xval_mean$method.mb = factor(jens_xval_mean$method.mb, c("Majority Vote", "Cross-correlation Vote", "NMI Vote"))
mb.kappa.best = mean(subset(jens_xval_mean, 
                                 reg_method   == "ANTS" & 
                                 method.mb    == "Majority Vote" &
                                 templates.mb == 19 & 
                                 atlases      == 9)$k.mb)
mb.diff.best = mean(subset(jens_xval_mean, 
                                 reg_method   == "ANTS" & 
                                 method.mb    == "Majority Vote" &
                                 templates.mb == 19 & 
                                 atlases      == 1)$k_diff)
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ADNI1-COMPLETE
% Prepares the data in the form needed for plotting.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
<<ADNI-volumes-prep,echo=F,cache=T>>=
means.complete   <- read.csv('data/cache/ADNI1:qc.csv')
package_totals   <- read.csv('data/cache/ADNI1:package_totals.csv')
@

\documentclass{article}
\usepackage[margin=1in]{geometry}
\usepackage{algorithm, color, algpseudocode, url, amsmath, geometry, ctable}
\usepackage{titlesec, siunitx, graphicx}
\usepackage[round,authoryear]{natbib}
\usepackage[section]{placeins}   % keep floats in their place.
\usepackage{authblk}             % Listing Author affiliations
\usepackage{rotating}            % rotating figures
\usepackage[hypcap]{caption}
\usepackage{lineno}

%draft mode
\usepackage[colorinlistoftodos, textwidth=4cm, shadow]{todonotes}
\usepackage[displaymath, tightpage]{preview}
\setlength{\marginparwidth}{1.2in}
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhead[RO,RE]{draft - December, 2013}

% styling
\newcommand{\subsubsubsection}[1]{\paragraph{#1}}
\renewcommand\Affilfont{\itshape\small}  %authblk
\linespread{1.3} % one and a half line spacing

% shortcuts 
\newcommand{\mb}{MAGeT-Brain}
\newcommand{\multiatlas}{multi-atlas}
\newcommand{\ants}{ANTS}
\newcommand{\animal}{ANIMAL}
\newcommand{\adnidataset}{ADNI1:Complete 1Yr 1.5T}
\newcommand{\fsl}{FSL FIRST}
\newcommand{\freesurfer}{FreeSurfer}
\newcommand{\maper}{MAPER}
\newcommand{\prsnr}{Pruessner}
\newcommand{\pseg}{\prsnr-protocol manual segmentation}
\newcommand{\psegs}{\prsnr-protocol manual segmentations}
\newcommand{\snt}{SNT}


% title and authors
%\title{Bootstrapping Multi-atlas Hippocampal Subfield Segmentation by using
%Multiple Automatically Generated Templates}
\title{Bootstrapping Multi-atlas Segmentation Using Multiple Automatically
Generated Templates for the Segmentation of the Whole Hippocampus and
Subfields}
\author[1]{Jon Pipitone}
\author[1]{Min Tae M. Park}
\author[1]{Julie Winterburn}
\author[1,9]{Tristram A. Lett}
\author[2,3]{Jason P. Lerch}
\author[4]{Jens C. Pruessner}
\author[4,5]{Martin Lepage}
\author[1,6,9]{Aristotle N. Voineskos}
\author[1,6,7,8]{M. Mallar Chakravarty}
\author[ ]{the Alzheimer's Disease Neuroimaging Initiative\footnote{Data
used in preparation of this article were obtained from the Alzheimer's Disease
Neuroimaging Initiative (ADNI) database (adni.loni.ucla.edu). As such, the
investigators within the ADNI contributed to the design and implementation of
ADNI and/or provided data but did not participate in analysis or writing of this
report. A complete listing of ADNI investigators can be found at:
http://adni.loni.ucla.edu/wp-content/uploads/how\_to\_apply/ADNI\_Acknowledgement\_List.pdf}}
\affil[1]{Kimel Family Translational Imaging-Genetics Lab, Centre for Addiction and
Mental Health, Toronto, ON, Canada}
\affil[2]{Neurosciences and Mental Health Laboratory, Hospital for Sick
Children, Toronto, ON, Canada}
\affil[3]{Department of Medical Biophysics, University of Toronto, Toronto, ON,
Canada}
\affil[4]{Douglas Mental Health University Institute, Verdun, QC, Canada}
\affil[5]{Department of Psychiatry, McGill University, Montreal, QC, Canada}
\affil[6]{Department of Psychiatry, University of Toronto, Toronto, ON, Canada}
\affil[7]{Institute of Biomaterials and Biomedical Engineering, University of
Toronto, Toronto, ON, Canada}
\affil[8]{Rotman Research Institute, Baycrest, Toronto, ON, Canada}
\affil[9]{Institute of Medical Science, University of Toronto, Toronto, ON, Canada}

\renewcommand\Authands{ and }

\date{}

\begin{document}
\maketitle
\linenumbers

\begin{abstract}

\textbf{Introduction:} 
Advances in image segmentation of magnetic resonance images (MRI) have
demonstrated that \multiatlas{} approaches improve segmentation accuracy and
precision over regular atlas-based approaches.  These approaches often rely on
a large number of such manually segmented atlases (e.g.  30-80) that take
significant time and expertise to produce. We present an algorithm, \mb{} 
({\textbf M}ultiple {\textbf A}utomatically {\textbf Ge}nerated {\textbf
T}emplates), for the automatic segmentation of the hippocampus that minimizes
the number of atlases needed while still achieving similar accuracy to
\multiatlas{} approaches. Thus, our method acts as an accurate \multiatlas{}
approach when using special, hard-to-define atlases that are laborious to
construct. \\
\textbf{Method:} \mb{} works by propagating atlas segmentations to a template
library, formed from a subset of target images, via transformations estimated by
nonlinear image registration. The resultant segmentations are then propagated
to each target image and fused using a label fusion method.  To explore the
effect of atlases and templates library size, registation and label
fusion method, we conduct a 10-fold Monte Carlo cross-validation of \mb{} of whole
hippocampal segmentation on 60 ADNI subjects, manually segmented using the
\prsnr{}-protocol, over a range of parameter settings. Using the best settings
found, we then conduct a leave-one-out cross-validation (LOOCV) of hippocampal
subfield segmentation using five high-resolution manually segmented atlases.
Two final experiments assess \mb{} when applied to first episode psychosis and
Alzheimer's disease populations, and \mb{} segmentations are compared with
existing automated methods (\fsl{}, \freesurfer{}, \maper{}) and biases are
explored.\\
\textbf{Results:} Using 9 atlases and 19 template images, \mb{} achieves a
mean Dice's Similarity Coefficient (DSC) of \Sexpr{round(mb.kappa.best, digits=3)} 
(to \psegs{}) over 10-folds of Monte Carlo % TODO: update cross-validation on 60 subjects, and shows
significantly lower variability in DSC than \multiatlas{} segmentation.
In a LOOCV, \mb{} reproduces the volumes of the cornu ammonis (CA) 1;
CA4/dentate % TODO: update
gyrus (DG); and strata radiatum (SR), strata lacunosum (SL), and strata
moleculare (SM) hippocampal subfields with a percent error in volume that is
at or lower than that produced by image resampling. \mb{} produces hippocampal
volumes in a first episode psychosis patient population that are highly
correlated with expert manual segmentation volumes (Pearson $r = 0.877, t =
16.244, p < 0.001$). Compared to \fsl{} and \freesurfer{}, \mb{} shows much smaller
fixed volume bias (within $250 mm^3$ on average) to semi-automated (\snt{})
segmentations available from ADNI, as well as a conservative, rather than
exaggerated, proportional volume bias.\\ \textbf{Conclusion:} We demonstrate
that \mb{} produces accurate hippocampal segmentations using only 5 atlases over
different hippocampal definitions, disease populations, and acquisition types,
as well as showing that accurate identification of the hippocampal subfields is
possible.
\end{abstract}

\parbox{4in}{
\textbf{Contact:} \\
Jon Pipitone and M. Mallar Chakravarty \\
Kimel Family Translation Imaging-Genetics Research Laboratory \\
Research Imaging Centre \\
Centre for Addiction and Mental Health \\
250 College St. \\
Toronto, Canada   M5T 1R8 \\
jon.pipitone@camh.ca; mallar.chakravarty@camh.ca}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                               INTRODUCTION
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

The hippocampus is a brain structure situated in the medial temporal
lobe, and has long been associated with learning and memory
\citep{DenHeijer2012,Scoville2000}. The hippocampus is of interest to
clinical neuroscientists because it is implicated in many forms of brain
dysfunction, including Alzheimer's disease \citep{Sabuncu2011} and
schizophrenia \citep{Narr2004,Karnik-Henry2012}. In neuroimaging studies,
structural magnetic resonance images (MRI) are often used for the volumetric
assessment of the hippocampus.  As such, accurate segmentation of the
hippocampus and its subfields in MRI is a necessary first step to better
understand the inter-individual variability of subject neuroanatomy. 

The gold standard for neuroanatomical segmentation is manual delineation by an
expert human rater.  However, with the availability of increasingly large MRI
datasets, the time and expertise required for manual segmentation becomes
prohibitive \citep{Mazziotta1995,Mazziotta2001,Mazziotta,Pausova2007}. This
effort is complicated by the fact that there is significant variation between
segmentation protocols with respect to specific anatomical boundaries of the
hippocampus \citep{Geuze2004} and this has led to efforts to create an unified
hippocampal segmentation protocol \citep{Jack2011,Boccardi2013,Boccardi2013a}.
In addition, there is controversy over the appropriate manual segmentation
protocol to use in a particular imaging study \citep{Nestor2012}. Thus, a
segmentation algorithm that can easily adapt to different manual segmentation
definitions would be of significant benefit to the neuroimaging community.

Automated segmentation techniques that are reliable, objective, and reproducible
can be considered complementary to manual segmentation. In the case of classical
model-based segmentation methods \citep{Haller1997,Csernansky1998}, an MRI atlas
that was previously manually labelled by an expert rater is matched to target
images using nonlinear registration methods. The resulting nonlinear
transformation is applied to the manual labels (i.e. {\em label propagation}) to
warp them into the target image space. While this methodology has been used
successfully in several contexts
\citep{Chakravarty2008,Chakravarty2009,Collins1995,Haller1997}, it is limited in
accuracy due to error in the estimated nonlinear transformation itself, partial
volume effects in label resampling, and irreconcilable differences between the
neuroanatomy represented within the atlas and target images.
 
One methodology that can be used to mitigate these sources of errors involves
the use of multiple manually segmented atlases and probabilistic segmentation
techniques, such as those found in the \freesurfer{} package \citep{Fischl2002}.
\freesurfer{} uses a probabilistic atlas of anatomical and tissue classes along
with spatial constraints for class labels encoded using a Markov random field
model to segment the entire brain. 

More recently, many groups have used multiple atlases to improve overall
segmentation accuracy (i.e. \multiatlas{} segmentation) over model-based approaches
\citep{Heckemann2006,Heckemann2011,Collins2010,Lotjonen2010,Aljabar2009,Leung2010,Wolz2010}.
Each atlas image is registered to a target image, and label propagation is
performed to produce several labellings of the target image (one from each
atlas). A {\it label fusion} technique, such as voxel-wise voting, is used to
merge these labels into the definitive segmentation for the target. In addition,
weighted voting procedures that use {\em atlas selection} techniques are often
used to exclude atlases from label fusion that are dissimilar to a target image
in order to reduce error from unrepresentative anatomy \citep{Aljabar2009}.
This involves the selection of a subset of atlases using a similarity metric
such as cross-correlation \citep{Aljabar2009} or normalized mutual information.
Such selection has the added benefit of significantly reducing the number of
nonlinear registrations. For example \citet{Collins2010} demonstrated that only
14 atlases, selected based on highest similarity between medial temporal lobe
neuroanatomy as evaluated by normalized mutual information \citep{Studholme1999}
from a library of 80 atlases, were required to achieve accurate segmentations of
the hippocampus. Additionally, several methods have been explored for label
fusion, including the STAPLE algorithm (Simultaneous Truth And Performance Level
Estimation; \citet{Warfield2004}) that computes a probabilistic segmentation
using an expectation-maximization framework from an set of competing
segmentations, or others where a subset of segmentations can be estimated using
metrics such as the sum of squared differences in the regions of interest to be
segmented \citep{Coupe2011}.

However, many of these methods require significant investment of time and
resources for the creation of the atlas library ranging between 30
\citep{Heckemann2006} and 80 \citep{Collins2010} manually segmented atlases.
This strategy has the main drawback of being inflexible as it does not easily
accommodate varying the definition of the hippocampal anatomy (such as the
commonly used heuristic of subdividing the hippocampus into head, body, and tail
\citep{Poppenk2011,Pruessner2000}). Furthermore, none of these methods have
demonstrated sufficient flexibility to accommodate atlases that are somehow
exceptional such as those derived from serial histological data
\citep{Chakravarty2006,Yelnik2007} or high-resolution MRI data that enables
robust identification of hippocampal subfields
\citep{Winterburn2013,Yushkevich2009,Mueller2009,VanLeemput2009,Wisse2012}. Due
to the recent availability of the latter, there has been increased interest in
the use of probabilistic methods for the identification of the hippocampal
subfields on standard T1-weighted images. Our group recently demonstrated that
through use of an intermediary automated segmentation stage, robust and accurate
segmentation of the striatum, pallidum, and thalamus using a single atlas
derived from serial histological data is possible \citep{Chakravarty2013}.
The novelty of this manuscript is the extension of our \multiatlas{} methodology
to the hippocampus using more than a single input atlas, while simultaneously
limiting the number of inputs used during segmentation, and demonstrating that
accurate identification of the hippocampal subfields is indeed possible using
this methodology.

Of particular relevance to the present work is the LEAP algorithm (Learning
Embeddings for Atlas Propagation; \citet{Wolz2010}) because of its focus on
performing \multiatlas{} segmentation with a limited number of input atlases.  The
LEAP algorithm is a clever modification to the basic \multiatlas{} strategy in
which an atlas library is grown, beginning with a set of manually labelled
atlases, by successively incorporating unlabelled target images once they
themselves have been labelled using \multiatlas{} techniques. The sequence in
which target images are labelled is chosen so that the similarity between the
atlas images and the target images is minimised at each step, effectively
allowing for deformations between very dissimilar images to be broken up into
sequences of smaller deformations. Although \citet{Wolz2010} begin with an atlas
library of 30 MR images, this method could theoretically work using a much
smaller atlas library.  In their validation, LEAP was used to segment the whole
hippocampus in the ADNI-1 baseline dataset, achieving a mean Dice score of 0.85
against semi-automated segmentations. 

Also of interest to this manuscript are methods that attempt to define
hippocampal subfields using standard T1- or T2-weighted data.  To the best of our
knowledge, there are only two automated segmentation algorithms that attempt
this problem. The first is included with the \freesurfer{} package
\citep{VanLeemput2009}. This work is limited as it omits the tail of the
hippocampus and the segmentation protocol has yet to be fully validated.
Nonetheless, it demonstrates that the applicability of hippocampal subfield
segmentation using data from 10 subjects. In the second method,
\citet{Yushkevich2009} hippocampal subfields were manually labelled on
high-resolution (either $0.2mm^3$ isotropic or $0.2mm \times 0.3mm \times 0.2mm$
resolution voxels) T2-weighted MR images acquired from five post-mortem medial
temporal lobe samples. Using nonlinear registration guided by shape-based models
of the subfield segmentations, and manually derived hippocampus masks of the
target images, the authors demonstrate accurate parcellation of hippocampal
subfields in clinical 3T T1-weighted MRI volumes. This method is not fully
automatic as it requires whole hippocampal parcellation of the target images.
%TODO: ref other Yush paper

In this paper we have describe a thorough validation of the \mb{} algorithm for
the automatic segmentation of the hippocampus and its subfields. First, we
address the feasibility of whole hippocampus segmentation with a limited number
of input atlases \citep{Chakravarty2013} by performing a multi-fold validation
experiment using a subset of the Alzheimer's Disease Neuroimaging Initiative
(ADNI) dataset manually segmented using the \prsnr{}-protocol, over a range of
atlas and template library sizes, registration and label fusion methods. We then
perform a leave-one-out validation to determine if hippocampal subfields can be
accurately identified, using the best parameters discovered in the first
experiment.  To ensure that we have not overfit our parameters to the aging or
neurodegenerative brain, we also apply \mb{} to a dataset of individuals
suffering from first episode psychosis.  Finally, we validate our algorithm
using all of the data available in the \adnidataset{} sample and compare our
segmentations to other popular segmentation algorithms. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                               METHODS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Methods}

%%%%%                     MAGeT Brain Algorithm                            %%%%%

\subsection{The \mb{} Algorithm}
In this paper, we use the term {\em label} to mean any segmentation (manual or
derived) of an MR image. {\em Label propagation} is the process by which two
images are registered and the resulting transformation is applied to the labels
from one image to bring them into alignment with the other image. We use the
term {\em atlas} to mean a manually segmented image, and the term {\em template}
to mean an automatically segmented image (i.e.  via label propagation). The
terms {\em atlas library} and {\em template library} describe any set of such
images. Additionally, we use the term {\em target} to refer to an unlabelled
image that is undergoing segmentation.

The simplest form of \multiatlas{} segmentation, which we call {\em basic 
\multiatlas{} segmentation}, involves three steps. First, each labelled 
input image (i.e. atlas or template) is registered to an unlabelled target image.
Second, the labels from each image are propagated to the target image space. 
Third, the labels are combined into a single label by label fusion
\citep{Heckemann2006, Heckemann2011}. The basic \multiatlas{} segmentation method
is described in detail in other publications
\citep{Collins2010,Heckemann2011,Aljabar2009}. When only a single atlas is used,
basic \multiatlas{} segmentation degenerates into model-based segmentation: labels
are propagated from the atlas to a target, and no label fusion is needed.

\mb{} ({\textbf M}ultiple {\textbf A}utomatically {\textbf Ge}nerated {\textbf
T}emplates) bootstraps the creation of a large template library given a limited
input atlas library, and then uses the template library in basic \multiatlas
segmentation.  Images for the template library are selected from a set of input
target images, either arbitrarily or so as to reflect the neuroanatomy or
demographics of the target set as a whole (for instance, by sampling equally
from cases and controls).  The template library images are automatically
labelled by each of the atlases via label propagation. Effectively, basic
\multiatlas{} segmentation is then conducted using the template library to
segment the entire set of target images (including the target images used in the
construction of the template library). Since each template library image has
multiple labels (one from each atlas), the final number of labels to be fused
for each target may be quite large (i.e. \# of atlas $\times$ \# of templates).

Figure \ref{fig:MAGeT} illustrates the \mb{} algorithm graphically. Source code
for \mb{} can be found at \url{http://github.com/pipitone/MAGeTbrain}.

\begin{figure}
  \begin{centering}
    \includegraphics[width=\textwidth]{figure/MA-MAGeTBrain-Schematic}
  \end{centering}
  \caption{A schematic illustration of basic \multiatlas{} segmentation and
\mb{} segmentation. In multi-atlas segmentation, manual labels from atlas images
are warped (propagated) into subject space by applying the transformations
estimated from nonlinear image registration. The resulting candidate labels
from all atlas images are then fused to create a final segmentation. In \mb{}
segmentation, a template library is created by sampling (either randomly or
representatively) from the subject images. Atlas labels are propagated to all
template images and then to each subject image (including those used in the template
library). The candidate the labels for a subject are then fused into a final
segmentation.  \label{fig:MAGeT}}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                            Experiments                              %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Experiments}

The following section describes experiments conducted to assess the
segmentation quality of the \mb{} algorithm. The first two experiments assess the
validity of \mb{} using cross-validation designs. Experiment 1 investigates the
accuracy of \mb{} whole hippocampus segmentation over a wide range of parameter
settings. The results of this experiment enable us to choose the parameter
settings offering the best performance for use in subsequent experiments.
Experiment 2 assesses hippocampal subfield segmentation quality in a
leave-one-out cross-validation design. The last two experiments assess the
validity of the \mb{} algorithm when applied to different diseases: first episode
schizophrenia (Experiment 3), and Alzheimer's disease (Experiment 4).
Additionally, in Experiment 4, we compare \mb{} segmentations with those of
well-known automated methods and assessed segmentation bias. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                                                                     %%%%%
%%%%%         Experiment 1: Whole Hippocampus Cross-Validation            %%%%%
%%%%%                                                                     %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Experiment 1: Whole Hippocampus Cross-Validation}

Monte Carlo Cross-Validation (MCCV) \citep{Shao1993} was performed using images
from the ADNI dataset \citep{Jack2008}, and manual whole hippocampus
segmentations following the protocol laid out in \citep{Pruessner2000}.  This
form of cross-validation allows us to rigorously validate a large number of
parameter settings of \mb{} (atlas and template library sizes, registration
algorithm, and label fusion method) and select the best parameters to use in
subsequent experiments. 

In the Supplementary Materials we have replicated this experiment using the
\snt{} semi-automated labels included with the ADNI dataset.

\paragraph{\adnidataset{} dataset} 
Data used in the preparation of this article were obtained from the Alzheimer's
Disease Neuroimaging Initiative (ADNI) database (adni.loni.usc.edu). The ADNI
was launched in 2003 by the National Institute on Aging (NIA), the National
Institute of Biomedical Imaging and Bioengineering (NIBIB), the Food and Drug
Administration (FDA), private pharmaceutical companies and non-profit
organizations, as a \$60 million, 5-year public-private partnership. The primary
goal of ADNI has been to test whether serial magnetic resonance imaging (MRI),
positron emission tomography (PET), other biological markers, and clinical and
neuropsychological assessment can be combined to measure the progression of mild
cognitive impairment (MCI) and early Alzheimer's disease (AD).  Determination of
sensitive and specific markers of very early AD progression is intended to aid
researchers and clinicians to develop new treatments and monitor their
effectiveness, as well as lessen the time and cost of clinical trials.  

The Principal Investigator of this initiative is Michael W. Weiner, MD, VA
Medical Center and University of California San Francisco. ADNI is the result
of efforts of many co-investigators from a broad range of academic institutions
and private corporations, and subjects have been recruited from over 50 sites
across the U.S. and Canada. The initial goal of ADNI was to recruit 800 subjects
but ADNI has been followed by ADNI-GO and ADNI-2. To date these three protocols
have recruited over 1500 adults, ages 55 to 90, to participate in the research,
consisting of cognitively normal (CN) older individuals, people with early or
late MCI, and people with early AD. The follow up duration of each group is
specified in the protocols for ADNI-1, ADNI-2 and ADNI-GO. Subjects originally
recruited for ADNI-1 and ADNI-GO had the option to be followed in ADNI-2. For
up-to-date information, see www.adni-info.org.

60 1.5T images were arbitrarily selected from the baseline scans in the {\em
\adnidataset{}} standardized dataset. 20 subjects were chosen from each disease
category: cognitively normal (CN), mild cognitive impairment (MCI) and
Alzheimer's disease (AD). Demographics for this subset are shown in Table
\ref{tab:ADNI1-xvalidation-demographics}. Fully manual segmentations of the
left and right whole hippocampi in these images were provided by one author
(JCP) according to the segmentation protocol specified in \citet{Pruessner2000}. 

Clinical, demographic and pre-processed T1-weighted MRI were downloaded by the
authors from the ADNI database (adni.loni.ucla.edu) between March 2012 and
August 2012. The image dataset used was the "\adnidataset{}" standardized dataset
available from ADNI \footnote{
\url{http://adni.loni.usc.edu/methods/mri-analysis/adni-standardized-data/}}
\citep{Wyman2012}. This image collection contains uniformly pre-processed images
which have been designated to be the "best" after quality control.  All images
were acquired using 1.5T scanners (General Electric Healthcare, Philips Medical
Systems or Siemens Medical Solutions) at multiple sites using the protocol
described in \citep{Jack2008}.  Representative 1.5T imaging parameters were TR =
2400ms, TI = 1000ms, TE = 3.5ms, flip angle = $8^{\circ}$, field of view = 240 x
240mm, a $192 \times 192 \times 166$ matrix ($x$, $y$, and $z$ directions)
yielding a voxel dimensions of $1.25mm \times 1.25mm \times 1.2mm$.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% ADNI1 X-Validation Dataset Demographics Table
%
<<tab:ADNI-xval-demographics, echo=F, dependson='ADNI1-xval-load', results="asis",cache=FALSE>>=
tab <- summary(DX.bl ~ AGE + PTGENDER + PTEDUCAT + CDRSB + ADAS13 +
               MMSE, data = adnimerge, subset = VISCODE == 'bl' & RID %in%
               jens_atlases$RID, method = "reverse", test=FALSE, overall=TRUE)
caption = 
  "\\textbf{ADNI-1 cross-validation subset demographics.} 
  CN     - Cognitively Normal. 
  LMCI   - Late-onset Mild Cognitive Impairment. 
  AD     - Alzheimer's Disease.  
  Hisp   - Hispanic. 
  CDR-SB - Clinical Dementia Rating-Sum of Boxes.  
  ADAS   - Alzheimer's Disease Assessment Scale.  
  MMSE   - Mini-Mental State Examination."
latex(tab, file="", size="scriptsize",landscape=FALSE, ctable=FALSE,
      caption=caption, caption.loc = c("top"),
      label="tab:ADNI1-xvalidation-demographics")
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\paragraph{Experiment details} 

Monte Carlo Cross-Validation (MCCV), also known as repeated random sub-sampling
cross-validation, consists of repeated rounds of validation conducted on a fixed
dataset \citep{Shao1993}. In each round, the dataset is randomly partitioned into
a training set and a validation set. The method to be validated is then given
the training data, and its output is compared with the validation set.

In this experiment, our dataset consists of 60 1.5T images and corresponding
\psegs{}. In each validation round, the dataset is partitioned into
a training set consisting of images and manual segmentations used as an atlas
library, and a validation set consisting of the remaining images to be segmented
by both \mb{} and \multiatlas{}. The computed segmentations are compared to the
manual segmentations (see Evaluation below). 

A total of ten validation rounds were performed on each subject in the dataset,
over each combination of parameter settings. The parameter settings explored
are: atlas library size (1-9), template library size (1-20), registration method
(\ants{} or \animal{}, described below), and label fusion method (majority vote,
cross-correlation weighted majority vote, and normalized mutual information
weighted majority vote, described below).  In each validation round, both a
\mb{} and \multiatlas{} segmentation is produced.  A total of $10 \times 60 \times
9 \times 20 \times 2 \times 3 =$ \Sexpr{10*60*9*20*2*3} validation rounds
were conducted and resulting segmentations analysed. 

Before registration, all images underwent preprocessing with the N3 algorithm
\citep{Sled1998} to minimize intensity nonuniformity. In this experiment we
compared two nonlinear image registration methods:

\subparagraph{Automatic Normalization and Image Matching and Anatomical
Labeling (\animal{})}

The \animal{} algorithm carries out image registration in two phases. In the
first, a 12-parameter linear transformation (3 translations, rotations, scales,
shears) is estimated between images using an algorithm that maximizes the
correlation between blurred MR intensities and gradient magnitude over the whole
brain \citep{Collins}. In the second phase, nonlinear registration is completed
using the \animal{} algorithm \citep{Collins1995}: an iterative procedure that
estimates a 3D deformation field between two MR images. At first, large
deformations are estimated using a blurred version of the input data. These larger
deformations are then input to subsequent steps where the fit is refined by
estimating smaller deformations on data blurred with a Gaussian kernel with a
smaller full width at half maximum (FWHM). The final transformation is a set of
local translations defined on a bed of equally spaced nodes that were estimated
through the optimization of the correlation coefficient.  For the purposes of
this work we used the regularization parameters optimized in
\citet{Robbins2004}, displayed in Table \ref{tab:ANIMAL-params}. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ANIMAL parameters                    
%                                     
\begin{table*}[!tbp]
\scriptsize
\caption{\textbf{\animal{} registration parameters.} \label{tab:ANIMAL-params}}
\begin{center}
\begin{tabular}{l | c c c}
\hline 
Parameters        & Stage 1 & Stage 2 & Stage 3  \tabularnewline
\hline 
Model Blur (FWHM) &   8     &    8    &   4      \tabularnewline
Input Blur (FWHM) &   8     &    8    &   4      \tabularnewline
Iterations        &   30    &    30   &   10     \tabularnewline
Step              &   8x8x8 &  4x4x4  &   2x2x2  \tabularnewline
Sub-Lattice       &   6     &    6    &   6      \tabularnewline
Lattice Diameter  &24x24x24 &12x12x12 & 6x6x6    \tabularnewline
\hline
\end{tabular}
\end{center}
\end{table*}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subparagraph{Automatic Normalization Tools (\ants{})}

\ants{} is a diffeomorphic registration algorithm which provides great flexibility
over the choice of transformation model, objective function, and the consistency
of the final transformation \citep{Avants2008}. The transformation is estimated in a
hierarchical fashion where the MRI data is subsampled, allowing large
deformations to be estimated and successively refined at later hierarchical
stages (where the data is subsampled to a finer grid). The deformation field and
the objective function are regularized with a Gaussian kernel at each level of
the hierarchy. The \ants{} algorithm is freely available
\url{http://www.picsl.upenn.edu/ANTS/}. We used an implementation of the \ants{}
algorithm compatible with the MINC data format, mincANTS
\url{https://github.com/vfonov/mincANTS}.

We used the following command line when running \ants{}:
{\small
\begin{verbatim}
  mincANTS 3 -m PR[target_file.mnc,source_file.mnc,1,4] 
   --number-of-affine-iterations 10000x10000x10000x10000x10000 
   --affine-gradient-descent-option 0.5x0.95x1.e-4x1.e-4
   --use-Histogram-Matching --MI-option 32x16000
   -r Gauss[3,0] -t SyN[0.5] -i 100x100x100x20
   -o transformation.xfm
 \end{verbatim}
}
These settings were adapted from the "reasonable starting point" given in the
\ants{} manual 
\footnote{\url{https://sourceforge.net/projects/advants/files/Documentation/}}.

\paragraph{Label fusion methods}
Label fusion is a term given to the process of combining the information from
several candidate labels for an image into a single labelling.  In this
experiment we explore three fusion methods: 
\begin{description}
  \item[Voxel-wise Majority Vote]
  Labels are propagated from all template library images to a target.  Each
  output voxel is given the most frequent label at that voxel location amongst
  all candidate labels.

  \item[Cross-correlation Weighted Majority Vote]
  An optimal combination of targets from the template library has previously been
  shown to improve segmentation accuracy \citep{Aljabar2009,Collins2010}.  In this
  method, each template library image is ranked in similarity to each unlabelled 
  image by the normalized cross-correlation (CC) of image intensities after linear
  registration, over a region of interest (ROI) generously encompassing the 
  hippocampus.  Only the top ranked template library image labels are used in a
  voxel-wise majority vote. The ROI is heuristically defined as the extent of all
  atlas labels after linear registration to the template, dilated by three voxels
  \citep{Chakravarty2013}.  The number of top ranked template library image labels
  is a configurable parameter and displayed as the size of the template library
  in the rest of the paper. 

  The {\tt xcorr\_vol} utility from the \animal{} toolkit is used to calculate the
  cross-correlation similarity measure.  
 
  \item[Normalised Mutual Information Weighted Majority Vote]
  This method is similar to cross-correlation weighted voting except that image
  similarity is calculated by the normalised mutual information score over the
  region of interest\citep{Studholme2001}.  The {\tt itk\_similarity} utility
  from the EZMinc toolkit\footnote{\url{https://github.com/vfonov/EZminc}} is
  used to calculate the normalised mutual information measure between two images.
\end{description}

\paragraph{Evaluation method}  
The Dice similarity coefficient (DSC), also known as Dice's Kappa, assesses the
agreement between two segmentations. It is one of the most widely used measures
of segmentation accuracy, and we use it as the basis of comparison in this
experiment.
%Additionally, we report the Jaccard index, another commonly used similarity
%measure:

 \[\text{Dice's coefficient (DSC)} = \frac{2|A \cap B|}{|A| + |B|}\]

% \[\text{Jaccard (J)} = \frac{|A \cap B|}{|A \cup B|} = \frac{DSC}{(2-DSC)}\]

where $A$ and $B$ are the regions being compared, and the cardinality is the
volume measured in voxels. The labels produced by \mb{} and \multiatlas{}
segmentation are compared to the manual labels using the Dice similarity
coefficient, and the recorded value for each subject at each parameter setting
explored in this experiment is the average over ten validation rounds. 

Additionally, the sensitivity of \mb{} and \multiatlas{} to atlas and template
library composition is evaluated by comparing the variability in Dice scores
over all validation rounds at fixed parameter settings.  This is achieved by
first computing the variance of DSC scores in each block of ten validation
rounds per subject. The distribution of these statistics across all subjects is
then compared between \mb{} and \multiatlas{} using a Student's t-test. A
significant difference between distributions is taken to show either a larger or
smaller level of variability between methods. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                                                                     %%%%%
%%%%%        Experiment 2: Hippocampal Subfield Cross-Validation          %%%%%
%%%%%                                                                     %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Experiment 2: Hippocampal Subfield Cross-Validation}
The previous experiment assesses \mb{} peformance on whole hippocampus
segmentation. In this experiment, we assess \mb{} hippocampal subfield
segmentation of standard 3T T1-weighted images using a leave-one-out
cross-validation (LOOCV) design. 

\paragraph{Winterburn Atlases} 
The Winterburn atlases \citep{Winterburn2013} are digital hippocampal
segmentations of five in-vivo $0.3mm$-isotropic T1-weighted MR images. The
segmentations include subfield segmentations for the cornu ammonis (CA) 1; CA2
and CA3; CA4 and dentate gyrus; subiculum; and strata radiatum (SR), strata
lacunosum (SL), and strata moleculare (SM). Subjects in the Winterburn atlases
range in age from 29-57 years (mean age of 37), and include two males and three
females.  

\paragraph{Experiment details} 
Leave-one-out cross-validation (LOOCV) is a validation approach in which an
algorithm is given all but one item in a dataset as training data (in our case,
atlas images and labels) and then is applied to the left-out item. This is done,
in turn, for each item in the dataset and the output across all items is
evaluated. 

In this experiment, the high-resolution $0.3mm^3$ voxel Winterburn atlases are
used as the \mb{} atlas library, but in each round of LOOCV a $0.9mm^3$ voxel
target image corresponding to the left-out atlas is used so as to evaluate \mb{}
on standard 3T T1-weighted resolution images.

Specifically, this experiments has two parts, each using different sets of
$0.9mm^3$ voxel target images: trilinear subsampled versions of the Winterburn
atlas images (Experiment 2a), and separately acquired T1 BRAVO acquisitions of
four of the five Winterburn atlas subjects (Experiment 2b).  Image subsampling
of the Winterburn atlas images was performed using trilinear subsampling
techniques. 

The 3T T1 BRAVO acquisitions of four of the five Winterburn atlas subjects were
separately obtained within a short time of the original atlas image
acquisitions.  Images were acquired on a 3T GE Discovery MR 750 system (General
Electric, Milwaukee, WI) using an 8-channel head coil with the enhanced fast
gradient recalled echo 3-dimensional acquisition protocol, EFGRE-BRAVO, with the
following parameters: $TE/TR/TI = 3.0ms/6.7ms/650ms$, flip angle $=8^\circ$,
$FOV=15.8cm$, slice thickness$=0.9mm$, 176 in-plane steps for an approximate
isotropic resolution of 0.9mm dimension voxels.

The template library is composed of all $0.9mm^3$ voxel target images (either
the {\em BRAVO} or {\em subsampled} sets), plus an additional set of 16 of
healthy subjects 3T T1 images acquired separately (Table
\ref{tab:WAval-healthy-demographics}). These images were acquired on a 3T GE
Discovery MR 750 system (General Electric, Milwaukee, WI) using an 8-channel
head coil with the enhanced fast gradient recalled echo 3-dimensional
acquisition protocol, EFGRE-BRAVO, with the following parameters: $TE/TR/TI =
3.0ms/6.7ms/650ms$, flip angle=$8^\circ$ , $FOV = 15.3cm$, slice
thickness$=0.9mm$, 170 in-plane steps for an approximate isotropic resolution of
0.9mm dimension voxels.

The optimal size of template library, registration method, and label fusion
method found in Experiment 1 are used. Figure \ref{fig:LOOCV-schematic}
illustrates schematically the experimental set up.

\begin{figure}
  \begin{centering}
    \includegraphics[width=\textwidth]{figure/WinterburnSubfieldLOOCVSchematic}
  \end{centering}
  \caption{A schematic illustration of the experimental set up of the
  leave-one-out cross-validation (LOOCV) subfield experiment.}
  \label{fig:LOOCV-schematic}
\end{figure}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Subfield Validation Template library demographics (healthy controls)
%                                     
<<tab:WAval-healthy-demographics, echo=F, results="asis",cache=FALSE>>=
master = read.csv('data/DT_study.csv')
tab <- summary( Diagnosis ~ Age + Sex + Education + Handedness, data = master,
    method="reverse", na.rm = TRUE, test=FALSE)
caption = 
  "\\textbf{Demographics for the hippocampal subfield cross-validation healthy
control subject sample used in the template library (excluding the Winterburn
atlas subjects).} Education is shown in years."
latex(tab, file="", size="scriptsize",landscape=FALSE, ctable=FALSE,
      caption=caption, caption.loc = c("top"),
      title="tab:WAval-healthy-demographics")
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\paragraph{Evaluation method}  
Evaluating the accuracy of hippocampal subfields for T1 images at
$0.9mm^3$-isotropic voxels is inherently ill-defined since there are no manual
protocols for segmentation at this resolution to use as a reference. Instead, we
can evaluate the {\it precision} with which \mb{} produces hippocampal subfields
that correspond to the segmentation protocol used by the given atlas library
images.  Specifically, we compute the relative percent error in volume of the
\mb{}-produced hippocampal subfields with respect to the full-resolution
Winterburn atlas segmentations. In addtion, by directly resampling the
Winterburn atlas segmentations to $0.9mm^3$ voxels (using standard
nearest-neighbour image resampling techniques) we obtain a scaled down version
of the labels preserving the original segmentation protocol within the limits of
error from rounding and interpolation. The relative percent error in volume of
these labels provides a baseline to compare \mb{} segmentations against. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                                                                     %%%%%
%%%%%         Experiment 3: Application of \mb{} to the segmentation      %%%%%
%%%%%                       of schizophrenia patients                     %%%%%
%%%%%                                                                     %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Experiment 3: Application to the segmentation of first episode
schizophrenia patients}
 
To validate that the \mb{} works effectively in the context of other neurological
disorders, in this experiment we use the Winterburn atlases to derive 
whole hippocampal segmentations of a dataset of patients with schizophrenia. The
resulting segmentations are assessed for quality by comparison with expert
manual segmentations.

\paragraph{First Episode Schizophrenia Dataset}
All patients were recruited and treated through the Prevention and Early
Intervention Program for Psychoses (PEPP-Montreal), a specialized early
intervention service at the Douglas Mental Health University Institute in
Montreal, Canada. People aged 14 to 35 years from the local catchment area
suffering from either affective or non-affective psychosis who had not taken
antipsychotic medication for more than one month with an IQ above 70 were
consecutively admitted as either in- or out-patients. Of those treated at PEPP,
only patients aged 18 to 30 years with no previous history of neurological
disease or head trauma causing loss of consciousness were eligible for the
neuroimaging study; only those suffering from schizophrenia spectrum disorders
were considered for this analysis.  For complete program details see
\citet{Malla2003}. 

Scanning of 81 subjects was carried out at the Montreal Neurological Institute
on a 1.5-T Siemens whole body MRI system.  Structural T1 volumes were acquired
for each participant using a three-dimensional (3D) gradient echo pulse sequence
with sagittal volume excitation (repetition time=22ms, echo time=9.2ms, flip
angle=$30^{\circ}$, 180 1mm contiguous sagittal slices). The rectangular
field-of-view for the images was 256mm (SI)$\times$204mm (AP).  Subject
demographics are shown in Table \ref{tab:SZFEP-Demographics}. 

Manual segmentation of each subject whole hippocampus is produced following a
validated segmentation protocol \citep{Pruessner2000}. 

\paragraph{Experiment details} 
\mb{} is configured with an atlas library composed of the Winterburn T1 atlases
(see Experiment 2) ignoring subfield delineations.  All images from the
first episode dataset are segmented by \mb{}.  The optimal size of template
library, registration method, and label fusion method found in Experiment 1 are
used. 

\paragraph{Evaluation method}
The Pruessner and Winterburn hippocampal segmentation protocols differ slightly in
the neuroanatomical features that are delineated \citep{Winterburn2013}. This
difference poses a problem for evaluation by measuring overlap.  That is, since
different protocols will necessarily produce segmentations that do not perfectly
overlap, the degree of overlap cannot be solely used to compare segmentation
methods using different protocols. In place of an overlap metric, we can assess
the degree of (Pearson) correlation in average bilateral hippocampal volume of the
subjects produced by each method. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% First Episode SZ Demographics Table
%
<<tab:FEP-SZ-demographics, echo=F, results="asis",cache=FALSE>>=
caption = 
  "\\textbf{Schizophrenia First Episode Patient Demographics.}
  ambi - ambidextrous. 
  SES  - Socioeconomic Status score. 
  FSIQ - Full Scale IQ.
"
fep_sz_demographics = read.csv("data/SZ_demographics.csv", na.strings=c("","."))
fep_sz_demographics = subset(fep_sz_demographics, Anon <= 81)
tab <- summary(DX ~ Age + Gender + Handedness + Education + SES + FSIQ,
               data=fep_sz_demographics, method = "reverse", test = FALSE)
latex(tab, file="", size="scriptsize",landscape=FALSE, ctable=FALSE,
      caption=caption, caption.loc = c("top"),
      title="tab:SZFEP-Demographics")
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                                                                     %%%%%
%%%%%         EXPERIMENT 4: Application of \mb{} to the segmentation      %%%%%
%%%%%                       of ADNI subjects                              %%%%%
%%%%%                                                                     %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Experiment 4: Application to the segmentation of Alzheimer's
disease patients}

To validate \mb{} segmentation quality with respect to other established
automated hippocampal segmentation methods, \mb{} was applied to large dataset
from the ADNI project and the resulting segmentations were compared to those
produced by \freesurfer{}, \fsl{}, \maper{}, as well as semi-automated
whole hippocampal segmentations (\snt{}) provided by ADNI.

\paragraph{\adnidataset dataset} 
The {\em \adnidataset{}} standardized dataset contains $1919$ images in total.
\snt{}, \maper, \freesurfer{} hippocampal volumes for a subset of images were
provided by ADNI, along with quality control data for each \freesurfer{}
segmentation (guidelines described in \citep{Hartig2010}).  

Clinical, demographic and pre-processed T1-weighted MRI were downloaded by the
authors from the ADNI database (adni.loni.ucla.edu) between March 2012 and
August 2012. The image dataset used was the "\adnidataset{}" standardized dataset
available from ADNI \footnote{
\url{http://adni.loni.ucla.edu/methods/mri-analysis/adni-standardized-data/}}
\citep{Wyman2012}. This image collection contains uniformly pre-processed images
which have been designated to be the "best" after quality control.  All images
were acquired using 1.5T scanners (General Electric Healthcare, Philips Medical
Systems or Siemens Medical Solutions) at multiple sites using the protocol
described in \citep{Jack2008}.  Representative 1.5T imaging parameters were TR =
2400ms, TI = 1000ms, TE = 3.5ms, flip angle = $8^{\circ}$, field of view = 240 x
240mm, a $192 \times 192 \times 166$ matrix ($x$, $y$, and $z$ directions)
yielding a voxel dimensions of $1.25mm \times 1.25mm \times 1.2mm$.  Clinical
and demographic data for the entire \adnidataset{} dataset are shown in Table
\ref{tab:ADNI1-Dataset-Demographics}.

Semi-automated segmentations of the left and right whole hippocampi are made
available with a subset of ADNI images \citep{Hsu2002}. These labels have been
generated using the \snt{} tool from Medtronic Surgical Navigation Technologies,
Louisville, CO (see Supplementary Materials for detailed discussion of the
segmentation process).

\paragraph{Experiment details} 
\mb{} was configured with an atlas library composed of the five Winterburn T1
atlases (described in Experiment 2), and size of template library,
registration method, and label fusion method were determined by the optimal
settings found in Experiment 1.  The \fsl{} segmentation method was used via
the \verb+run_first_all+ script according to the FIRST user guide
\footnote{http://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FIRST/UserGuide}.  All images
in the \adnidataset{} dataset were segmented by both methods. 

One author (MP) performed visual quality inspection for \mb{} and \fsl{} 
segmentations using similar quality control guidelines (if either hippocampus
was under or over segmented by $10mm$ or greater in three or more slices then
the segmentation did not pass).  Only images meeting the conditions of having
segmentations from all methods (\snt{}, \maper{}, \freesurfer{}, \fsl{}, and \mb{}) and also
passing quality control inspection were included in the analysis.  

\paragraph{Evaluation method}
As in Experiment 3, the \snt{} and Winterburn hippocampal segmentation protocols
differ in the neuroanatomical features delineated, and so we assessed \mb{} by
the degree of (Pearson) correlation of average hippocampal volume across
subjects. We also computed the correlation in hippocampal volume between
existing, established automated segmentation methods -- \fsl{}, \freesurfer{},
and \maper{}, and \snt{} semi-automated segmentations. Additionally, we evaluate
the volume-related fixed and proportional biases in all segmentation methods
using Bland-Altman plots \citep{Bland1986}.  


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                                             
% ADNI1 Complete 1Yr Dataset Demographics Table 
%                                                                             
<<tab:ADNI1-Dataset-Demographics, echo=F, results="asis",cache=FALSE>>=
# RID < 2000 ensures only ADNI1 patients
yr1 = read.csv("data/ADNI_baseline_volumes/ADNI1_Complete_1Yr_1.5T_11_15_2012.csv")
yr1$VISCODE <- factor(yr1$Visit, levels = c(1,2,3,4), labels=c("bl","m03","m06","m12"))
yr1 = subset(yr1, !grepl("Scaled_2", Description))
yr1 = yr1[,c("RID","VISCODE")]
yr1 = 
adnimerge.yr1 = merge(adnimerge, yr1) 
tab <- summary(DX.bl ~ AGE + PTGENDER + PTEDUCAT + CDRSB + ADAS13 +
               MMSE, data = adnimerge.yr1, 
               #subset = RID %in% yr1$RID & VISCODE %in% c('bl','m06','m12'),   
               method = "reverse", test=FALSE, overall=TRUE)
caption = 
  "\\textbf{ADNI1 1.5T Complete 1Yr dataset demographics.} 
  CN     - Cognitively Normal. 
  LMCI   - Late-onset Mild Cognitive Impairment. 
  AD     - Alzheimer's Disease.  
  Hisp   - Hispanic. 
  CDR-SB - Clinical Dementia Rating-Sum of Boxes.  
  ADAS   - Alzheimer's Disease Assessment Scale.  
  MMSE   - Mini-Mental State Examination."
latex(tab, file="", size="scriptsize",landscape=FALSE, ctable=FALSE,
    caption=caption, caption.loc = c("top"),
    title="tab:ADNI1-Dataset-Demographics",
    label="tab:ADNI1-Dataset-Demographics")
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                               RESULTS                                        %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Results}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                                                                     %%%%%
%%%%%     RESULTS: Experiment 1: Whole Hippocampus Cross-Validation       %%%%%
%%%%%                                                                     %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Experiment 1 Results: Whole Hippocampus Cross-Validation}

In this experiment we conduct 10 rounds of \mb{} and \multiatlas{} segmentation of
of 60 subjects using atlas and template library sizes varying from 1-9 and 1-20
images respectively, two registration algorithms (\ants{} or \animal{}), and three
label fusion techniques (unweighted, cross-correlation, and normalised mutual
information weighted majority vote).  Computed segmentations are compared to
\psegs using Dice's Similarity Coefficient (DSC).  In the Supplementary
Materials we have replicated this experiment using the \snt semi-automated
labels included with the ADNI dataset.

We find that for \mb{} segmentations, similarity score increases
as atlas and template library size is increased, although with diminishing returns and
an eventual trend towards a plateau (Figure \ref{fig:ADNI1-xval-k-mean}).  A maximum
similarity score of \Sexpr{round(mb.kappa.best, digits=3)} is found when using 9
atlases, 19 templates, ANTS registration, and majority vote label fusion).  The
\ants{} registration method consistently out-performs \animal{} registration
over all variable settings we tested. Additionally, by itself, using a weighted
voting strategy did not significantly improve segmentation accuracy, contrary to
the findings of \citet{Aljabar2009} using basic \multiatlas{} segmentation.
Given these findings, in the remainder of this section only results using the
\ants{} registration algorithm and majority vote fusion will be shown.  

With at least five templates, \mb{} shows a mean improvement in similarity score
over \multiatlas{} segmentation when using the same size of atlas library and
majority vote label fusion (Figure \ref{fig:ADNI1-xval-k-diff}). The magnitude
of improvement increases with the size of template library, and shows
diminishing returns with larger atlas libraries. Peak improvement
(+\Sexpr{round(mb.diff.best, digits=3)} DSC) is found with a single atlas
and template library of 19 images.

In addition to a mean increase in similarity score over \multiatlas{}-based
segmentation, \mb{} also shows more consistency in similarity scores across all
subjects and validation folds (Figure \ref{fig:ADNI1-xval-variability}). A
template library of at least 13 images is sufficient to show significant ($p <
0.05$) decrease in variance for all sizes of atlas library tested (1-9 images).  

We find similar behaviour with respect to optimal parameter settings and
increased consistency of \mb{} segmentations in the replication of this
experiment (Experiment 5, Supplementary Materials) where atlases use a different
hippocampal definition is used. This strongly suggests that these results are
independant of the segmentation protocol used and are, instead, features of the
\mb{} algorithm.  

We have omitted results obtained when using an even number of atlases or
templates since with these configurations we found significantly decreased
performance. We believe this is results from an inherent bias in the majority
vote fusion method used (see Discussion). 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ADNI1-XVAL: mean Kappa plot by atlases, templates, reg and voting method. 
\begin{figure}
<<fig:ADNI1-xval-k-mean, cache=TRUE, dependson='ADNI1-xval-load', fig.width=7, fig.height=7>>=
stderr <- function(x) sqrt(var(x)/length(x))
ggplot(subset(jens_xval_mean, (templates.mb*atlases) %% 2 == 1 & templates.mb < 21),
       aes(x=templates.mb,y=k.mb, colour=as.factor(atlases), linetype=reg_method)) + #as.factor((atlases*templates.mb) %% 2 ))) + 
  facet_grid(.~method.mb) + 
  stat_summary(fun.y=mean,geom='line',
               aes(y=k.mb, weight=1, group=interaction(reg_method, as.factor(atlases)))) + 
  stat_summary(fun.y=mean,geom='point',
               aes(y=k.mb, weight=1, group=interaction(reg_method, as.factor(atlases)))) + 
  stat_summary(fun.y=mean,
               fun.ymin=function (x) mean(x) - stderr(x),
               fun.ymax=function (x) mean(x) + stderr(x), 
               geom='errorbar',
               aes(y=k.mb, weight=1, group=interaction(reg_method, as.factor(atlases))), linetype='solid', width=0.5) + 
  #stat_smooth(method='lm', formula=y~log(x)) + 
  scale_y_continuous(breaks=seq(0,1,0.01)) + 
  scale_colour_hue(name="Number of Atlases") +
  scale_linetype(name="Registration Method") +
  xlab( "Number of Templates" ) + 
  ylab( "Mean similarity (DSC)" ) + 
  theme(legend.direction = "horizontal", legend.position = "bottom", 
        axis.text = element_text(size = 8))
@
  \caption{Mean Dice's Similarity Coefficient of \mb{} segmentations relative to
  \psegs{} for 60 ADNI subjects vs. atlas and template library
  size, registration algorithm, and label fusion method. Error bars indicate
  standard error.
  \label{fig:ADNI1-xval-k-mean}}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ADNI1-XVAL: "increase" in mean kappa over \multiatlas{}
\begin{figure}
<<fig:ADN11-xval-k-diff,cache=TRUE,dependson='ADNI1-xval-load'>>=
ggplot(subset(jens_xval_mean, reg_method=="ANTS" & 
                method.mb=="Majority Vote" & (templates.mb*atlases) %% 2 == 1), 
       aes(x=templates.mb, y=k_diff, colour=as.factor(atlases))) + 
  #facet_grid(reg_method~method.y) + 
  stat_summary(fun.data=mean_cl_boot,geom='errorbar',
               aes(y=k_diff,colour=as.factor(atlases), width=0.2)) +
  stat_summary(fun.y=mean, geom="point", 
               aes(y=k_diff,colour=as.factor(atlases))) + 
  stat_summary(fun.y=mean, geom="line", 
               aes(y=k_diff,colour=as.factor(atlases))) + 
  #stat_smooth(method=lm, formula=y~log(x)) + 
  geom_hline(aes(alpha=0.5, yintercept=0), linetype='dashed') + 
  scale_x_continuous(breaks=seq(1,20,2)) + scale_y_continuous(breaks=seq(-1,1,by=0.01)) + 
  scale_colour_hue(name="Number of Atlases") +
  scale_alpha_continuous(guide = "none") + 
  scale_linetype_discrete(guide = "none") + 
  xlab( "Number of Templates" ) + 
  ylab( "Increase in mean similarity (DSC)" ) +
  theme(legend.direction = "horizontal", legend.position = "bottom")
@
  \caption{Increase in mean Dice's Similarity Coefficient of \mb{} over
  \multiatlas{} segmentations vs. atlas and template library size when using the
  \ants{} registration method, and majority-vote label fusion.
  Segmentation similarity is computed against \psegs{}.  
  Error bars indicate standard error.
  \label{fig:ADNI1-xval-k-diff}}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ADNI1-XVAL: show variability of MAGeT over parameters
\begin{figure}
<<fig:ADN1-Xval-variability,cache=TRUE,dependson='ADNI1-Xval-prep',fig.width=5,fig.height=5>>=
ants = subset(jens_xval_data, 
                     reg_method=="ANTS" & 
                     method.mb=="Majority Vote" &
                    templates.mb %in% seq(1,20,2))

ants.stats = ddply(ants, c("subject", "label", "atlases","templates.mb"), 
                   function (df) {
                     data.frame(
                       MA.sd  =  sd(df$k.ma),
                       MB.sd  =  sd(df$k.mb),
                       MA.var = var(df$k.ma),
                       MB.var = var(df$k.mb)
                       )
                   })

stats.tests = ddply(ants.stats, c("atlases","templates.mb"), function (df) {
  t.var = t.test(df$MA.var, df$MB.var)
  t.sd  = t.test(df$MA.sd , df$MB.sd)
  diff_mean_var = mean(df$MA.var - df$MB.var)
  diff_mean_sd  = mean(df$MA.sd -  df$MB.sd)
  
  # test statistic is positive if MA mean is larger than MB
  # i.e. that MA has a greater mean of variances/SDs
  # i.e. that MB has a smaller mean, and so is doing "better"
  data.frame(
    stat      = c("Variance", "Standard Deviation"),
    statistic = c(t.var$statistic, t.sd$statistic),
    p.value   = c(t.var$p.value, t.sd$p.value),
    direction = c(diff_mean_var, diff_mean_sd)
  )
})

ggplot(subset(stats.tests, direction > 0 & stat == "Variance"), 
  aes(x=templates.mb, y=p.value, colour=as.factor(atlases))) + 
  #facet_grid( . ~ stat) + 
  geom_line(size=0.5) +
  geom_point(size=2) + 
  geom_hline(aes(yintercept=0.05, alpha=0.5), linetype='dashed') + 
  geom_hline(aes(yintercept=0.01, alpha=0.5), linetype='dashed') + 
  scale_x_continuous(breaks=seq(1,20,by=2)) + 
  xlab( "Number of Templates" ) + 
  ylab( "Variability (p)") +
  scale_colour_hue(name="Atlases") +
  scale_alpha_continuous(guide='none') + 
  scale_linetype_discrete(guide='none') + 
  scale_size_continuous(guide='none') + 
  theme(legend.direction = "horizontal", legend.position = "bottom")
@
  \caption{{\bf Difference in variability of \mb{} vs. \multiatlas{} segmentation
  with respect to manual segmentation.}
  Variance of segmentation accuracy between \mb{} and \multiatlas{} segmentation
  is computed for each subject across all ten rounds of validation. 
  Shown on the y-axis is the  p-value resulting from a t-test comparing the
  distribution of variances at each parameter setting (atlas/template library
  size). 
  Only points where \mb{} mean variability is lower than \multiatlas{} are shown.
  Dashed lines indicate a p-value of 0.05 and 0.01.}
  \label{fig:ADNI1-xval-variability}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\FloatBarrier

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                                                                     %%%%%
%%%%%    RESULTS: Experiment 2: Hippocampal Subfield Cross-Validation     %%%%%
%%%%%                                                                     %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Experiment 2 Results: Winterburn Atlases Cross-Validation}
<<WAval-prep, cache=T>>=
wa.xval.vols = na.omit(read.csv('data/WAval.csv'))
wa.xval.casted = dcast(melt(wa.xval.vols, id.vars=c("file","version")), file + variable ~ version)
wa.xval.casted = rename(wa.xval.casted, c("variable"="region"))
levels(wa.xval.casted$region) <-list("CA1"="X1", "CA1"="X101", 
                            "Subiculum"="X2","Subiculum"="X102", 
                            "CA4/DG"="X4","CA4/DG"="X104", 
                            "CA2/CA3"="X5","CA2/CA3"="X105", 
                            "SR/SL/SM"="X6","SR/SL/SM"="X106")


fmt_tstat = function(a, b) {
  test = t.test(a,b, paired=T)
  p = sprintf("%0.3f", max(0.001,round(test$p.value,3)))
  t = sprintf("%0.3f", round(test$statistic,3))
  paste(t," (",p,")")
}

wa.p = ddply(wa.xval.casted, c("region"), function (df) {
  with(df, {
       data.frame(
         res = fmt_tstat(gold_0.3mm, gold_0.9mm),
         bra = fmt_tstat(gold_0.3mm, mb_bravo),
         mbr = fmt_tstat(gold_0.3mm, mb_0.9mm)
       )})
  })

wa.p = rename(wa.p, c(
  'region'='Subregion','res'='Resampled',
  'bra'='MAGeT on BRAVO','mbr'='MAGeT on Resampled'))

wa.xval.error = ddply(wa.xval.casted, c("file", "region"), function(df) {
  with(df, 
  data.frame(
    resampled = (gold_0.9mm - gold_0.3mm) / gold_0.3mm * 100, 
    mb_bravo  = (mb_bravo   - gold_0.3mm) / gold_0.3mm * 100, 
    mb_0.9mm  = (mb_0.9mm   - gold_0.3mm) / gold_0.3mm * 100))})

wa.s = ddply(wa.xval.error, c('region'), function(df) {
  with(df,data.frame(
    m_res = mean(resampled,na.rm=T), sd_res = sd(resampled,na.rm=T),
    m_bravo = mean(mb_bravo,na.rm=T), sd_bravo = sd(mb_bravo,na.rm=T),
    m_mb_res = mean(mb_0.9mm,na.rm=T), sd_mb_res = sd(mb_0.9mm,na.rm=T)))})
@

In this experiment the \mb{} segmentation of hippocampal subfields is assessed
through a leave-one-out validation in which resampled images ($0.9mm^3$
voxels) of each Winterburn atlas subject are segmented using the remaining
high-resolution Winterburn atlas subjects' images. 

Figure \ref{fig:WAval-vol-boxplot} shows the mean relative percent error in volume, 
with respect to the full-resolution Winterburn atlas, of each hippocampal subfield
of the resampled Winterburn labels, and of the \mb{} segmentations of the resampled
Winterburn atlas images and T1 BRAVO Winterburn subject acquisitions.  A
paired-samples t-test was conducted to compare the distribution of relative
percent error in the \mb{} segmentation volumes and the resampled segmentation
volumes. There was no significant difference found for the CA1, Subiculum, and
CA2/CA3 subregions. The CA4/DG subregion shows significantly lower percent error 
  ($M_{resampled}=$\Sexpr{wa.s$m_res[wa.s$region=='CA4/DG']},
  $SD_{resampled}=$\Sexpr{wa.s$sd_res[wa.s$region=='CA4/DG']};
  $M_{MAGeT(BRAVO)}=$\Sexpr{wa.s$m_bravo[wa.s$region=='CA4/DG']},    
  $SD_{MAGeT(BRAVO)}=$\Sexpr{wa.s$sd_bravo[wa.s$region=='CA4/DG']};    
  $M_{MAGeT(resampled)}=$\Sexpr{wa.s$m_mb_res[wa.s$region=='CA4/DG']},    
  $SD_{MAGeT(resampled)}=$\Sexpr{wa.s$sd_mb_res[wa.s$region=='CA4/DG']};    
  $p < 0.001$), and the SR/SL/SM shows significantly different percent error in the opposite
direction 
  ($M_{resampled}=$\Sexpr{wa.s$m_res[wa.s$region=='SR/SL/SM']},
  $SD_{resampled}=$\Sexpr{wa.s$sd_res[wa.s$region=='SR/SL/SM']};
  $M_{MAGeT(BRAVO)}=$\Sexpr{wa.s$m_bravo[wa.s$region=='SR/SL/SM']},    
  $SD_{MAGeT(BRAVO)}=$\Sexpr{wa.s$sd_bravo[wa.s$region=='SR/SL/SM']};    
  $M_{MAGeT(resampled)}=$\Sexpr{wa.s$m_mb_res[wa.s$region=='SR/SL/SM']},    
  $SD_{MAGeT(resampled)}=$\Sexpr{wa.s$sd_mb_res[wa.s$region=='SR/SL/SM']};    
  $p < 0.001$). Bland-Altman plots comparing \mb{} to subsampled segmentation
volume reveals a proportional bias towards underestimating volumes in all
subregions, and prominant fixed biases in the volumes of the CA4/DG and SR/SL/SM subregions 
congruent with significant differences seen in percent error in volume
associated with subsampling alone. 


Figure \ref{fig:subfield-montage} shows slices subfield segmentations for a
single subject for qualitative inspection.  
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% WAxval - t.test comparing Manual volumes and Computed volumes of subregions 
%          across folds
<<tab:WAxval-t-test-manual-computed, echo=F, results="asis",cache=FALSE>>=
latex(wa.p, file="", size="scriptsize",landscape=FALSE, ctable=TRUE,
    caption="\\textbf{Paired-sample t-tests comparing manually segmented
             Winterburn atlas subregion volumes and computed volumes (reported
             as $t (p)$). }", 
    col.just=c("l","r","r","r"),
    caption.loc = c("bottom"), rowname=NULL, 
    label="tab:WAxval-t-test-manual-computed")
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% % Winterburn-XVAL: boxplot showing raw volumes of all methods and all subjects
%% \begin{figure}[h!]
%% <<fig:WAval-volumes,cache=T,fig.width=6,fig.height=5>>=
%% m=melt(wa.xval.casted, id.vars=c('region','file'))
%% levels(m$variable) <- list("Original atlas images"="gold_0.3mm",
%%                            "Subsampled atlas images"="gold_0.9mm",
%%                            "MAGeT on subsampled atlas images" = "mb_0.9mm",
%%                            "MAGeT on T1 BRAVO images"="mb_bravo")
%% m = rename(m, c(
%%   'region'='Subregion','value'='Volume',
%%   'variable'='Method'))
%% 
%% ggplot(m,aes(y=Volume,x=Subregion,colour=Method))  + 
%%   geom_boxplot() + 
%%   geom_point(position=position_dodge(width=0.75)) +
%%   ylab(expression('Volume ' (mm^3))) + 
%%   theme(legend.direction = "horizontal", legend.position = "bottom")
%% @
%%   \caption{{\bf Manual and computed unilateral hippocampal subfield
%% volumes.}\label{fig:WAval-volumes}}
%% \end{figure}
%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Winterburn-XVAL: compare resampling
\begin{figure}[h!]
<<fig:WAval-vol-boxplot,cache=T,fig.width=6,fig.height=5>>=
wa.xval.error.melted = melt(wa.xval.error,id.vars=c("file", "region"))
wa.xval.error.melted = rename(wa.xval.error.melted, c("variable"="measure", "value"="percenterr"))
levels(wa.xval.error.melted$measure) <- list("Subsampled atlas labels"="resampled",
                               "MAGeT on subsampled atlas images" = "mb_0.9mm",
                               "MAGeT on T1 BRAVO images"="mb_bravo")

ggplot(wa.xval.error.melted, aes(y=percenterr,x=measure,colour=measure)) +
  facet_grid(.~region) + 
  geom_hline(aes(yintercept=0), colour="grey", size=1) + 
  geom_boxplot() + 
  geom_point(group=1, position="dodge") + 
  labs(y="Percent error in volume", x="Subfield") +
  theme(axis.ticks = element_blank(), axis.text.x = element_blank()) + 
  scale_colour_discrete("") + 
  theme(legend.direction = "vertical", legend.position = "bottom")
@
  \caption{{\bf Percent error in computed unilateral hippocampal subfield
segmentation volume relative to manual segmentation volume.} 
  Percent error is measured against the volumes of the unmodified Winterburn
  atlas subfield segmentations.
  {\bf Subsampled atlas labels} volumes of the manual segmentations of the Winterburn
  atlases after resampling to $0.9mm^3$ voxels.  
  {\bf MAGeT on subsampled atlas images} volumes are \mb{} segmentations of the Winterburn atlas
  images after resampling to $0.9mm^3$ voxels.
  {\bf MAGeT on T1 BRAVO} volumes are \mb{} segmentations of T1 BRAVO images
  ($0.9mm^3$ voxels) acquired separately of four of the five Winterburn atlas
  subjects.\label{fig:WAval-vol-boxplot}}
\end{figure}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Winterburn-XVAL: bland-altman 
\begin{figure}[h!]
<<fig:WAval-bland,cache=T,fig.width=7,fig.height=6>>=
wa.xval.volumes = melt(wa.xval.casted, id.vars=c('file', 'region', 'gold_0.3mm', 'gold_0.9mm'))
wa.xval.volumes = rename(wa.xval.volumes, c("variable"="measure", "value"="volume"))
levels(wa.xval.volumes$measure) <- list("Subsampled atlas labels"="gold_0.9mm",
                               "MAGeT on subsampled atlas images" = "mb_0.9mm",
                               "MAGeT on T1 BRAVO images"="mb_bravo")

wa.xval.volumes$diff = wa.xval.volumes$gold_0.9mm - wa.xval.volumes$volume 
wa.xval.volumes$mean = (wa.xval.volumes$gold_0.9mm + wa.xval.volumes$volume)/2
wa.xval.bland.limits = ddply(wa.xval.volumes,c("region"),function(df) {
  data.frame(y = mean(df$diff,na.rm=T) + c(-1.96,0,2) * sd(df$diff,na.rm=T))
})

ggplot(wa.xval.volumes, aes(x=mean, y=diff, colour=measure)) + 
  facet_wrap(~region, ncol=3, scales='free') + 
  geom_smooth(method="lm", formula=y~x, fullrange=T, se=F) + 
  geom_point(size=1) +  
  geom_hline(aes(yintercept = y), linetype="dashed", colour="brown",
             data=wa.xval.bland.limits, size=0.3, alpha=0.5) + 
  geom_text(aes(y = y, x=Inf, label=round(y,0)), colour="black", 
             data = wa.xval.bland.limits, hjust=1.1,vjust=-0.8, size=2.5) + 
  xlab(expression('Mean of resampled and \\mb subregion volume ' (mm^3))) + 
  ylab(expression('Difference between manual and \\mb subregion volume ' (mm^3))) + 
  scale_color_discrete(name="") + 
  theme(legend.direction = "horizontal", legend.position = "bottom", 
        axis.text.y = element_text(angle = 90, hjust=0.5), 
        axis.text = element_text(size = 8))

@
  \caption{{\bf Bland-Altman plots comparing unilateral \mb{} subfield
segmentation volume with resampled subfield segmentation volume.} The overall
mean difference in volume, and limits of agreement ($\pm 1.96SD$) are shown by
dashed horizontal lines. Linear fit lines are shown for each target image type.
Note, points below the mean difference indicate overestimation of the volume
with respect to the resampled volume, and vice versa. 
  \label{fig:WAval-bland}}
\end{figure}


\begin{sidewaysfigure}
    \begin{centering}
      \includegraphics[width=\linewidth]{figure/winterburn-atlas-montage/figure.pdf}
    \end{centering}
    \caption{Detailed subfield segmentation results for a single subject. In
    the upper left corner is the original high-resolution Winterburn atlas manual
    subfield segmentation; in the upper right corner is the Winterburn atlas
    segmentation subsampled from 0.3mm- to 0.9mm-isotropic voxels; in the lower left
    corner is the \mb{} segmentation of the subsampled Winterburn atlas images; in the
    lower right corner is the \mb{} segmentation of a separately acquired T1 BRAVO
    image of the same subject. In each segmentation, slices from the left
    hemisphere are shown in Talairach-like ICBM152 space: the first row shows axial
    slices from inferior to superior; the second row shows sagittal slices from
    lateral to medial; the third row shows coronal slices from anterior to
    posterior.  \label{fig:subfield-montage}}
\end{sidewaysfigure}



\FloatBarrier
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                                                                     %%%%%
%%%%%    RESULTS: Experiment 3, Application of \mb{} to the segmentation  %%%%%
%%%%%                       of schizophrenia patients                     %%%%%
%%%%%                                                                     %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Experiment 3 Results: Application to the segmentation of first
episode schizophrenia patients}
 
In this experiment \mb{} is applied to a dataset of images of first episode
schizophrenia patients, using the Winterburn atlases and a template library of
21 subject images selected at random.  Expert manual whole hippocampal
segmentations are used as a gold standard. 

\begin{figure}
<<fig:FEP-volumes,cache=FALSE,dependson="setup",fig.width=5,fig.height=5>>=
fep.raw.volumes=read.csv('data/SZ_vol_by_method.csv')
fep.raw.volumes=subset(fep.raw.volumes, SID <= 81)
fep.raw.volumes=melt(fep.raw.volumes, id.vars=c('SID','method')) 
fep.volumes = dcast(fep.raw.volumes, SID~method, value.var="value", fun.aggregate=mean)
fep.volumes = melt(fep.volumes, id.vars=c('SID', 'manual'), variable.name='method', value.name='volume')

fep.lm = ddply(fep.volumes,c("method"), function (df) {
  data.frame(eqn=lm_eqn(lm(manual ~ volume, df)))})
fep.lm$y = 6800-0:3*150

ggplot(data=fep.volumes, aes(x=manual, y=volume, colour=method)) + 
  geom_smooth(method="lm", formula=y~x) + 
  geom_point() + 
  geom_text(aes(x=3350,y=y,label=eqn),parse=T,data=fep.lm,
      size=3,hjust=0) +
  xlab(expression("Mean manual hippocampus volume " (mm^3))) + 
  ylab(expression("Mean computed hippocampus volume "  (mm^3))) + 
  theme(legend.direction = "horizontal", legend.position = "bottom")
@
  \caption{Mean bilateral hippocampus volume as measured by \mb{}, \fsl{}, and
\freesurfer{} vs. manually segmented volumes from the First Episode Patients with
Schizophrenia dataset. \mb{} is run two ways: with an atlas library consistening
of the five Winterburn atlases, or with five manually segmented FEP subjects as
atlases (not included as subjects). Linear fit lines are shown, with shaded
region showing standard error. 
  \label{fig:SZ-volumes}}
\end{figure}

\begin{figure}
<<fig:FEP-Bland-Altman, cache=TRUE, dependson='fig:FEP-volumes', fig.width=7, fig.height=7>>=
fep.volumes$diff = fep.volumes$manual - fep.volumes$volume
fep.volumes$mean = (fep.volumes$manual + fep.volumes$volume)/2
limits = ddply(fep.volumes, c("method"), function (df) { 
  data.frame(
    y = mean(df$diff,na.rm=T) + c(-1.96,0,2) * sd(df$diff,na.rm=T) 
)}) 

ggplot(fep.volumes, aes(x= mean, y = diff)) + 
  facet_wrap( ~ method, nrow=2, scales="fixed") + 
  geom_smooth(method="lm", formula=y~x, fullrange=T, se=F) + 
  geom_point(size=1) +  
  geom_hline(aes(yintercept = y), linetype="dashed", colour="brown",
             data=limits, size=0.3, alpha=0.5) + 
  geom_text(aes(y = y, x=Inf, label=round(y,0)), colour="black", data = limits,
            hjust=1.1,vjust=-0.8, size=2.5) + 
  xlab(expression('Mean manual and computed volume ' (mm^3))) + 
  ylab(expression('Difference in manual and computed volume ' (mm^3))) + 
  scale_y_continuous(breaks=seq(-10000,4000, 1000)) + 
  scale_x_continuous(breaks=seq(0,10000, 1000)) + 
  theme(legend.direction = "horizontal", legend.position = "bottom", 
        axis.text.y = element_text(angle = 90, hjust=0.5), 
        axis.text = element_text(size = 8))
@
  \caption{Bland-Altman plots comparing subject mean hippocampal volume as
measured in the FEP dataset by manual segmentation and each of the
four automated methods investigated (\freesurfer{}, \fsl{}, \mb{} with
Winterburn atlases, \mb{} with FEP manual atlases). The overall
mean difference in volume, and limits of agreement ($\pm 1.96SD$) are shown by
dashed horizontal lines. Linear fit lines are shown for each diagnosis group.
Note, points below the mean difference indicate overestimation of the volume
with respect to the manual volume, and vice versa. }
  \label{fig:FEP-Bland-Altman}
\end{figure}

% <<FEP-t-test,cache=TRUE,dependson="FEP-volumes">>=
%   fep.cor.test = cor.test(fep.volumes$manual,fep.volumes$MAGeT_Winterburn)
% @
% \mb{} produces hippocampal volumes that are highly correlated with manual
% segmentation volumes (Pearson $r = \Sexpr{fep.cor.test$estimate}$, $t =
% \Sexpr{fep.cor.test$statistic}$, $p < \Sexpr{max(0.001, fep.cor.test$p.value)}$;
% Figure \ref{fig:SZ-volumes}). 
% 

\FloatBarrier
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                                                                     %%%%%
%%%%%                           RESULTS                                   %%%%%
%%%%%                                                                     %%%%%
%%%%%         EXPERIMENT 4: Application of \mb{} to the segmentation      %%%%%
%%%%%                       of ADNI subjects                              %%%%%
%%%%%                                                                     %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Experiment 4 Results: Application to the segmentation of Alzheimer's
disease patients}

Based on the results from Experiment 1, in this experiment \mb{} was configured
with a template library of 21 randomly chosen subject images (7 from each
disease class) and majority vote label fusion.  The entire \adnidataset{} dataset
was segmented by \mb{}, and the resulting volumes compared with those obtained by
expert semi-automated segmentation (\snt{}), and three other automated segmentation
techniques: \maper{}, \freesurfer{}, and \fsl{}. Table
\ref{tab:ADNI1-1.5T-Complete-1Yr-Dataset-Method-Totals} shows the total count of
segmentations available, including a count of those which have failed a quality
control inspection.  A total of \Sexpr{length(means.complete$RID)} images are
included in the following analysis, having met quality criteria and having
segmentations from every method. 
 
We found a close relationship in total bilateral hippocampal volume between all
methods and the \snt{} semi-automated label volumes (Figure
\ref{fig:ADNI-volumes-plot}).  Volumes are correlated with Pearson $r > 0.78$
for all methods across disease categories.  Within disease categories (Figure
\ref{fig:ADNI-volumes-boxplot}), \mb{} is consistently well correlated to manual
volumes (Pearson $r > 0.85$), but appears to slightly over-estimate the volume
of the AD hippocampus. 

Bland-Altman plots illustrate the level of agreement of each method with \snt{}
segmentation hippocampal volumes (Figure \ref{fig:ADNI-Bland-Altman}).  As
\citet{Bland1986} noted, high correlation amongst measures of the same quantity
does not necessarily imply agreement (as correlation can be driven by a large
range in true values, for instance).  All methods show an obvious proportional
bias: \freesurfer{} and \fsl{} markedly under-estimate smaller hippocampi and
over-estimate large hippocampi, whereas \maper{} and \mb{} show a reverse,
conservative bias (Figure \ref{fig:ADNI-Bland-Altman}).  Additionally, all
methods show a fixed volume bias, with \freesurfer{} and \fsl{} most
dramatically over-estimating hippocampal volume by $2600 mm^3$ and $2800 mm^3$
on average, respectively, and \maper{} and \mb{} within $250 mm^3$ on average. 

Figure \ref{fig:ADNI-segmentations} shows a qualitative comparison of \mb{} and
\snt{} hippocampal segmentations for 10 randomly selected subjects in each disease
category, and illustrates some of the common errors found during visual
inspection. Mostly frequently, we found \mb{} improperly includes the vestigial
hippocampal sulcus and, although not anatomically incorrect, \mb{}
under-estimates the hippocampal body in comparison to the \snt{} segmentation.  

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ADNI1 1yr Complete Dataset Package Totals & Failures
%                        
<<tab:ADNI-seg-package-totals, echo=F, results="asis",cache=FALSE>>=
package_totals$Total <- NULL
latex(package_totals, file="", size="scriptsize",landscape=FALSE, ctable=TRUE,
    caption="\\textbf{Number of segmented images and quality control failures of 
             \\adnidataset{} dataset by method.}", 
    caption.loc = c("top"), rowname=NULL, 
    label="tab:ADNI1-1.5T-Complete-1Yr-Dataset-Method-Totals")
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure}[h]
<<fig:ADNI-volumes-plot,dependson='ADNI-volumes-prep',cache=T,fig.width=6,fig.height=4>>=
melted=melt(means.complete, measure.vars=c("FS", "FSL", "MAPER","MAGeT"), 
            variable.name = "Method", value.name = "volume")

df = means.complete

levels(melted$Method) = c("FS"    = "FreeSurfer", 
                          "FSL"   = "FSL", 
                          "MAPER" = "MAPER", 
                          "MAGeT" = "MAGeT")

adni.volumes.lm = ddply(melted,c("Method"), function (df) {
  data.frame(eqn=lm_eqn(lm(volume ~ SNT, df)))})
adni.volumes.lm$y = 6450-0:3*300

ggplot(data=melted, aes(x=SNT, y=volume, colour=Method)) + 
    geom_point(size=1) + 
    geom_smooth(method="lm") + 
    xlab(expression("SNT mean hippocampus volume " (mm^3))) + 
    ylab(expression("Automated mean hippocampal volume " (mm^3))) +
    geom_text(aes(x=850,y=y,label=eqn),parse=T,data=adni.volumes.lm,
      size=2.5,hjust=0) +
    theme(legend.direction = "horizontal", legend.position = "bottom")

#    annotate("text", y = c(2000,1500,1000,500), x=Inf-100, size=2.5,
#              label = c(paste("FS r =", round(cor(df$SNT, df$FS),2)),
#                        paste("FSL r =", round(cor(df$SNT, df$FSL),2)),
#                        paste("MAPER r =", round(cor(df$SNT, df$MAPER),2)),
#                        paste("MAGeT r =", round(cor(df$SNT, df$MAGeT),2))),
#              hjust=1.1,vjust=1.5) +
@
  \caption{Subject mean hippocampal volume as measured in the \adnidataset{}
dataset by each of the four automated methods investigated (\freesurfer{} (FS), \fsl{},
\maper{}, \mb{}) vs. \snt{}. Linear fit lines and Pearson correlations are shown
for each method.}
  \label{fig:ADNI-volumes-plot}
\end{figure}


\begin{figure}[h]
<<fig:ADNI-volumes-boxplot,dependson='ADNI-volumes-prep',cache=T,fig.width=7,fig.height=4>>=
melted = melt(means.complete,measure.vars=c("FS", "FSL", "MAPER","MAGeT"),
              variable.name="Method", value.name="Volume")
correlations = ddply(melted, c("DX","Method"), function (df) {
  data.frame(
    pearson = cor(df$SNT, df$Volume)
  )
})
m2 = melt(means.complete,measure.vars=c("FS", "FSL", "MAPER","MAGeT","SNT"), variable.name="Method")
levels(m2$Method) = c("FS"    = "FreeSurfer", 
                      "FSL"   = "FSL", 
                      "MAPER" = "MAPER", 
                      "MAGeT" = "MAGeT", 
                      "SNT"   = "SNT")
m2$DX = factor(m2$DX, levels(m2$DX)[c(2,3,1)])

qplot(DX,value,data=m2,
      colour=Method,geom="boxplot") + 
      #geom_text(aes(y=-Inf,x=c(.7,.85,1,1.15, 1.7,1.85,2,2.15, 2.7,2.85,3,3.15), vjust=-5, label=round(pearson,2)), 
      #          colour = 'black', size=3, data=correlations) +
      xlab("Diagnosis") + 
      ylab(expression(paste("Hippocampal volume (", mm^3, ")"))) + 
      theme(legend.direction = "horizontal", legend.position = "bottom")
@
  \caption{Subject mean hippocampal volume as measured in the \adnidataset{}
dataset by \freesurfer{}, \fsl{}, \maper{}, \mb{}, and \snt{} vs. disease
category.}
  \label{fig:ADNI-volumes-boxplot}
\end{figure}

 
\begin{figure}
<<fig:ADNI-Bland-Altman, cache=TRUE, dependson='ADNI-volumes-prep', fig.width=7, fig.height=7>>=
names(means.complete)[8] = "FreeSurfer"
melted=melt(means.complete, measure.vars=c("FreeSurfer", "FSL", "MAPER","MAGeT"), 
            variable.name = "method", value.name = "volume")

melted$diff = melted$SNT - melted$volume
melted = subset(melted, (method == "FreeSurfer") | 
                        (method == "FSL"  ) | # & diff > -5000 & diff < 900) | 
                        (method == "MAPER") | # & diff > -500 & diff < 1000) | 
                        (method == "MAGeT"))  # & diff > -1100))
#melted = subset(melted, method == "MAGeT")
melted$DX = factor(melted$DX, levels(melted$DX)[c(2,3,1)])
melted$mean = ( melted$SNT + melted$volume ) / 2
limits = ddply(melted, c("method"), function (df) { 
  data.frame(
    y = mean(df$diff) + c(-1.96,0,2) * sd(df$diff) 
)}) 

names(melted)[4] = "Diagnosis"
ggplot(melted, aes(x= mean, y = diff, colour=Diagnosis)) + 
  facet_wrap( ~ method, nrow=2, scales="fixed") + 
  geom_smooth(method="lm", formula=y~x, fullrange=T, se=F) + 
  geom_point(size=1) +  
  geom_hline(aes(yintercept = y), linetype="dashed", colour="brown",
             data=limits, size=0.3, alpha=0.5) + 
  geom_text(aes(y = y, x=Inf, label=round(y,0)), colour="black", data = limits,
            hjust=1.1,vjust=-0.8, size=2.5) + 
  xlab(expression('Mean of SNT and automated hippocampal volume ' (mm^3))) + 
  ylab(expression('Difference in manual and automated hippocampal volume ' (mm^3))) + 
  scale_y_continuous(breaks=seq(-10000,4000, 1000)) + 
  scale_x_continuous(breaks=seq(0,10000, 1000)) + 
  theme(legend.direction = "horizontal", legend.position = "bottom", 
        axis.text.y = element_text(angle = 90, hjust=0.5), 
        axis.text = element_text(size = 8))
@
  \caption{Bland-Altman plots comparing subject mean hippocampal volume as
measured in the \adnidataset{} dataset by \snt{} segmentation and each of the
four automated methods investigated (\freesurfer{}, \fsl{}, \maper{}, \mb{}). The overall
mean difference in volume, and limits of agreement ($\pm 1.96SD$) are shown by
dashed horizontal lines. Linear fit lines are shown for each diagnosis group.
Note, points below the mean difference indicate overestimation of the volume
with respect to the \snt{} volume, and vice versa. }

  \label{fig:ADNI-Bland-Altman}
\end{figure}




\begin{figure}
  \begin{centering}
    \includegraphics[width=6in]{figure/ADNI1_SNT_MB_montage/montage.pdf}
  \end{centering}
  \caption{\snt{} and \mb{} segmentations for 30 ADNI subjects (10
  subjects randomly selected from each disease category in the subject pool used
  in Experiment 1). Sagittal slices are shown for each unlabelled T1-weighted
  anatomical image. \snt{} labels appear in green, and \mb{} labels appear in
  blue. Noted are examples of common segmentation idiosyncrasies: 
  {\em (a)} over-estimation of hippocampal head and  
  {\em (b)} translated segmentation (seen in \snt{} segmentations only); 
  {\em (c)} under-estimation of hippocampal body and
  {\em (d)} improper inclusion of the vestigial hippocampal sulcus by \mb{}.}
  \label{fig:ADNI-segmentations}
\end{figure}

\FloatBarrier

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                Discussion
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Discussion}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Tabulation of segmentation accuracies of existing methods (ADNI)
%
<<ADNI1-literature, echo=F, results="asis",cache=FALSE>>=
# caption = 
#   "\\textbf{Automated segmentation accuracy (overlap with manual labels) of the 
#    ADNI dataset.} For each method, the number of manually labelled atlases used for 
#    training, the best Dice's overlap measure, the disease classes measured, and 
#    the validation procedure are shown. LOOCV = Leave-one-out cross-validation. 
#    Some studies of automated segmentation of ADNI images are excluded because they 
#    do not not provide overlap measures for the hippocampus \\cite{Heckemann2011, Chupin2009}.
#   "
# 
# tab = read.csv("data/ADNI-existing-work.csv")
# tab$Notes <- NULL
# 
# adni_lit = subset(tab, Dataset=="ADNI")
# adni_lit$Dataset <- NULL
# 
# 
# latex(adni_lit, #file="", 
#       size="scriptsize",
#       caption=caption, 
#       rowname=NULL,
#       col.just=c("p{2in}","p{1in}","p{1in}","p{1in}","p{1in}"),
#       title="")
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Tabulation of segmentation accuracies of existing methods (ADNI)
%
%
\begin{table}[!tbp]
\scriptsize
\caption{\textbf{Automated segmentation accuracy (overlap with \snt{} labels)
of the ADNI dataset.} For each method, the number of labelled atlases
used for training, the best Dice's overlap measure, the disease classes
measured, and the validation procedure are shown. Unless specified, validation
datasets are composed equally of subjects diagnosed with Alzheimer's Disease
(AD), Mild Cognitive Impairment (MCI), and Cognitively Normal (CN). LOOCV =
Leave-one-out cross-validation. 
   Some studies of automated segmentation of ADNI images are excluded because they 
   do not not provide overlap measures for the hippocampus \citep{Heckemann2011,Chupin2009}.
  \label{tab:other-methods}} 
\begin{center}
\begin{tabular}{ l  c  p{1in}  l  p{2in}  }
\hline\hline
Method & Atlases & DSC & Reference & Validation \tabularnewline
\hline
\mb{}                        &9 & \Sexpr{round(mb.kappa.best, digits=3)} & & 10 rounds of Monte Carlo CV on a pool of 69 subjects \tabularnewline % TODO: update
LEAP                         &30&0.848                 &\cite{Wolz2010}  &Segmentation of 182 subjects\tabularnewline
ACM (AdaBoost-based)         &21&0.862                 &\cite{Morra2008} &LOOCV on atlases\tabularnewline
Patch-based label fusion     &16&0.883 (CN) \newline 0.838 (AD)&\cite{Coupe2011e}&LOOCV on atlases\tabularnewline
Multi-atlas                  &30&0.885                 &\cite{Lotjonen2010}&Segmentation of 60 subjects\tabularnewline
Multi-atlas + weighted fusion&20&0.898 (CN) \newline 0.798 (left HC, MCI) &\cite{Wang2011}  &10 rounds of Monte Carlo CV on 20 subjects, pool of 139 (CN/MCI)\tabularnewline
Multi-atlas (MAPS)           &55&0.890                   &\cite{Leung2010}&Segmentation of 30 subjects (10 AD, MCI, and CN)\tabularnewline
\hline
\end{tabular}
\end{center}
\end{table}

In this manuscript we have presented the implementation and validation of the
\mb{} framework -- a methodology that requires very few input atlases in order
to provide accurate and reliable segmentations.  Experiment 1 compares \mb{} to
basic-\multiatlas{} segmentation by characterising the behaviour of each
approach with varying parameter settings, and allows us to choose an optimal
setting for subsequent experiments. Experiment 2 demonstrates the reliability of
\mb{} in producing subfield segmentations which match the segmentation protocol
of the input atlases despite contrast and resolution limitations in standard
T1-weighted image volumes. Experiments 2 and 3 validate whole hippocampal
segmentation precision and consistency on populations with different ageing and
neuropsychiatric characteristics. All of these experiments together demonstrate
that \mb{} algorithmic performance is not dependent on a single definition of
the hippocampus but is effective with differing hippocampal definitions
\citep{Winterburn2013,Pruessner2000,Hsu2002}.  

The core claim the \mb{} method is based on, that we can meaningfully bootstrap
a template library from a small set of labelled atlas images, is validated in
the cross validation conducted in Experiment 1 (and the replication in
Experiment 5, Supplementary Materials). We find that both increasing the number
of atlases and the number of templates used improves \mb{} segmentation over and
above basic-\multiatlas segmentations using the same number of atlas images.
That is, by taking the extra step of generating a template library from a small
atlas set \mb{} is able to improve the final segmentation similarity. The
magnitude of this improvement is greatest with a small number of atlases, but
even with larger atlas libraries we have found that generating a template
library reduces the variability in segmentation precision (i.e.  \mb{} more
consistently produces high quality segmentations than does basic-\multiatlas{}
segmentation). These effects do not appear dependant on the hippocampal
segmentation protocol used. 

Interestingly, previous work on \multiatlas{} segmentation methods
\citep{Aljabar2009,Collins2010} has found that cross-correlation and normalized
mutual information-based weighted label fusion improves segmentation accuracy
over simple majority vote label fusion, and yet we did not see a significant
indication of this effect in the \mb{} segmentations. Selectively filtering out
atlases with lower image similarity is believed to reduce sources of error from
estimating deformations via nonlinear registration, partial volume effects from
nearest neighbour image resampling, and neuroanatomical mismatch between atlases
and subjects. That \mb{} does not see the same boost in performance from
weighted voting may suggest that the neuroanatomical variability of a template
library constructed from study subjects more closely matches any particular
subject and thereby leaving less error to filter. From our previous work on the
\mb{} algorithm we have shown that the reduction in error is not simply a
smoothing or averaging effect \citep{Chakravarty2013}.

Although, the goal of this manuscript was not to exhaustively test or validate
multiple different voting strategies in the context of our segmentation
algorithm, it is important to note that other strategies for voting are
available.  For example, other groups have used the STAPLE algorithm
\citep{Warfield2004} (or variants of the STAPLE algorithm
\citep{Robitaille2012}) which weights each segmentation based upon its estimated
performance level with respect to the other available candidate segmentations.
Further, the sensitivity and specificity parameters can also be tuned to
potentially improve segmentation accuracy and reliability.  It is likely that
using more sophisticated voting methods would have a positive effect on the
overall segmentation performance, as demonstrated by the STAPLE algorithm.  

More work is required to determine the source of the slight decrease in
segmentation performance when the number of templates are set to an even number.
Our initial concern was that this dip in performance was a by-product of the
\mb{} algorithm itself.  However, this this pattern is also found in the results
of the \multiatlas{} segmentations we used in our experiments.  We believe that
our majority voting methodology is biased towards labels with the lowest numeric
values when breaking ties (by way of the implementation of the \verb+mode+
function used to determine majority), thus causing the slight bias observed when
using an even number of templates. This is another area where the voting scheme
could be used to improve performance.  However, it is worth noting that this
limitation was previously identified by \citet{Heckemann2006a} and,
subsequently, other groups have not even considered the potential pitfalls of an
even number of candidate labels (e.g.  \citet{Leung2010}).

Another concern is the moderate improvement observed in \mb{} in comparison to
\multiatlas{} segmentation when using the same number of atlases.  The actual
benefit in using \mb{} is consistency of the labelling regardless of atlas or
template choice, as mentioned above. This is an important consideration that few
have touched on previously. The 10-fold Monte Carlo cross-validation that we
present in Experiment 1 is amongst one of the most stringent performed in the
\multiatlas/segmentation literature. To the best of our knowledge, with the
exception of \citep{Wang2011}, other groups using ADNI data for validation do at
most a single round of leave-one-out-validation (Table \ref{tab:other-methods}).
The thoroughness of our validation suggests that our results are reflective of a
true average over the choice of parameter settings and are independent of atlas
or template choice (provided the input atlases are consistently segmented).  

On that note, one author (JW), an expert manual rater (citep{Winterburn2013),
identified regular inconsistencies in the \snt{} segmentations: occurrences of
over- and under-estimation, as well as misalignments of the entire segmentation
volume (Figure \ref{fig:ADNI-segmentations}). Although the \snt{} segmentations
are used as benchmarks for validation in many other studies (Table
\ref{tab:other-methods}), these segmentation inconsistencies present the
possibility that a more accurate and consistent benchmark segmentation protocol
ought to be used in order to truly understand the results of such validations.
Indeed, our replication of the 10-fold cross-validation using \snt{}
segmentations (Experiment 5, Supplementary Materials) shows noticeably poorer
mean similarity scores for both \mb{} and \multiatlas. 

Thus, in comparison to other methodologies in the field \mb{} performs
favourably. Table \ref{tab:other-methods} surveys some of the most recent
reported DSC values reported on ADNI dataset, using \snt{} segmentations for the
atlas library and as gold standards for evaluation.  While it is difficult to
compare segmentation results across studies, gold standards, evaluation metrics,
and algorithms it is worth noting that the methods summarized require more
atlases (between 16-55) than our \mb{} implementation with the Winterburn
atlases \citep{Winterburn2013}.

There are some important differences between our method and these specific
methods. Others have reported the difficulty with mis-registrations in
candidate segmentation (i.e. segmentations generated that are then input in the
voxel-voting procedure \citep{Collins2010}). The work of \citet{Leung2010}
tackles this problem by using an intensity threshold that is estimated
heuristically at the time of segmentation (this work also reports some of the
highest DSC scores for the segmentation of ADNI data). While this method is
effective for the ADNI dataset (which is partially homogenized with respect to
image acquisition and pre-processing), it is unclear if this type of heuristic
is applicable to other datasets. In all cases, these methods require more
atlases than our implementation with the Winterburn atlases.
\citet{Lotjonen2010} achieve highly accurate segmentation but correct their
segmentations using classifications derived using an expectation maximization
framework. In their initial work, \citet{Chupin2009} develop their probabilistic
methodology using a cohort of 8 healthy controls and 15 epilepsy patients, and
then use this method to segment an ADNI sample, with a hierarchical
experimentation protocol. These methods suggest that some post-processing of the
final segmentations would improve accuracy of the segmentation. While that may
be true, there is little consensus regarding how to achieve this.  

To the best of our knowledge, no other groups have validated their work using
multiple atlas segmentation protocols, different acquisitions, and disease
populations in order to demonstrate the robustness of their technique.  This is
one of the clear strengths of this work.  Furthermore, unlike some of the
algorithms mentioned, our implementation does not require retuning for new
populations or datasets as it inherently models the variability of the dataset
through the template library.  However it should be noted that the increased
accuracy that follows increasing the number of atlases and templates comes at an
increased computational cost ($O(log(n))$), as previously mentioned in
other work \citep{Heckemann2006}. 

Among the automated segmentation methods we compared in this paper
(\freesurfer{}, \maper{}, \fsl{}), we find extremely variable
performance of all methods.  With the exception of \fsl{} all methods correlate
well with the \snt{} volumes provided in the ADNI database.  However, \freesurfer{}
and \fsl{} provide radically different definitions of the size of the hippocampus
in comparison to the other methods.  Further, when estimating bias of these
methods relative to \snt{} hippocampal volumes we see that large hippocampi are
over estimated while small hippocampi are under estimated. By comparison, \mb{}
and \maper{} are far more conservative in volume estimation, suggesting these
methods may be better suited for estimating true-positives, especially in
neurodegenerative disease subjects featuring smaller overall hippocampi.
However, in this analysis we have only compared methods by total hippocampal
volume, and so more work is needed to understand the full extent to which these
methods differ.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Tabulation of subfield segmentation protocols
%
%
\begin{table}[!tbp]
\scriptsize
\caption{\textbf{Summary of labelled subfields of the Hippocampus from recent
MRI segmentation protocols.} \label{tab:subfield-segmentation-protocols}} 
\begin{center}
\begin{tabular}{ l p{4in} }
\hline\hline
Protocol & Labelled Subfields  \tabularnewline
\hline
\citet{Winterburn2013} &  CA1,  CA2/CA3,  CA4/dentate gyrus,  strata
                          radiatum/lacunosum/moleculare, subiculum \tabularnewline
\citet{Wisse2012}      &  CA1,  CA2,  CA3,  CA4/dentate gyrus, subiculum,
                          entorhinal cortex \tabularnewline
\citet{VanLeemput2009} &  CA1,  CA2/CA3,  CA4/dentate gyrus, presubiculum, subiculum,
                          hippocampal fissure,  fimbria,  hippocampal tail,
                          inferior lateral ventricle, choroid plexus \tabularnewline
\citet{Yushkevich2009} &  CA1, CA2/CA3, dentate gyrus (hilus), dentate gyrus
                          (stratum moleculare), strata
                          radiatum/lacunosom/moleculare/vestigial hippocampal
                          sulcus \tabularnewline
\citet{Mueller2007}    &  CA1, CA2, CA3/CA4 \& dentate gyrus, Sibiculum,
                          entorhinal cortex \tabularnewline
\hline
\end{tabular}
\end{center}
\end{table}

Finally, we have provide evidence that using the Winterburn high-resolution
hippocampal subfield atlases \citep{Winterburn2013} our algorithmic framework is
appropriate for the segmentation of hippocampal subfields in standard
T1-weighted data. Subfield segmentation is a burgeoning topic in the literature
although very few automated methods are available for the segmentation of 3T
data \citep{Yushkevich2009,VanLeemput2009}. While recent work demonstrates that
subfield segmentations can be used for classification of AD, MCI, and CN, there
has been no explicit validation of the segmentations being produced other than
indirectly via classification accuracy (for instance, the semi-automated
subfield segmentations produced in \citet{Yushkevich2009}).  Our work
demonstrates that we can reliably reproduce segmentations, corresponding in volumes 
to the input atlases used, with only modest error for the CA1, subiculum, and 
CA4/dentate subregions.

The fact that CA2/CA3 and molecular layers cannot be reasonably reproduced
should not be surprising as these are extremely thin and spatially convoluted
regions that originally required high-resolution MRI for identification and so
it is likely that the extents of these regions are well below the resolution and
contrast offered by standard T1-weighted images. In addition, some manual
subfield segmentation methodologies do not attempt to parse these regions even
on high-resolution scans. See Table \ref{ab:subfield-segmentation-protocols} for
a comparison of manual subfield segmentation methodologies. Further complicating
this, is that that different research groups have different operational
definitions for these different subfields. The disagreement in the community has
led to an international working group devoted to normalizing the ontology and
segmentation rules for the hippocampal subfields
(\url{http://www.hippocampalsubfields.com/}). The definitional and operational
disagreements make evaluating the accuracy of automated methodologies with
respect to a "ground truth" (e.g. using overlap similarity metrics, such as
Dice's Kappa) not particularly meaningful until these disagreements have been
resolved.  Thus, because of this, and the inability to discern subregions in
standard T1-weighted images, we opted to speak of the precision or reliability
of \mb{} subfield segmentation rather than speak of accuracy.  


In conclusion, we have presented a flexible \multiatlas{}-based framework that has
considerable advantages over other methods since only a small number of atlases
is required to initialize the algorithm.  We demonstrate that our method works
robustly over hippocampal definitions, different disease populations, and
different acquisition types. Finally, we also demonstrate that accurate
identification of the hippocampal subfields is possible.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                               Conclusion 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Acknowledgements}
We wish acknowledge support from the CAMH Foundation, thanks to Michael and
Sonja Koerner, the Kimel Family, and the Paul E. Garfinkel New Investigator
Catalyst Award. MMC is funded by the W. Garfield Weston Foundation and ANV is
funded by the Canadian Institutes of Health Research, Ontario Mental Health
Foundation, NARSAD, and the National Institute of Mental Health (R01MH099167).

Computations were performed on the gpc supercomputer at the SciNet HPC
Consortium. SciNet is funded by: the Canada Foundation for Innovation under the
auspices of Compute Canada; the Government of Ontario; Ontario Research Fund -
Research Excellence; and the University of Toronto.

In addition, computations were performed on the CAMH Specialized Computing 
Cluster. The SCC is funded by: The Canada Foundation for Innovation, Research 
Hospital Fund.

ADNI Acknowledgements: Data collection and sharing for this project was funded
by the Alzheimer's Disease Neuroimaging Initiative (ADNI) (National Institutes
of Health Grant U01 AG024904). ADNI is funded by the National Institute on
Aging, the National Institute of Biomedical Imaging and Bioengineering, and
through generous contributions from the following: Abbott; Alzheimer's
Association; Alzheimer's Drug Discovery Foundation; Amorfix Life Sciences Ltd.;
AstraZeneca; Bayer HealthCare; BioClinica, Inc.; Biogen Idec Inc.;
Bristol-Myers Squibb Company; Eisai Inc.; Elan Pharmaceuticals Inc.; Eli Lilly
and Company; F. Hoffmann-La Roche Ltd and its affiliated company Genentech,
Inc.; GE Healthcare; Innogenetics, N.V.; IXICO Ltd.; Janssen Alzheimer
Immunotherapy Research  Development, LLC.; Johnson \& Johnson Pharmaceutical
Research  Development LLC.; Medpace, Inc.; Merck \& Co., Inc.; Meso Scale
Diagnostics, LLC.; Novartis Pharmaceuticals Corporation; Pfizer Inc.; Servier;
Synarc Inc.; and Takeda Pharmaceutical Company. The Canadian Institutes of
Health Research is providing funds to support ADNI clinical sites in Canada.
Private sector contributions are facilitated by the Foundation for the National
Institutes of Health (www.fnih.org). The grantee organization is the Northern
California Institute for Research and Education, and the study is Rev March 26,
2012 coordinated by the Alzheimer's disease Cooperative Study at the University
of California, San Diego. ADNI data are disseminated by the Laboratory for
NeuroImaging at the University of California, Los Angeles. This research was
also supported by NIH grants P30 AG010129 and K01 AG030514.

We would also like to thank G. Clinton, E. Hazel, and B. Worrell for inspiring
this work. 

\section{Supplementary Materials}

\subsection{\snt{} Hippocampal Labels}
% The following blurb is taken (except for the first sentence) verbatim 
Semi-automated hippocampal volumetry was carried out using a commercially
available high dimensional brain mapping tool (Medtronic Surgical Navigation
Technologies, Louisville, CO), that has previously been validated and compared
to manual tracing of the hippocampus \citep{Hsu2002}. Measurement of hippocampal
volume is achieved first by placing manually 22 control points as local
landmarks for the hippocampus on the individual brain MRI data: one landmark at
the hippocampal head, one at the tail, and four per image (i.e., at the
superior, inferior, medial and lateral boundaries) on five equally spaced images
perpendicular to the long axis of the hippocampus. Second, fluid image
transformation is used to match the individual brains to a template brain
\citep{Christensen1997}. The pixels corresponding to the hippocampus are then
labeled and counted to obtain volumes. This method of hippocampal voluming has a
documented reliability of an intraclass coefficient better than .94
\citep{Hsu2002}.



\subsection{Experiment 5: Whole Hippocampus Segmentation Cross-Validation with \snt{} 
Segmentations}

This experiment is a replication of Experiment 1 using a pool of 69 images and
\snt{} semi-automated segmentations from the ADNI dataset \citep{Hsu2002}. See
Experiment 1 for full details on the ADNI dataset, and validation process. 

\subsubsection{Methods}
\paragraph{Dataset} 
69 1.5T images were arbitrarily selected from the baseline scans in the {\em
\adnidataset{}} standardized dataset. 23 subjects were chosen from each disease
category: cognitively normal (CN), mild cognitive impairment (MCI) and
Alzheimer's disease (AD). Demographics for this subset are shown in Table
\ref{tab:ADNI1-xvalidation-demographics}.  Each image has a corresponding
semi-automated segmentation of the left and right whole hippocampus made
available with ADNI images (\snt; see Supplementary Materials). 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% ADNI1 X-Validation Dataset Demographics Table
%
<<tab:ADNI-SNT-Xval-demographics, echo=F, results="asis",cache=FALSE>>=
adni_69_RIDs = c(295,413,619,685,729,782,938,954,1018,1155,907,981,222,324,448,
                 546,553,572,602,610,814,1341,675,681,731,1130,41,68,70,101,
                 249,293,316,414,698,1206,1222,1339,751,1030,3,5,10,16,22,53,
                 168,183,241,1205,328,1095,991,213,159,337,343,642,753,1109,
                 1217,29,56,1188,1293,149,382,431,1202)

tab <- summary(DX.bl ~ AGE + PTGENDER + PTEDUCAT + CDRSB + ADAS13 +
               MMSE, data = adnimerge, subset = VISCODE == 'bl' & RID %in%
               adni_69_RIDs, method = "reverse", test=FALSE, overall=TRUE)
caption = 
  "\\textbf{ADNI1 \\snt{} cross-validation subset demographics.} 
  CN     - Cognitively Normal. 
  LMCI   - Late-onset Mild Cognitive Impairment. 
  AD     - Alzheimer's Disease.  
  Hisp   - Hispanic. 
  CDR-SB - Clinical Dementia Rating-Sum of Boxes.  
  ADAS   - Alzheimer's Disease Assessment Scale.  
  MMSE   - Mini-Mental State Examination."
latex(tab, file="", size="scriptsize",landscape=FALSE, ctable=FALSE,
      caption=caption, caption.loc = c("top"),
      label="tab:ADNI1-SNT-xvalidation-demographics")
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\paragraph{Experiment details} 
A total of ten validation rounds were performed on each subject in the dataset,
for each combination of parameter settings: atlas library size (1-9), template
library size (1-20), registration method (\ants{} or \animal{}), and label
fusion method (majority vote, cross-correlation weighted majority vote, and
normalized mutual information weighted majority vote).  A total of $10 \times 69
\times 9 \times 20 \times 2 \times 3 =$ \Sexpr{10*69*9*20*2*3} validation rounds
are conducted.  The computed segmentations for a subject are compared to the
\snt{} labels provided by ADNI using Dice's Similarity Coefficient and the score
is averaged over the validation rounds.

% ######################
\subsubsection{Results}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ADNI1-XVAL: prep
% Prepares the data in a the form needed for plotting.
<<ADNI1-SNT-xval-prep,include=FALSE,cache=TRUE>>=
snt_xval_data  <- read.csv(gzfile('data/cache/ADNI-SNT-XVAL:all_data.csv.gz'))
snt_xval_mean  <- read.csv(gzfile('data/cache/ADNI-SNT-XVAL:all_data_mean.csv.gz'))
snt_xval_mean$reg_method = factor(snt_xval_mean$reg_method, c("ANTS", "ANIMAL"))
snt_xval_mean$method.mb = factor(snt_xval_mean$method.mb, c("Majority Vote", "Cross-correlation Vote", "NMI Vote"))

snt.mb.kappa.best = mean(subset(snt_xval_mean, 
                                 reg_method   == "ANTS" & 
                                 method.mb    == "Majority Vote" &
                                 templates.mb == 19 & 
                                 atlases      == 9)$k.mb)
snt.mb.diff.best = mean(subset(snt_xval_mean, 
                                 reg_method   == "ANTS" & 
                                 method.mb    == "Majority Vote" &
                                 templates.mb == 19 & 
                                 atlases      == 1)$k_diff)
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

As when comparing against manual labels in Experiment 1, we find similar
behaviour when comparing \mb{} segmentations to \snt{} labels: similarity scores
increase with increasing numbers of atlases and templates, with diminishing
increases in improvement trending towards a plateau (Figure
\ref{fig:ADNI1-xval-k-mean}).  As in Experiment 1, using \ants{} registration
leads to significantly increased similarity scores, and there is no significant
difference in scores from any of the label fusion methods.  Mean DSC score peaks
at \Sexpr{round(snt.mb.kappa.best, digits=3)} when using 9 atlases, 19
templates, ANTS registration, and majority vote label fusion).  Compared to
\multiatlas segmentations, we find \mb{} segmentations show increasing
improvement with larger atlas and template libraries when using more than 9
templates and 5 or fewer atlases (Figure \ref{fig:ADNI1-SNT-xval-k-diff}). Peak
improvement (+\Sexpr{round(snt.mb.diff.best, digits=3)} DSC) is found with a
single atlas and template library of 19 images.  In addition to a mean increase
in similarity score over \multiatlas{}-based segmentation, \mb{} also shows more
consistency in similarity scores across all subjects and validation folds
(Figure \ref{ADNI1-SNT-xval-variability}) with a large enough template library.  

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ADNI1-XVAL: mean Kappa plot by atlases, templates, reg and voting method. 
\begin{figure}
<<fig:ADNI1-SNT-xval-k-mean, cache=TRUE, dependson='ADNI1-xval-load', fig.width=5, fig.height=5>>=
stderr <- function(x) sqrt(var(x)/length(x))
ggplot(subset(snt_xval_mean, (templates.mb*atlases) %% 2 == 1),
       aes(x=templates.mb,y=k.mb, colour=as.factor(atlases), linetype=reg_method)) + #as.factor((atlases*templates.mb) %% 2 ))) + 
  facet_grid(.~method.mb) + 
  stat_summary(fun.y=mean,geom='line',
               aes(y=k.mb, weight=1, group=interaction(reg_method,atlases))) + 
  stat_summary(fun.y=mean,
               fun.ymin=function (x) mean(x) - stderr(x),
               fun.ymax=function (x) mean(x) + stderr(x), 
               geom='errorbar',
               aes(y=k.mb, weight=1, group=interaction(reg_method,atlases)), width=0.5) + 
  #stat_smooth(method='lm', formula=y~log(x)) + 
  scale_y_continuous(breaks=seq(0,1,0.05)) + 
  scale_colour_hue(name="Number of Atlases") +
  xlab( "Number of Templates" ) + 
  ylab( "Mean similarity (DSC)" ) + 
  theme(legend.direction = "horizontal", legend.position = "bottom", 
        axis.text = element_text(size = 8))
@
  \caption{Mean Dice's Similarity Coefficient of \mb{} segmentations relative to
  \snt{} segmentations for 69 ADNI subjects vs. atlas and template library
  size, registration algorithm, and label fusion method. 
  Error bars indicate standard error.
  \label{fig:ADNI1-SNT-xval-k-mean}}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ADNI1-XVAL: "increase" in mean kappa over \multiatlas
\begin{figure}
<<fig:ADN11-SNT-xval-k-diff,cache=TRUE,dependson='ADNI1-xval-load', fig.width=5, fig.height=5>>=
ggplot(subset(snt_xval_mean, reg_method=="ANTS" & 
                method.mb=="Majority Vote" & (templates.mb*atlases) %% 2 == 1), 
       aes(x=templates.mb, y=k_diff, colour=as.factor(atlases))) + 
  #facet_grid(reg_method~method.y) + 
  stat_summary(fun.data=mean_cl_boot,geom='errorbar',
               aes(y=k_diff,colour=as.factor(atlases), width=0.2)) +
  stat_summary(fun.y=mean, geom="point", 
               aes(y=k_diff,colour=as.factor(atlases))) + 
  stat_summary(fun.y=mean, geom="line", 
               aes(y=k_diff,colour=as.factor(atlases))) + 
  #stat_smooth(method=lm, formula=y~log(x)) + 
  geom_hline(aes(alpha=0.5, yintercept=0), linetype='dashed') + 
  scale_x_continuous(breaks=seq(1,20,2)) + scale_y_continuous(breaks=seq(-1,1,by=0.01)) + 
  scale_colour_hue(name="Number of Atlases") +
  scale_alpha_continuous(guide = "none") + 
  scale_linetype_discrete(guide = "none") + 
  xlab( "Number of Templates" ) + 
  ylab( "Increase in mean similarity (DSC)" ) +
  theme(legend.direction = "horizontal", legend.position = "bottom")
@
  \caption{Increase in mean Dice's Similarity Coefficient of \mb{} over
  \multiatlas{} segmentations vs. atlas and template library size when using the
  \ants{} registration method, and majority-vote label fusion. 
  Segmentation similarity is computed against \snt{} segmentations.  
  Error bars indicate standard error.
  \label{fig:ADNI1-SNT-xval-k-diff}}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ADNI1-SNT-XVAL: show variability of MAGeT over parameters
\begin{figure}
<<fig:ADN1-SNT-Xval-variability, cache=TRUE, dependson='ADNI1-Xval-prep', fig.width=5, fig.width=5>>=
ants = subset(snt_xval_data, 
                     reg_method=="ANTS" & 
                     method.mb=="Majority Vote" &
                    templates.mb %in% seq(1,20,2))

ants.stats = ddply(ants, c("subject", "label", "atlases","templates.mb"), 
                   function (df) {
                     data.frame(
                       MA.sd  =  sd(df$k.ma),
                       MB.sd  =  sd(df$k.mb),
                       MA.var = var(df$k.ma),
                       MB.var = var(df$k.mb)
                       )
                   })

stats.tests = ddply(ants.stats, c("atlases","templates.mb"), function (df) {
  t.var = t.test(df$MA.var, df$MB.var)
  t.sd  = t.test(df$MA.sd , df$MB.sd)
  diff_mean_var = mean(df$MA.var - df$MB.var)
  diff_mean_sd  = mean(df$MA.sd -  df$MB.sd)
  
  # test statistic is positive if MA mean is larger than MB
  # i.e. that MA has a greater mean of variances/SDs
  # i.e. that MB has a smaller mean, and so is doing "better"
  data.frame(
    stat      = c("Variance", "Standard Deviation"),
    statistic = c(t.var$statistic, t.sd$statistic),
    p.value   = c(t.var$p.value, t.sd$p.value),
    direction = c(diff_mean_var, diff_mean_sd)
  )
})

ggplot(subset(stats.tests, direction > 0 & stat == "Variance"), 
  aes(x=templates.mb, y=p.value, colour=as.factor(atlases))) + 
  #facet_grid( . ~ stat) + 
  geom_line(size=0.5) +
  geom_point(size=2) + 
  geom_hline(aes(yintercept=0.05, alpha=0.5), linetype='dashed') + 
  geom_hline(aes(yintercept=0.01, alpha=0.5), linetype='dashed') + 
  scale_x_continuous(breaks=seq(1,20,by=2)) + 
  #  scale_y_log10(limits=c(0.001,1), breaks=c(0.01,0.05,0.1,1.0)) + 
  xlab( "Number of Templates" ) + 
  ylab( "Variability (p)") +
  scale_colour_hue(name="Atlases") +
  scale_alpha_continuous(guide='none') + 
  scale_linetype_discrete(guide='none') + 
  scale_size_continuous(guide='none') + 
  theme(legend.direction = "horizontal", legend.position = "bottom")
@
  \caption{{\bf Difference in variability of \mb{} vs. \multiatlas{} segmentation 
  with respect to \snt{} segmentations.}
  Variance of segmentation accuracy between \mb{} and \multiatlas{} segmentation is
  computed for each subject across all ten rounds of validation. Shown on the
  y-axis is the p-value from a t-test comparing the distribution of variances at
  each parameter setting (atlas/template library size). 
  Only points where \mb{} mean variability is lower than \multiatlas{} are shown.
  Dashed lines indicate a p-value of 0.05 and 0.01.}
  \label{ADNI1-SNT-xval-variability}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




\bibliographystyle{abbrvnat}
\bibliography{references}

% \section*{R Session Information}
% <<results = "asis">>=
% toLatex(sessionInfo(), locale=FALSE)
% @
\end{document}
