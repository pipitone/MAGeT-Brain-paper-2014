%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Sweave/Knitr init
<<setup, include=FALSE, cache=FALSE>>=
library(knitr)
opts_chunk$set(echo = FALSE, 
               message = FALSE, 
               warning = FALSE, 
               fig.align = 'center', 
               tidy = FALSE, 
               comment = NA, 
               cache = TRUE,
               fig.width = 6, 
               fig.height = 6)
library(ggplot2)
library(Hmisc)
library(reshape2)
library(ADNIMERGE)
library(plyr)
options(digits=3)
theme_set(theme_bw())


# Multiple plot function
#
# ggplot objects can be passed in ..., or to plotlist (as a list of ggplot objects)
# - cols:   Number of columns in layout
# - layout: A matrix specifying the layout. If present, 'cols' is ignored.
#
# If the layout is something like matrix(c(1,2,3,3), nrow=2, byrow=TRUE),
# then plot 1 will go in the upper left, 2 will go in the upper right, and
# 3 will go all the way across the bottom.
#
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  require(grid)

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = cols, nrow = ceiling(numPlots/cols))
  }

 if (numPlots==1) {
    print(plots[[1]])

  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}

bland_altman_plot <- function(x, y, c) {
  data = data.frame(x=x,y=y,diff=x-y, m = (x+y)/2, c=c)
  return(ggplot(data, aes(x= m, y = diff, colour = as.factor(c))) + 
    geom_hline(yintercept = mean(data$diff) + c(-2, 0, 2) * sd(data$diff), 
               linetype=2, color='brown') + geom_point())
}

lm_eqn = function(m) {
  l <- list(a = format(coef(m)[1], digits = 2),
      b = format(abs(coef(m)[2]), digits = 2),
      r2 = format(summary(m)$r.squared, digits = 3));
  if (coef(m)[2] >= 0)  {
    eq <- substitute(italic(y) == a + b %.% italic(x)*","~~italic(r)^2~"="~r2,l)
  } else {
    eq <- substitute(italic(y) == a - b %.% italic(x)*","~~italic(r)^2~"="~r2,l)    
  }

  as.character(as.expression(eq))
}
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass{article}
\usepackage[margin=1in]{geometry}
\usepackage{algorithm, color, algpseudocode, amsmath, url, geometry, ctable}
\usepackage{titlesec, siunitx}
\usepackage[round,authoryear]{natbib}
\usepackage[section]{placeins}  % keep floats in their place.

%draft mode
\usepackage[colorinlistoftodos, textwidth=4cm, shadow]{todonotes}
\usepackage[displaymath, tightpage]{preview}
\setlength{\marginparwidth}{1.2in}

% add \subsubsubsection
% \setcounter{secnumdepth}{4}  
% \titleformat{\paragraph}
% {\normalfont\normalsize\bfseries}{\theparagraph}{1em}{}
% \titlespacing*{\paragraph}
% {0pt}{3.25ex plus 1ex minus .2ex}{1.5ex plus .2ex}
\newcommand{\subsubsubsection}[1]{\paragraph{#1}}

% shortcuts 
\newcommand{\mb}{MAGeT-Brain }
\newcommand{\ants}{ANTS }
\newcommand{\animal}{ANIMAL }
\newcommand{\adnidataset}{ADNI1:Complete 1Yr 1.5T }
%notes and TODO formatting
%\newcommand{\marginnote}[1]{\-\marginpar[\raggedleft\footnotesize #1]{\raggedright\footnotesize #1}}
%\newcommand{\comment}[1]{\begin{kframe}{\textcolor{red}{#1}}\end{kframe}}
%\newcommand{\todo}[1]{\comment{TODO #1}}
%\newcommand{\mc}[1]{\comment{MC: #1}}
\begin{document}
%\SweaveOpts{concordance=TRUE}

\title{Bootstrapping Multi-atlas Hippocampal Segmentation with \mb}
\author{Pipitone J., Winterburn J., Lett, T., Lerch J., Pruessner J., Lepage M., \\ 
Voineskos A., Chakravarty M.M., and \\ 
the Alzheimer's Disease Neuroimaging Initiative}
\maketitle

\begin{abstract}
Neuroimaging research often relies on automated anatomical segmentations of MR
images of the brain. Current multi-atlas based approaches provide accurate
segmentations of brain images by propagating manually derived segmentations of
specific neuroanatomical structures to unlabelled data. These approaches often
rely on a large number of such manually segmented atlases that take significant
time and expertise to produce. We present an algorithm for the automatic
segmentation of the hippocampus that minimizes the number of atlases needed
while still achieving similar accuracy to multi-atlas approaches.
\todo[inline]{finish}

\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                               INTRODUCTION
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

The hippocampus is a neuroanatomical structure situated in the medial temporal
lobe of the brain, and has long been associated with learning and memory
\citep{DenHeijer2012,Scoville2000}.  In addition to its known functional roles,
the hippocampus is of interest to neuroscientists because it is implicated in
several forms of brain disfunction such as Alzheimer's disease
\citep{Sabuncu2011} and schizophrenia \citep{Narr2004,Karnik-Henry2012}.  In
neuroimaging experiments, magnetic resonance images (MRI) are often used for the
identification of the hippocampus.  As such, accurate segmentation of the
hippocampus and its subregions in MRI is a necessary first step to better
understand the unique neuroanatomy of subjects. Typically, the gold standard for
neuroanatomical segmentation is manual delineation by an expert human. However
the rapid increase in the availability of MRI data and the time and expertise
required for manual segmentation is prohibitive
\citep{Mazziotta1995,Mazziotta2001,Mazziotta,Pausova2007,Weiner2013}.
Further, there is little agreement between researchers regarding how exactly the
hippocampus should be identified in MRI images \citep{Geuze2004} and this has
led to efforts to create an unified hippocampal segmentation protocol
\citep{Jack2011}.  

Automated segmentation techniques that are reliable, objective, and reproducible
are a necessary alternative to manual segmentation.  In the case of classical
model-based segmentation methods \citep{Haller1997,Csernansky1998}, an MRI atlas
that was previously manually labelled by an expert rater is matched to target
images using nonlinear registration methods.  The resulting nonlinear
transformation is applied to the manual labels (ie. {\em label propagation}) to
apply them to the target image.  While this methodology has been used
successfully in several contexts
\citep{MallarMedIA200809,MallarHBM20082009,Collins1995,Haller1997}, it is limited
in accuracy by the introduction of errors due inaccuracies in the nonlinear
transformation itself, partial volume effects in label resampling, and
irreconcilable differences between the neuroanatomy represented within the atlas
and target images.
 
One methodology that can be used to mitigate these sources of errors involves
the use of multiple manually segmented atlases and probabilistic segmentation
techniques, such as those found in the FreeSurfer package \citep{Fischl2002},
FreeSurfer uses a probabilistic atlas of anatomical and tissue classes along
with spatial constraints for class labels encoded using a Markov random field
model to segment the entire brain.  

More recently, many groups have been using multiple atlases to improve overall
segmentation accuracy (ie. multi-atlas segmentation) over model-based approaches
\citep{Heckemann2006,Heckemann2011,Collins2010,Lotjonen2010,Aljabar2009,Leung2010,Wolz2010}.
Each atlas image is registered to a target image, and label propagation is
performed to produce several labellings of the target image (one from each
atlas). A {\it label fusion} technique, such as voxel-wise voting, is used to
merge these labels into a definitive segmentation for the target.  In addition,
weighted voting procedures that use {\em atlas selection} techniques are often
used to exclude atlases from label fusion that are dissimilar to a target image
in order to reduce error from unrepresentative anatomy \citep{Aljabar2009}.
This involves the selection of a subset of atlases using a similarity metric
such a cross-correlation \citep{Aljabar2009} or normalized mutual information.
Such selection has the added benefit of significantly reducing the number of
nonlinear registrations.  For example Collins and Pruessner \citep{Collins2010}
demonstrated that only 14 atlases, selected based on highest similarity between
medial temporal lobe neuroanatomy as evaluated by normalized mutual information
\citep{Studholme1999} from a library of 80 atlases, were required to achieve
accurate segmentations of the hippocampus.  Several methods have been explored
for label fusion including the STAPLE algorithm \citep{Warfield2004} that
computes a probabilistic segmentation using an expectation maximization
framework from an set of competing segmentations; or others where a subset of
segmentations can be estimated using metrics such as the sum of squared
differences in the regions of interest to be segmented \citep{Coupe2011}.

However, many of these methods require significant investment of time and
resources for the creation of the atlas library; ranging from atlas libraries
that require between 30 \citep{Heckemann2006} and 80 \citep{Collins2010}
manually segmented atlases.  This strategy has the main drawback of being
inflexible as it does not easily accommodate varying the definition of the
hippocampal anatomy (such as the commonly used heuristic of subdividing the
hippocampus in to head, body, and tail \citep{Poppenk2011,Pruessner2000}).
Furthermore, none of these methods have demonstrated sufficient flexibility to
accommodate atlases that are somehow exceptional such as those derived from
serial histological data \citep{Chakravarty06a,Yelnik2007} or high-resolution MRI
data that enables robust identification of hippocampal subfields
\citep{Winterburn2013,Yushkevich2009,Mueller2009,VanLeemput2009,Wisse2012}.  Due to
the recent availability of the latter, there has been increased interest in the
use of probabilistic methods for the identification of the hippocampal subfields
on standard T1-weighted images.  Our group recently demonstrated that through
use of an intermediary automated segmentation stage, robust and accurate
segmentation of the striatum, pallidum, and thalamus using a single atlas
derived from serial histological data \citep{Chakravarty2013} is possible.  The
novelty of this manuscript is the extension our multi-atlas methodology to the
hippocampus using more than a single input atlas, while simultaneously limiting
the number of possible inputs used during segmentation, and demonstrating that
accurate identification of the hippocampal subfields is indeed possible using
this methodology.

There are few methods that have attempted to perform multi-atlas segmentation
with a limited number of input atlases. The LEAP algorithm is an elegant
modification to the basic multi-atlas strategy \citep{Wolz2010} in which the
atlas library is grown, beginning with a set of manually labelled atlases, and
successively incorporating unlabelled target images after themselves being
labelling using multi-atlas techniques. The sequence in which target images are
labelled is chosen so that the similarity between the atlas images and the
target images is minimised at each step, effectively allowing for deformations
between very dissimilar images to be broken up into sequences of smaller
deformations.  Although Wolz et al. begin with an atlas library of 30 MR images,
this method could theoretically work using a much smaller atlas library.  In
their validation, LEAP was used to segment the whole hippocampus in the ADNI1
baseline dataset, achieving a mean Dice score of 0.85 with manual segmentations.

To the best of our knowledge there are two other segmentation methods that
attempt to define the hippocampal subfields using standard T1-weighted data.
The first is included with the FreeSurfer package \citep{VanLeemput2009}.  This
work is limited as it omits the tail of the hippocampus and the segmentation
protocol has yet to be fully validated.  Nonetheless, they demonstrate that the
applicability of their work using data from 10 subjects.  In the second method,
Yushkevich and colleagues \citep{Yushkevich2009} acquired and labelled
hippocampal subfields on high-resolution MRI data from post-mortem medial
temporal lobe samples an demonstrate it's applicability in the segmentation of
other MRI-volumes using nonlinear registration guided using manually derived
hippocampus masks and specific landmarks. In their work they demonstrate
accurate parcellations of the subfields.

Here we address the issue of limiting the number of input atlases by tuning our
algorithm, for segmentation of the entire hippocampus, using a multi-fold
experiment performed on a subset Alzheimer's Disease Neuroimaging Initiative
(ADNI) 1 dataset. Based on the parameters we find in our experiment, we validate
our algorithm using all of the data available in the ADNI Complete 1Yr sample
and compare our segmentations to the other segmentations that are available
through the ADNI informatics portal.  To ensure that we have not over-fit our
parameters to the aging or neurodegenerative brain, we also apply our
segmentations to a dataset of normal controls and individuals suffering from
first episode psychosis. Finally, we perform a leave-one-out validation
experiment to determine if the subfields can be accurately identified using our
multi-atlas framework. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                               METHODS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Methods}

%%%%%                     MAGeT Brain Algorithm                            %%%%%

\subsection{The \mb Algorithm}
In this paper, we will use the term {\em label} to mean any segmentation (manual or 
derived) of an MR image.  {\em Label propagation}, or {\em labelling}, is the 
process by which two images are registered and the resulting transformation 
is applied to the labels from one image to bring them into alignment with the 
other image. We will use the term {\em atlas} to mean a manually segmented image,
and the term {\em template} to mean an automatically segmented image (i.e. 
via label propagation). The terms {\em atlas library} and {\em template library} 
describe any set of such images.Additionally, we will use the term {\em target} 
to refer to an unlabelled image that is undergoing segmentation.

The simplest form of multi-atlas segmentation, (which we will call {\em basic 
multi-atlas segmentation}), involves three steps.  First, each labelled 
input image (i.e. atlas or template) is registered to an unlabelled target image.
Second, the labels from each image are propogated to the target image space. 
Third, the labels are combined into a single labelling by way of a label fusion method 
\citep{Heckemann2006, Heckemann2011}. This method is described in detail in other
publications \citep{Collins2010,Heckemann2011,Aljabar2009}.

\mb bootstraps the creation of a large template library given a limited input atlas 
library, and then uses the template library in basic multi-atlas segmentation. 
Images for the template library are selected from a set of input target images, 
either arbitrarily or so as to reflect the neuroanatomy or demographics of the 
target set as a whole (for instance, by sampling equally from cases and controls). 
The template library images are then labelled by each of the atlases. Basic 
multi-atlas segmentation is then conducted using the template library
to segment the entire set of target images (including the targets whose images
are used in the construction of the template library).  Since each template
library image has multiple labels (one from each atlas), the final number of 
labels to be fused for each target may be quite large (i.e. \# of atlas $\times$ 
\# of templates).

Figure \ref{alg:MAGeT} describes the \mb algorithm in pseudocode. Source code 
for \mb can be found at \url{http://github.com/pipitone/MAGeTbrain}.

\begin{algorithm}
  \scriptsize
  \caption{Pseudocode for the \mb algorithm}
  \label{alg:MAGeT}
  \begin{algorithmic}
    \Function{BasicMultiAtlasSegmentation}{Templates, Subjects}
      \ForAll{$target$}
        \ForAll{$template$}
          \State propagate all labels for template to target space
          \State store target labels
        \EndFor
        \State fuse target labels
      \EndFor
    \EndFunction
    \\
    \Function {MAGeTBrain}{Subjects, Atlases, n}
      \For{$i = 1 \to n$}
        \State choose a target to be used as a template
        \State propagate labels from each atlas to template space
        \State store the template with all of its labels
      \EndFor
      \State MultiAtlas(Templates, Subjects)
    \EndFunction
  \end{algorithmic}
\end{algorithm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                            Experiments                              %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Experiments}

The following section describes the experiments we conducted to assess the
segmentation quality of the \mb algorithm. The first two experiments assess the
validity of \mb using a cross-validation design. Experiment 1 investigates the
accuracy of \mb whole hippocampus segmentation over a wide range of parameter
settings. This enables us to choose the parameter settings offering the best
performance for use in subsequent experiments. Experiment 2 tests hippocampal
subfield segmentation quality. The last two experiments assess the validity of
the \mb algorithm when applied to different diseases: Alzheimer's disease
(Experiment 3) and first episode schizophrenia patients (Experiment 4). 

%The ADNI experiment includes comparison of volumes with other automated
%segmentation methods. Evaluation is done by correlating volumes b/c overlap
%metrics assume identical segmentation protocol. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                                                                     %%%%%
%%%%%         Experiment 1: Whole Hippocampus Cross-Validation            %%%%%
%%%%%                                                                     %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Experiment 1: Whole Hippocampus Cross-Validation}

Monte Carlo Cross-Validation (MCCV) \citep{Shao1993} was performed using a pool
of images and manual hippocampal segmentations from ADNI1 dataset.  This form of
cross-validation allows us to rigorously validate a large number of parameter
settings of \mb (atlas and template library sizes, registration algorithm, and 
label fusion method) and select the best parameters to use in subsequent 
experiments.

\paragraph{ADNI1 dataset} 

69 1.5T images were arbitrarily selected from the baseline scans in the {\em
\adnidataset} standardized dataset. 23 subjects were chosen from each disease
category: cognitively normal (CN), mild cognitive impairment (MCI) and
Alzheimer's disease (AD). Demographics for this subset are shown in Table
\ref{tab:ADNI1-xvalidation-demographics}.  Manual segmentations of the left and
right whole hippocampi are available. These labels have been generated using the
SNT tool from Medtronic Surgical Navigation Technologies, Louisville, CO (see
Supplementary Materials for detailed discussion of the manual segmentation
process used).

Clinical, demographic and pre-processed T1-weighted MRI were downloaded by the
authors from the ADNI database (adni.loni.ucla.edu) between March 2012 and
August 2012. The image dataset download was the "\adnidataset"
standardized dataset available from ADNI \footnote{
\url{http://adni.loni.ucla.edu/methods/mri-analysis/adni-standardized-data/}}
\citep{Wyman2012}. This image collection contains uniformly preprocessed images
which have been designated to be the "best" after quality control.  All images
were acquired using 1.5T scanners (General Electric Healthcare, Philips Medical
Systems or Siemens Medical Solutions) at multiple sites using the protocol
described in \citep{Jack2008}.  Representative 1.5T imaging parameters were TR
= 2400ms, TI = 1000ms, TE = 3.5ms, flip angle = $8{\circ}$, field of view = 240
x 240mm, a $192 \times 192 \times 166$ matrix ($x$, $y$, and $z$ directions)
yielding a voxel resolution of $1.25 \times 1.25 \times 1.2mm^3$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% ADNI1 X-Validation Dataset Demographics Table
%
<<ADNI-Xval-demographics, echo=F, results="asis",cache=FALSE>>=
adni_69_RIDs = c(295,413,619,685,729,782,938,954,1018,1155,907,981,222,324,448,
                 546,553,572,602,610,814,1341,675,681,731,1130,41,68,70,101,
                 249,293,316,414,698,1206,1222,1339,751,1030,3,5,10,16,22,53,
                 168,183,241,1205,328,1095,991,213,159,337,343,642,753,1109,
                 1217,29,56,1188,1293,149,382,431,1202)
tab <- summary(DX.bl ~ AGE + PTGENDER + PTEDUCAT + PTETHCAT + CDRSB + ADAS13 +
               MMSE, data = adnimerge, subset = VISCODE == 'bl' & RID %in%
               adni_69_RIDs, method = "reverse", test=FALSE, overall=TRUE)

latex(tab, file="", size="scriptsize",landscape=FALSE, ctable=FALSE,
      caption="ADNI-1 cross-validation subset demographics", 
      title="tab:ADNI1-xvalidation-demographics")
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\paragraph{Experiment details} 

Monte Carlo Cross-Validation (MCCV), also known as repeated random sub-sampling
cross-validation, consists of repeated rounds of validation conducted on a fixed
dataset \cite{Shao1993}. In each round, the dataset is randomly partitioned into
a training set and a validation set. The method to be validated is then given
the training data, and its output is compared with the validation set.

In this experiment, our dataset consists of 69 1.5T images and corresponding
manual segmentations. In each validation round, the dataset is partitioned into 
a training set consisting of images and their manual labels to be used as an atlas 
library, and a validation set consisting of the remaining images segmented by both 
\mb and multi-atlas. The resulting segmentations are compared to the manual 
segmentations for the images.

A total of ten validation rounds are perfomed on each subject in the dataset,
over each combination of parameter settings. The parameter settings
we explore are: atlas library size (1-9), template library size (1-20),
registration method (\ants or \animal), and label fusion method (majority vote,
cross-correlation weighted majority vote, and normalized mutual information
weighted majority vote).  A total of $10 \times 69 \times 9 \times 20 \times 2
\times 3 = \num{7452000}$ validation rounds were conducted, resulting in a total
of $\num{1490400}$ segmentations analysed. 

Before registration, all images underwent preprocessing with the N3 algorithm
\citep{Sled1998} to minimize intensity nonuniformity. In this experiment we use
one of two non-linear image registration methods.

\subparagraph{Automatic Normalization and Image Matching and Anatomical
Labeling (\animal)}

The \animal algorithm carries out image registration is in two phases. In the
first, a 12-parameter linear transformation (3 translations, rotations, scales,
shears) is estimated between images using an algorithm that maximizes the
correlation between blurred MR intensities and gradient magnitude over the whole
brain \citep{Collins}. In the second phase, nonlinear registration is completed
using the \animal algorithm \citep{Collins1995}: an iterative procedure that
estimates a 3D deformation field between two MR images. At first, large
deformations are estimated using blurred version of the input data. These larger
deformations are then input to subsequent steps where the fit is refined by
estimating smaller deformations on data blurred with a Gaussian kernel with a
smaller FWHM. The final transformation is a set of local translations defined on
a bed of equally spaced nodes that were estimated through the optimization of
the correlation coefficient.  For the purposes of this work we used the
regularization parameters optimized in Robbins et al. \citep{Robbins2004},
displayed in table \ref{tab:ANIMAL-params}. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ANIMAL parameters                    
%                                     
\begin{table}[!tbp]
\begin{center}
\caption{\animal  registration parameters}
\begin{tabular}{l | c c c}
\hline 
Parameters        & Stage 1 & Stage 2 & Stage 3  \tabularnewline
\hline 
Model Blur (FWHM) &   8     &    8    &   4      \tabularnewline
Input Blur (FWHM) &   8     &    8    &   4      \tabularnewline
Iterations        &   30    &    30   &   10     \tabularnewline
Step              &   8x8x8 &  4x4x4  &   2x2x2  \tabularnewline
Sub-Lattice       &   6     &    6    &   6      \tabularnewline
Lattice Diameter  &24x24x24 &12x12x12 & 6x6x6    \tabularnewline
\hline
\end{tabular}
\end{center}
\label{tab:ANIMAL-params}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subparagraph{Automatic Normalization Tools (\ants)}

\ants is a diffeomorphic registration algorithm which provides great flexibility
over the choice of transformation model, objective function, and the consistency
of the final transformation. The transformation is estimated in a hierarchical
fashion where the MRI data is subsampled, allowing large deformations to be
estimated and successively refined at later hierarchical stages (where the data
is subsampled to a finer grid). The deformation field and the objective function
are regularized with a Gaussian kernel at each level of the hierarchy. The \ants
algorithm is freely available \url{http://www.picsl.upenn.edu/ANTS/}. We used an
implementation of the \ants algorithm compatible with the MINC data format,
mincANTS \url{https://github.com/vfonov/mincANTS}.

We used the following command line when running \ants:
{\small
\begin{verbatim}
  mincANTS 3 -m PR[target_file.mnc,source_file.mnc,1,4] 
   --number-of-affine-iterations 10000x10000x10000x10000x10000 
   --affine-gradient-descent-option 0.5x0.95x1.e-4x1.e-4
   --use-Histogram-Matching --MI-option 32x16000
   -r Gauss[3,0] -t SyN[0.5] -i 100x100x100x20
   -o transformation.xfm
 \end{verbatim}
}
These settings were adapted from the "reasonable starting point" given in the
\ants manual 
\footnote{\url{https://sourceforge.net/projects/advants/files/Documentation/}}.

\paragraph{Label fusion methods}
Label fusion is a term given to the process of combining the information from
several candidate labellings for an intensity image into a single labelling.  In
this experiment we explore three fusion methods. 
\begin{description}
  \item[Voxel-wise Majority Vote]
  Labels are propagated from all template library images to a target.  Each
  output voxel is given the most frequent label at that voxel location amongst
  all candidate labellings.  Ties are broken arbitrarily.

  \item[Cross-correlation Weighted Majority Vote]
  An optimal combination of targets from the template library has previously been
  shown to improve segmentation accuracy \citep{Aljabar2009,Collins2010}.  In this
  method, each template library image is ranked in similarity to each unlabelled 
  image by the normalized cross-correlation (CC) of image intensities after linear
  registration, over a region of interest (ROI) generously encompassing the 
  hippocampus.  Only the top ranked template library image labels are used in a
  voxel-wise majority vote. The ROI is heuristically defined as the extent of all
  atlas labels after linear registration to the template, dilated by three voxels
  \citep{Chakravarty2012}.  The number of top ranked template library image labels
  is a configurable parameter and displayed as the size of the template library
  in the rest of the paper. 

  The {\tt xcorr\_vol} utility from the \animal toolkit is used to calculate the
  cross-correlation similarity measure.  
 
  \item[Normalised Mutual Information Weighted Majority Vote]
  This method is similar to cross-correlation weighted voting except that image
  similarity is calculated by the normalised mutual information score over the
  region of interest\citep{Studholme2001}.  The {\tt itk\_similarity} utility
  from the EZMinc toolkit\footnote{\url{https://github.com/vfonov/EZminc}} is
  used to calculate the normalised mutual information measure between to images.
\end{description}
\paragraph{Evaluation method}  

The Dice similarity coefficient (DSC) assesses the agreement between two
segmentations. It is one of the most widely used measures of segmentation
performance, and we use it as the basis of comparison in this experiment.
Additionally, we report the Jaccard index, another commonly used similarity
measure:

 \[\text{Dice's coefficient (DSC)} = \frac{2|A \cap B|}{|A| + |B|}\]

 \[\text{Jaccard (J)} = \frac{|A \cap B|}{|A \cup B|} = \frac{DSC}{(2-DSC)}\]

where $A$ and $B$ are the regions being compared, and the cardinality is the
volume measured in voxels. 

The manual segmentations (SNT) provided as part of the ADNI dataset are used as 
the gold standard to compare with.  The segmentation accuracy reported is averaged 
over the ten validation rounds for each parameter setting.  

In order to investigate the performance of \mb in a real world setting in which 
only one set of atlas and template images are used, we explore the variability 
in label agreement at fixed parameter settings when the choice for atlas and 
template images is varied. This is achieved by first computing the standard 
deviation and variance of DSC scores in each block 
of ten validation rounds per subject. The distribution of these statistics across 
all subjects is then compared between \mb and multi-atlas using a Student's 
t-test. A significant difference between distributions is taken to show either
a larger or smaller level of variability between methods. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                                                                     %%%%%
%%%%%        Experiment 2: Hippocampal Subfield Cross-Validation          %%%%%
%%%%%                                                                     %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Experiment 2: Winterburn Atlases Cross-Validation}
In this experiment, the accuracy of the \mb algorithm on hippocampal subregion
segmentation is tested using a leave-one-out cross-validation (LOOCV) design.
The optimal parameter settings found in Experiment 1 are used.

\paragraph{Winterburn Atlases dataset} 
The Winterburn atlases \citep{Winterburn2013} are digital hippocampal
segmentations of five in-vivo $300\mu$ isotropic T1-weighted MR images. The
segmentations include subfield segmentations for the cornus ammonis (CA) 1, CA4,
dentate gyrus, subiculum, and CA 2 and 3 combined. Subjects in the Winterburn
atlases range in age from 29-57 years (mean age of 37), and include two males
and three females.  

In addition to the high-resolution scans distributed as part of the Winterburn
atlases, we also obtained additional 3T T1 BRAVO images (0.9mm-isotropic voxels)
of four of the five Winterburn atlas subjects. 

\paragraph{Experiment details} 
Leave-one-out cross-validation (LOOCV) is an approach in which the method to be
validated is given all but one item in a dataset as training data, and the
output is compared with the left-out item. This is done, in turn, for each item
in the dataset. 

In this experiment, the five $300\mu$-isotropic voxel Winterburn atlases are
used as the atlas library for \mb segmentation. LOOCV is conducted separately
for two different input datasets: the four Winterburn atlas subject T1 BRAVO
images (referred to as the {\em BRAVO} dataset), and the five
Winterburn atlas subject images subsampled to 0.9mm-isotropic voxel resolution
(referred to as the {\em Subsampled} dataset. Each subject in the
dataset is segmented by \mb with that subject's image excluded from the atlas
library. The template library consists of 3T T1 images (0.9mm-isotropic
voxels) of healthy subjects in addition to the images from the dataset being
evaluated.

The optimal size of template library, registration method, and label fusion
method found in Experiment 1 are used. 

\paragraph{Evaluation method}  
\mb performance is measured with respect to straight-forward nearest-neighbour
resampling of the Winterburn atlas labels to 0.9mm-isotropic voxels (i.e. no 
label propagation). The volumes of each hippocampal subregion in the subsampled
Winterburn atlas labels are compared to the volumes obtained from the full 
resolution Winterburn atlas labels, the \mb labels on the subsampled Winterburn 
atlas images, and the \mb labels on the T1 BRAVO acquisitions. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                                                                     %%%%%
%%%%%         Experiment 3: Application of \mb to the segmentation        %%%%%
%%%%%                       of schizophrenia patients                     %%%%%
%%%%%                                                                     %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Experiment 3: Application to the segmentation first episode
schizophrenia patients}
 
To validate that \mb algorithm works effectively in the context of other
neuropsychiatric disorders, we use the Winterburn atlases with \mb to predict
the hippocampal segmentation of dataset of Schizophrenia patient MR images. The
resulting segmentations are assessed for quality by comparison with expert
manual segmentations.

\paragraph{SZ-FEP dataset}
All patients were recruited and treated through the Prevention and Early
Intervention Program for Psychoses (PEPP-Montreal), a specialized early
intervention service at the Douglas Mental Health University Institute in
Montreal, Canada. People aged 15–30 years from the local catchment area
suffering from either affective or non-affective psychosis who had not taken
antipsychotic medication for more than one month with an IQ above 70 were
consecutively admitted as either in- or out-patients. Of those treated at PEPP,
only patients aged 18 to 30 years with no previous history of neurological
disease or head trauma causing loss of consciousness were eligible for the
neuroimaging study; only those suffering from schizophrenia spectrum disorders
were considered for this analysis.  For complete program details see Malla et
al. \citep{Malla2003}. 

Scanning of 81 subjects was carried out at the Montreal Neurological Institute
on a 1.5-T Siemens whole body MRI system.  Structural T1 volumes were acquired
for each participant using a three-dimensional (3D) gradient echo pulse sequence
with sagittal volume excitation (repetition time=22ms, echo time=9.2ms, flip
angle=$30{\circ}$, 180 1mm contiguous sagittal slices). The rectangular
field-of-view for the images was 256mm (SI)$\times$204mm (AP).  Subject
demographics are shown in table \ref{tab:SZFEP-Demographics}. 

The hippocampus were traced following a validated protocol developed by Dr Jens
Pruessner \todo{cite: (Pruessner et al., 2000)}. A recent update to this
protocol by Dr J Pruessner in 2006 allows to accurately and consistently
subdivide the hippocampus into three different subregions: head, body, and tail.
We use these segmentations as to validate our implementation of \mb.

\paragraph{Experiment details} 
\mb is configured with an atlas library composed of the Winterburn T1 atlases
(see Experiment 2).  All images from the SZ-FEP dataset are segmented.  The optimal
size of template library, registration method, and label fusion method found in
Experiment 1 are used. 

\paragraph{Evaluation method}
The manual segmentation protocol used to segment the Winterburn atlases has some
neuroanatomical differences in comparison to the protocol used to segment the
SZFEP dataset.  Therefore, rather than evaluate using an overlap metric, such as
DSC, which assumes a fixed segmentation protocol, we instead correlate whole
hippocampus volume between \mb and manual segmentations. 

\todo{done elsewhere?}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% First Episode SZ Demographics Table
%
<<FEP-SZ-demographics, echo=F, results="asis",cache=FALSE>>=
fep_sz_demographics = read.csv("data/SZ_demographics.csv", na.strings=c("","."))
fep_sz_demographics = subset(fep_sz_demographics, Anon <= 81)
tab <- summary(DX ~ Age + Gender + Handedness + Education + SES + FSIQ,
               data=fep_sz_demographics, method = "reverse", test = FALSE)
latex(tab, file="", ctable=FALSE,
      caption="Schizophrenia First Episode Patient Demographics",
      title="tab:SZFEP-Demographics")
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                                                                     %%%%%
%%%%%         EXPERIMENT 4: Application of \mb to the segmentation        %%%%%
%%%%%                       of ADNI subjects                              %%%%%
%%%%%                                                                     %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Experiment 4: Application to the segmentation of Alzheimer's
disease patients}

To validate that \mb algorithm works as well as established automated methods,
\mb is applied to the ADNI1 dataset and the resulting segmentations are
compared to those produced by FreeSurfer, FSL, MAPER, and by expert manual
segmentation.

\paragraph{ADNI1 dataset revisited} 
All images from the {\em \adnidataset} standardized dataset described
in Experiment 1 are used.  Clinical and demographic data are shown in table
\ref{tab:ADNI1-1.5T-Complete-1Yr-Dataset-Demographics}. 

\paragraph{Experiment details} 
\mb is configured with an atlas library composed of the Winterburn T1 atlases
(see Experiment 2). All images from the \adnidataset dataset are
segmented. The optimal size of template library, registration method, and label
fusion method found in Experiment 1 are used. The template library is composed
of equal numbers of images from each disease class (AD, MCI, and cognitively
normal controls). 

\paragraph{Evaluation method}
Since the hippocampal segmentation protocols differ between the ADNI labels and
Winterburn atlases, this poses a problem for direct evaluation between labels
produced by \mb and the ADNI labels in terms of overlap; we would not expect
different segmentation protocols to have a high degree of overlap.  Instead, to
evaluate the performance of \mb we compare the correlation of \mb segmentation
volumes with manual segmentation (SNT) volumes. Additionally, we correlate the
hippocampal volumes of established automated segmentation methods to \mb
segmentations.  

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ADNI1-COMPLETE
% Prepares the data in a the form needed for plotting.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
<<ADNI-src-volumes-prep,echo=F,cache=T>>=
totals.complete  <- read.csv('data/cache/ADNI1:totals.complete.csv')
totals           <- read.csv('data/cache/ADNI1:totals.csv')
package_totals   <- read.csv('data/cache/ADNI1:package_totals.csv')
@


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                                             
% ADNI1 Complete 1Yr Dataset Demographics Table 
%                                                                             
<<ADNI1-scr-demographics, echo=F, results="asis",cache=FALSE>>=
# RID < 2000 ensures only ADNI1 patients
yr1 = read.csv("data/ADNI_baseline_volumes/ADNI1_Complete_1Yr_1.5T_11_15_2012.csv")
yr1$VISCODE <- factor(yr1$Visit, levels = c(1,2,3,4), labels=c("bl","m03","m06","m12"))
yr1 = subset(yr1, !grepl("Scaled_2", Description))
yr1 = yr1[,c("RID","VISCODE")]
yr1 = 
adnimerge.yr1 = merge(adnimerge, yr1) 
tab <- summary(DX.bl ~ AGE + PTGENDER + PTEDUCAT + PTETHCAT + CDRSB + ADAS13 +
               MMSE, data = adnimerge.yr1, 
               #subset = RID %in% yr1$RID & VISCODE %in% c('bl','m06','m12'),   
               method = "reverse", test=FALSE, overall=TRUE)

latex(tab, file="", size="scriptsize", 
    caption="ADNI1 1.5T Complete 1Yr dataset demographics",
    label="tab:ADN1-1.5T-Complete-1Yr-Dataset-Demographics")
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                               RESULTS                                        %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Results}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                                                                     %%%%%
%%%%%     RESULTS: Experiment 1: Whole Hippocampus Cross-Validation       %%%%%
%%%%%                                                                     %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Experiment 1 Results: Whole Hippocampus Cross-Validation}

In this experiment we conducted 10 rounds of \mb and multi-atlas segmentation of
each of 69 subjects at a range of atlas and template library sizes, registration
algorithm (\ants or \animal), and three label fusion techniques.  Hippocampal
\mb-based segmentations using both \animal and \ants registration algorithm
demonstrate good overlap with SNT derived gold-standards (Figure
\ref{fig:ADNI1-xval-k-mean}). Qualitatively, both \animal and \ants-based
segmentations demonstrate trend overlap accuracy that increases with the size of
atlas library and template library. Improvement in accuracy diminishes noticeably
with template libraries larger than roughly ten images. 

No marked difference in segmentation accuracy is seen when either \animal or \ants
registration is used with any number of atlases or templates.  In every parameter 
configuration, the use of \mb with \ants registration shows a pronounced increase
in segmentation accuracy over \mb with \animal registration.  Surprisingly, the 
label fusion method used does not significantly improve label accuracy, contrary 
to the findings of Aljabar et al. \cite{Aljabar2009} when using weighted voting
on much larger altas/template libraries. In the remainder of  this section, only 
results using the \ants registration algorithm and majority vote fusion will 
be shown.

With an increasing number of templates, \mb shows improvement in overlap
accuracy over multi-atlas-based segmentation when using the same number of atlases
and voting method (Figure \ref{fig:ADNI1-xva-k-diff}). The magnitude of improvement over
multi-atlas-based segmentation decreases with an increasing number of atlases,
with accuracy converging with 7 atlases.  Peak improvement in \mb accuracy (~0.02
DSC) is found when one atlas is used with a template library of 20 images.

\todo{mention failures}

In addition to an improvement in accuracy over multi-atlas-based segmentation,
\mb also shows a decrease in the variability of segmentation accuracy 
(Figure \ref{ADNI1-xval-variability}).  The size of template library 
necessary to reach a significant (p<0.5) decrease in variance and standard 
deviation grows with the size of atlas library used.  A template library of 19
images is sufficient to show significant decrease in variance and standard 
deviation for 3-7 atlases. 
\todo{Tris: only show variance OR standard deviation because otherwise the story gets complicated... why compare measures?}

It is interesting to note that with an even number of templates, \mb shows a
small decrease in performance relative to when one fewer template image is used.
See section \todo{ref} for a discussion of this behaviour. In the remainder of
this section, only results from odd-sized template libraries will be shown. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ADNI1-XVAL: prep
% Prepares the data in a the form needed for plotting.
<<ADNI1-xval-prep,dependson='ADNI1-xval-load',include=FALSE,cache=TRUE>>=
all_data  <- read.csv('data/cache/ADNI-XVAL:all_data.csv')
all_data_mean  <- read.csv('data/cache/ADNI-XVAL:all_data_mean.csv')
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{figure}
<<ADN1-library-composition, cache=TRUE, dependson='ADNI1-Xval-prep'>>=
# These composition datasheets describe the subjects and subject DX in the 
# template and atlas libraries for each voting run
atlas_comp = read.csv('data/a2a_ants/atlas_library_composition.csv')
templ_comp = read.csv('data/a2a_ants/template_library_composition.csv')
a2a.best = subset(all_data, atlases == 9 &
                    templates.mb == 19 &
                    reg_method=='ANTS' &
                    method.mb =='Majority Vote')

cumulative_dist = 
  ggplot(a2a.best, aes(x=k.mb)) + stat_ecdf() + scale_y_continuous(breaks=seq(0,1,0.1))

a2a.best = subset(a2a.best, k.mb > 0.75) # drop the guys that suck

a2a.best = merge(a2a.best, atlas_comp, by=c("timestamp","atlases"))
a2a.best = merge(a2a.best, templ_comp, by.x=c("timestamp","templates.mb"), by.y=c("timestamp","templates"))
a2a.best$templates_AD_percent = (a2a.best$templates_AD / 19) * 100
a2a.best$templates_MCI_percent = (a2a.best$templates_MCI / 19) * 100
a2a.best.melted = melt(a2a.best, measure.vars=c("templates_AD_percent", "templates_MCI_percent"))

k_by_composition = 
  ggplot(a2a.best.melted, aes(x=value, y=k.mb, colour=DX)) + facet_grid(variable ~ DX) + 
  geom_boxplot(aes(group=as.factor(value), colour=DX)) +  geom_smooth(method="lm") 

snt.unilateral.vols = read.csv('data/a2a_snt_volumes.csv')
a2a.best = merge(a2a.best, snt.unilateral.vols)

# bland-altman plots
bland_mb_overall = with(a2a.best, bland_altman_plot(volume.snt, volume.mb, DX) + 
  geom_smooth(method="lm") + 
  scale_y_continuous(breaks=seq(-500, 500, 50)))

bland_ma_overall = with(a2a.best, bland_altman_plot(volume.snt, volume.ma, DX) + 
  geom_smooth(method="lm") + 
  scale_y_continuous(breaks=seq(-500, 500, 50)))

# just the trials with a high percentage of MCI in the template library
a2a.best.highMCI = subset(a2a.best, templates_MCI_percent > 50)

bland_mb_highMCI = with(a2a.best.highMCI, bland_altman_plot(volume.snt, volume.ma, DX) + 
  geom_smooth(method="lm") + 
  scale_y_continuous(breaks=seq(-500, 500, 50)))

  
@
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ADNI1-XVAL: mean Kappa plot by atlases, templates, reg and voting method. 
\begin{figure}
<<ADN1-xval-k-mean, cache=TRUE, dependson='ADNI1-Xval-prep'>>=
ggplot(subset(all_data_mean, (templates.mb*atlases) %% 2 == 1),
       aes(x=templates.mb,y=k.mb, colour=as.factor(atlases))) + #as.factor((atlases*templates.mb) %% 2 ))) + 
  facet_grid(reg_method~method.mb) + 
  stat_summary(fun.y=mean,geom='line',
               aes(y=k.mb, weight=1, group=as.factor(atlases))) + 
    stat_summary(fun.y=mean,geom='point',
               aes(y=k.mb, weight=1, group=as.factor(atlases))) + 
  #stat_smooth(method='lm', formula=y~log(x)) + 
  scale_colour_hue(name="Atlases") +
  xlab( "Number of Templates" ) + 
  ylab( "Mean DSC" ) + 
  theme(legend.direction = "horizontal", legend.position = "bottom")
@
  \label{fig:ADNI1-xval-k_mean}
  \caption{
  {\bf Mean DSC of \mb segmentations across 69 ADNI1 subjects, by atlas and
  template library size, registration algorithm, and label fusion method.} 
  }
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ADNI1-XVAL: "increase" in mean kappa over multi-atlas
\begin{figure}
<<ADN1-Xval-k-diff,cache=TRUE,dependson='ADNI1-Xval-prep',fig.width=6,fig.height=4>>=
ggplot(subset(all_data_mean, reg_method=="ANTS" & 
                method.mb=="Majority Vote" & (templates.mb*atlases) %% 2 == 1), 
       aes(x=templates.mb, y=k_diff, colour=as.factor(atlases))) + 
  #facet_grid(reg_method~method.y) + 
  stat_summary(fun.data=mean_cl_boot,geom='errorbar',
               aes(y=k_diff,colour=as.factor(atlases), width=0.2)) +
  stat_summary(fun.y=mean, geom="point", 
               aes(y=k_diff,colour=as.factor(atlases))) + 
  stat_summary(fun.y=mean, geom="line", 
               aes(y=k_diff,colour=as.factor(atlases))) + 
  #stat_smooth(method=lm, formula=y~log(x)) + 
  geom_hline(aes(alpha=0.5, yintercept=0), linetype='dashed') + 
  scale_x_continuous(breaks=seq(1,20,2)) + scale_y_continuous(breaks=seq(-1,1,by=0.01)) + 
  scale_colour_hue(name="Atlases") +
  scale_alpha_continuous(guide = "none") + 
  scale_linetype_discrete(guide = "none") + 
  xlab( "Number of Templates" ) + 
  ylab( "Difference in mean DSC" ) +
  theme(legend.direction = "horizontal", legend.position = "bottom")
@
  \caption{The difference in mean DSC between \mb and multi-atlas segmentations for 
  a range of parameter settings.}
  \label{ADNI1-xval-k-diff}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ADNI1-XVAL: show variability of MAGeT over parameters
\begin{figure}
<<ADN1-Xval-variability, cache=TRUE, dependson='ADNI1-Xval-prep'>>=
ANTSmajvote = subset(all_data, 
                     reg_method=="ANTS" & 
                     method.mb=="Majority Vote" &
                    templates.mb %in% seq(1,20,2))

data.stats = ddply(ANTSmajvote, c("subject", "label","atlases","templates.mb"), function (df) {
  data.frame(
    MA.sd  =  sd(df$k.ma),
    MB.sd  =  sd(df$k.mb),
    MA.var = var(df$k.ma),
    MB.var = var(df$k.mb)
  )
})

stats.tests = ddply(data.stats, c("atlases","templates.mb"), function (df) {
  t.var = t.test(df$MA.var, df$MB.var)
  t.sd  = t.test(df$MA.sd , df$MB.sd)
  diff_mean_var = mean(df$MA.var - df$MB.var)
  diff_mean_sd  = mean(df$MA.sd -  df$MB.sd)
  
  # test statistic is positive if MA mean is larger than MB
  # i.e. that MA has a greater mean of variances/SDs
  # i.e. that MB has a smaller mean, and so is doing "better"
  data.frame(
    stat      = c("Variance", "Standard Deviation"),
    statistic = c(t.var$statistic, t.sd$statistic),
    p.value   = c(t.var$p.value, t.sd$p.value),
    direction = c(diff_mean_var, diff_mean_sd)
  )
})

ggplot(subset(stats.tests, direction > 0, stat == "Variance"), 
  aes(x=templates.mb, y=p.value, colour=as.factor(atlases))) + 
  #facet_grid( . ~ stat) + 
  geom_line(size=1) +
  geom_point(size=3) + 
  geom_hline(aes(yintercept=0.05, alpha=0.5), linetype='dashed') + 
  geom_hline(aes(yintercept=0.01, alpha=0.5), linetype='dashed') + 
  scale_x_continuous(breaks=seq(1,20,by=2)) + 
  scale_y_log10(limits=c(0.001,1), breaks=c(0.01,0.05,0.1,1.0)) + 
  xlab( "Number of Templates" ) + 
  ylab( "Difference of variance during validation (p-value)" ) +
  scale_colour_hue(name="Atlases") +
  scale_alpha_continuous(guide='none') + 
  scale_linetype_discrete(guide='none') + 
  scale_size_continuous(guide='none') + 
  theme(legend.direction = "horizontal", legend.position = "bottom")
@
  \caption{{\bf Difference in variability of \mb vs. multi-atlas segmentation 
  accuracy.}
  Variance of segmentation accuracy between \mb and multi-atlas segmentation 
  is computed for each subject across all ten rounds of validation. Shown on the 
  y-axis (scaled logarithmically) is the  p-value resulting from a t-test 
  comparing the distribution of variances at each parameter setting 
  (atlas/template library size). Only points where \mb mean variability is lower 
  than multi-atlas are shown.}
  \label{ADNI1-xval-variability}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\FloatBarrier

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                                                                     %%%%%
%%%%%    RESULTS: Experiment 2: Hippocampal Subfield Cross-Validation     %%%%%
%%%%%                                                                     %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Experiment 2 Results: Winterburn Atlases Cross-Validation}
This experiment explores \mb segmentations of hippocampal subfields. To
achieve this, a leave-one-out validation is conducted in which lower-resolution
images ($0.9mm^3$ voxels) of each Winterburn atlas subject is segmented using 
the remaining Winterburn atlases. As a point of comparison, volumes of Winterburn 
atlases when subsampled to $0.9mm^3$ voxels are also computed.

In general, across hippocampal subregions the percent error in volume between
\mb segmentations and the manual Winterburn atlas segmentations compares
favourably to error when resampling the atlas segmentations (Figure
\ref{fig:WAval-vol-boxplot}). In particular, the CA1, CA4, and Dentate
subregions all show near or smaller percent errors. The Sibiculum and CA2/CA3
subregions show distinctly larger volumes than resampling error. 
\todo{note direction of change}. 

Figure \ref{fig:subfield-montage} shows a qualitative comparision of \mb subfield
segmentation.  


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Winterburn-XVAL: compare resampling
\begin{figure}[h!]
<<WAval-vol-boxplot,cache=T,fig.width=6,fig.height=4>>=
data = subset(read.csv('data/WAval.csv'))
casted = dcast(melt(data, id.vars=c("file","version")), file + variable ~ version)
casted = rename(casted, c("variable"="region"))

error = ddply(casted, c("file", "region"), function(df) {
  with(df, 
  data.frame(
    resampled = (gold_0.9mm - gold_0.3mm) / gold_0.3mm * 100, 
    mb_bravo  = (mb_bravo   - gold_0.3mm) / gold_0.3mm * 100, 
    mb_0.9mm  = (mb_0.9mm   - gold_0.3mm) / gold_0.3mm * 100))})

levels(error$region) <-list("CA1"="X1", "CA1"="X101", 
                            "Subiculum"="X2","Subiculum"="X102", 
                            "CA4/DG"="X4","CA4/DG"="X104", 
                            "CA2/CA3"="X5","CA2/CA3"="X105", 
                            "SR/SL/SM"="X6","SR/SL/SM"="X106")
melted = melt(error,id.vars=c("file", "region"))
melted = rename(melted, c("variable"="measure", "value"="percenterr"))
levels(melted$measure) <- list("Subsampled"="resampled",
                               "MAGeT + Subsampled" = "mb_0.9mm",
                               "MAGeT + BRAVO"="mb_bravo")

ggplot(melted, aes(y=percenterr,x=region,colour=measure)) +
  geom_boxplot() +
  labs(y="Percent error in volume", x="Region") +
  scale_colour_discrete("") + 
  theme(legend.direction = "horizontal", legend.position = "bottom")
@
  \caption{{\bf Percent error in segmentation volume by hippocampus subregion.} 
  Percent error is measured against the volumes of of the unmodified Winterburn
  atlas segmentations.
  {\bf Subsampled} are volumes of the manual segmentations of the Winterburn
  atlases after resampling to $0.9mm^3$.  
  {\bf MAGeT + WA Subsampled} volumes are \mb segmentations of the Winterburn atlas
  images after resampling to $0.9mm^3$ voxels.
  {\bf MAGeT + WA BRAVO} volumes are \mb segmentations of T1 BRAVO images
  ($0.9mm^3$ voxels) acquired separately of four of the five Winterburn atlas
  subjects.} 
  \label{fig:WAval-vol-boxplot}
\end{figure}


\begin{figure}
  \begin{centering}
    \includegraphics[width=6in]{figure/subfield-montage.pdf}
  \end{centering}
  \caption{Sagittal slices from two subjects showing a comparison of the
  original Winterburn atlas subfield segmentations (at 0.3mm3-isotropic voxel
  resolution), the subsampled Winterburn segmentations (at 0.9mm3-isotropic
  voxel resolution), and the MAGeT brain labels on the subsampled atlas image.}
  \label{fig:subfield-montage}
\end{figure}


\FloatBarrier
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                                                                     %%%%%
%%%%%    RESULTS: Experiment 3, Application of \mb to the segmentation    %%%%%
%%%%%                       of schizophrenia patients                     %%%%%
%%%%%                                                                     %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Experiment 3 Results: Application to the segmentation of first episode
\\ \mbox{schizophrenia patients}}
 
In this experiment \mb is applied to a dataset of images of first episode
schizophrenia parients, using the Winterburn atlases and a template library of
21 subject images selected at random.  Expert manual whole hippocampal
segmentations are used as gold standards. 

\mb produces hippocampus segmentation volumes that are highly correlated with 
manual segmentation volumes (Figure \ref{fig:SZ-volumes}). 
\todo{p-value}

\begin{figure}
<<FEP-volumes,cache=FALSE,dependson="setup">>=
SZ_volumes=read.csv("data/SZ_volumes_by_method.csv", sep="\t")
casted = dcast(SZ_volumes, Subject + Label ~ Method)
lm = lm(MAGeT ~ Manual, casted)
ggplot(data=casted, aes(x = Manual, y = MAGeT)) + 
  geom_smooth(method="lm", formula=y~x) + 
  geom_point() + 
  geom_text(aes(x=3500, y=5000, label=lm_eqn(lm),hjust=0,size=1), parse=TRUE, data=data.frame()) +
  xlab(expression("Manual unilateral whole hippocampus volume " (mm^3))) + 
  ylab(expression("MAGeT unilateral whole hippocampus volume "  (mm^3))) + 
  scale_size_continuous(guide="none") 
@
  \caption{{\bf First Episode Schizophrenic Patients.} Comparison of total
  HC volumes for \mb against manually rated Hippocampal volumes}
  \label{fig:SZ-volumes}
\end{figure}

\FloatBarrier
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                                                                     %%%%%
%%%%%                           RESULTS                                   %%%%%
%%%%%                                                                     %%%%%
%%%%%         EXPERIMENT 4: Application of \mb to the segmentation        %%%%%
%%%%%                       of ADNI subjects                              %%%%%
%%%%%                                                                     %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Experiment 4 Results: Application to the segmentation of Alzheimer's
disease patients}

Based on the results from the ADNI1 Cross-Validation experiment, in this
experiment \mb was configured with a template library of 21 randomly
chosen subject images (7 from each disease class) and used majority vote label
fusion. The entire \adnidataset dataset was segmented by \mb and we 
now compare the resulting volumes with those obtained by manual segmentation (SNT), 
and other automated segmentation techniques (MAPER, FreeSurfer, and FSL).  Table
\ref{tab:ADN1-1.5T-Complete-1yr-Dataset-Segmentations} shows the total count of 
segmentations available, including a count of those which have failed a quality 
control inspection. Only those images which had segmentations from every method
are included in the following analysis (a total of
\Sexpr{length(totals.complete$RID)} images; Table 
\ref{tab:ADNI1-1.5T-Complete-1Yr-Dataset-Method-Totals}).
 
We find a close relationship in total bilateral hippocampal volume between
all methods and manually segmented volumes (Figure \ref{fig:ADNI-scr-volumes-plot}). 
Volumes are correlated with Pearson-r > 0.78 for all methods across disease categories.
Within disease categories (Figure \ref{fig:ADNI-scr-volumes-boxplot}),
\mb is consistently well correlated to manual volumes (Pearson-r > 0.85), but appears to 
slightly over-estimate the volume of the AD hippocampus. 

To investigate the level of agreement with manually segmented hippocampal volumes, 
we constructed Bland-Altman plots for each method (Figure \ref{fig:ADNI1-src-Bland-Altman}).  
As Bland \& Altman, 1985 \cite{Bland1986} noted, high 
correlation amongst measures of the same quantity does not necessarily 
imply agreement (as correlation can be driven by a large range in true values, 
for instance).  What is most striking in Figure \ref{fig:ADNI1-src-Bland-Altman}
is that all methods show an obvious proportional bias: FreeSurfer and FSL 
markedly under-estimate smaller hippocampi and over-estimate large hippocampi, 
whereas MAPER and \mb more conservatively show the reverse bias.  Additionally, 
all methods show a fixed bias, with FreeSurfer and FSL most dramatically 
over-estimating hippocampal volume by $2600mm^3$ and $2800mm^3$ on average, respectively, 
and MAPER and \mb within $250mm^3$ on average. 

Figure \ref{fig:ADNI-scr-subfields} shows a qualitative comparison of \mb and 
manual (SNT) hippocampal segmentations for 10 randomly selected subjects in 
each disease category, and illustrates some of the common errors found during 
visual inspection. Mostly frequently, we find \mb improperly includes the vestigial
hippocampal sulcus and, although not anatomically incorrect, \mb under-estimates 
the hippocampal body in comparison to the manual (SNT) segmentation.  

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ADNI1 1yr Complete Dataset Package Totals & Failures
%                        
<<ADNI1-scr-package-totals, echo=F, results="asis",cache=FALSE>>=
caption = paste(
  "Pass/fail quality control indicators were supplied with the FreeSurfer",
  "volumes downloaded from the ADNI website (we used the temporal lobe quality",
  "control indicator, TEMPQC). One of the authors (MP) performed visual",
  "quality inspection for MAGeT and FSL segmentations.", sep=" ")
latex(package_totals, file="", size="scriptsize", 
    caption = caption,
    title = "",
    label="tab:ADNI1-1.5T-Complete-1Yr-Dataset-Method-Totals")
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{figure}[h]
<<ADNI-scr-volumes-boxplot,dependson='ADNI-baseline-volumes-prep',cache=T,fig.width=7,fig.height=4>>=
melted = melt(totals.complete,measure.vars=c("FS", "FSL", "MAPER","MAGeT"),
              variable.name="Method", value.name="Volume")
correlations = ddply(melted, c("DX","Method"), function (df) {
  data.frame(
    pearson = cor(df$SNT, df$Volume)
  )
})

qplot(DX,value,data=melt(totals.complete,measure.vars=c("FS", "FSL", "MAPER","MAGeT","SNT")),
      colour=variable,geom="boxplot") + 
      geom_text(aes(y=-Inf,x=c(.7,.85,1,1.15, 1.7,1.85,2,2.15, 2.7,2.85,3,3.15), vjust=-5, label=round(pearson,2)), 
                colour = 'black', size=3, data=correlations) +
      xlab("Diagnosis") + 
      ylab(expression(paste("Bilateral whole hippocampal volume (", mm^3, ")"))) + 
      theme(legend.direction = "horizontal", legend.position = "bottom")
@
  \caption{Comparison of hippocampus volumes obtained by FreeSurfer (FS), FSL, 
  MAPER, \mb (MAGeT) and manual (SNT) by disease category.  Pearson correlation 
  with manual volumes are shown below each box-and-whisker.}
  \label{fig:ADNI-scr-volumes-boxplot}
\end{figure}

\begin{figure}[h]
<<ADNI-scr-volumes-plot,dependson='ADNI-baseline-volumes-prep',cache=T,fig.width=6,fig.height=4>>=
melted=melt(totals.complete, measure.vars=c("FS", "FSL", "MAPER","MAGeT"), 
            variable.name = "Method", value.name = "volume")

df = totals.complete

ggplot(data=melted, aes(x=SNT, y=volume, colour=Method)) + 
    geom_point() + 
    geom_smooth(method="lm") + 
    xlab(expression("Manual bilateral whole hippocampal volume " (mm^3))) + 
    ylab(expression("Automated bilateral whole hippocampal volume " (mm^3))) +
    annotate("text", y = c(3000,2500,2000,1500), x=Inf-100, size=3,
              label = c(paste("FS r=", round(cor(df$SNT, df$FS),2)),
                        paste("FSL r=", round(cor(df$SNT, df$FSL),2)),
                        paste("MAPER r=", round(cor(df$SNT, df$MAPER),2)),
                        paste("MAGeT r=", round(cor(df$SNT, df$MAGeT),2))),
              hjust=1.1,vjust=1.5) +
    theme(legend.direction = "horizontal", legend.position = "bottom")
@
  \caption{Comparison of hippocampus volumes obtained by FreeSurfer (FS), FSL, 
  MAPER, \mb (MAGeT) and manual (SNT). Pearson correlation with manual volumes
  are shown for each method.}
  \label{fig:ADNI-scr-volumes-plot}
\end{figure}
 
\begin{figure}
<<ADN1-src-Bland-Atlman, cache=TRUE, dependson='ADNI-baseline-volumes-prep', fig.width=6, fig.height=6>>=
melted=melt(totals.complete, measure.vars=c("FS", "FSL", "MAPER","MAGeT"), 
            variable.name = "method", value.name = "volume")
melted$diff = melted$SNT - melted$volume
melted$mean = ( melted$SNT + melted$volume ) / 2
limits = ddply(melted, c("method"), function (df) { 
  data.frame(
    y = mean(df$diff) + c(-1.96,0,2) * sd(df$diff) 
)}) 

ggplot(melted, aes(x= mean, y = diff, colour=DX)) + 
  facet_wrap( ~ method, nrow=2, scales="free") + 
  geom_point() +  
  geom_hline(aes(yintercept = y), linetype="dashed", colour="brown", data=limits) + 
  geom_text(aes(y = y, x=Inf, label=round(y,0)), colour="black", data = limits, hjust=1.1,vjust=-0.8, size=3) + 
  xlab('Mean of manual and automated total hippocampal volume') + 
  ylab('Difference between manual and automated total hippocampal volume') + 
  scale_y_continuous(breaks=seq(-10000,4000, 1000)) + 
  scale_x_continuous(breaks=seq(0,10000, 1000)) + 
  geom_smooth(method="lm", formula = y~x) + 
  theme(legend.direction = "horizontal", legend.position = "bottom")
@
  \caption{Bland-Altman plot comparing manual (SNT) and automated total hippocampal volumes 
  in the \adnidataset dataset.  The overall mean difference, and limits of 
  agreement ($\pm 1.96SD$) are shown by dashed horizontal lines.}
  \label{fig:ADNI-scr-Bland-Altman}
\end{figure}


\begin{figure}
  \begin{centering}
    \includegraphics[width=6in]{figure/ADNI1_SNT_MB_montage/montage.pdf}
  \end{centering}
  \caption{Manual and MAGeT segmentation results for 30 ADNI1 subjects (10
  subjects randomly selected from each disease category in the subject pool used
  in Experiment 1). Sagittal slices are shown for subject unlabelled T1-weighted
  anatomical image, SNT manual label (green), and \mb label (blue). Noted are
  examples of common segmentation idiosyncracies: 
  {\em (a)} over-estimation of hippocampal head and  
  {\em (b)} translated manual segmentation by SNT; 
  {\em (c)} under-estimation of hippocampal body and
  {\em (d)} improper inclusion of the vestigial hippocampal sulcus by \mb.}
  \label{fig:ADNI-scr-subfields}
\end{figure}

\FloatBarrier

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                Discussion
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Discussion}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Tabulation of segmentation accuracies of existing methods (ADNI)
%
<<ADNI1-literature, echo=F, results="asis",cache=FALSE>>=
caption = paste(
  "Survey of automated segmentation accuracy of the ADNI dataset",
  sep=" ")

tab = read.csv("data/ADNI-existing-work.csv")
tab$Notes <- NULL

adni_lit = subset(tab, Dataset=="ADNI")
adni_lit$Dataset <- NULL
other_lit = subset(tab, Dataset!="ADNI")
other_lit$Dataset <- NULL

latex(adni_lit, file="", 
      size="scriptsize",
      caption=caption, 
      rowname=NULL,
      col.just=c("p{1.5in}l","p{0.5in}","p{1.3in}","p{1.5in}"),
      title="")
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{verbatim}

Experiment 1: 
- address the absence of weighted-voting effects. 
  - hypothesis: the benefits of weighted voting only outweigh the resampling
    error effects when choosing from a large library.  In this experiment, the 
    template library (during weighted voting) consists of only 20 templates, so
    the most we could hope for is a "squashing" upwards of the curve towards 
    the 20-template limit (which is the same across all cases in this experiment).
  - we do see a slight "squashing" effect, with XCORR more strongly than NMI. 
    Perhaps in future experiments with larger template libraries, this could be
    explored further.
- Why don't we use STAPLE? What would we expect from STAPLE or other fusion methods? 
  - couldn't get STAPLE to work with our image formats
  - Idea: expect smoothness across range of templates (no even # dips, below)
  - perhaps more sophisticated fusion methods would boost results over majority 
    vote based techniques.

- why does MAGeT brain show a dip in average Kappa when using an even number
  templates. Does MA show this same pattern? (yes)
  - Hypothesis: our voting method is biased when breaking ties to choose the 
    label with the lowest numeric value.
  - If we compute the total number of labels fused (atlases * templates) then 
    both MB/MA perform worse when fusing an even number of labels. 

- we only show a +0.02 increase in mean Kappa over multi-atlas, and this is when
  using 1 atlas (which we know from Figure 2, is when we perform worst). Why does
  this increase justify the extra effort involved in MB? 
  - decrease in variability
  - we are comparing "true" averages (see above)... does this make our criteria 
    for a worthy improvement less strict? 
    

- how does MAGeT stack up, Kappa-wise, to other methods, in an absolute sense.
- because of the extensive cross-validation in experiment 1, we are very likely
  showing results that approach the true average of MB and MA on that dataset
  (i.e. our mid 0.8 range result is a mean across 69 subjects and 10 repetitions
  each).
- even with this caveat, do we think we do well enough?  i.e. other than parameter 
  tuning, to what extent does this experiment tell us about how MB would do in 
  practice. 

- effects we are seeing is not only averaging effects (Chakravarty et al. 2012). 

- take aways: as in other studies (Aljabar, Heckemann) we find that performance
  scales with the number of inputs (approx. log(n)), and that a large enough
  template library can boost performance with a small number of atlases. The use 
  of templates /can/ have a negative impact on performance (Figure 2), that is 
  balanced by the improvement of growing the template library.  Likely the negative
  impact on peformance is as a result of resampling/mislabelling error. In other 
  words, tuning MAGeT brain involves balancing the tension between an improvement 
  in peformance due to increase neuroanatomical capture and decreased peformance
  due to resampling error. 

Experiment 2: 
- describe resampling error during downsampling (essentially partial volume effect 
  due to averaging/majority vote in nearest neighbour selection)
- Why would some structures have greater downsampling error than others? (i.e. what
  is it about a structure that would make it especially prone to resampling error)
  - since error is discretised to whole voxels, smaller regions will show larger
    percent error
  - average unilateral volume (approx; mm3): 
     region   volume   downsampling error
     CA1      800            2%
     CA4/DG   600          -30%
     SR/SL/SM 700           30%
     Sibculum 350            0%
     CA2/3    200           15%

- observation: when downsampling error is small (<10 percent), MB error is larger, 
  and vice versa when downsampling error is large.  Could this a case where the 
  inevitable MAGeT resampling error outweighs the small downsampling error?
- observation: MAGeT produces similar volumes for the downsampled and BRAVO images
  which demonstrates reliability. Additionally, MB's error is in the same *direction*
  as the downsampling error except for SR/SL/SM
- for MB to show less error than resampling means that voting across templates is 
  in aggregate performing better than local nearest neighbour fitting. presumably 
  we'd see the same improvement with basic multiatlas as well.

- take away: MB produces subregion volumes that are comparable or better than
  resampling error, except for the CA2/3 where error is near 25 percent (but 
  even then resampling error is ~15%)

Experiment 3: 
- what is an "acceptable" r^2 value? 
- take away: MB has proven to be robust with atlases derived from three different
  segmentation protocols (SNT, Winterburn, and now Pruessner) on three different
  populations (older with AD progression; young and healthy; young and SZ). 
  
Experiment 4: 
- address the smaller difference in mean volume across disease classes. smaller 
  than every other method. 
  
- address the segmentation bias towards over-estimating smaller hippocampi, and 
  underestimating larger HC
  
- visual inspection/QC reveals MB segmentations are satisfactory (failure rate 
  is lower than the other methods (but we may be biased. :-). 
  
- take away: MB, with the Winterburn atlases, produces HC volumes more inline with
  SNT than FSL/FS.  Comparable to MAPER but with far fewer atlases required. 

\end{verbatim}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                               Conclusion 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion}

\section{Supplementary Materials}

\subsection{ADNI Manual Labels}
% The following blurb is taken (except for the first sentence) verbatim 
Semi-automated hippocampal volumetry was carried out using a commercially
available high dimensional brain mapping tool (Medtronic Surgical Navigation
Technologies, Louisville, CO), that has previously been validated and compared
to manual tracing of the hippocampus \citep{Hsu2002}. Measurement of hippocampal
volume is achieved first by placing manually 22 control points as local
landmarks for the hippocampus on the individual brain MRI data: one landmark at
the hippocampal head, one at the tail, and four per image (i.e., at the
superior, inferior, medial and lateral boundaries) on five equally spaced images
perpendicular to the long axis of the hippocampus. Second, fluid image
transformation is used to match the individual brains to a template brain
\citep{Christensen1997}. The pixels corresponding to the hippocampus are then
labeled and counted to obtain volumes. This method of hippocampal voluming has a
documented reliability of an intraclass coefficient better than .94
\citep{Hsu2002}.

\bibliographystyle{plainnat}
\bibliography{references}
\end{document}
