

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Sweave/Knitr init
<<setup, include=FALSE, cache=FALSE>>=
opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, 
    fig.align = 'center', tidy = FALSE, comment = NA, cache = TRUE)
library(ggplot2)
library(Hmisc)
library(reshape2)
library(ADNIMERGE)
library(plyr)
options(digits=3)
theme_set(theme_bw())
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass{article}
\usepackage[margin=1in]{geometry}
\usepackage{algorithm, color, algpseudocode, amsmath, url, geometry, ctable}
\usepackage[round,authoryear]{natbib}

%draft mode
\usepackage[colorlinks]{hyperref}
\usepackage[colorinlistoftodos, textwidth=4cm, shadow]{todonotes}
\usepackage[displaymath, tightpage]{preview}
\setlength{\marginparwidth}{1.2in}

%notes and TODO formatting
%\newcommand{\marginnote}[1]{\-\marginpar[\raggedleft\footnotesize #1]{\raggedright\footnotesize #1}}
%\newcommand{\comment}[1]{\begin{kframe}{\textcolor{red}{#1}}\end{kframe}}
%\newcommand{\todo}[1]{\comment{TODO #1}}
%\newcommand{\mc}[1]{\comment{MC: #1}}
\begin{document}

\title{Bootstrapping Multi-atlas Hippocampal Segmentation with MAGeT}
\author{Pipitone J., Winterburn J., Lerch J., Pruessner J., Lepage M., \\ 
Voineskos A., Chakravarty M.M., and \\ 
the Alzheimer's Disease Neuroimaging Initiative}
\maketitle

\begin{abstract}
Neuroimaging research often relies on automated anatomical segmentations of MR
images of the brain. Current multi-atlas based approaches provide accurate
segmentations of brain images by propagating manually derived segmentations of
specific neuroanatomical structures to unlabelled data. These approaches often
rely on a large number of such manually segmented atlases that take significant
time and expertise to produce. We present an algorithm for the automatic
segmentation of the hippocampus that minimizes the number of atlases needed
while still achieving similar accuracy to multi-atlas approaches.
\todo[inline]{finish}
\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                               INTRODUCTION
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

The hippocampus is of particular interest to many researchers because it is
implicated in forms of brain dysfunction such as Alzheimer's
disease\citep{Sabuncu2011} and schizophrenia\citep{Narr2004,Karnik-Henry2012},
and has functional significance in cognitive processes such as learning and
memory\citep{DenHeijer2012,Scoville2000}.  For many research questions
involving magnetic resonance imaging (MRI) data accurate identification of the
hippocampus and its subregions is a necessary first step to better understand
the individual neuroanatomy of subjects.  

Currently, the gold standard for neuroanatomical segmentation is manual
delineation by an expert human rater.  This is problematic for hippocampal
segmentation for several reasons.  First, manual segmentation takes a
significant investment of time and expertise \citep{Hammers2003} which may not
be readily available to researchers or clinicians.  Second, the amount of data
produced in neuroimaging experiments increasingly exceeds the capacity for
identification of specific neuroanatomical structures by an expert manual
rater.  Third, the true definition of hippocampal anatomy in MR images is
disputed \citep{Geuze2004}, as evidenced by efforts to create an unified
segmentation protocol \citep{Jack2011}.  

Compounding each of these problems is the significant neuroanatomical
variability in the hippocampus throughout the course of aging, maturation, and
neuropsychiatric disorders
\citep{Mouiha2011b,Sabuncu2011,Giedd1998,Gogtay2006,Narr2002}.  The result is that
existing hippocampal atlases available to a researcher may not accurately
represent neuroanatomy of a specific population under study.  Additionally, in
the course of a research or clinical study, it may be necessary to make
adjustments to hippocampal definition as a means of hypothesis testing.  For
example, Poppenk \citep{Poppenk2011} found that subdividing the hippocampus
into anterior and posterior regions resulted in a predictive relationship
between volume difference of those regions and recollection memory performance.
Making such modifications to a set of MRI data segmentations requires additional
manual effort. 

Fully-automated segmentation techniques require no human expertise beyond that
of initial setup or training. One broad class of automated approach is that of
the {\em model-based} approaches which employ models of anatomical feature
variation to constrain segmentations. In this paper we focus on a subclass known
as {\em multi-atlas} approaches which make use of a series of expertly segmented
MRIs (the atlas library) as models to guide the segmentation of a query
subject's MRI, and achieve some of the best automated hippocampal segmentation
accuracies to-date. 

The multi-atlas segmentation technique was pioneered by Heckemann et al. with
the MAPER algorithm \citep{Heckemann2006,Heckemann2011}. The basic strategy is as
follows. Each atlas image is fit a subject's neuroanatomy using nonlinear
registration techniques \citep{Collins1995,Klein2009}. This resulting nonlinear
transformation is then applied to the atlas labels to bring them into the
subject space.  Finally, a {\it label fusion} technique, such as voxel-wise
voting, is used to merge these labels into a definitive segmentation for the
subject. Typically, an atlas selection approach is used to improve accuracy by
only using labels from atlases that are most similar to a subject image
(cross-correlation of image intensities is a common similarity metric)
\citep{Aljabar2009}. 

% - Warfield2004: STAPLE as an alternative decision fusion technique?

Multi-atlas techniques have been applied very successfully to hippocampal
segmentation. Collins et al. found that with an atlas library of 80 atlas
images, the use of the ANIMAL nonlinear registration algorithm, the normalised
mutual information as similarity metric for atlas selection, and majority vote
for decision fusion they were able to achieve a mean Dice Kappa similarity score
(DSC) to manual labels of 0.886\citep{Collins2010}. The Alzheimer's Disease
Neuroimaging Initiative (ADNI) is a commonly used benchmarking dataset of MR
images of controls and patients with MCI or Alzheimer's (see Methods for more
information on the ADNI dataset).  Leung et al. tuned a multi-atlas  approach to
the segmentation of ADNI1 1 year dataset of images and using 55 atlases and the
STAPLE decision fusion method \citep{Warfield2004} achieved an mean DSC of 0.89
to the manual segmentations supplied with the ADNI data  \citep{Leung2010}. The
MAPER whole brain segmentation algorithm (described above), using 30 atlases,
achieved a mean DSC score of 0.889 on all ADNI1 baseline images
\citep{Heckemann2011}. In \citep{Lotjonen2012}, the authors use a proprietary
non-linear registration method based on intensity differences, and
post-processing step taking into account these intensity differences to tidy up
fused segmentations. Using images from the ADNI1 baseline dataset, they achieved
a mean DSC of 0.885 with 30 atlases. With the LEAP algorithm, Wolz et al.
explored an elegant modification to the basic strategy: the atlas library is
grown, beginning with a set of manually labelled atlases and successively
incorporating unlabelled subject images after being labelling using multi-atlas
techniques\citep{Wolz2010}.  The sequence in which subject images are labelled
is chosen so that the similarity between the atlas images and the target images
is minimised at each step, effectively allowing for deformations between very
dissimilar images to be broken up into sequences of smaller deformations.  With
an atlas library of 30 MR images, LEAP was used to segment the ADNI1 baseline
dataset, achieving a mean Dice score of 0.85 with manual segmentations.

While not purely nulti-atlas techniques, there are several important algorithms
for hippocampal segmentation that inform our approach. The popular FreeSurfer
application's whole brain segmentation algoritm uses a probabilistic atlas of
anatomical and tissue classes along with spatial constraints for class labels
encoded using a Markov random field model \citep{Fischl2002}. When segmenting
hippocampal subfields, FreeSurfer employs a Bayesian inference algorithm using a
probabilistic atlas of anatomical classes as a prior, and a likelihood model of
how those classes translate into MR image intensities, both trained on manual
segmentations of high resolution MR images \citep{Fischl2009}. Yushkevitch et
al. describe a semi-automated method for hippocampal subfield segmentation of
focal T2 images\citep{Yushkevitch2010}.  The unlabelled MR image must be
manually partitioned into 'head', 'body' and 'tail', and then multi-atlas
methods are used to segment the image.  Finally, an AdaBoost-based bias
correction classifier is trained on texture, spatial location, and intensities
of manual segmentations and is applied to fix mislabelled voxels.  
%  Chupin's use of shape-based priors 
%   - Mouiha2011b - Hippocampal atrophy rates in AD: compare SNT vs FreeSurfer
%     on ADNI
%

Aside from the algorithmic choices used in multi-atlas segmentation, it is
natural to ask about how the features of the atlases themselves impact the
resulting segmentations. As noted, by choosing atlases ranked most similar to a
subject image by voxel intensity profile segmentation accuracy is improved,
suggesting that neuroanatomical similarity plays a role\citep{Aljabar2009}.
Carmichael et al. explored this directly and found that when using only one
atlas the important factors leading to improved accuracy are that the atlas have
neuroanatomical features that match the subject, and that the atlas segmentation
use the same protocol as the gold-standard \citep{Carmichael2005}. Nestor et al.
found that hippocampal segmentation protocols that include more dorsal
white-matter and posterior anatomy tended to produce higher overlap and better
accuracy at distinguishing disease classes in the ADNI1 1 year dataset
\citep{Nestor2012}. These results suggest both atlas library neuroanatomy and
delineation protocol play a significant role in the resulting segmentation.

Considered along with our earlier discussion on the difficulty of producing
manual segmentations of MR images and the need for adaptable segmentation
definitions in order to conduct research, this presents a real problem of labour
and expertise when using existing multi-atlas segmentation methods which rely on
relatively large atlas libraries (typically between 30 and 80 atlases). Indeed,
it may be especially prohibitive to use these methods in situations where
producing a single atlas is challenging (e.g. histology-based atlases, or
atlases from very high resolution images). In this paper we address the problem
of producing accurate segmentations using small numbers of manually segmented
atlases. 

% MAGeT bootstrapping: tune the template library to your dataset, reduce the
% number of input atlases you need, with the upshot that with fewer atlases it's
% that much easier to change definitions in order to test hypothesis

Our algorith, called MAGeT brain ({\em M}ultiple {\em A}utomatically {\em
Ge}nerated {\em T}emplates), is an extension to the basic multi-atlas-based
segmentation schema\citep{Chakravarty2012}. Principally, we explore the
possibility of using a small atlas library to bootstrap a much larger
\emph{template library} composed of images taken from the target population.
The template library is then used to segment the subjects in a similar fashion
to basic multi-atlas segmentation: by label propagation and label fusion. The
intuition driving this approach is that by generating a template library we
leverage the unique neuroanatomy of subject population on hand to initialize the
segmentation process and improve accuracy over direct propagation from the atlas
library to unlabelled subjects while also using fewer manually segmented
atlases. 

The insight of generating a template library is not new.  Heckemann et al.
compared ``indirect'' segmentation -- taking a single atlas and propagating the
labels to intermediate subjects before fusing them in a target image space -- to
multi-atlas segmentation and found that the indirect approach performed worse
\citep{Heckemann2006}. In this paper we continue the same line of investigation
but explore the performance when using multiple atlases as well as the effect of
different registration and fusion methods.

The LEAP algorithm \citep{Wolz2010}, described above, is another example of
indirect segmentation previously explored.  LEAP proceeds by iteratively
segmenting unlabelled images most similar to the atlas library images and then
incorporating the labelled images into the atlas library for future iterations.
The novelty explored in our current work is to demonstrate the viability of
achieving comparable segmentation accuracy using the basic multi-atlas schema
and using significantly fewer manually created atlases.

In previous work \citep{Chakravarty2012}, we applied MAGeT brain to segmentation
of the human striatum, globus pallidus, and thalamus using a single
histologically-derived atlas. The contribution of the present work is to extend
our approach to the human hippocampus and perform a rigorous validation. We
first conduct an intensive cross-validation of MAGeT on a pool of 69 MRIs from
the ADNI database, comparing the performance of MAGeT against basic multi-atlas
segmentation using a range of atlas and template library sizes, registration and
fusion methods.  We then compare MAGeT segmentations of the entire ADNI
screening dataset with those of established automated and manual segmentation
techniques.  Finally, we compare MAGeT segmentations to those of manual
segmentations from a dataset of first episode schizophrenic patient MRIs. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                               METHODS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Methods}


%%%%%                     MAGeT Brain Algorithm                            %%%%%

\subsection{MAGeT Brain Algorithm}
\todo{Make sure we explain what MAGeT stands for}
\todo{reference Chakravarty2012}

In this paper, we use the term {\it atlas} to mean any manually segmented MR
image, and the term {\it atlas library} to mean a set of such images.  We use
the term {\it template} to refer to any MR image, and associated labelling,
used to segment another image, and the term {\it template library} to refer to
a set of such images.  An atlas library may be used as a template library but,
as we will discuss, a template library may also be composed of images with
computer generated labellings. 

The simplest form of multi-atlas segmentation combines labellings derived from
several atlases by way of label fusion \citep{Heckemann2006}.  We will refer to
this as {\em basic multi-atlas segmentation}.  The primary steps are as
follow are: (1) an atlas library and unlabelled MR images are given as input,
(2) each atlas image is nonlinearly registered to each unlabelled image, (4)
each atlas' labels are propagated via the resulting transformations to the
unlabelled image space, and (5) the resulting labels are fused to produce a
single, definitive segmentation. The particular registration and voting method
used are left unspecified.

The segmentation approach we propose is best understood as an extension of
multi-atlas segmentation.  MAGeT brain adds a preliminary stage to this process
in which the template library is constructed rather than given as input.  As
before, MAGeT brain accepts an atlas library and unlabelled MR subject images as
input.  Template library images are selected from subject images.  The choice of
subjects used in the template library can be made to reflect the neuroanatomy or
demographics of the subject set as a whole (for instance, by sampling equally
from cases and controls).  

To create the template library, labels from each atlas image are propagated to
each template library image via the transformation resulting from a non-linear
registration between pair of images. As a result, each template library image
has a label from each atlas. Basic multi-atlas segmentation is then used to
produce segmentations for the entire set of unlabelled images (including those
images used in the template library). Figure \ref{alg:MAGeT} describes the MAGeT
brain algorithm in pseudocode.  Source code can be found at
\url{http://github.com/pipitone/MAGeTbrain}.

\begin{algorithm}
  \scriptsize
  \caption{Pseudocode for the MAGeT Brain algorithm}
  \label{alg:MAGeT}
  \begin{algorithmic}
    \Function{BasicMultiAtlasSegmentation}{Templates, Subjects}
      \ForAll{$subject$}
        \ForAll{$template$}
          \State propagate all labels for template to subject space
          \State store subject labels
        \EndFor
        \State fuse subject labels
      \EndFor
    \EndFunction
    \\
    \Function {MAGeTBrain}{Subjects, Atlases, n}
      \For{$i = 1 \to n$}
        \State choose a subject to be used as a template
        \State propagate labels from each atlas to template space
        \State store the template with all of its labels
      \EndFor
      \State MultiAtlas(Templates, Subjects)
    \EndFunction
  \end{algorithmic}
\end{algorithm}


\begin{figure}[h]
  \centering
  \includegraphics[width=0.5\textwidth]{figure/MAGeT-figure.png}
  \caption{Diagram of the MAGeT Brain algorithm \label{fig:MAGeT-diagram}}
\end{figure}

%%%%%                             Subjects                                 %%%%%

\subsection{Subjects}

\subsubsection{ADNI1 1.5T Screening Dataset}
Clinical, demographic and pre-processed T1-weighted MRI used in this paper were
downloaded by the authors from the ADNI1 database (adni.loni.ucla.edu) between
March 2012 and August 2012. The image dataset download was the "ADNI1:Screening
1.5T" standardized dataset available from ADNI
\footnote{
 \url{http://adni.loni.ucla.edu/methods/mri-analysis/adni-standardized-data/}}
\citep{Wyman2012}. This image collection contains uniformly preprocessed images
which have been designated to be the "best" after quality control.  All images
were acquired using 1.5T scanners (General Electric Healthcare, Philips Medical
Systems or Siemens Medical Solutions) at multiple sites using the protocol
described in \citep{Jack2008a}.  Representative 1.5T imaging parameters were TR
= 2400ms, TI = 1000ms, TE = 3.5ms, flip angle = $8{\circ}$, field of view = 240
x 240mm, a 192 x 192 x 166 matrix (x, y, and z directions) yielding a voxel
resolution of 1.25 x 1.25 x 1.2 $mm^3$. Clinical and demographic data are shown
in table \ref{tab:ADNI1_1.5T_Screening_Dataset_Demographics}. 

For a subset of ADNI1 images, labels of the left and right hippocampi are
available (herein refered to as SNT labels).  Semi-automated hippocampal
volumetry was carried out using a commercially available high dimensional brain
mapping tool (Medtronic Surgical Navigation Technologies, Louisville, CO), that
has previously been validated and compared to manual tracing of the hippocampus
\citep{Hsu2002}. Measurement of hippocampal volume is achieved first by placing
manually 22 control points as local landmarks for the hippocampus on the
individual brain MRI data: one landmark at the hippocampal head, one at the
tail, and four per image (i.e., at the superior, inferior, medial and lateral
boundaries) on five equally spaced images perpendicular to the long axis of the
hippocampus. Second, fluid image transformation is used to match the individual
brains to a template brain \citep{Christensen1997}. The pixels corresponding to
the hippocampus are then labeled and counted to obtain volumes. This method of
hippocampal voluming has a documented reliability of an intraclass coefficient
better than .94 \citep{Hsu2002}.

%Representative 3T image parameters were TR = 2300ms, TI = 900ms, TE = 3.0ms,
%flip angle = $8{\circ}$, field of view = 256 x 240mm, a 256 x 256 x 166 matrix
%(x, y, and z directions) yielding a voxel resolution of 1.00 x 1.00 x 1.2
%$mm^3$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ADNI1 Screening Dataset Demographics Table                                  %
%                                                                             %
<<ADNI1-screening-demographics, echo=F, results="asis",cache=FALSE>>=
# RID < 2000 ensures only ADNI1 patients
tab <- summary(DX.bl ~ AGE + PTGENDER + PTEDUCAT + PTETHCAT + CDRSB + ADAS13 +
               MMSE, data = adnimerge, subset = VISCODE == 'bl' & RID < 2000,   
               method = "reverse", test=FALSE, overall=TRUE)
latex(tab, file="", size="scriptsize", 
    caption="ADNI1 1.5T Screening dataset demographics",
    title="tab:ADN1_1.5T_Screening_Dataset_Demographics")
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%





\subsubsection{SZ First Episode Patients}

\todo{include image characteristics}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% First Episode SZ Demographics Table                                         %
%                                                                             %
<<FEP-SZ-demographics, echo=F, results="asis",cache=FALSE>>=
fep_sz_demographics = read.csv("data/SZ_demographics.csv", na.strings=c("","."))
fep_sz_demographics = subset(fep_sz_demographics, Anon <= 81)
tab <- summary(DX ~ Age + Gender + Handedness + Education + SES + FSIQ,
               data=fep_sz_demographics, method = "reverse", test = FALSE)
latex(tab, file="", size="scriptsize", ctable=FALSE,
      caption="Schizophrenia First Episode Patient Demographics",
      title="tab:SZFEP_Demographics")
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%                       Image pre-processing                           %%%%%

\subsection{Image pre-processing}

Before images were registered, the N3 algorithm \citep{Sled1998} is first used
to minimize the intensity nonuniformity in each of the atlases and unlabeled
subject images.   


%%%%%                       Registration Methods                           %%%%%

\subsection{Registration}

\subsubsection{Automatic Normalization and Image Matching and Anatomical
Labeling (ANIMAL)}

The ANIMAL algorithm carries out image registration is in two phases. In the
first, a 12-parameter linear transformation (3 translations, rotations, scales,
shears) is estimated between images using an algorithm that maximizes the
correlation between blurred MR intensities and gradient magnitude over the whole
brain \citep{Collins}. In the second phase, nonlinear registration is completed
using the ANIMAL algorithm \citep{Collins1995}: an iterative procedure that
estimates a 3D deformation field between two MR images. At first, large
deformations are estimated using blurred version of the input data. These larger
deformations are then input to subsequent steps where the fit is refined by
estimating smaller deformations on data blurred with a Gaussian kernel with a
smaller FWHM. The final transformation is a set of local translations defined on
a bed of equally spaced nodes that were estimated through the optimization of
the correlation coefficient.  For the purposes of this work we used the
regularization parameters optimized in Robbins et al. \citep{Robbins2004},
displayed in table \ref{tab:ANIMAL_params}. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ANIMAL parameters                                                           %
%                                                                             %
\begin{table*}[!tbp]
\scriptsize
\caption{ANIMAL Registration Parameters\label{tab:ANIMAL_params}} 
\begin{center}
\begin{tabular}{l | c c c}
\hline 
Parameters        & Stage 1 & Stage 2 & Stage 3  \tabularnewline
\hline 
Model Blur (FWHM) &   8     &    8    &   4      \tabularnewline
Input Blur (FWHM) &   8     &    8    &   4      \tabularnewline
Iterations        &   30    &    30   &   10     \tabularnewline
Step              &   8x8x8 &  4x4x4  &   2x2x2  \tabularnewline
Sub-Lattice       &   6     &    6    &   6      \tabularnewline
Lattice Diameter  &24x24x24 &12x12x12 & 6x6x6    \tabularnewline
\hline
\end{tabular}
\end{center}
\end{table*}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Automatic Normalization Tools (ANTS)}

ANTs is a diffeomorphic registration algorithm which provides great flexibility
over the choice of transformation model, objective function, and the consistency
of the final transformation. The transformation is estimated in a hierarchical
fashion where the MRI data is subsampled, allowing large deformations to be
estimated and successively refined at later hierarchical stages (where the data
is subsampled to a finer grid). The deformation field and the objective function
are regularized with a Gaussian kernel at each level of the hierarchy. The ANTs
algorithm is freely available \url{http://www.picsl.upenn.edu/ANTS/}. We used an
implementation of the ANTS algorithm compatible with the MINC data format,
mincANTS \url{https://github.com/vfonov/mincANTS}.

We used the following command line when running the ANTS command, 
{\small
\begin{verbatim}
  mincANTS 3 -m PR[target_file.mnc,source_file.mnc,1,4] 
   --number-of-affine-iterations 10000x10000x10000x10000x10000 
   --affine-gradient-descent-option 0.5x0.95x1.e-4x1.e-4
   --use-Histogram-Matching --MI-option 32x16000
   -r Gauss[3,0] -t SyN[0.5] -i 100x100x100x20
   -o transformation.xfm
 \end{verbatim}
}
These settings were adapted from the "reasonable starting point" given in the
ANTS manual 
\footnote{\url{https://sourceforge.net/projects/advants/files/Documentation/}}.



%%%%%                           Label Fusion                               %%%%%

\subsection{Label Fusion}

Label fusion is a term given to the process of combining the information from
several candidate labellings for an MR image into a single labelling.  In this
paper we explore the benefits of three different fusion methods. 

\subsubsection{Voxel-wise Majority Vote}

Labels are propagated from all template library images to a subject.  Each
output voxel is given the most frequent label at that voxel location amongst
all candidate labellings.  Ties are broken arbitrarily.

\subsubsection{Cross-correlation Weighted Majority Vote}

An optimal combination of subjects from the template library has previously been
shown to improve segmentation accuracy \citep{Aljabar2009,Collins2010}.  In this
method, each template library image is ranked in similarity to each unlabelled 
image by the normalized cross-correlation (CC) of image intensities after linear
registration, over a region of interest (ROI) generously encompassing the 
hippocampus.  Only the top ranked template library image labels are used in a
voxel-wise majority vote. The ROI is heuristically defined as the extent of all
atlas labels after linear registration to the template, dilated by three voxels
\citep{Chakravarty2012}.  The number of top ranked template library image labels
is a configurable parameter.

The {\tt xcorr\_vol} utility from the ANIMAL toolkit is used to calculate the
cross-correlation similarity measure.  
 
\subsubsection{Normalised Mutual Information Weighted Majority Vote}
 
This method is similar to cross-correlation weighted voting except that image
similarity is calculated by the normalised mutual information score over the
region of interest\citep{Studholme2001}.  The {\tt itk\_similarity} utility from
the EZMinc toolkit\footnote{\url{https://github.com/vfonov/EZminc}} is used to
calculate the normalised mutual information measure between to images.

%%%%%                        Overlap Measure                               %%%%%

\subsection{Overlap Measure}

The agreement between two segmentations can assessed using the Dice Similarity
Coefficient (DSC):

\begin{equation*} 
DSC=\frac{2|A \cap B|}{|A| + |B|}
\end{equation*}

where $A$ and $B$ are the regions being compared, and the cardinality is the
volume measured in voxels. Using this measure we can compare an automatically
generated segmentation to a gold-standard segmentation.

%%%%%
%%%%%                            Experiments                               %%%%%
%%%%%
\subsection{Experiments}

Experiments were performed to assess the performance of MAGeT brain with various 
parameter settings as well as on diverse datasets.  In each experiment we contrast 
the performance of MAGeT brain with that standard single- and multi-atlas 
segmentations derived from the same atlas library. 

%%%%%
%%%%%                 Experiments: ADNI-1 cross-validationn               %%%%%
%%%%%
\subsubsection{ADNI-1 cross-validation}

To test the accuracy of the MAGeT brain algorithm with different parameter 
settings, repeated random sub-sampling cross-validation (RRSCV) was performed
on a subset of the ADNI-1 dataset.

{\bf Dataset evaluated.} 69 1.5T images were randomly selected from the 
{\em ADNI1:Screening 1.5T} standardized dataset.  Demographics for this subset 
are shown in Table \ref{tab:ADNI1_xvalidation_demographics}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ADNI1 X-Validation Dataset Demographics Table
%
<<ADNI-69-demographics, echo=F, results="asis",cache=FALSE>>=
adni_69_RIDs = c("295","413","619","685","729","782","938","954",
                 "1018","1155","907","981","222","324","448","546",
                 "553","572","602","610","814","1341","675","681",
                 "731","1130","41","68","70","101","249","293","316",
                 "414","698","1206","1222","1339","751","1030","3",
                 "5","10","16","22","53","168","183","241","1205",
                 "328","1095","991","213","159","337","343","642",
                 "753","1109","1217","29","56","1188","1293","149",
                 "382","431","1202")
tab <- summary(DX.bl ~ AGE + PTGENDER + PTEDUCAT + PTETHCAT + CDRSB + ADAS13 +
               MMSE, data = adnimerge, subset = VISCODE == 'bl' & RID %in%
               adni_69_RIDs, method = "reverse", test=FALSE, overall=TRUE)

latex(tab, file="", size="scriptsize",landscape=FALSE, ctable=FALSE,
      caption="ADNI-1 cross-validation subset demographics", 
      title="tab:ADNI1_xvalidation_demographics")
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

{\bf Atlas and template libary.}  Atlases consisted of images taken from the
dataset, with corresponding manual labels provided by SNT.  Atlas library size
was varied from 3 to 9 images.  The remaining images were segmented, with the
template library size varying from 3 to 20 images.  Template library images were
selected randomly from the images to be segmented. 

{\bf Registration method.}  Both the ANTS and ANIMAL registration methods were
used.


{\bf Label fusion.} Majority vote, cross-correlation weighted majority vote, and
Normalized Mutual Information weighted majority vote are used.  With the
weighted majority vote fusion methods, the number of top labels used in the
fusion was varied from 3 to 20 images.

{\bf Evaluation.}  Repeated random sub-sampling cross-validation (RRSCV)
consists of repeated trials in which items from the dataset are randomly
assigned to a training set or validation set. In each trial, performance on the
validation set is measured, and then averaged across all trials. 

We performed RRSCV on each combination of parameters listed above: atlas library
size, template library size, registration method, and label fusion method.  We
performed 10 trials per parameter combination.  In each validation trial, the
training set consisted of the images used as atlases, and the validation set
consisted of the images to be segmented. The MAGeT brain algorithm and the basic
multi-atlas segmentation procedure were applied to segment the images in the
validation set.  Additionally, in each trial, the single-atlas segmentation was
obtained for each atlas-template.  

The gold-standard for the segmentation accuracy of images in the validation set
was the SNT manual labels.

\todo{ show off the number of registrations/comparisions we did}


%%%%%
%%%%%               Experiments: ADNI-1 Screening Validation               %%%%%
%%%%%
\subsubsection{ADNI-1 Screening Validation}
\todo{comparison across field strengths, a la Heckemann2011?}
To test the accuracy of MAGeT brain on a real-world task we segment the entire
ADNI-1 dataset using an atlas set that is not representative of the subject set.

{\bf Dataset evaluated.} All images from the {\em ADNI1:Screening 1.5T} 
standardized dataset.

{\bf Atlas and template libary.} The atlas library consisted of the entire 
Winterburn atlas set.  The Winterburn atlases are digital segmentations of the
hippocampus in five in-vivo 300u isotropic T1-weighted MR scans, and include 
subfield segmentations for the cornus ammonis (CA) 1, CA4, dentate gyrus, 
subiculum, and CA 2 and 3 combined. Subjects in the Winterburn atlases range in 
age from 29-57 years (mean age of 37), and include two males and three females.  

The template library consisted of 21 randomly selected images from the ADNI1 
data dataset (7 healthy, MCI and AD subjects).  

{\bf Registration method.} ANTS, as it performed best in the cross-validation
experiment. 

\todo{okay to reference results whilst still in Methods?}

{\bf Label fusion.} Majority vote, as it is simpliest to run and performed 
equally well in cross-validation experiment.

{\bf Evaluation.}

Since hippocampal segmentation protocols differ between the ADNI labels and
Winterburn atlases, this poses a problem for direct similarity comparisons
between labels produced by MAGeT brain and the ADNI labels.  

\todo{explain why we did(n't) resegment the ADNI images with the low-res
protocol and compare directly like that.} 

To evaluate the performance of MAGeT brain, we correlate our segmentation
volumes with manual segmentation volumes, as well as with hippocampal volumes
of established automated segmentation methods.

Additionally, we compared classification accuracy of subjects
by diagnosis based on hippocampal volume using both the SMT labels and our
produced labels.  

\todo{Include a description of validation process.. Note that we could use rms
{\tt validate} or t-test: contrast with QDA or LDA (Coupe 2011) used in LOOCV,
with adni/our segmentations}

\todo{Also consider self-consistency (i.e. Kappa of same subject at different
field strengths) a la Heckemann2011}

\todo{Also: group differences, expecting separation}

%%%%%
%%%%%          Experiments: SZ First Episode Patient Validation           %%%%%
%%%%%
\subsubsection{SZ First Episode Patient Validation}

{\bf Dataset evaluated.} To validate that MAGeT performance generalises to other
diseases, we measure the performance using the best parameter settings previous
found, on a dataset consiting of first episode schizophrenia patients.
\todo{Refer to the FEP description above... or just include it here}.
 
{\bf Atlas and template libary.} - two different atlas sets: a manual
hippocampal segmentation of patients, and Winterburn atlas set.  

{\bf Registration method.} ANTS.

{\bf Label fusion.} Majority vote.

{\bf Evaluation.} We validate the FEP-atlas segmentations using Dice's Kappa,
and the Winterburn-atlas segmentations by correlating volumes. 


%%%%%
%%%%%              Experiments: Winterburn Atlases Validation              %%%%%
%%%%%
\subsubsection{Winterburn Atlases Validation}
{\bf Dataset evaluated.} - T1 BRAVO scans of the same subjects included in the 
Winterburn atlas set.  These scans are taken within .... weeks of the scans for 
the Winterburn atlases.

{\bf Atlas and template libary.} - Atlas library is Winterburn T1 atlases.  
Template library consists of all five T1 BRAVOs, plus 15 T1 healthy control images.

{\bf Registration method.} ANTS

{\bf Label fusion.} Majority vote.

{\bf Evaluation.}  - Leave one out cross-validation (LOOCV) in which all five
subjects are segmented in separate runs of MAGeT brain.  In each run, the subject
to be segmented is excluded from the Atlas library (so only four atlases are used).

Segmentation accuracy is judged by difference in hippocampal volume.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                               Results
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Results}

%%%%%
%%%%%                  Results: ADNI-1 cross-validationn                   %%%%%
%%%%%
\subsection{ADNI-1 Cross-Validation}

- find significant improvement over multi-atlas performed with the same
  parameters. Also, find smoothed performance is monotonically increasing but
  asymptotic in size of both template and atlas library, with peak performance
  reached after 15 templates. 
  
\todo{Can we statistically capture what "peak" performance is?  Something like,
the point at which gains become statistically insignificant?}

\begin{figure}
<<ADNI1_cross_validation_means, cache=TRUE, fig=TRUE>>=
t_data       = read.csv(file='data/a2a_tracc_results_2012_08_30.csv')
a_data       = read.csv(file='data/a2a_ants_results_2012_08_30.csv')

t_multiatlas = read.csv(file='data/a2a_tracc_multiatlas_2012_08_14.csv')
a_multiatlas = read.csv(file='data/a2a_ants_multiatlas_2012_08_14.csv')
t_ma_means   = aggregate( k ~ num_atlases , data=t_multiatlas, mean)
a_ma_means   = aggregate( k ~ num_atlases , data=a_multiatlas, mean)

# add registration method to data frames (before joining)
t_data       = cbind(t_data, reg_method = "ANIMAL")
a_data       = cbind(a_data, reg_method = "ANTS")

# add column with kappa - multiatlas mean
# num_atlases - 2 is a cheap trick to perform the necessary lookup into the ma_means tables
t_data$k_minus_ma = t_data$k - t_ma_means[ t_data$num_atlases - 2, 2 ]
a_data$k_minus_ma = a_data$k - a_ma_means[ a_data$num_atlases - 2, 2 ]

all_data     = rbind(t_data,a_data)

# use top_n as the number of templates for weighted voting schemes
all_data[ all_data$method != "majvote", ]$num_templates = all_data[ all_data$method != "majvote", ]$top_n

t_naive      = read.csv(file='data/a2a_tracc_naive.csv')
a_naive      = read.csv(file='data/a2a_ants_naive_2012_08_30.csv')
t_mean_naive = mean(t_naive$k)
a_mean_naive = mean(a_naive$k)
df_naive     = data.frame(
                value = c(rep(t_mean_naive,3),rep(a_mean_naive,3)),
                method = rep(c("majvote", "nmi", "xcorr"),2), 
                reg_method = c(rep("ANIMAL",3),rep("ANTS",3)))

method_labels <- list("Majority Vote" = "majvote", "NMI Vote" = "nmi", "Cross-correlation Vote" = "xcorr")
levels(all_data$method) <- method_labels
levels(df_naive$method) <- method_labels

ggplot(all_data, aes(x=num_templates, y=k, colour=as.factor(num_atlases))) + 
  facet_grid(method ~ reg_method) + 
  geom_smooth() + 
  geom_hline(data = df_naive, aes(yintercept = value, linetype="dashed")) + 
  scale_colour_hue(name="Atlases") +
  xlab( "Number of Templates" ) + ylab( "Mean Kappa" ) 
@
  \caption{Comparison of MAGeT performance on ADNI-1 subset.  Smoothing line
  fitted using GAM (generalised additive model) from R with defaults from
  ggplot2 (formula: y ~ s(x, bs = "cs"))}
  \label{ADNI1_cross_validation_means}
\end{figure}

\begin{figure}
<<ADN1-cross-validation-MA-difference, cache=TRUE, fig=TRUE>>=
ggplot(all_data, aes(x=num_templates, y=k_minus_ma, colour=as.factor(num_atlases))) + 
  facet_grid(method ~ reg_method) + 
  geom_smooth() + 
  scale_colour_hue(name="Atlases") +
  xlab( "Number of Templates" ) + 
  ylab( "Difference in mean Kappa between voting method and multiatlas" )
@
  \caption{Difference in mean Kappa between MAGeT brain and multi-atlas}
  \label{ADNI1_cross_validation_MA_difference}
\end{figure}



<<a2a_multiatlas_means, results="asis",cache=FALSE>>=
latex(merge(a_ma_means, t_ma_means, by="num_atlases"),
colheads=c("Atlases", "ANTS", "ANIMAL"), file="", dec=2,
	caption="Multi-atlas means")
@

%\begin{table}
%    \begin{tabular}{c|c|c}
%        Number of Atlases & ANIMAL Kappa (Jaccard) & ANTS Kappa (Jaccard) \\ \hline
%        3                 & 0.76 (0.63)             & 0.80 (0.69)          \\ 
%        4                 & 0.75 (0.62)             & 0.79 (0.67)          \\ 
%        5                 & 0.79 (0.66)             & 0.82 (0.71)          \\ 
%        6                 & 0.78 (0.65)             & 0.82 (0.70)          \\ 
%        7                 & 0.80 (0.67)             & 0.83 (0.72)          \\ 
%        8                 & 0.79 (0.67)             & 0.83 (0.72)          \\ 
%        9                 & 0.80 (0.68)             & 0.84 (0.73)          \\
%    \end{tabular}
%\end{table}

Ideas:
\begin{itemize}
\item more atlases -> better performance
\item  larger template library -> better performance, but tails off around 10-15 templates
\item  no significant difference between majority or weighted vote methods (haven???t tested this statistically though). 
\item  consistently performs better than average naive performance by XXX
\item  using ANTS, with a large enough template library (>12) MAGeT brain performs
  better than the average multi-atlas approach with the same number of atlases.
  using ANIMAL, 5 or more atlases needed before boost seen. 
\item  more atlases -> smaller template library required to improve on average multi-atlas performance
\item  discuss variance?  best/worst case? --how often do we expect random template library selection to work decently
\end{itemize}

\todo{show cost (in registrations) / benefit tradec off graph:  show number of
registrations per Kappa?  or hours of manual labour per Kappa?)}

%%%%%
%%%%%                  Results: ADNI-1 Screening Validation               %%%%%
%%%%%
\subsection{ADNI-1 Screen Validation}


Ideas: 
\begin{itemize}
\item  A2A shows that if atlas population strongly(?) represents subject set
variability, then free choice from atlas population will produce improvements
(we know this b/c of extensive validation trials). 
\item  what about in the case where atlas population doesn???t strongly
represent subject set variability (e.g. a priori atlas set)?  then, we can use
atlas selection to refine atlas set? 
\end{itemize}

\todo{Kappa against our manual rater is low... explain that}

<<ADNI-baseline-volumes-prep,echo=F,cache=T>>=
yr1   = read.csv("data/ADNI_baseline_volumes/ADNI1_Complete_1Yr_1.5T_11_15_2012.csv")
mb    = read.csv("data/ADNI_baseline_volumes/ADNI1_1.5T_MAGeT_volumes.csv")
maper = read.csv("data/ADNI_baseline_volumes/MAPER_volumes.csv")
snt   = read.csv("data/ADNI_baseline_volumes/UCSFSNTVOL.csv")
ucsd  = read.csv("data/ADNI_baseline_volumes/UCSDVOL.csv")
fs    = read.csv("data/ADNI_baseline_volumes/UCSFFSX_02_15_12.csv")
fsl   = read.csv("data/ADNI_baseline_volumes/ADNI1_1.5T_FSLFIRST_volumes.csv")

# recode VISCODE
viscode_levels = list("bl"=1,"bl"=2, "m06"=3,"m12"=4)
yr1$VISCODE <- as.factor(yr1$Visit)
levels(yr1$VISCODE) <-viscode_levels

yr1$Scaled_2 <- grepl("Scaled_2", yr1$Description)

#TODO: include Scaled_2? 
subjects = subset(yr1, VISCODE == 'bl' & Scaled_2 == FALSE)

# fetch just the columns we need, and do a little renaming
mb_pruned     = data.frame(MAGeT_L = mb$Left_Hippo, MAGeT_R = mb$Right_Hippo, Source = mb$SourceImageID)
maper_pruned  = data.frame(MAPER_L = maper$Left_Hippo, MAPER_R = maper$Right_Hippo, Source = maper$SourceImageID)
snt_pruned    = data.frame(SNT_L = snt$LEFTHIPPO, SNT_R = snt$RIGHTHIPPO, Source = snt$IMAGEUID)
ucsd_pruned   = data.frame(RID=ucsd$RID, VISCODE=ucsd$VISCODE, UCSD_L=ucsd$LHIPPOC, UCSD_R=ucsd$RHIPPOC)
fs_pruned     = subset(fs, TEMPQC != "Fail")
fs_pruned     = data.frame(FS_L=fs_pruned$ST29SV, FS_R=fs_pruned$ST88SV, Source = fs_pruned$IMAGEUID)
fsl_pruned    = data.frame(FSL_L=fsl$X17, FSL_R=fsl$X53, Source=fsl$Source)

# diagnoses
dx = adnimerge[c("DX.bl", "RID", "VISCODE")]

# Now create one data.frame with all the yr1 volume data we have from each datasource
combined = merge(subjects, mb_pruned   , by.x="Image.Data.ID", by.y="Source", all.x=TRUE)
combined = merge(combined, maper_pruned, by.x="Image.Data.ID", by.y="Source", all.x=TRUE)  # only Baseline
combined = merge(combined, snt_pruned  , by.x="Image.Data.ID", by.y="Source", all.x=TRUE)
combined = merge(combined, ucsd_pruned , by=c("RID", "VISCODE"), all.x =TRUE)              # TODO: this a unique key?
combined = merge(combined, fs_pruned   , by.x="Image.Data.ID", by.y="Source", all.x=TRUE)
combined = merge(combined, fsl_pruned  , by.x="Image.Data.ID", by.y="Source", all.x=TRUE)
combined = merge(combined, dx          , by=c("RID","VISCODE"), all.x=TRUE)

attach(combined)
vols = data.frame(RID = RID, VISCODE = VISCODE, DX = DX.bl,
                  MAGeT = MAGeT_L + MAGeT_R, 
                  MAPER = MAPER_L + MAPER_R, 
                  SNT   = SNT_L + SNT_R, 
                  UCSD  = UCSD_L + UCSD_R,
                  FS    = FS_L + FS_R, 
                  FSL   = FSL_L + FSL_R)
@

\begin{figure}[h]
<<ADNI-baseline-volumes-boxplot,echo=F,fig=T, fig.align='center',dependson='ADNI-baseline-volumes-prep',cache=T>>=
totals = vols
qplot(DX,value,data=melt(totals,measure.vars=c("FS", "FSL","UCSD", "MAPER","MAGeT","SNT"),na.rm=T),
      colour=variable,geom="boxplot") + 
        xlab("Diagnosis") + ylab("Total Hippocampal Volume (mm3)")

@
  \caption{Comparison of HC volumes by FreeSurfer (FSF), MAGeT brain (MAGeT), MAPER, and manual (SNT).}
  \label{ADNI-baseline-volumes-boxplot}
\end{figure}

\begin{figure}[h]
<<ADNI-baseline-volumes-plot,echo=F,fig=T, fig.align='center',dependson='ADNI-baseline-volumes-boxplot',cache=T>>=
by_snt_volumes = melt(totals, measure.vars=c("FSL","MAPER","MAGeT", "FS", "UCSD"))
fsl=subset(by_snt_volumes, variable=="FSL")
maper=subset(by_snt_volumes, variable=="MAPER")
maget=subset(by_snt_volumes, variable=="MAGeT")

qplot(SNT,value,data=by_snt_volumes,
      colour=variable, geom="smooth", method="lm") + 
    geom_point() +
#     geom_text(aes(
#       label=paste("FSL       R=", round(cor(fsl$SNT,fsl$value, use="complete.obs"), 2), 
#                   ", p<", round(as.double(t.test(fsl$SNT,fsl$value, paired=T)["p.value"]), 2)),
#       x=1800,y=10000, hjust=0,size=2)) + 
#     geom_text(aes(
#       label=paste("MAPER R=", round(cor(maper$SNT,maper$value, use="complete.obs"), 2), 
#                   ", p<", t.test(maper$SNT,maper$value, paired=T)["p.value"]), 
#       x=1800,y= 9500, hjust=0, size=2)) +
#     geom_text(aes(
#       label=paste("MAGeT  R=", round(cor(maget$SNT,maget$value, use="complete.obs"),2), 
#                   ", p<", t.test(maget$SNT,maget$value, paired=T)["p.value"]), 
#       x=1800,y= 9000, hjust=0, size=2)) +
    xlab("Total Hippocampal Volume (Manual Segmentation)") + 
    ylab("Total Hippocampal Volume (Automatic Segmentation)")
@
  \caption{{\bf ADNI Baseline cohort.} Comparison of HC volumes by FreeSurfer
  (FSF), MAGeT brain (MAGeT), MAPER, and manual (SNT).}
  \label{ADNI-baseline-volumes-plot}
\end{figure}

%%%%%
%%%%%             Results: First Episode Patient Validation          %%%%%
%%%%%
\subsection{First Episode Schizophrenic Patients}
High volume correlation between Winterburn segmentation volumes and ground
truth.  (High-ish?) Kappa when using manual segmentations as Atlases. 

\begin{figure}
<<SZ_volumes,echo=F,fig=T, fig.align='center',cache=T>>=
SZ_volumes=read.csv("data/SZ_volumes_by_method.csv")
qplot(Manual,MAGeT,data=SZ_volumes) + geom_smooth(method="lm") + 
#   geom_text(aes(
#       label=paste("R=", round(cor(Manual,MAGeT, use="complete.obs"), 2), 
#                   ", p<", t.test(Manual, MAGeT, paired=T)["p.value"]),
#       x=6500,y=10000, hjust=0,size=2)) +
    xlab("Total Hippocampal Volume (Manual Segmentation)") + 
    ylab("Total Hippocampal Volume (MAGeT Segmentation)")

@
  \caption{{\bf First Episode Schizophrenic Patients.} Comparison of total
  HC volumes for MAGeT against manually rated Hippocampal volumes}
  \label{SZ_volumes}
\end{figure}

%%%%%
%%%%%              Experiments: Winterburn Atlases Validation              %%%%%
%%%%%
\subsection{Winterburn Atlases Validation}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                Discussion
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Discussion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                               Conclusion 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion}

\bibliographystyle{plainnat}
\bibliography{references}
\end{document}
