<<setup, include=FALSE, cache=FALSE>>=
library(knitr)
opts_chunk$set(echo = FALSE, 
               message = FALSE, 
               warning = FALSE, 
               fig.align = 'center', 
               tidy = FALSE, 
               comment = NA, 
               cache = TRUE,
               fig.width = 6, 
               fig.height = 6)
library(ggplot2)
library(Hmisc)
library(reshape2)
library(ADNIMERGE)
library(plyr)
options(digits=3)
theme_set(theme_bw(base_size = 12))
theme_update(
  legend.key = element_rect(fill='white',colour='white'))
lm_eqn = function(m) {
  l <- list(a = format(coef(m)[1], digits = 2),
      b = format(abs(coef(m)[2]), digits = 2),
      pearson = format(sqrt(summary(m)$r.squared), digits = 3));
  if (coef(m)[2] >= 0)  {
    eq <- substitute(italic(y) == a + b %.% italic(x)*","~~italic(r)~"="~pearson,l)
  } else {
    eq <- substitute(italic(y) == a - b %.% italic(x)*","~~italic(r)~"="~pearson,l)    
  }

  as.character(as.expression(eq))
}

@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


<<load,include=FALSE,cache=TRUE>>=

########################################
# ADNI1-XVAL: prep
# Prepares the data in a the form needed for plotting.
jens_atlases = read.csv('data/jens_atlases.csv')
jens_xval_data  <- read.csv(gzfile('data/cache/ADNI-JENS-XVAL:all_data.csv.gz'))
jens_xval_mean  <- read.csv(gzfile('data/cache/ADNI-JENS-XVAL:all_data_mean.csv.gz'))
jens_xval_mean$reg_method = factor(jens_xval_mean$reg_method, c("ANTS", "ANIMAL"))
jens_xval_mean$method.mb = factor(jens_xval_mean$method.mb, c("Majority Vote", "Cross-correlation Vote", "NMI Vote"))
mb.kappa.best = round(mean(subset(jens_xval_mean, 
                                 reg_method   == "ANTS" & 
                                 method.mb    == "Majority Vote" &
                                 templates.mb == 19 & 
                                 atlases      == 9)$k.mb), digits=3)
mb.diff.best = mean(subset(jens_xval_mean, 
                                 reg_method   == "ANTS" & 
                                 method.mb    == "Majority Vote" &
                                 templates.mb == 19 & 
                                 atlases      == 1)$k_diff)


########################################
# ADNI1-COMPLETE
# Prepares the data in the form needed for plotting.
########################################
means.complete   <- read.csv('data/cache/ADNI1:qc.csv')
package_totals   <- read.csv('data/cache/ADNI1:package_totals.csv')

########################################
# ADNI1-SNT-XVAL: prep
# Prepares the data in a the form needed for plotting.
snt_xval_data  <- read.csv(gzfile('data/cache/ADNI-SNT-XVAL:all_data.csv.gz'))
snt_xval_mean  <- read.csv(gzfile('data/cache/ADNI-SNT-XVAL:all_data_mean.csv.gz'))
snt_xval_mean$reg_method = factor(snt_xval_mean$reg_method, c("ANTS", "ANIMAL"))
snt_xval_mean$method.mb = factor(snt_xval_mean$method.mb, c("Majority Vote", "Cross-correlation Vote", "NMI Vote"))

snt.mb.kappa.best =round(mean(subset(snt_xval_mean, 
                                 reg_method   == "ANTS" & 
                                 method.mb    == "Majority Vote" &
                                 templates.mb == 19 & 
                                 atlases      == 9)$k.mb), digits=3)
snt.mb.diff.best = mean(subset(snt_xval_mean, 
                                 reg_method   == "ANTS" & 
                                 method.mb    == "Majority Vote" &
                                 templates.mb == 19 & 
                                 atlases      == 1)$k_diff)

########################################
# ADNI1-FEP-XVAL: prep
# Prepares the data in a the form needed for plotting.
fep.xval <-read.csv('data/results-fep-xval-ants-2013-12-29-191914.csv')
fep.xval$atlases <- as.factor(fep.xval$atlases)
fep.xval.mean <- ddply(fep.xval, .(subject,atlases,templates,label), function (df) {
  data.frame(k=mean(df$k),volume=mean(df$volume))
})

fep.mb.kappa.best = round(mean(subset(fep.xval.mean, 
                               templates == 19 & 
                               atlases   == 9)$k), digits=3)
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass{article}
\usepackage[margin=1in]{geometry}
\usepackage{color, url, amsmath, geometry, ctable}
\usepackage{titlesec, siunitx, graphicx}
\usepackage[round,authoryear]{natbib}
\usepackage[section]{placeins}   % keep floats in their place.
\usepackage{authblk}             % Listing Author affiliations
\usepackage{rotating}            % rotating figures
\usepackage[hypcap]{caption}
\usepackage{setspace}            % line spacing control
\usepackage{subcaption}          % subfigures
%\newcommand{\subfloat}[2][need a sub-caption]{\subcaptionbox{#1}{#2}}
\usepackage{lineno}              % line numbers
\usepackage{multirow,rotating}   % vertical text in tables
%\usepackage[displaymath, tightpage]{preview} %draft mode
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhead[RO,RE]{}

% styling
\newcommand{\subsubsubsection}[1]{\paragraph{#1}}
\renewcommand\Affilfont{\itshape\small}  %authblk
\onehalfspacing

% shortcuts 
\newcommand{\mb}{MAGeT-Brain}
\newcommand{\multiatlas}{multi-atlas}
\newcommand{\ants}{ANTS}
\newcommand{\animal}{ANIMAL}
\newcommand{\adnidataset}{ADNI1:Complete 1Yr 1.5T}
\newcommand{\fsl}{FSL FIRST}
\newcommand{\freesurfer}{FreeSurfer}
\newcommand{\maper}{MAPER}
\newcommand{\prsnr}{Pruessner}
\newcommand{\pseg}{\prsnr-protocol manual segmentation}
\newcommand{\psegs}{\prsnr-protocol manual segmentations}
\newcommand{\snt}{SNT}
% experiment #'s 
\newcommand{\expadnixval}{Experiment 1} 
\newcommand{\expfepxval}{Experiment 2} 
\newcommand{\expadni}{Experiment 3}
\newcommand{\expsubfield}{Experiment 4}
\newcommand{\expadnixvalsnt}{Experiment 5}
% experiment descriptions (suitable for titles)
\newcommand{\expadnixvaldesc}{Whole Hippocampus Segmentation Cross-Validation --- Alzheimer's Disease} 
\newcommand{\expfepxvaldesc}{Whole Hippocampus Segmentation Cross-Validation --- First Episode of Psychosis} 
\newcommand{\expadnidesc}{Whole Hippocampus Segmentation Comparison --- ADNI1 Complete 1Yr} 
\newcommand{\expsubfielddesc}{Hippocampal Subfield Segmentation Cross-Validation} 
\newcommand{\expadnixvalsntdesc}{Whole Hippocampus Segmentation Cross-Validation --- Alzheimer's Disease, \snt{} Segmentations}

% title and authors
%\title{Bootstrapping Multi-atlas Hippocampal Subfield Segmentation by using
%Multiple Automatically Generated Templates}
\title{Bootstrapping Multi-atlas Segmentation Using Multiple Automatically
Generated Templates for the Segmentation of the Whole Hippocampus and
Subfields}
\author[1]{Jon Pipitone}
\author[1]{Min Tae M. Park}
\author[1]{Julie Winterburn}
\author[1,9]{Tristram A. Lett}
\author[2,3]{Jason P. Lerch}
\author[4]{Jens C. Pruessner}
\author[4,5]{Martin Lepage}
\author[1,6,9]{Aristotle N. Voineskos}
\author[1,6,7,8]{M. Mallar Chakravarty}
\author[ ]{the Alzheimer's Disease Neuroimaging Initiative\footnote{Data
used in preparation of this article were obtained from the Alzheimer's Disease
Neuroimaging Initiative (ADNI) database (adni.loni.usc.edu). As such, the
investigators within the ADNI contributed to the design and implementation of
ADNI and/or provided data but did not participate in analysis or writing of this
report. A complete listing of ADNI investigators can be found at:
http://adni.loni.usc.edu/wp-content/uploads/how\_to\_apply/ADNI\_Acknowledgement\_List.pdf}}
\affil[1]{Kimel Family Translational Imaging-Genetics Lab, Centre for Addiction and
Mental Health, Toronto, ON, Canada}
\affil[2]{Neurosciences and Mental Health Laboratory, Hospital for Sick
Children, Toronto, ON, Canada}
\affil[3]{Department of Medical Biophysics, University of Toronto, Toronto, ON,
Canada}
\affil[4]{Douglas Mental Health University Institute, Verdun, QC, Canada}
\affil[5]{Department of Psychiatry, McGill University, Montreal, QC, Canada}
\affil[6]{Department of Psychiatry, University of Toronto, Toronto, ON, Canada}
\affil[7]{Institute of Biomaterials and Biomedical Engineering, University of
Toronto, Toronto, ON, Canada}
\affil[8]{Rotman Research Institute, Baycrest, Toronto, ON, Canada}
\affil[9]{Institute of Medical Science, University of Toronto, Toronto, ON, Canada}

\renewcommand\Authands{ and }

\date{}

\begin{document}
\maketitle
\linenumbers

\begin{abstract}

\textbf{Introduction:} 
Advances in image segmentation of magnetic resonance images (MRI) have
demonstrated that \multiatlas{} approaches improve segmentation accuracy and
precision over regular atlas-based approaches. These approaches often rely on
a large number of such manually segmented atlases (e.g. 30-80) that take
significant time and expertise to produce. We present an algorithm, \mb{} 
({\textbf M}ultiple {\textbf A}utomatically {\textbf Ge}nerated {\textbf
T}emplates), for the automatic segmentation of the hippocampus that minimizes
the number of atlases needed while still achieving similar aggreement to
\multiatlas{} approaches. Thus, our method acts as an accurate \multiatlas{}
approach when using special, hard-to-define atlases that are laborious to
construct. \\
\textbf{Method:} \mb{} works by propagating atlas segmentations to a template
library, formed from a subset of target images, via transformations estimated by
nonlinear image registration. The resulting segmentations are then propagated
to each target image and fused using a label fusion method. 

We conduct two separate Monte Carlo cross-validation experiments comparing \mb{}
and \multiatlas{} whole hippocampal segmentation using differing atlas and
template library sizes, and registation and label fusion methods. The first
experiment is a 10-fold validation (per parameter setting) over 60 subjects
taken from the Alzheimer's Disease Neuroimaging Database (ADNI), and the second
is a five-fold validation over 81 subjects having had a first episode of psychosis.
In both cases, automated segmentations are compared with manual segmentions
following the \prsnr{}-protocol. Using the best settings found from these
experiments, we segment \Sexpr{length(means.complete$RID)} images of the
\adnidataset{} dataset and compare these with segmentations from existing
automated methods: \fsl{}, \freesurfer{}, \maper{}, and \snt.  Finally, we
conduct a leave-one-out cross-validation (LOOCV) of hippocampal subfield
segmentation using five high-resolution manually segmented atlases
\citep{Winterburn2013}.

\textbf{Results:} \textbf{[TODO: update with FEP-XVAL and subfield XVAL results.]} 
Using 9 atlases and 19 template images, \mb{} achieves a
mean Dice's Similarity Coefficient (DSC) of \Sexpr{mb.kappa.best} 
(to \psegs{}) over 10-folds of Monte Carlo 
significantly lower variability in DSC than \multiatlas{} segmentation.
In a LOOCV, \mb{} accurately reproduces the subfields... . 

\mb{} produces hippocampal
volumes in a first episode psychosis patient population that are highly
correlated with expert manual segmentation volumes (Pearson $r = 0.877, t =
16.244, p < 0.001$). Compared to \fsl{} and \freesurfer{}, \mb{} shows much smaller
fixed volume bias (within $250 mm^3$ on average) to semi-automated (\snt{})
segmentations available from ADNI, as well as a conservative, rather than
exaggerated, proportional volume bias.\\ \textbf{Conclusion:} We demonstrate
that \mb{} produces accurate hippocampal segmentations using only 5 atlases over
different hippocampal definitions, disease populations, and acquisition types,
as well as showing that accurate identification of the hippocampal subfields is
possible.
\end{abstract}

\parbox{4in}{
\textbf{Contact:} \\
Jon Pipitone and M. Mallar Chakravarty \\
Kimel Family Translation Imaging-Genetics Research Laboratory \\
Research Imaging Centre \\
Centre for Addiction and Mental Health \\
250 College St. \\
Toronto, Canada   M5T 1R8 \\
jon.pipitone@camh.ca; mallar.chakravarty@camh.ca}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                               INTRODUCTION
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

The hippocampus is a brain structure situated in the medial temporal
lobe, and has long been associated with learning and memory
\citep{DenHeijer2012,Jeneson2012,Wixted2011,Scoville2000}. The hippocampus is of
interest to clinical neuroscientists because it is implicated in many forms of
brain dysfunction, including Alzheimer's disease \citep{Sabuncu2011} and
schizophrenia \citep{Narr2004,Karnik-Henry2012}. In neuroimaging studies,
structural magnetic resonance images (MRI) are often used for the volumetric
assessment of the hippocampus. As such, accurate segmentation of the
hippocampus and its subfields in MRI is a necessary first step to better
understand the inter-individual variability of subject neuroanatomy. 

The gold standard for neuroanatomical segmentation is manual delineation by an
expert human rater. However, with the availability of increasingly large MRI
datasets the time and expertise required for manual segmentation becomes
prohibitive \citep{Mazziotta1995,Mazziotta2001,Mazziotta,Pausova2007}. This
effort is complicated by the fact that there is significant variation between
segmentation protocols with respect to specific anatomical boundaries of the
hippocampus \citep{Geuze2004} and this has led to efforts to create an unified
hippocampal segmentation protocol \citep{Jack2011,Boccardi2013,Boccardi2013a}.
In addition, there is controversy over the appropriate manual segmentation
protocol to use in a particular imaging study \citep{Nestor2012}. Thus, a
segmentation algorithm that can easily adapt to different manual segmentation
definitions would be of significant benefit to the neuroimaging community.

Automated segmentation techniques that are reliable, objective, and reproducible
can be considered complementary to manual segmentation. In the case of classical
model-based segmentation methods \citep{Haller1997,Csernansky1998}, an MRI atlas
that was previously manually labelled by an expert rater is matched to target
images using nonlinear registration methods. The resulting nonlinear
transformation is applied to the manual labels (i.e. {\em label propagation}) to
warp them into the target image space. While this methodology has been used
successfully in several contexts
\citep{Chakravarty2008,Chakravarty2009,Collins1995,Haller1997}, it is limited in
accuracy due to error in the estimated nonlinear transformation itself, partial
volume effects in label resampling, and irreconcilable differences between the
neuroanatomy represented within the atlas and target images.
 
One methodology that can be used to mitigate these sources of error involves
the use of multiple manually segmented atlases and probabilistic segmentation
techniques, such as those found in the \freesurfer{} package \citep{Fischl2002}.
\freesurfer{} uses a probabilistic atlas of anatomical and tissue classes along
with spatial constraints for class labels encoded using a Markov random field
model to segment the entire brain. 

More recently, many groups have used multiple atlases to improve overall
segmentation accuracy (i.e. \multiatlas{} segmentation) over model-based approaches
\citep{Heckemann2006,Heckemann2011,Collins2010,Lotjonen2010,Aljabar2009,Leung2010,Wolz2010}.
Each atlas image is registered to a target image, and label propagation is
performed to produce several labellings of the target image (one from each
atlas). A {\it label fusion} technique, such as voxel-wise voting, is used to
merge these labels into the definitive segmentation for the target. In addition,
weighted voting procedures that use {\em atlas selection} techniques are often
used to exclude atlases from label fusion that are dissimilar to a target image
in order to reduce error from unrepresentative anatomy \citep{Aljabar2009}.
This involves the selection of a subset of atlases using a similarity metric
such as cross-correlation \citep{Aljabar2009} or normalized mutual information.
Such selection has the added benefit of significantly reducing the number of
nonlinear registrations. For example \citet{Collins2010} demonstrated that only
14 atlases, selected based on highest similarity between medial temporal lobe
neuroanatomy as evaluated by normalized mutual information \citep{Studholme1999}
from a library of 80 atlases, were required to achieve accurate segmentations of
the hippocampus. Also, several methods have been explored for label
fusion. For example, the STAPLE algorithm (Simultaneous Truth And Performance
Level Estimation; \citet{Warfield2004}) uses an expectation-maximization
framework to compute a probabilistic segmentation from a set of competing
regmentations, or the work of \citet{Coupe2011} who show that a subset of
segmentations can be estimated using metrics, such as the sum of squared
differences in the regions of interest to be segmented.

However, many of these methods require significant investment of time and
resources for the creation of the atlas library ranging between 30
\citep{Heckemann2006} and 80 \citep{Collins2010} manually segmented atlases.
This strategy has the main drawback of being inflexible as it does not easily
accommodate varying the definition of the hippocampal anatomy (such as the
commonly used heuristic of subdividing the hippocampus into head, body, and tail
\citep{Poppenk2011,Pruessner2000}). Furthermore, none of these methods have
demonstrated sufficient flexibility to accommodate atlases that are somehow
exceptional such as those derived from serial histological data
\citep{Chakravarty2006,Yelnik2007} or high-resolution MRI data that enables
robust identification of hippocampal subfields
\citep{Winterburn2013,Yushkevich2009,Mueller2009,VanLeemput2009,Wisse2012}. Due
to the recent availability of the latter, there has been increased interest in
the use of probabilistic methods for the identification of the hippocampal
subfields on standard T1-weighted images. Our group recently demonstrated that
through use of an intermediary automated segmentation stage, robust and accurate
segmentation of the striatum, pallidum, and thalamus using a single atlas
derived from serial histological data is possible \citep{Chakravarty2013}.
The novelty of this manuscript is the extension of our \multiatlas{} methodology
to the segmentation of hippocampus. Additionally, in this paper we rigorously explore the
effects of using multiple input atlases, of varying the size of the template
library constructed, and registration and label fusion methods. As a result, we
aim to demonstrate that it is indeed possible to reliably apply the segmentation
represented in a very small set of segmented input atlases to an unlabelled
target image set.

Of particular relevance to the present work is the LEAP algorithm (Learning
Embeddings for Atlas Propagation; \citet{Wolz2010}) because of its focus on
performing \multiatlas{} segmentation with a limited number of input atlases. The
LEAP algorithm is a clever modification to the basic \multiatlas{} strategy in
which an atlas library is grown, beginning with a set of manually labelled
atlases, by successively incorporating unlabelled target images once they
themselves have been labelled using \multiatlas{} techniques. The sequence in
which target images are labelled is chosen so that the similarity between the
atlas images and the target images is minimised at each step, effectively
allowing for deformations between very dissimilar images to be broken up into
sequences of smaller deformations. Although \citet{Wolz2010} begin with an atlas
library of 30 MR images, this method could theoretically work using a much
smaller atlas library. In their validation, LEAP was used to segment the whole
hippocampus in the ADNI1 baseline dataset, achieving a mean Dice score of 0.85
against semi-automated segmentations. 

Also of interest to this manuscript are the methods that attempt to define
hippocampal subfields using standard T1- or T2-weighted data, of which there are
few. \citet{VanLeemput2009} demonstrate that the applicability of hippocampal
subfield segmentation in T1-weighted images by Bayesian techniques using Markov
random field shape priors learned from 10 manual segmentations. This work,
available as part of the \freesurfer{} package, is limited as the segmentation
omits the tail of the hippocampus and the protocol has yet to be fully
validated. \citet{Yushkevich2009} manually segment hippocampal subfields on
high-resolution (either $0.2mm^3$ isotropic or $0.2mm \times 0.3mm \times 0.2mm$
resolution voxels) T2-weighted MR images acquired from five post-mortem medial
temporal lobe samples. Then, using nonlinear registration guided by shape-based
models of the subfield segmentations, and manually derived hippocampus masks of
the target images, the authors demonstrate accurate parcellation of hippocampal
subfields in clinical 3T T1-weighted MRI volumes. Using \multiatlas{} with bias
correction techniques, \citet{Yushkevich2010} demonstrate a semi-automated
method of subfield segmentation on in vivo focal T2-weighted MR acquisitions of
the temporal lobe. Manual input is only needed to mark divisions between
the head, body and tail of the hippocampus on target images. 

In this paper we describe a thorough validation of the \mb{} algorithm for the
fully automatic segmentation of the hippocampus and its subfields. First, we
address the very idea of boostrapping a template library from a limited number
of input atlases \citep{Chakravarty2013} for whole hippocampus segmentation by
conducting a multi-fold validation experiment over a range of atlas and template
library sizes, registration and label fusion methods. This type of validation is
done first on a subset of the Alzheimer's Disease Neuroimaging Initiative (ADNI)
dataset with manual segmentations  \prsnr{}-protocol, and then replicated on a
first episode psychosis patient dataset to determine the behaviour of \mb{} when
segmenting younger and differently diseased subjects. Next, we compare \mb{}
with other popular segmentation algorithms (\freesurfer{}, \fsl{}, \maper{}, and
\snt{}) on all the images available in the \adnidataset{} sample. Lastly, using
the optimal parameter settings for \mb{} found from the previous experiments, we
investigate hippocampal subfield segmentation by conducting a leave-one-out
validation using the \citet{Winterburn2013} manually segmented high-resolution
MR atlases. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                                                                      %%%%%
%%%%%                     MAGeT Brain Algorithm                            %%%%%
%%%%%                                                                      %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{The \mb{} Algorithm}
In this paper, we use the term {\em label} to mean any segmentation (manual or
derived) of an MR image. {\em Label propagation} is the process by which two
images are registered and the resulting transformation is applied to the labels
from one image to bring them into alignment with the other image. We use the
term {\em atlas} to mean a manually segmented image, and the term {\em template}
to mean an automatically segmented image (i.e. via label propagation). The
terms {\em atlas library} and {\em template library} describe any set of such
images. Additionally, we use the term {\em target} to refer to an unlabelled
image that is undergoing segmentation.

The simplest form of \multiatlas{} segmentation, which we call {\em basic 
\multiatlas{} segmentation}, involves three steps. First, each labelled 
input image (i.e. atlas or template) is registered to an unlabelled target image.
Second, the labels from each image are propagated to the target image space. 
Third, the labels are combined into a single label by label fusion
\citep{Heckemann2006, Heckemann2011}. The basic \multiatlas{} segmentation method
is described in detail in other publications
\citep{Collins2010,Heckemann2011,Aljabar2009}. When only a single atlas is used,
basic \multiatlas{} segmentation degenerates into model-based segmentation: labels
are propagated from the atlas to a target, and no label fusion is needed.

\mb{} ({\textbf M}ultiple {\textbf A}utomatically {\textbf Ge}nerated {\textbf
T}emplates) bootstraps the creation of a large template library given a limited
input atlas library, and then uses the template library in basic \multiatlas{}
segmentation. Images for the template library are selected from a set of input
target images, either arbitrarily or so as to reflect the neuroanatomy or
demographics of the target set as a whole (for instance, by sampling equally
from cases and controls). The template library images are automatically
labelled by each of the atlases via label propagation. Effectively, basic
\multiatlas{} segmentation is then conducted using the template library to
segment the entire set of target images (including the target images used in the
construction of the template library). Since each template library image has
multiple labels (one from each atlas), the final number of labels to be fused
for each target may be quite large (i.e. \# of atlas $\times$ \# of templates).

Figure \ref{fig:MAGeT} illustrates the \mb{} algorithm graphically. Source code
for \mb{} can be found at \url{http://github.com/pipitone/MAGeTbrain}.

\begin{figure}
  \centering
    \includegraphics[width=\textwidth]{figure/MA-MAGeTBrain-Schematic}
  \caption{A schematic illustration of basic \multiatlas{} segmentation and
\mb{} segmentation. In multi-atlas segmentation, manual labels from atlas images
are warped (propagated) into subject space by applying the transformations
estimated from nonlinear image registration. The resulting candidate labels
from all atlas images are then fused to create a final segmentation. In \mb{}
segmentation, a template library is created by sampling (either randomly or
representatively) from the subject images. Atlas labels are propagated to all
template images and then to each subject image (including those used in the template
library). The candidate labels for a subject are then fused into a final
segmentation. \label{fig:MAGeT}}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                            Experiments                              %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Experiments}
\label{sec:experiments}

The following section describes experiments conducted to assess the
segmentation quality of the \mb{} algorithm:  

\begin{itemize}
  \item \expadnixval{} investigates \mb{} whole hippocampus
  segmentation of aging and Alzheimer's diseased subjects over a wide range of
  parameter settings using a Monte Carlo cross-validation design. The results of
  this experiment enable us to choose the parameter settings offering the best
  performance for use in subsequent experiments. 

  \item \expfepxval{} is a similar cross-validation to explore \mb{}
  segmentations on the brain images of young, first episode psychosis patients. 
  In addition, \mb{} segmentations with two different atlas segmentation
  protocols are compared to automated segmentations by the \fsl and
  \freesurfer algorithms.  The results of this experiment combined with the
  previous experiment establishes parameter settings that do not overfit to the
  neuroanatomical features of a specific patient cohort.

  \item \expadni{} bridges \mb{} with the existing segmentation literature by
  comparing \mb{} whole hippocampus segmentations with those of several well-known
  automated methods (\freesurfer, \fsl, \maper, \snt) on the entire
  \adnidataset{} image dataset consisting of \Sexpr{length(means.complete$RID)}
  brain images of subjects diagnosed as cognitively normal, having mild cognitive
  impairment, or Alzheimer's disease.

  \item \expsubfield{} assesses hippocampal subfield segmentation quality in a
  leave-one-out cross-validation on the five high-resolution manually segmented
  Winterburn MR atlases \citep{Winterburn2013}.
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                                                                     %%%%%
%%%%%         Experiment 1: Whole Hippocampus Cross-Validation            %%%%%
%%%%%                                                                     %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{\expadnixval{}: \expadnixvaldesc{}}
\label{exp:adni-xval}

In this experiment we explore the very idea of bootstrapping a template library
for multi-atlas-based segmentation from a small number of input atlases. To do
so, we conduct repeated cross-validations of \mb{} whilst varying the
composition and sizes of the atlas and template libraries used, as well as
varying the registration algorithm and label fusion method. The dataset used in
this experiment is images from the ADNI dataset \citep{Jack2008} along with
whole hippocampus labels manually segmented following the \prsnr-protocol
\citep{Pruessner2000}. 

Note, in the Supplementary Materials we have replicated this experiment using
the \snt{} semi-automated segmentations included as part of the ADNI
dataset.

\subsubsection{\expadnixval{}: Materials and Methods}

\paragraph{\adnidataset{} dataset} 
\label{adnidataset}
Data used in the preparation of this article were obtained from the Alzheimer's
Disease Neuroimaging Initiative (ADNI) database (adni.loni.usc.edu). The ADNI
was launched in 2003 by the National Institute on Aging (NIA), the National
Institute of Biomedical Imaging and Bioengineering (NIBIB), the Food and Drug
Administration (FDA), private pharmaceutical companies and non-profit
organizations, as a \$60 million, 5-year public-private partnership. The primary
goal of ADNI has been to test whether serial magnetic resonance imaging (MRI),
positron emission tomography (PET), other biological markers, and clinical and
neuropsychological assessment can be combined to measure the progression of mild
cognitive impairment (MCI) and early Alzheimer's disease (AD). Determination of
sensitive and specific markers of very early AD progression is intended to aid
researchers and clinicians to develop new treatments and monitor their
effectiveness, as well as lessen the time and cost of clinical trials. 

The Principal Investigator of this initiative is Michael W. Weiner, MD, VA
Medical Center and University of California San Francisco. ADNI is the result
of efforts of many co-investigators from a broad range of academic institutions
and private corporations, and subjects have been recruited from over 50 sites
across the U.S. and Canada. The initial goal of ADNI was to recruit 800 subjects
but ADNI has been followed by ADNI-GO and ADNI-2. To date these three protocols
have recruited over 1500 adults, ages 55 to 90, to participate in the research,
consisting of cognitively normal (CN) older individuals, people with early or
late MCI, and people with early AD. The follow up duration of each group is
specified in the protocols for ADNI-1, ADNI-2 and ADNI-GO. Subjects originally
recruited for ADNI-1 and ADNI-GO had the option to be followed in ADNI-2. For
up-to-date information, see www.adni-info.org.

Sixty 1.5T images were arbitrarily selected from the baseline scans in the {\em
\adnidataset{}} standardized dataset. Twenty subjects were chosen from each disease
category: cognitively normal (CN), mild cognitive impairment (MCI) and
Alzheimer's disease (AD). Demographics for this subset are shown in Table
\ref{tab:ADNI1-xvalidation-demographics}. Fully manual segmentations of the
left and right whole hippocampi in these images were provided by one author
(JCP) according to the segmentation protocol specified in \citet{Pruessner2000}. 

Clinical, demographic and pre-processed T1-weighted MRI were downloaded by the
authors from the ADNI database (adni.loni.usc.edu) between March 2012 and
August 2012. The image dataset used was the \adnidataset{} standardized dataset
available from ADNI \footnote{
\url{http://adni.loni.usc.edu/methods/mri-analysis/adni-standardized-data/}}
\citep{Wyman2012}. This image collection contains uniformly pre-processed images
which have been designated to be the ``best'' after quality control. All images
were acquired using 1.5T scanners (General Electric Healthcare, Philips Medical
Systems or Siemens Medical Solutions) at multiple sites using the protocol
described in \citet{Jack2008}. Representative 1.5T imaging parameters were TR =
2400ms, TI = 1000ms, TE = 3.5ms, flip angle = $8^{\circ}$, field of view = 240 x
240mm, a $192 \times 192 \times 166$ matrix ($x$, $y$, and $z$ directions)
yielding voxel dimensions of $1.25mm \times 1.25mm \times 1.2mm$.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% ADNI1 X-Validation Dataset Demographics Table
%
<<tab:ADNI-xval-demographics, echo=F, dependson='ADNI1-xval-load', results="asis",cache=FALSE>>=
tab <- summary(DX.bl ~ AGE + PTGENDER + PTEDUCAT + CDRSB + ADAS13 +
               MMSE, data = adnimerge, subset = VISCODE == 'bl' & RID %in%
               jens_atlases$RID, method = "reverse", test=FALSE, overall=TRUE)
caption = 
  "\\textbf{ADNI1 cross-validation subset demographics.} 
  CN     - Cognitively Normal. 
  LMCI   - Late-onset Mild Cognitive Impairment. 
  AD     - Alzheimer's Disease. 
  CDR-SB - Clinical Dementia Rating-Sum of Boxes. 
  ADAS   - Alzheimer's Disease Assessment Scale. 
  MMSE   - Mini-Mental State Examination."
latex(tab, file="", size="scriptsize",landscape=FALSE, ctable=FALSE,
      caption=caption, caption.loc = c("top"),
      label="tab:ADNI1-xvalidation-demographics")
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\paragraph{Experiment details} 

Monte Carlo Cross-Validation (MCCV), also known as repeated random sub-sampling
cross-validation, consists of repeated rounds of validation conducted on a fixed
dataset \citep{Shao1993}. In each round, the dataset is randomly partitioned into
a training set and a validation set. The method to be validated is then given
the training data, and its output is compared with the validation set.

In this experiment, our dataset consists of 60 1.5T images and corresponding
\psegs{}. In each validation round, the dataset is partitioned into
a training set consisting of images and manual segmentations used as an atlas
library, and a validation set consisting of the remaining images to be segmented
by both \mb{} and \multiatlas{}. The computed segmentations are compared to the
manual segmentations (see Evaluation below). 

A total of ten validation rounds were performed on each subject in the dataset,
over each combination of parameter settings. The parameter settings explored
are: atlas library size (1-9), template library size (1-20), registration method
(\ants{} or \animal{}, described below), and label fusion method (majority vote,
cross-correlation weighted majority vote, and normalized mutual information
weighted majority vote, described below). In each validation round, both a
\mb{} and \multiatlas{} segmentation is produced. A total of $10 \times 60 \times
9 \times 20 \times 2 \times 3 =$ \Sexpr{10*60*9*20*2*3} validation rounds
were conducted and resulting segmentations analysed. 

Before registration, all images underwent preprocessing with the N3 algorithm
\citep{Sled1998} to minimize intensity nonuniformity. In this experiment we
compared two nonlinear image registration methods:

\subparagraph{Automatic Normalization and Image Matching and Anatomical
Labeling (\animal{})}

The \animal{} algorithm carries out image registration in two phases. In the
first, a 12-parameter linear transformation (3 translations, rotations, scales,
shears) is estimated between images using an algorithm that maximizes the
correlation between blurred MR intensities and gradient magnitude over the whole
brain \citep{Collins}. In the second phase, nonlinear registration is completed
using the \animal{} algorithm \citep{Collins1995}: an iterative procedure that
estimates a 3D deformation field between two MR images. At first, large
deformations are estimated using a blurred version of the input data. These
larger deformations are then input to subsequent steps where the fit is refined
by estimating smaller deformations on data blurred with a Gaussian kernel with a
smaller full width at half maximum (FWHM). The final transformation is a set of
local translations defined on a bed of equally spaced nodes that were estimated
through the optimization of the correlation coefficient. For the purposes of
this work we used the regularization parameters optimized in
\citet{Robbins2004}, displayed in Table \ref{tab:ANIMAL-params}. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ANIMAL parameters                    
%                                     
\begin{table*}[!tbp]
\scriptsize
\caption{\textbf{\animal{} registration parameters.} \label{tab:ANIMAL-params}}
\begin{center}
\begin{tabular}{l | c c c}
\hline 
Parameters        & Stage 1 & Stage 2 & Stage 3  \tabularnewline
\hline 
Model Blur (FWHM) &   8     &    8    &   4      \tabularnewline
Input Blur (FWHM) &   8     &    8    &   4      \tabularnewline
Iterations        &   30    &    30   &   10     \tabularnewline
Step              &   8x8x8 &  4x4x4  &   2x2x2  \tabularnewline
Sub-Lattice       &   6     &    6    &   6      \tabularnewline
Lattice Diameter  &24x24x24 &12x12x12 & 6x6x6    \tabularnewline
\hline
\end{tabular}
\end{center}
\end{table*}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subparagraph{Automatic Normalization Tools (\ants{})}

\ants{} is a diffeomorphic registration algorithm which provides great flexibility
over the choice of transformation model, objective function, and the consistency
of the final transformation \citep{Avants2008}. The transformation is estimated in a
hierarchical fashion where the MRI data is subsampled, allowing large
deformations to be estimated and successively refined at later hierarchical
stages (where the data is subsampled to a finer grid). The deformation field and
the objective function are regularized with a Gaussian kernel at each level of
the hierarchy. The \ants{} algorithm is freely available
\url{http://www.picsl.upenn.edu/ANTS/}. We used an implementation of the \ants{}
algorithm compatible with the MINC data format, mincANTS
\url{https://github.com/vfonov/mincANTS}.

We used the following command line when running \ants{}:
{\small
\begin{verbatim}
  mincANTS 3 -m PR[target_file.mnc,source_file.mnc,1,4] 
   --number-of-affine-iterations 10000x10000x10000x10000x10000 
   --affine-gradient-descent-option 0.5x0.95x1.e-4x1.e-4
   --use-Histogram-Matching --MI-option 32x16000
   -r Gauss[3,0] -t SyN[0.5] -i 100x100x100x20
   -o transformation.xfm
 \end{verbatim}
}
These settings were adapted from the "reasonable starting point" given in the
\ants{} manual 
\footnote{\url{https://sourceforge.net/projects/advants/files/Documentation/}}.

\paragraph{Label fusion methods}
Label fusion is a term given to the process of combining the information from
several candidate labels for an image into a single labelling. In this
experiment we explore three fusion methods: 
\begin{description}
  \item[Voxel-wise Majority Vote]
  Labels are propagated from all template library images to a target. Each
  output voxel is given the most frequent label at that voxel location amongst
  all candidate labels.

  \item[Cross-correlation Weighted Majority Vote]
  An optimal combination of targets from the template library has previously been
  shown to improve segmentation accuracy \citep{Aljabar2009,Collins2010}. In this
  method, each template library image is ranked in similarity to each unlabelled 
  image by the normalized cross-correlation (CC) of image intensities after linear
  registration, over a region of interest (ROI) generously encompassing the 
  hippocampus. Only the top ranked template library image labels are used in a
  voxel-wise majority vote. The ROI is heuristically defined as the extent of all
  atlas labels after linear registration to the template, dilated by three voxels
  \citep{Chakravarty2013}. The number of top ranked template library image labels
  is a configurable parameter and displayed as the size of the template library
  in the rest of the paper. 

  The {\tt xcorr\_vol} utility from the \animal{} toolkit is used to calculate the
  cross-correlation similarity measure. 
 
  \item[Normalised Mutual Information Weighted Majority Vote]
  This method is similar to cross-correlation weighted voting except that image
  similarity is calculated by the normalised mutual information score over the
  region of interest \citep{Studholme2001}. The {\tt itk\_similarity} utility
  from the EZMinc toolkit\footnote{\url{https://github.com/vfonov/EZminc}} is
  used to calculate the normalised mutual information measure between two images.
\end{description}

\paragraph{Evaluation method}  
The Dice similarity coefficient (DSC), also known as Dice's Kappa, assesses the
agreement between two segmentations. It is one of the most widely used measures
of segmentation agreement, and we use it as the basis of comparison in this
experiment.
%Additionally, we report the Jaccard index, another commonly used similarity
%measure:

 \[\text{Dice's coefficient (DSC)} = \frac{2|A \cap B|}{|A| + |B|}\]

% \[\text{Jaccard (J)} = \frac{|A \cap B|}{|A \cup B|} = \frac{DSC}{(2-DSC)}\]

where $A$ and $B$ are the regions being compared, and the cardinality is the
volume measured in voxels. The labels produced by \mb{} and \multiatlas{}
segmentation are compared to the manual labels using the Dice similarity
coefficient, and the recorded value for each subject at each parameter setting
explored in this experiment is the average over ten validation rounds. 

Additionally, the sensitivity of \mb{} and \multiatlas{} to atlas and template
library composition is evaluated by comparing the variability in Dice scores
over all validation rounds at fixed parameter settings. This is achieved by
first computing the variance of DSC scores in each block of ten validation
rounds per subject. The distribution of these statistics across all subjects is
then compared between \mb{} and \multiatlas{} using a Student's t-test. A
significant difference between distributions is taken to show either a larger or
smaller level of variability between methods. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%     RESULTS: Experiment 1: Whole Hippocampus Cross-Validation       %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{\expadnixval{}: Results}

We find that for \mb{} segmentations, similarity score increases as atlas and
template library size is increased, although with diminishing returns and an
eventual trend towards a plateau (Figure \ref{fig:ADNI1-xval-k-mean}). A
maximum similarity score of \Sexpr{mb.kappa.best} is found when using 9 atlases,
19 templates, ANTS registration, and majority vote label fusion. The \ants{}
registration method consistently out-performs \animal{} registration over all
variable settings we tested. Additionally, by itself, using a weighted voting
strategy did not significantly improve segmentation agreement, contrary to the
findings of \citet{Aljabar2009} using basic \multiatlas{} segmentation. Given
these findings, in the remainder of our experiments only results using the \ants{}
registration algorithm and majority vote fusion will be shown. 

With at least five templates, \mb{} shows a mean improvement in similarity score
over \multiatlas{} segmentation when using the same size of atlas library and
majority vote label fusion (Figure \ref{fig:ADNI1-xval-k-diff}). The magnitude
of improvement increases with the size of template library, and shows
diminishing returns with larger atlas libraries. Peak improvement
(+\Sexpr{round(mb.diff.best, digits=3)} DSC) is found with a single atlas
and template library of 19 images.

In addition to a mean increase in similarity score over \multiatlas{}-based
segmentation, \mb{} also shows more consistency in similarity scores across all
subjects and validation folds (Figure \ref{fig:ADNI1-xval-variability}). A
template library of at least 13 images is sufficient to show significant ($p <
0.05$) decrease in variance for all sizes of atlas library tested (1-9 images). 

We find similar behaviour with respect to optimal parameter settings and
increased consistency of \mb{} segmentations in the replication of this
experiment (\expadnixvalsnt{}, Supplementary Materials) where a different
hippocampal definition is used (\snt{} labels available with the ADNI datasets).
This strongly suggests that these results are independent of the segmentation
protocol used and are, instead, features of the \mb{} algorithm. 

We have omitted results obtained when using an even number of atlases or
templates since with these configurations we found significantly decreased
performance. We believe this results from an inherent bias in the majority vote
fusion method used (see Discussion). 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ADNI1-XVAL: mean Kappa plot by atlases, templates, reg and voting method. 
<<fig:ADNI1-xval-k-mean,dependson='ADNI1-xval-load',fig.show='hide',fig.width=10>>=
stderr <- function(x) sqrt(var(x)/length(x))
ggplot(subset(jens_xval_mean, (templates.mb*atlases) %% 2 == 1 & templates.mb < 21),
       aes(x=templates.mb,y=k.mb, colour=as.factor(atlases), linetype=reg_method)) + #as.factor((atlases*templates.mb) %% 2 ))) + 
  facet_grid(.~method.mb) + 
  stat_summary(fun.y=mean,geom='line',
               aes(y=k.mb, weight=1, group=interaction(reg_method, as.factor(atlases)))) + 
  stat_summary(fun.y=mean,geom='point',
               aes(y=k.mb, weight=1, group=interaction(reg_method, as.factor(atlases)))) + 
  stat_summary(fun.y=mean,
               fun.ymin=function (x) mean(x) - stderr(x),
               fun.ymax=function (x) mean(x) + stderr(x), 
               geom='errorbar',
               aes(y=k.mb, weight=1, group=interaction(reg_method, as.factor(atlases))), linetype='solid', width=0.5) + 
  scale_y_continuous(breaks=seq(0,1,0.01)) + 
  scale_colour_hue(name="Number of Atlases") +
  scale_linetype(name="Registration Method") +
  xlab( "Number of Templates" ) + 
  ylab( "Mean similarity (DSC)" ) + 
  theme(legend.key.size = unit(0.7, 'lines'),
        legend.position = "bottom", 
        legend.box = "horizontal", 
        legend.text = element_text(size=rel(0.7)),
        axis.text = element_text(size = 8))
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ADNI1-XVAL: "increase" in mean kappa over \multiatlas{}
<<fig:ADNI1-xval-k-diff,dependson='ADNI1-xval-load',fig.show='hide'>>=
ggplot(subset(jens_xval_mean, reg_method=="ANTS" & 
                method.mb=="Majority Vote" & (templates.mb*atlases) %% 2 == 1), 
       aes(x=templates.mb, y=k_diff, colour=as.factor(atlases))) + 
  #facet_grid(reg_method~method.y) + 
  stat_summary(fun.data=mean_cl_boot,geom='errorbar',
               aes(y=k_diff,colour=as.factor(atlases), width=0.2)) +
  stat_summary(fun.y=mean, geom="point", 
               aes(y=k_diff,colour=as.factor(atlases))) + 
  stat_summary(fun.y=mean, geom="line", 
               aes(y=k_diff,colour=as.factor(atlases))) + 
  #stat_smooth(method=lm, formula=y~log(x)) + 
  geom_hline(aes(alpha=0.5, yintercept=0), linetype='dashed') + 
  scale_x_continuous(breaks=seq(1,20,2)) + scale_y_continuous(breaks=seq(-1,1,by=0.01)) + 
  scale_colour_hue(name="Number of Atlases") +
  scale_alpha_continuous(guide = "none") + 
  scale_linetype_discrete(guide = "none") + 
  xlab( "Number of Templates" ) + 
  ylab( "Increase in mean similarity (DSC)" ) +
  theme(legend.direction = "horizontal", legend.position = "bottom")
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ADNI1-XVAL: show variability of MAGeT over parameters
<<fig:ADNI1-xval-variability,dependson='load',fig.show='hide'>>=
ants = subset(jens_xval_data, 
                     reg_method=="ANTS" & 
                     method.mb=="Majority Vote" &
                    templates.mb %in% seq(1,20,2))

ants.stats = ddply(ants, c("subject", "label", "atlases","templates.mb"), 
                   function (df) {
                     data.frame(
                       MA.sd  =  sd(df$k.ma),
                       MB.sd  =  sd(df$k.mb),
                       MA.var = var(df$k.ma),
                       MB.var = var(df$k.mb)
                       )
                   })

stats.tests = ddply(ants.stats, c("atlases","templates.mb"), function (df) {
  t.var = t.test(df$MA.var, df$MB.var)
  t.sd  = t.test(df$MA.sd , df$MB.sd)
  diff_mean_var = mean(df$MA.var - df$MB.var)
  diff_mean_sd  = mean(df$MA.sd -  df$MB.sd)
  
  # test statistic is positive if MA mean is larger than MB
  # i.e. that MA has a greater mean of variances/SDs
  # i.e. that MB has a smaller mean, and so is doing "better"
  data.frame(
    stat      = c("Variance", "Standard Deviation"),
    statistic = c(t.var$statistic, t.sd$statistic),
    p.value   = c(t.var$p.value, t.sd$p.value),
    direction = c(diff_mean_var, diff_mean_sd)
  )
})

ggplot(subset(stats.tests, direction > 0 & stat == "Variance"), 
  aes(x=templates.mb, y=p.value, colour=as.factor(atlases))) + 
  #facet_grid( . ~ stat) + 
  geom_line(size=0.5) +
  geom_point(size=2) + 
  geom_hline(aes(yintercept=0.05, alpha=0.5), linetype='dashed') + 
  geom_hline(aes(yintercept=0.01, alpha=0.5), linetype='dashed') + 
  scale_x_continuous(breaks=seq(1,20,by=2)) + 
  xlab( "Number of Templates" ) + 
  ylab( "Variability (p)") +
  scale_colour_hue(name="Atlases") +
  scale_alpha_continuous(guide='none') + 
  scale_linetype_discrete(guide='none') + 
  scale_size_continuous(guide='none') + 
  theme(legend.direction = "horizontal", legend.position = "bottom")
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure}
  \centering
  \begin{subfigure}[t]{\textwidth}
    \includegraphics[width=\textwidth]{figure/fig:ADNI1-xval-k-mean}
    \caption{DSC vs. atlas and template library size} 
    \label{fig:ADNI1-xval-k-mean}
  \end{subfigure}%
  \hfill
  \begin{subfigure}[b]{0.48\textwidth}
    \includegraphics[width=\textwidth]{figure/fig:ADNI1-xval-k-diff}
    \caption{Increase in similarity score over \multiatlas} 
    \label{fig:ADNI1-xval-k-diff}
  \end{subfigure}%
  \hfill
  \begin{subfigure}[b]{0.48\textwidth}
    \includegraphics[width=\textwidth]{figure/fig:ADNI1-xval-variability}
    \caption{Difference in variability with \multiatlas} 
    \label{fig:ADNI1-xval-variability}
  \end{subfigure}
  \caption{\textbf{Whole hippocampus segmentation cross-validation on
  ADNI subjects with \psegs{}.}
(\ref{fig:ADNI1-xval-k-mean}) Average DSC score of \mb{} with manual
  segmentations for 60 ADNI subjects taken over 10 folds of
  cross-validation at each parameter setting. Error bars indicate standard
  error. 
(\ref{fig:ADNI1-xval-k-diff}) Increase in DSC of \mb{} over \multiatlas{}
  segmentations. 
(\ref{fig:ADNI1-xval-variability}) shows the significance of t-tests comparing
  the variability in DSC scores of \mb{} and \multiatlas{} across validation
  folds. Only points where \mb{} mean variability is lower than \multiatlas{} are
  shown. Dashed lines indicate p-values of 0.05 and 0.01.}
\end{figure}

%
%-------------------------------------------------------------------------------
%

\FloatBarrier
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                                                                     %%%%%
%%%%%         Experiment 2: Application of \mb{} to the segmentation      %%%%%
%%%%%                       of Psychosis patients                         %%%%%
%%%%%                                                                     %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{\expfepxval{}: \expfepxvaldesc{}}
\label{exp:fep-xval}
To validate that the \mb{} works effectively in the context of other
neurological disorders, in this experiment we replicate the cross-validation
done in \expadnixval{} with a dataset of patients having had a single episode of
psychosis. We also compare \mb{} segmentations with those of two well-known
automated segmentation methods, \fsl{} and \freesurfer{}. 

\subsubsection{\expfepxval{}: Materials and Methods}
\paragraph{First Episode Psychosis (FEP) Dataset}
All patients were recruited and treated through the Prevention and Early
Intervention Program for Psychoses (PEPP-Montreal), a specialized early
intervention service at the Douglas Mental Health University Institute in
Montreal, Canada. People aged 14 to 35 years from the local catchment area
suffering from either affective or non-affective psychosis who had not taken
antipsychotic medication for more than one month with an IQ above 70 were
consecutively admitted as either in- or out-patients. Of those treated at PEPP,
only patients aged 18 to 30 years with no previous history of neurological
disease or head trauma causing loss of consciousness were eligible for the
neuroimaging study; only those suffering from schizophrenia spectrum disorders
were considered for this analysis. For complete program details see
\citet{Malla2003}. 

Scanning of 81 subjects was carried out at the Montreal Neurological Institute
on a 1.5-T Siemens whole body MRI system. Structural T1 volumes were acquired
for each participant using a three-dimensional (3D) gradient echo pulse sequence
with sagittal volume excitation (repetition time=22ms, echo time=9.2ms, flip
angle=$30^{\circ}$, 180 1mm contiguous sagittal slices). The rectangular
field-of-view for the images was 256mm (SI)$\times$204mm (AP). Subject
demographics are shown in Table \ref{tab:SZFEP-Demographics}. 

Expert whole hippocampal manual segmentation of each subject is produced
following a validated segmentation protocol \citep{Pruessner2000}. 

\paragraph{Winterburn Atlases} 
The Winterburn atlases \citep{Winterburn2013} are digital hippocampal
segmentations of five in-vivo $0.3mm$-isotropic T1-weighted MR images. The
segmentations include subfield segmentations for the cornu ammonis (CA) 1; CA2
and CA3; CA4 and dentate gyrus; subiculum; and strata radiatum (SR), strata
lacunosum (SL), and strata moleculare (SM). Subjects in the Winterburn atlases
range in age from 29-57 years (mean age of 37), and include two males and three
females. 

\paragraph{Experiment details} 
The same overall design as \expadnixval{} is followed in this experiment: a
Monte Carlo cross-validation (MCCV) is conducted using the pool of 81 first
episode psychosis subject brain images and corresponding \prsnr-protocol manual
segmentations. Five rounds of validation are conducted for each subject, and
each atlas and template library size combination (1-9 atlases, 1-19 templates).
In each round, images and their manual labels are randomly selected from the
pool, and the remaining images are segmented using \mb{} with a random subset of
the unlabelled images also serving as template images. Majority vote fusion, and
the \ants{} registration algorithm are used, as these have shown to behave
favourably in previous experiments.

In addition to the MCCV, we segment the entire first episode psychosis dataset
using \mb{} using two different atlases, as well as two popular automated
segmentation packages, \fsl{} and \freesurfer{}. Specifically, \mb{} is run once
with the five Winterburn atlas images and labels as atlases and a randomly selected
subset of 19 target images as templates. \mb{} is run a second time using
the same template images, but we using five additional first
episode psychosis subjects and corresponding manual segmentations (not included
above) as atlases. \fsl{} and \freesurfer{} are run with the default settings:
\fsl{} \verb+run_first_all+ script was used according to the FIRST user guide
\footnote{http://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FIRST/UserGuide}, and
\freesurfer{} was run with the command \verb+recon-all -all+. 

\paragraph{Evaluation method}
Manual and automated segmentations are directly compared using Dice's similarity
coefficent (DSC). In the MCCV, the per-subject DSC value is computed as the
average value over the five rounds of validation for a given atlas and template
library size. The reported average DSC value per given atlas and template
library size is the average DSC value over all subjects segmented. 

The \prsnr{} segmentation protocol differs slightly from the Winterburn
protocol, and those used by \freesurfer{} and \fsl{}, in the inclusion of
neuroanatomical features and the manner they are delineated (see
\citet{Winterburn2013}, and Table \ref{tab:subfield-segmentation-protocols} in
the Discussion below). This variation in protocol poses a problem if an overlap
measure is used for evaluation: since different protocols will necessarily
produce segmentations that do not perfectly overlap, the degree of overlap
cannot be solely used to compare segmentation methods using different protocols.
In place of an overlap metric, we assess the degree of (Pearson) correlation in
average bilateral hippocampal volume produced by each method. Additionally, we
evaluate the volume-related fixed and proportional biases in all segmentation
methods using Bland-Altman plots \citep{Bland1986}. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% First Episode Psychosis Demographics Table
%
<<tab:FEP-SZ-demographics, echo=F, results="asis",cache=FALSE>>=
caption = 
  "\\textbf{First Episode Psychosis Subject Demographics.}
  ambi - ambidextrous. 
  SES  - Socioeconomic Status score. 
  FSIQ - Full Scale IQ.
"
fep_sz_demographics = read.csv("data/SZ_demographics.csv", na.strings=c("","."))
fep_sz_demographics = subset(fep_sz_demographics, Anon <= 81)
tab <- summary(DX ~ Age + Gender + Handedness + Education + SES + FSIQ,
               data=fep_sz_demographics, method = "reverse", test = FALSE)
latex(tab, file="", size="scriptsize",landscape=FALSE, ctable=FALSE,
      caption=caption, caption.loc = c("top"),
      title="tab:SZFEP-Demographics")
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%
%-------------------------------------------------------------------------------
%

\FloatBarrier
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%    RESULTS: Experiment 2, Application of \mb{} to the segmentation  %%%%%
%%%%%                       of psychosis patients                         %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{\expfepxval{}: Results}

As in \expadnixval, we find that similarity score increases with a greater
number of atlases or templates but quickly plateaus (Figure \ref{fig:FEP-xval}).
A maximum similarity score of \Sexpr{fep.mb.kappa.best} is found when using 9
atlases, 19 templates, ANTS registration, and majority vote label fusion. 

We found a close relationship in average hippocampal volume between the manual
label volumes and \mb{} when using the Winterburn atlases, or manually segmented
FEP subjects as atlases (Figure \ref{fig:FEP-vols}). Both sets of volumes are
correlated with Pearson $r > 0.88$. \freesurfer{} and \fsl{} volumes are both
correlated with manual volumes at Pearson $r > 0.7$.

As \citet{Bland1986} noted, high correlation amongst measures of the same
quantity does not necessarily imply agreement (as correlation can be driven by a
large range in true values, for instance). Figure \ref{fig:FEP-Bland-Altman}
shows Bland-Altman plots illustrating the level of agreement of each method with
manual volumes. All methods show an obvious proportional bias: \freesurfer{}
and \fsl{} markedly underestimate smaller hippocampi and over-estimate large
hippocampi (the limits of agreement are between $-2482mm^3$ and $-784mm^3$, and
between $-1653mm^3$ and $79mm^3$, respectively), whereas both \mb{} methods show
a much less exaggerated, but conservative bias (limits of agreement between
$-67mm^3$ and $766mm^3$ when using FEP atlases, and between $-333mm^3$ and
$504mm^3$ when using Winterburn atlases). On average, \freesurfer{} and \fsl{}
overestimate hippocampal volume by about $1600 mm^3$ and $800 mm^3$,
respectively. In contrast, on average \mb{} underestimates volumes by about
$300mm^3$ when using FEP atlases and by about $80mm^3$ when using Winterburn
atlases (compared to the \psegs).
 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% FEP-XVAL: mean Kappa plot by atlases, templates, reg and voting method. 
<<fig:FEP-xval,fig.show='hide',dependson='load'>>=
  stderr <- function(x) sqrt(var(x)/length(x))
  ggplot(fep.xval.mean, aes(x=templates,y=k, colour=atlases)) + 
    stat_summary(fun.y=mean,geom='line', aes(y=k,weight=1,group=atlases)) + 
    stat_summary(fun.y=mean,geom='point',aes(y=k,weight=1,group=atlases)) + 
    stat_summary(fun.y=mean,
                 fun.ymin=function (x) mean(x) - stderr(x),
                 fun.ymax=function (x) mean(x) + stderr(x), 
                 geom='errorbar',aes(y=k, weight=1, group=atlases), 
                 linetype='solid', width=0.5) + 
    #stat_smooth(method='lm', formula=y~log(x)) + 
    scale_y_continuous(breaks=seq(0,1,0.01)) + 
    scale_colour_hue(name="Number of Atlases") +
    scale_linetype(name="Registration Method") +
    xlab( "Number of Templates" ) + 
    ylab( "Mean similarity (DSC)" ) + 
    theme(legend.direction = "horizontal", legend.position = "bottom") 
@

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% FEP-volumes
<<fig:FEP-vols,fig.show='hide'>>=
  fep.raw.volumes=read.csv('data/SZ_vol_by_method.csv')
  fep.raw.volumes=subset(fep.raw.volumes, SID <= 81)
  fep.raw.volumes=melt(fep.raw.volumes, id.vars=c('SID','Method')) 
  fep.volumes = dcast(fep.raw.volumes, SID~Method, value.var="value", fun.aggregate=mean)
  fep.volumes = melt(fep.volumes, id.vars=c('SID', 'manual'), variable.name='Method', value.name='volume')

  fep.lm = ddply(fep.volumes,c("Method"), function (df) {
    data.frame(eqn=lm_eqn(lm(manual ~ volume, df)))})
  fep.lm$y = 6900-0:3*150

  ggplot(data=fep.volumes, aes(x=manual, y=volume, colour=Method)) + 
    geom_smooth(method="lm", formula=y~x) + 
    geom_point() + 
    geom_text(aes(x=3350,y=y,label=eqn),parse=T,data=fep.lm,
        size=3,hjust=0) +
    xlab(expression("Mean manual hippocampus volume " (mm^3))) + 
    ylab(expression("Mean computed hippocampus volume "  (mm^3))) + 
    theme(legend.direction = "horizontal", legend.position = "bottom")
@

<<fig:FEP-Bland-Altman,dependson='fig:FEP-vols',fig.width=10,fig.height=6,fig.show='hide'>>=
fep.volumes$diff = fep.volumes$manual - fep.volumes$volume
fep.volumes$mean = (fep.volumes$manual + fep.volumes$volume)/2
limits = ddply(fep.volumes, c("Method"), function (df) { 
  data.frame(
    y = mean(df$diff,na.rm=T) + c(-1.96,0,2) * sd(df$diff,na.rm=T) 
)}) 

ggplot(fep.volumes, aes(x= mean, y = diff)) + 
  facet_wrap( ~ Method, nrow=2, scales="fixed") + 
  geom_smooth(method="lm", formula=y~x, fullrange=T, se=F) + 
  scale_shape_discrete(solid=F,legend=F) + 
  geom_point(size=2,mapping=aes(shape=1)) +  
  geom_hline(aes(yintercept = y), linetype="dashed", colour="brown",
             data=limits, size=0.3, alpha=0.5) + 
  geom_text(aes(y = y, x=Inf, label=round(y,0)), colour="black", data = limits,
            hjust=1.1,vjust=-0.8, size=2.5) + 
  xlab(expression('Mean manual and computed volume ' (mm^3))) + 
  ylab(expression('manual - computed volume ' (mm^3))) + 
  scale_y_continuous(breaks=seq(-10000,4000, 1000)) + 
  scale_x_continuous(breaks=seq(0,10000, 1000)) + 
  theme(legend.direction = "horizontal", legend.position = "bottom", 
        axis.text.y = element_text(angle = 90, hjust=0.5), 
        axis.text = element_text(size = 8))
@


\begin{figure}
  \centering
  \begin{subfigure}[t]{0.48\textwidth} 
    \includegraphics[width=\textwidth]{figure/fig:FEP-xval}
    \caption{Dice's similarity score vs. atlas and template library size} 
    \label{fig:FEP-xval}
  \end{subfigure}%
  \hfill
  \begin{subfigure}[t]{0.48\textwidth}
    \includegraphics[width=\textwidth]{figure/fig:FEP-vols} 
    \caption{Computed vs. manual hippocampus volume} 
    \label{fig:FEP-vols}
  \end{subfigure}
  \begin{subfigure}[b]{\textwidth}
    \includegraphics[width=\textwidth]{figure/fig:FEP-Bland-Altman}
    \caption{Bland-Altman plots of computed vs. manual hippocampus volume} 
    \label{fig:FEP-Bland-Altman}
  \end{subfigure}
  \caption{\textbf{First Episode Patient dataset validation.}
  All manual segmentation of the 81 subjects is done with the \prsnr-protocol.
  \mb{} uses \ants{} registration and majority vote label fusion. 
(\ref{fig:FEP-xval}) shows mean DSC score of \mb{} segmentations, as atlas and
  template library size is varied over a 5-fold validation. Error bars indicate
  standard error. 
(\ref{fig:FEP-vols}) shows segmentation volumes from \fsl,
  \freesurfer, \mb{} using the five Winterburn atlases (MAGeT-Winterburn), and
  \mb{} using five manually segmented FEP subjects as atlases (MAGeT-FEP). Linear
  fit lines are shown, with the shaded region showing standard error.
(\ref{fig:FEP-Bland-Altman}) shows the agreement between computed and
  manually volumes. The overall mean difference in volume, and limits of
  agreement ($\pm 1.96SD$) are shown by dashed horizontal lines. Linear fit lines
  are shown for each diagnosis group. Note, points below the mean difference
  indicate overestimation of the volume with respect to the manual volume, and
  vice versa.}
\end{figure}

%
%-------------------------------------------------------------------------------
%

\FloatBarrier
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                                                                     %%%%%
%%%%%         EXPERIMENT 3: Application of \mb{} to the segmentation      %%%%%
%%%%%                       of ADNI subjects                              %%%%%
%%%%%                                                                     %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{\expadni{}: \expadnidesc{}}
\label{exp:adni}
To validate \mb{} segmentation quality with respect to other established
automated hippocampal segmentation methods, \mb{} was applied to a large dataset
from the ADNI project and the resulting segmentations were compared to those
produced by \freesurfer{}, \fsl{}, \maper{}, as well as semi-automated whole
hippocampal segmentations (\snt{}) provided by ADNI.

%%%%%%%%%%
\subsubsection{\expadni{}: Materials and Methods}

\paragraph{\adnidataset{} dataset}  %%%%%%%%%%%
The {\em \adnidataset{}} standardized dataset contains $1919$ images of subjects
diagnosed with Alzheimer's disease (AD), late-onset mild cognitive impairment
(LMCI), or who are identified as cognitively normal (CN). See Section
\ref{adnidataset} for study details, inclusion criteria and imaging
characteristics. 

Semi-automated segmentations of the left and right whole hippocampi are made
available with a subset of ADNI images \citep{Hsu2002}. These labels have been
generated using the \snt{} tool from Medtronic Surgical Navigation Technologies,
Louisville, CO (see Supplementary Materials for detailed discussion of the
segmentation process).  

\maper{} -- a \multiatlas segmentation tool , and \freesurfer{} hippocampal volumes for a subset of images were also
provided by ADNI, along with quality control data for each \freesurfer{}
segmentation (guidelines described in \citep{Hartig2010}). 

\paragraph{Experiment details} %%%%%%%%%%
\mb{} was configured with an atlas library composed of the five Winterburn atlas
images (\expfepxval, section \ref{exp:fep-xval}) and segmentations. A template
library of 19 images were randomly selected from the target dataset of ADNI
subjects, and \ants{} registration and majority vote label fusion were used as
these were found to perform favourably in earlier experiments. 

\fsl{} segmentation was performed using the \verb+run_first_all+ script
according to the FIRST user guide
\footnote{http://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FIRST/UserGuide}. All images in
the \adnidataset{} dataset were segmented by both methods. 

One author (MP) performed visual quality inspection for \mb{} and \fsl{}
segmentations using similar quality control guidelines (if either hippocampus
was under or over segmented by $10mm$ or greater in three or more slices then
the segmentation did not pass). Only images meeting the conditions of having
segmentations from all methods (\snt{}, \maper{}, \freesurfer{}, \fsl{}, and
\mb{}) and also passing similar quality control inspection were included in the
analysis. 

\paragraph{Evaluation method} %%%%%%%%%%
As in previous experiments, the Winterburn hippocampal segmentation protocol
differs in the delineated neuroanatomical features (\citet{Winterburn2013}, and
Table \ref{tab:subfield-segmentation-protocols}, Discussion) and so we assess
\mb{} by the degree of (Pearson) correlation of average hippocampal volume
across subjects. We also computed the correlation in hippocampal volume between
existing, established automated segmentation methods -- \fsl{}, \freesurfer{},
and \maper{}, and \snt{} semi-automated segmentations. Additionally, we evaluate
the volume-related fixed and proportional biases in all segmentation methods
using Bland-Altman plots \citep{Bland1986}. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                                             
% ADNI1 Complete 1Yr Dataset Demographics Table 
%                                                                             
<<tab:ADNI1-Dataset-Demographics, echo=F, results="asis",cache=FALSE>>=
# RID < 2000 ensures only ADNI1 patients
yr1 = read.csv("data/ADNI_baseline_volumes/ADNI1_Complete_1Yr_1.5T_11_15_2012.csv")
yr1$VISCODE <- factor(yr1$Visit, levels = c(1,2,3,4), labels=c("bl","m03","m06","m12"))
yr1 = subset(yr1, !grepl("Scaled_2", Description))
yr1 = yr1[,c("RID","VISCODE")]
yr1 = 
adnimerge.yr1 = merge(adnimerge, yr1) 
tab <- summary(DX.bl ~ AGE + PTGENDER + PTEDUCAT + CDRSB + ADAS13 +
               MMSE, data = adnimerge.yr1, 
               #subset = RID %in% yr1$RID & VISCODE %in% c('bl','m06','m12'),   
               method = "reverse", test=FALSE, overall=TRUE)
caption = 
  "\\textbf{ADNI1 1.5T Complete 1Yr dataset demographics.} 
  CN     - Cognitively Normal. 
  LMCI   - Late-onset Mild Cognitive Impairment. 
  AD     - Alzheimer's Disease. 
  CDR-SB - Clinical Dementia Rating-Sum of Boxes. 
  ADAS   - Alzheimer's Disease Assessment Scale. 
  MMSE   - Mini-Mental State Examination."
latex(tab, file="", size="scriptsize",landscape=FALSE, ctable=FALSE,
    caption=caption, caption.loc = c("top"),
    title="tab:ADNI1-Dataset-Demographics",
    label="tab:ADNI1-Dataset-Demographics")
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%
%-------------------------------------------------------------------------------
%

\FloatBarrier
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                           RESULTS                                   %%%%%
%%%%%         EXPERIMENT 3: Application of \mb{} to the segmentation      %%%%%
%%%%%                       of ADNI subjects                              %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{\expadni{}: Results}

We found a close relationship in total bilateral hippocampal volume between all
methods and the \snt{} semi-automated label volumes (Figure
\ref{fig:ADNI-volumes-plot}). Volumes are correlated with Pearson $r > 0.78$
for all methods across disease categories. Within disease categories (Figure
\ref{fig:ADNI-volumes-boxplot}), \mb{} is consistently well correlated to manual
volumes (Pearson $r > 0.85$), but appears to slightly over-estimate the volume
of the AD hippocampus. 

Bland-Altman plots illustrate the level of agreement of each method with \snt{}
segmentation hippocampal volumes (Figure \ref{fig:ADNI-Bland-Altman}). All
methods show an obvious proportional bias: \freesurfer{} and \fsl{} markedly
under-estimate smaller hippocampi and over-estimate large hippocampi, whereas
\maper{} and \mb{} show a reverse, conservative bias (Figure
\ref{fig:ADNI-Bland-Altman}). Additionally, all methods show a fixed volume
bias, with \freesurfer{} and \fsl{} most dramatically over-estimating
hippocampal volume by $2600 mm^3$ and $2800 mm^3$ on average, respectively, and
\maper{} and \mb{} within $250 mm^3$ on average. 

Figure \ref{fig:ADNI-segmentations} shows a qualitative comparison of \mb{} and
\snt{} hippocampal segmentations for 10 randomly selected subjects in each disease
category, and illustrates some of the common errors found during visual
inspection. Mostly frequently, we found \mb{} improperly includes the vestigial
hippocampal sulcus and, although not anatomically incorrect, \mb{}
under-estimates the hippocampal body in comparison to the \snt{} segmentation. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ADNI1 1yr Complete Dataset Package Totals & Failures
%                        
<<tab:ADNI-seg-package-totals, echo=F, results="asis",cache=FALSE>>=
package_totals$Total <- NULL
latex(package_totals, file="", size="scriptsize",landscape=FALSE, ctable=TRUE,
    caption="\\textbf{Number of segmented images and quality control failures of 
             \\adnidataset{} dataset by method.}", 
    caption.loc = c("top"), rowname=NULL, 
    label="tab:ADNI1-1.5T-Complete-1Yr-Dataset-Method-Totals")
@

%%%%%%%%%
% ADNI volumes by automated method
%%%%%%%%%
<<fig:ADNI-volumes-plot,dependson='load',fig.show='hide'>>=
melted=melt(means.complete, measure.vars=c("FS", "FSL", "MAPER","MAGeT"), 
            variable.name = "Method", value.name = "volume")

df = means.complete

levels(melted$Method) = c("FS"    = "FreeSurfer", 
                          "FSL"   = "FSL", 
                          "MAPER" = "MAPER", 
                          "MAGeT" = "MAGeT")

adni.volumes.lm = ddply(melted,c("Method"), function (df) {
  data.frame(eqn=lm_eqn(lm(volume ~ SNT, df)))})
adni.volumes.lm$y = 6450-0:3*300

ggplot(data=melted, aes(x=SNT, y=volume, colour=Method)) + 
    geom_point(size=1) + 
    geom_smooth(method="lm") + 
    xlab(expression("SNT mean hippocampus volume " (mm^3))) + 
    ylab(expression("Automated mean hippocampal volume " (mm^3))) +
    geom_text(aes(x=850,y=y,label=eqn),parse=T,data=adni.volumes.lm,
      size=2.5,hjust=0) +
    theme(legend.direction = "horizontal", legend.position = "bottom")
@


%%%%%%%%%
% ADNI volumes by disease group and method
%%%%%%%%%
<<fig:ADNI-volumes-boxplot,dependson='load',fig.show='hide'>>=
melted = melt(means.complete,measure.vars=c("FS", "FSL", "MAPER","MAGeT"),
              variable.name="Method", value.name="Volume")
correlations = ddply(melted, c("DX","Method"), function (df) {
  data.frame(
    pearson = cor(df$SNT, df$Volume)
  )
})
m2 = melt(means.complete,measure.vars=c("FS", "FSL", "MAPER","MAGeT","SNT"), variable.name="Method")
levels(m2$Method) = c("FS"    = "FreeSurfer", 
                      "FSL"   = "FSL", 
                      "MAPER" = "MAPER", 
                      "MAGeT" = "MAGeT", 
                      "SNT"   = "SNT")
m2$DX = factor(m2$DX, levels(m2$DX)[c(2,3,1)])

qplot(DX,value,data=m2,
      colour=Method,geom="boxplot") + 
      #geom_text(aes(y=-Inf,x=c(.7,.85,1,1.15, 1.7,1.85,2,2.15, 2.7,2.85,3,3.15), vjust=-5, label=round(pearson,2)), 
      #          colour = 'black', size=3, data=correlations) +
      xlab("Diagnosis") + 
      ylab(expression(paste("Hippocampal volume (", mm^3, ")"))) + 
      theme(legend.direction = "horizontal", legend.position = "bottom")
@
 
%%%%%%%%%
% ADNI Bland-Altman plots
%%%%%%%%%
<<fig:ADNI-Bland-Altman,dependson='load',fig.show='hide',fig.height=4,fig.width=10>>=
names(means.complete)[8] = "FreeSurfer"
melted=melt(means.complete, measure.vars=c("FreeSurfer", "FSL", "MAPER","MAGeT"), 
            variable.name = "method", value.name = "volume")

melted$diff = melted$SNT - melted$volume
melted = subset(melted, (method == "FreeSurfer") | 
                        (method == "FSL"  ) | # & diff > -5000 & diff < 900) | 
                        (method == "MAPER") | # & diff > -500 & diff < 1000) | 
                        (method == "MAGeT"))  # & diff > -1100))
#melted = subset(melted, method == "MAGeT")
melted$DX = factor(melted$DX, levels(melted$DX)[c(2,3,1)])
melted$mean = ( melted$SNT + melted$volume ) / 2
limits = ddply(melted, c("method"), function (df) { 
  data.frame(
    y = mean(df$diff) + c(-1.96,0,2) * sd(df$diff) 
)}) 

names(melted)[4] = "Diagnosis"
ggplot(melted, aes(x= mean, y = diff, colour=Diagnosis)) + 
  facet_wrap( ~ method, nrow=1, scales="fixed") + 
  geom_smooth(method="lm", formula=y~x, fullrange=T, se=F) + 
  geom_point(size=1) +  
  geom_hline(aes(yintercept = y), linetype="dashed", colour="brown",
             data=limits, size=0.3, alpha=0.5) + 
  geom_text(aes(y = y, x=Inf, label=round(y,0)), colour="black", data = limits,
            hjust=1.1,vjust=-0.8, size=2.5) + 
  xlab(expression('Mean of SNT and automated volume ' (mm^3))) + 
  ylab(expression('SNT - automated volume ' (mm^3))) + 
  scale_y_continuous(breaks=seq(-10000,4000, 1000)) + 
  scale_x_continuous(breaks=seq(0,10000, 1000)) + 
  theme(legend.direction = "horizontal", legend.position = "bottom", 
        axis.text.y = element_text(angle = 90, hjust=0.5), 
        axis.text = element_text(size = 8))
@

%%%%%%%%%
% Big figure combining the above three ADNI plots
%%%%%%%%%
\begin{figure}
  \centering
  \begin{subfigure}[t]{0.48\textwidth} 
    \includegraphics[width=\textwidth]{figure/fig:ADNI-volumes-plot}
    \caption{Computed vs. semi-automated (\snt) segmentation volume} 
    \label{fig:ADNI-volumes-plot}
  \end{subfigure}%
  \hfill
  \begin{subfigure}[t]{0.48\textwidth}
    \includegraphics[width=\textwidth]{figure/fig:ADNI-volumes-boxplot} 
    \caption{Hippocampal volume by diagnosis group and segmentation method} 
    \label{fig:ADNI-volumes-boxplot}
  \end{subfigure}
  \begin{subfigure}[b]{\textwidth}
    \includegraphics[width=\textwidth]{figure/fig:ADNI-Bland-Altman}
    \caption{Bland-Altman plots of computed vs. \snt{} hippocampus volume} 
    \label{fig:ADNI-Bland-Altman}
  \end{subfigure}
  \caption{\textbf{\adnidataset{} dataset segmentation.}
(\ref{fig:ADNI-volumes-plot}) Subject mean hippocampal volume as measured by
  each of the four automated methods (\freesurfer{} (FS), \fsl{},
  \maper{}, \mb{}) versus the semi-automated \snt{} segmentation volumes. Linear
  fit lines and Pearson correlations with \snt{} labels are shown for each method.
(\ref{fig:ADNI-volumes-boxplot}) Mean hippocampal volume by method and disease
  category. AD = Alzheimer's disease, LMCI = late-onset mild cognitive
  impairment, and CN = cognitively normal.
(\ref{fig:ADNI-Bland-Altman}) Bland-Altman plots comparing subject mean
  hippocampal volume as measured in the \adnidataset{} dataset by \snt{}
  segmentation and each automated methods. The overall mean difference in volume,
  and limits of agreement ($\pm 1.96SD$) are shown by dashed horizontal lines.
  Linear fit lines are shown for each diagnosis group. Note, points below the
  mean difference indicate overestimation of the volume with respect to the \snt{}
  volume, and vice versa.}
\end{figure}




\begin{figure}
  \centering
  \includegraphics[width=6in]{figure/ADNI1_SNT_MB_montage/montage.pdf}
  \caption{\snt{} and \mb{} segmentations for 30 ADNI subjects --- 10
  subjects randomly selected from each disease category in the subject pool used
  in \expadnixval{} (Section \ref{exp:adni-xval}. Sagittal slices are shown for
  each unlabelled T1-weighted anatomical image. \snt{} labels appear in green,
  and \mb{} labels appear in blue. Noted are examples of common segmentation
  idiosyncrasies: 
  {\em (a)} over-estimation of hippocampal head and  
  {\em (b)} translated segmentation (seen in \snt{} segmentations only); 
  {\em (c)} under-estimation of hippocampal body and
  {\em (d)} improper inclusion of the vestigial hippocampal sulcus by \mb{}.}
  \label{fig:ADNI-segmentations}
\end{figure}

%
%-------------------------------------------------------------------------------
%

\FloatBarrier
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                                                                     %%%%%
%%%%%        Experiment 4: Hippocampal Subfield Cross-Validation          %%%%%
%%%%%                                                                     %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{\expsubfield{}: \expsubfielddesc{}}
\label{exp:winterburn-xval}
The previous experiment assesses \mb{} performance on whole hippocampus
segmentation. In this experiment, we evaluate \mb{} hippocampal subfield
segmentation of standard 3T T1-weighted images at $0.9m^3$-isotropic voxels. We
use a modified leave-one-out cross-validation (LOOCV) design. 

\subsubsection{\expsubfield{}: Materials and Methods}

\paragraph{Winterburn Atlases}  %%%%%%%%%%
The Winterburn atlases \citep{Winterburn2013} are digital hippocampal
subfield segmentations of five in-vivo $0.3mm$-isotropic T1-weighted MR images,
described more fully in \expfepxval, section \ref{exp:fep-xval}. 


\paragraph{Healthy Control Dataset}  %%%%%%%%%%
T1 MR images of 14 subjects were acquired as a part of an ongoing study
at the Centre for Addiction and Mental Health (Table
\ref{tab:WAval-healthy-demographics}). Subjects were known to be free of
neuropsychiatric disorders and gave informed consent. These images were
acquired on a 3T GE Discovery MR 750 system (General Electric, Milwaukee, WI)
using an 8-channel head coil with the enhanced fast gradient recalled echo
3-dimensional acquisition protocol, FGRE-BRAVO, with the following parameters:
$TE/TR/TI = 3.0ms/6.7ms/650ms$, flip angle=$8^\circ$ , $FOV = 15.3cm$, slice
thickness$=0.9mm$, 170 in-plane steps for an approximate 0.9mm isotropic voxel
resolution. 

\paragraph{Experiment details} 
Leave-one-out cross-validation (LOOCV) is a validation approach in which an
algorithm is given all but one item in a dataset as training data (in our case,
atlas images and labels) and then the algorithm is applied to the left-out item.
This is done, in turn, for each item in the dataset and the output across all
items is evaluated together. 

In this experiment, the Winterburn atlases are resampled to $0.9mm$-isotropic
voxel resolution to simulate standard 3T T1-weighted resolution images. Image
subsampling is performed using trilinear subsampling techniques. In each round
of LOOCV, a single atlas image is selected and treated as a target image to be
segmented by \mb{}. So as to have an odd-sized atlas library, atlas image is
segmented once using each possible triple of atlas images, and corresponding
manual segmentations, from the remaining four unselected atlases. Thus, for
each of the five atlases, a total of ${3 \choose 4}=4$ segmentations are
evaluated, resulting in a combined total of $5\times4=20$ segmentations
evaluated overall. We chose an atlas library with an odd number of images so as
to ensure unbiased label fusion when using majority voting (see Discussion). 

The template library used has a total of 19 images composed of all five
resampled atlas images plus the additional 14 images from the healthy control
dataset. The \ants{} registration algorithm was used for image registration, and
majority voting was used for label fusion, as these methods proved most
favourable in the previous whole hippocampal validation experiments.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Subfield Validation Template library demographics (healthy controls)
%                                     
<<tab:WAval-healthy-demographics, echo=F, results="asis",cache=FALSE>>=
master = read.csv('data/DT_study.csv')
tab <- summary( Diagnosis ~ Age + Sex + Education + Handedness, data = master,
    method="reverse", na.rm = TRUE, test=FALSE)
caption = 
  "\\textbf{Demographics for the hippocampal subfield cross-validation healthy
control subject sample used in the template library (excluding the Winterburn
atlas subjects).} Education is shown in years."
latex(tab, file="", size="scriptsize",landscape=FALSE, ctable=FALSE,
      caption=caption, caption.loc = c("top"),
      title="tab:WAval-healthy-demographics")
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\paragraph{Evaluation method}  
Evaluating the agreement of automated hippocampal subfield segmentations with
manual segmentations for T1 images at $0.9mm^3$-isotropic voxels is inherently
ill-defined since there are no manual protocols for segmentation at this
resolution. Instead, we must evaluate the reliability, or {\it precision}, with
which \mb{} produces hippocampal subfields segmentations at this resolution that
correspond in form to the segmentation protocol used by the given
high-resolution atlas library images. 

By directly resampling the Winterburn atlas segmentations to $0.9mm^3$ voxels
(using standard nearest-neighbour image resampling techniques) we obtain a
subsampled version of the labels which preserve the original segmentation
protocol within the limits of error from rounding and interpolation. Therefore,
using the resampled Winterburn segmentations as definitive for the $0.9mm^3$
resolution we evaluate reliability of \mb{} segmentations using DSC overlap
scores and evaluate consistency across the range of hippocampal sizes using
Bland-Altman plots of subfield volumes. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%    RESULTS: Experiment 4: Hippocampal Subfield Cross-Validation     %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{\expsubfield{}: Results}

%%%%%%%%%%
% Winterburn xValidation Kappas
%%%%%%%%%%
<<fig:WAxval-kappa,fig.show='hide'>>=
wa.n.sim = read.csv('data/winterburn.xval.similarity.csv')
wa.n.sim.whole = read.csv('data/winterburn.xval.similarity.whole.csv')
wa.n.sim.whole$label = as.factor(wa.n.sim.whole$label)
levels(wa.n.sim.whole$label) <- list(
  "Whole"=1,
  "Whole"=2)
wa.n.sim.whole$res='0.9'
wa.n.sim.whole=wa.n.sim.whole[c('atlases','subject','res','label','k','se','sn','j')]

wa.n.sim$label = as.factor(wa.n.sim$label)
levels(wa.n.sim$label) <-list(
  "CA1"=1, "CA1"=101, 
  "CA2/CA3"=5,"CA2/CA3"=105, 
  "CA4/DG"=4,"CA4/DG"=104, 
  "Subiculum"=2,"Subiculum"=102, 
  "SR/SL/SM"=6,"SR/SL/SM"=106)

wa.n.sim = rbind(wa.n.sim, wa.n.sim.whole)

# kappa vs. region
ggplot(wa.n.sim, aes(x=as.factor(label),y=k)) + 
  geom_boxplot(fill='lightblue') + 
  scale_y_continuous(breaks=seq(0,1,0.1)) +
  xlab("Subregion") + 
  ylab("Dice's Similarity Coefficient (DSC)")

CA1   = subset(wa.n.sim,label=='CA1')$k
CA23  = subset(wa.n.sim,label=='CA2/CA3')$k
CA4DG = subset(wa.n.sim,label=='CA4/DG')$k
Sub   = subset(wa.n.sim,label=='Subiculum')$k
SRLM  = subset(wa.n.sim,label=='SR/SL/SM')$k
Whole = subset(wa.n.sim,label=='Whole')$k
@

Figure \ref{fig:WAxval-kappa} shows the overlap similarity scores between the
\mb{} segmentations and the resampled Winterburn atlases for each hippocampal
subfield across all subjects and folds of the validation. Mean and standard
deviation DSC scores of the subfields are shown in Table
\ref{tab:WAxval-perturb-kappa}, along with DSC scores for the resampled atlas
segmentations when perturbed slightly and compared to the originals. We find
that the CA4/DG subfield shows the highest mean DSC score of
\Sexpr{mean(CA4DG)}$\pm$\Sexpr{sd(CA4DG)}, followed by the Subiculum and CA1
subfields having scores of \Sexpr{mean(CA1)}$\pm$\Sexpr{sd(CA1)} and
\Sexpr{mean(Sub)}$\pm$\Sexpr{sd(Sub)}, respectively. Both the CA4/DG and
molecular regions score below 0.5. These scores may seem low but not when taken
in context and compared to existing (semi-)automated methods (see Discussion).
The whole hippocampus is segmented with a mean DSC score
of\Sexpr{mean(Whole)}$\pm$\Sexpr{sd(Whole)}.

%%%%%%%%%%
% Winterburn Bland-Altman
%%%%%%%%%%
<<fig:WAxval-Bland-Altman,fig.width=10,fig.show='hide'>>=
wa.n.vol = read.csv('data/winterburn.xval.volumes.csv') # xval volumes
winterburn = read.csv('data/winterburn.volumes.csv')    # resampled volumes
subfield_labels <-list(
  "CA1"="X1", "CA1"="X101", 
  "CA2/CA3"="X5","CA2/CA3"="X105", 
  "CA4/DG"="X4","CA4/DG"="X104",
  "Subiculum"="X2","Subiculum"="X102",
  "SR/SL/SM"="X6","SR/SL/SM"="X106", 
  "Whole" = "left", "Whole" = "right")
hemispheres <- list(
  "Right"="X1","Left"="X101", 
  "Right"="X5","Left"="X105", 
  "Right"="X4","Left"="X104",
  "Right"="X2","Left"="X102",
  "Right"="X6","Left"="X106",
  "Right"="right","Left"="left")


# compute whole hippocampal volumes (we do this the stupid way)
wa.n.vol = within(wa.n.vol, {
  right = X1+X2+X4+X5+X6
  left  = X101+X102+X104+X105+X106
  })
winterburn = within(winterburn, {
  right = X1+X2+X4+X5+X6
  left  = X101+X102+X104+X105+X106
  })

wa.n.vol.melt = melt(wa.n.vol, id.vars=c('atlases','subject','res'))
winterburn.melt = melt(winterburn, id.vars=c('subject','res'))
winterburn.cast = dcast(winterburn.melt, subject + variable ~ res)
wa.n.all.vols = merge(wa.n.vol.melt, winterburn.cast, by=c('subject','variable'))

levels(wa.n.all.vols$subject) <- list(
  "1"="anusha", 
  "2"="jon",
  "3"="mallar",
  "4"="sofia",
  "5"="nancy")

# mean per subfield/hemisphere across all 4 validation folds
wa.n.mean.vols = ddply(wa.n.all.vols, c("variable", "subject", "res"), function(df) {
  data.frame(mb    = mean(df$value),
             high  = mean(df$'0.3'),
             low   = mean(df$'0.9'))
})
wa.n.mean.vols$diff = wa.n.mean.vols$low - wa.n.mean.vols$mb
wa.n.mean.vols$mean = (wa.n.mean.vols$low + wa.n.mean.vols$mb)/2
wa.n.mean.vols$hemisphere        <- wa.n.mean.vols$variable
levels(wa.n.mean.vols$variable)  <- subfield_labels


wa.n.all.vols$diff = wa.n.all.vols$'0.9' - wa.n.all.vols$value
wa.n.all.vols$mean = (wa.n.all.vols$'0.9' + wa.n.all.vols$value)/2
wa.n.all.vols$Hemisphere        <- wa.n.all.vols$variable
levels(wa.n.all.vols$variable)   <- subfield_labels
levels(wa.n.all.vols$Hemisphere) <- hemispheres

wa.n.xval.bland.limits = ddply(wa.n.mean.vols,c("variable"),function(df) {
  data.frame(y = mean(df$diff,na.rm=T) + c(-1.96,0,2) * sd(df$diff,na.rm=T))
})

ggplot(wa.n.all.vols, aes(x=mean, y=diff)) + 
  facet_wrap(~variable, ncol=3, scales='free_x') + 
  geom_smooth(method="lm", formula=y~x, fullrange=T, se=F) + 
  geom_point(size=2) +  
  geom_hline(aes(yintercept = y), linetype="dashed", colour="brown",
             data=wa.n.xval.bland.limits, size=0.3, alpha=0.5) + 
  geom_text(aes(y = y, x=Inf, label=round(y,0)), colour="black", 
             data = wa.n.xval.bland.limits, hjust=1.1,vjust=-0.8, size=2.5) + 
  xlab(expression('Mean of resampled and MAGeT-Brain subfield volume ' (mm^3))) + 
  ylab(expression('Difference of manual and MAGeT-Brain subfield volume ' (mm^3))) + 
  #scale_x_continuous(limits=c(0,1000)) + 
  #scale_color_discrete(name="") + 
  scale_shape_discrete(name='Subject') + 
  theme(legend.direction = "horizontal", legend.position = "bottom", 
        axis.text.y = element_text(angle = 90, hjust=0.5), 
        axis.text = element_text(size = 8))
@

\begin{figure}
  \centering
  \begin{subfigure}[t]{\textwidth}
    \centering
    \includegraphics[height=3in]{figure/fig:WAxval-kappa}
    \caption{DSC score by subfield}
    \label{fig:WAxval-kappa}
  \end{subfigure}\hfill
  \begin{subfigure}[b]{\textwidth}
    \includegraphics[width=\textwidth]{figure/fig:WAxval-Bland-Altman}
    \caption{Bland-Altman plots of computed vs. manual subfield volumes}
    \label{fig:WAxval-Bland-Altman}
  \end{subfigure}
  \caption{\textbf{Hippocampal subfield cross-validation.}
(\ref{fig:WAxval-kappa}) Similarity of \mb{} segmentation of subfields and the
  resampled Winterburn atlas segmentations at $0.9mm^3$ voxel resolution, over all
  validaiton folds. Overlap score for each hemisphere is measured separately.
(\ref{fig:WAxval-Bland-Altman}) shows the agreement, by subfield, of computed
  and manual volumes across all validation folds. The overall mean difference in
  volume, and limits of agreement ($\pm 1.96SD$) are shown by dashed horizontal
  lines. Linear fit lines are shown. Note, points below the mean difference
  indication overestimation of the volume with respect to the resampled volume,
  and vice versa.}
\end{figure}

Figure \ref{fig:WAxval-Bland-Altman} contains Bland-Altman plots comparing \mb{}
volumes with manual volumes across all validation folds. \mb{} displays a
conservative proportional bias --- small hippocampi are overestimated in volume,
and larger hippocampi are underestimated 
(a mean maximum difference of approximately $200mm^3$ across all subfields).
\mb{} display a slight conservative fixed bias, tending to underestimate all
subfields except CA4/DG (mean underestimation: $CA1=76mm^3$, $CA2/3=56mm^3$,
$CA4/DG=-16mm^3$, $Subiculum=48mm^3$, $SR/SL/SM=96mm^3$). 

<<tab:WAxval-perturb-kappa, echo=F,results="asis">>=
wa.perturb = read.csv('data/winterburn.perturb.kappa.csv')
wa.perturb = wa.perturb[c("subject","label","operation","k")]
wa.perturb$label = as.factor(wa.perturb$label)
levels(wa.perturb$label) <-list(
  "CA1"="1", "CA1"="101",  "CA2/CA3"="5","CA2/CA3"="105",
  "CA4/DG"="4","CA4/DG"="104",  "Subiculum"="2","Subiculum"="102", 
  "SR/SL/SM"="6", "SR/SL/SM"="106")
mean_range = function (v) {
  sprintf("$%0.2f \\pm %0.2f$", mean(v), sd(v))
}
wa.perturb.table = dcast(wa.perturb, label ~ operation, fun.aggregate=mean_range)
wa.sim.sum = dcast(wa.n.sim, label ~ ., value.var = 'k', fun.aggregate=mean_range)
names(wa.sim.sum)[2] = 'MAGeT'
wa.perturb.table = merge(wa.perturb.table, wa.sim.sum)

wa.perturb.table=wa.perturb.table[c('label','MAGeT', 'translate','contract','expand')]
names(wa.perturb.table) = c("Subfield", "MAGeT", "0.9mm translation", "0.99 scaling", "1.01 scaling")
wa.perturb.table=wa.perturb.table[c(1,2,3)] # remove scaling results

caption="Overlap similarity results for the each of the subfields of the hippocampus. 
Simulated overlap similarity results are also given for resampled labels that were 
translated by one voxel (i.e.: $0.9mm$) in all directions. Values are given as
mean Dice's Similarity Coefficient (DSC) $\\pm$ standard deviation"
latex(wa.perturb.table, file="", size="scriptsize",landscape=FALSE, ctable=F,
      caption=caption, caption.loc = c("top"),
      col.just=rep('c',5),  
      label="tab:WAxval-perturb-kappa", rowname=NULL)
@

Figure \ref{fig:subfield-montage} shows slices subfield segmentations for a
single subject for qualitative inspection. 

\begin{figure}
    \centering
    \includegraphics[width=5in]{figure/winterburn-atlas-montage/figure.pdf}
    \caption{\textbf{Detailed subfield segmentation results for a single subject.} In
    the upper left corner is the original high-resolution Winterburn atlas manual
    subfield segmentation; in the upper right corner is the Winterburn atlas
    segmentation subsampled from 0.3mm- to 0.9mm-isotropic voxels; in the lower left
    corner is the \mb{} segmentation of the subsampled Winterburn atlas image
    from a single fold of the cross-validation. In each segmentation, slices from the left
    hemisphere are shown in Talairach-like ICBM152 space: the first row shows axial
    slices from inferior to superior; the second row shows sagittal slices from
    lateral to medial; the third row shows coronal slices from anterior to
    posterior. \label{fig:subfield-montage}}
\end{figure}

%
%-------------------------------------------------------------------------------
%

\FloatBarrier
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                Discussion
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Discussion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Tabulation of segmentation accuracies of existing methods (ADNI)
%
%
\begin{sidewaystable}[!tbp]
\scriptsize
\caption{\textbf{Automated segmentation accuracy of the Hippocampus} 
This table shows the best published Dice's overlap measure between automated and
ground truth segmentations. Unless otherwise specified,
validation datasets are composed equally of cases and control subjects, and use
manual segmentation labels as ground truth in computing DSC scores. AD =
Alzheimer's Disease; MCI = Mild Cognitive Impairment; CN = Cognitively Normal
(CN); FEP = First Episode of Psychosis; LOOCV = Leave-one-out cross-validation; MCCV
= Monte Carlo cross-validation; SNT = Surgical Medtronic Navigation Technologies
semi-automated labels. Some studies of automated segmentation of ADNI images
are excluded because they do not not provide overlap measures for the
hippocampus \citep{Heckemann2011,Chupin2009}.
  \label{tab:other-methods}} 
\begin{center}
\begin{tabular}{ p{1.2in}  c  p{1.1in} l  p{3.2in} p{1in} }
\hline\hline
Method & Atlases & DSC \newline {\tiny mean (AD; MCI; CN)} & Reference & Validation & Dataset (Truth)\tabularnewline
\hline
%%  
\mb{}                     &9 & \Sexpr{snt.mb.kappa.best} &
& 10-fold MCCV on 69 subjects 
& ADNI (SNT) 
\tabularnewline 
%%  
Patch-based label fusion  &16&0.861 {\tiny (0.838; ---; 0.883)} &\cite{Coupe2011e}
& LOOCV 
& ADNI (SNT) 
\tabularnewline
%%  
Multi-atlas               &20&0.848 {\tiny (---; 0.798, 0.898)} &\cite{Wang2011}  
& 10-fold MCCV on 20 of 139 subjects
& ADNI (SNT) 
\tabularnewline
%%  
ACM (AdaBoost-based)      &21&0.862                           &\cite{Morra2008} 
& LOOCV                                          
& ADNI (SNT)                                           
\tabularnewline                                  
%%                                               
LEAP                      &30&0.848                           &\cite{Wolz2010}  
& Segmentation of 182 subjects                   
& ADNI (SNT)                                           
\tabularnewline                                  
%%                                               
Multi-atlas               &30&0.885                           &\cite{Lotjonen2010}
& Segmentation of 60 subjects                    
& ADNI (SNT)                                           
\tabularnewline                                  
%%                                               
Multi-atlas (MAPS)        &55&0.890                           &\cite{Leung2010}
& Segmentation of 30 subjects (10 AD, MCI, and CN)
& ADNI (SNT) 
\tabularnewline

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\hline
%& & {\tiny mean (right; left)} & & & \tabularnewline
%\hline
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%
\mb{}                      &9 & \Sexpr{mb.kappa.best}       &
& 10-fold MCCV on 60 subjects 
& ADNI (\prsnr)
\tabularnewline 
\mb{}                      &9 & \Sexpr{fep.mb.kappa.best}   &
& 5-fold MCCV on 81 subjects 
& FEP subjects 
\tabularnewline 
%%
Neural nets                &10&0.740   &\cite{Powell2008} % {\tiny (0.72, 0.75)} 
& Segmentation of 5 subjects 
& controls %Other
\tabularnewline
%%
Probablistic atlas         &11&0.852   &\cite{VanderLijn2008}
& 11 atlases used in 100 rounds of LOOCV on 20 elderly subjects
& elderly controls %Other
\tabularnewline
%%
Probabilistic Atlas        &16&0.860   &\cite{Chupin2009}
& LOOCV 
& AD subjects %Other
\tabularnewline
%%
Anatomically-guided EM     &17&0.812   &\cite{Pohl2007} %{\tiny (0.815, 0.808)} 
& LOOCV on 17 controls, segmentation of 33 mixed subjects
& mixed diagnosis %Other
\tabularnewline
%%
Multi-atlas                &30&0.820   &\cite{Heckemann2006} %{\tiny (0.83, 0.81)}    
& LOOCV
& controls %Other
\tabularnewline
%%
Multi-atlas                &30&0.880   &\cite{Gousias2008} %{\tiny (0.88,---)}    
& 30 adult atlas used, segmentation of 33 2yr old subjects 
& 2yr old controls  %Other
\tabularnewline
%%
Multi-atlas                &80&0.890   &\cite{Collins2010}
& LOOCV                 
& controls %Other       
\tabularnewline
%%                      
Multi-atlas                &55&0.860   &\cite{Barnes2008}%{\tiny (---,0.86)}    
& LOOCV 
& controls and AD %Other
\tabularnewline
%%
Multi-atlas               &275&0.835   &\cite{Aljabar2009}% {\tiny (0.832, 0.837)} 
& LOOCV 
& controls %Other
\tabularnewline
\hline
\end{tabular}
\end{center}
\end{sidewaystable}

In this manuscript we have presented the implementation and validation of the
\mb{} framework -- a methodology that requires very few input atlases in order
to provide accurate and reliable segmentations. Both \expadnixval{} (Section
\ref{exp:adni-xval}) and \expfepxval (Section \ref{exp:fepi-xval}) compare \mb{}
to basic-\multiatlas{} segmentation by characterising the change in segmentation
quality with varying parameter settings (atlas and template library sizes,
registration method, and label fusion method) and differing age and
neuropsychiatric populations. Together, these experiments allow us to choose
optimal \mb{} parameter settings for use in subsequent experiments. \expadni{}
(Section \ref{exp:adni}) demonstrates that across
\Sexpr{length(means.complete$RID)} images from the \adnidataset{} dataset, \mb{}
performs as well as, or better, than other established and popular methods.
Finally, \expsubfield{} (Section \ref{exp:winterburn-xval}) demonstrates the
reliability of \mb{} in producing subfield segmentations which match the
segmentation protocol of the input atlases despite contrast and resolution
limitations in standard T1-weighted image volumes.  All of these experiments
together demonstrate that \mb's algorithmic performance is not dependent on a
single definition of the hippocampus but is effective with differing hippocampal
definitions \citep{Winterburn2013,Pruessner2000,Hsu2002}, across image types,
and subject populations. 

The core claim the \mb{} method is based on -- that we can meaningfully bootstrap
a template library from a small set of labelled atlas images -- is validated in
the cross validation conducted in \expadnixval{} (and the replication in in
\expfepxval{} and \expadnixvalsnt{}, Supplementary Materials). We find that both
increasing the number of atlases and the number of templates used improves \mb{}
segmentation over and above basic-\multiatlas{} segmentations using the same
number of atlas images. That is, by taking the extra step of generating a
template library using target images, \mb{} is able to improve the overlap
between the automatically generated segmentations and manually generated ``gold
standard'' segmentations. The magnitude of this improvement is greatest with a
small number of atlases, but even with larger atlas libraries we have found that
generating a template library reduces the variability in segmentation precision
(i.e. \mb{} more consistently produces high quality segmentations than does
basic-\multiatlas{} segmentation). These effects do not appear dependant on the
hippocampal segmentation protocol used. 

Interestingly, previous work on \multiatlas{} segmentation methods
\citep{Aljabar2009,Collins2010} has found that cross-correlation and normalized
mutual information-based weighted label fusion improves segmentation accuracy
over simple majority vote label fusion, and yet we did not see a significant
indication of this effect in the \mb{} segmentations. Selectively filtering out
atlases with lower image similarity is believed to reduce sources of error from
estimating deformations via nonlinear registration, partial volume effects from
nearest neighbour image resampling, and neuroanatomical mismatch between atlases
and subjects. That \mb{} does not see the same boost in performance from
weighted voting may suggest that the neuroanatomical variability of a template
library constructed from study subjects more closely matches any particular
subject and thereby leaving less error to filter. From our previous work on the
\mb{} algorithm we have shown that the reduction in error is not simply a
smoothing or averaging effect \citep{Chakravarty2013}.

Although, the goal of this manuscript was not to exhaustively test or validate
multiple different voting strategies in the context of our segmentation
algorithm, it is important to note that other strategies for voting are
available. For example, other groups have used the STAPLE algorithm
\citep{Warfield2004} (or variants of the STAPLE algorithm
\citep{Robitaille2012}) which weights each segmentation based upon its estimated
performance level with respect to the other available candidate segmentations.
Further, the sensitivity and specificity parameters can also be tuned to
potentially improve segmentation accuracy and reliability. It is likely that
using more sophisticated voting methods would have a positive effect on the
overall segmentation performance, as demonstrated by the STAPLE algorithm.
However, it is also important to note that even in the absence of a more
sophisticated label fusion algorithm, MAGeT Brain performs reasonably well in
comparison to other groups that have tested new segmentation algorithm with
Alzhiemer disease, mild cognitive impairment, and cognitively normal data from
the ADNI database (Table \ref{tab:other-methods}. In addition, our validation
in \expfepxval{} (with the first episode psychosis subjects) yields DSC's that
are amongst the highest reported. Thus, more work is required to determine the
extent to which label fusion will improve the accuracy of our algorithm.

More work is required to determine the source of the slight decrease in
segmentation performance when the number of templates are set to an even number.
Our initial concern was that this dip in performance was a by-product of the
\mb{} algorithm itself. However, this pattern is also found in the results
of the \multiatlas{} segmentations we used in our experiments. We believe that
our majority voting methodology is biased towards labels with the lowest numeric
values when breaking ties (by way of the implementation of the \verb+mode+
function used to determine majority), thus causing the slight bias observed when
using an even number of templates. This is another area where the voting scheme
could be used to improve performance. However, it is worth noting that this
limitation was previously identified by \citet{Heckemann2006a} and,
subsequently, other groups have not even considered the potential pitfalls of an
even number of candidate labels (e.g. \citet{Leung2010}).

Another concern is the moderate improvement observed in \mb{} in comparison to
\multiatlas{} segmentation when using the same number of atlases. The actual
benefit in using \mb{} is consistency of the labelling regardless of atlas or
template choice, as mentioned above. This is an important consideration that few
have touched on previously. The 10-fold Monte Carlo cross-validation that we
present in \expadnixval{} and \expfepxval{} is amongst one of the most stringent
performed in the \multiatlas{} segmentation literature. To the best of our
knowledge, with the exception of \citep{Wang2011}, other groups using ADNI data
for validation do at most a single round of leave-one-out-validation (Table
\ref{tab:other-methods}). The thoroughness of our validation suggests that our
results are reflective of a true average over the choice of parameter settings
and are independent of atlas or template choice (provided the input atlases are
consistently segmented). 

On that note, one author (JW), an expert manual rater \citep{Winterburn2013},
identified regular inconsistencies in the \snt{} segmentations: occurrences of
over- and under-estimation, as well as misalignments of the entire segmentation
volume (Figure \ref{fig:ADNI-segmentations}). Although the \snt{} segmentations
are used as benchmarks for validation in many other studies (Table
\ref{tab:other-methods}), these segmentation inconsistencies present the
possibility that a more accurate and consistent benchmark segmentation protocol
ought to be used in order to truly understand the results of such validations.
Indeed, our replication of the 10-fold cross-validation using \snt{}
segmentations (\expadnixvalsnt{}, Supplementary Materials) shows noticeably poorer
mean similarity scores for both \mb{} and \multiatlas. 

Thus, in comparison to other methodologies in the field \mb{} performs
favourably. Table \ref{tab:other-methods} surveys some of the most recent
reported DSC values reported on ADNI dataset, using \snt{} segmentations for the
atlas library and as gold standards for evaluation. While it is difficult to
compare segmentation results across studies, gold standards, evaluation metrics,
and algorithms it is worth noting that the methods summarized require more
atlases (between 16-55) than our \mb{} implementation with the Winterburn
atlases \citep{Winterburn2013}.

There are some important differences between our method and these specific
methods. Others have reported the difficulty with mis-registrations in
candidate segmentation (i.e. segmentations generated that are then input in the
voxel-voting procedure \citep{Collins2010}). The work of \citet{Leung2010}
tackles this problem by using an intensity threshold that is estimated
heuristically at the time of segmentation (this work also reports some of the
highest DSC scores for the segmentation of ADNI data). While this method is
effective for the ADNI dataset (which is partially homogenized with respect to
image acquisition and pre-processing), it is unclear if this type of heuristic
is applicable to other datasets. In all cases, these methods require more
atlases than our implementation with the Winterburn atlases.
\citet{Lotjonen2010} achieve highly accurate segmentation but correct their
segmentations using classifications derived using an expectation maximization
framework. In their initial work, \citet{Chupin2009} develop their probabilistic
methodology using a cohort of 8 healthy controls and 15 epilepsy patients, and
then use this method to segment an ADNI sample, with a hierarchical
experimentation protocol. These methods suggest that some post-processing of the
final segmentations would improve accuracy of the segmentation. While that may
be true, there is little consensus regarding how to achieve this. 

To the best of our knowledge, no other groups have validated their work using
multiple atlas segmentation protocols, different acquisitions, and disease
populations in order to demonstrate the robustness of their technique. This is
one of the clear strengths of this work. Furthermore, unlike some of the
algorithms mentioned, our implementation does not require retuning for new
populations or datasets as it inherently models the variability of the dataset
through the template library. However it should be noted that the increased
accuracy that follows increasing the number of atlases and templates comes at an
increased computational cost ($O(log(n))$), as previously mentioned in
other work \citep{Heckemann2006}. 

Among the automated segmentation methods we compared in this paper
(\freesurfer{}, \maper{}, \fsl{}), we find extremely variable
performance of all methods. With the exception of \fsl{} all methods correlate
well with the \snt{} volumes provided in the ADNI database. However, \freesurfer{}
and \fsl{} provide radically different definitions of the size of the hippocampus
in comparison to the other methods. Further, when estimating bias of these
methods relative to \snt{} hippocampal volumes we see that large hippocampi are
over estimated while small hippocampi are under estimated. By comparison, \mb{}
and \maper{} are far more conservative in volume estimation, suggesting these
methods may be better suited for estimating true-positives, especially in
neurodegenerative disease subjects featuring smaller overall hippocampi.
However, in this analysis we have only compared methods by total hippocampal
volume, and so more work is needed to understand the full extent to which these
methods differ.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Tabulation of subfield segmentation protocols
%
%
\begin{table}[!tbp]
\scriptsize
\caption{\textbf{Summary of labelled subfields of the Hippocampus from recent
MRI segmentation protocols.} \label{tab:subfield-segmentation-protocols}} 
\begin{center}
\begin{tabular}{ l p{4in} }
\hline\hline
Protocol & Labelled Subfields  \tabularnewline
\hline
\citet{Winterburn2013} &  CA1,  CA2/CA3,  CA4/dentate gyrus,  strata
                          radiatum/lacunosum/moleculare, subiculum \tabularnewline
\citet{Wisse2012}      &  CA1,  CA2,  CA3,  CA4/dentate gyrus, subiculum,
                          entorhinal cortex \tabularnewline
\citet{VanLeemput2009} &  CA1,  CA2/CA3,  CA4/dentate gyrus, presubiculum, subiculum,
                          hippocampal fissure,  fimbria,  hippocampal tail,
                          inferior lateral ventricle, choroid plexus \tabularnewline
\citet{Yushkevich2009} &  CA1, CA2/CA3, dentate gyrus (hilus), dentate gyrus
                          (stratum moleculare), strata
                          radiatum/lacunosom/moleculare/vestigial hippocampal
                          sulcus \tabularnewline
\citet{Mueller2007}    &  CA1, CA2, CA3/CA4 \& dentate gyrus, Sibiculum,
                          entorhinal cortex \tabularnewline
\hline
\end{tabular}
\end{center}
\end{table}

Finally, we have provided evidence that using the Winterburn high-resolution
hippocampal subfield atlases \citep{Winterburn2013} our algorithmic framework is
appropriate for the segmentation of hippocampal subfields in standard
T1-weighted data. Subfield segmentation is a burgeoning topic in the literature
although very few automated methods are available for the segmentation of 3T
data \citep{Yushkevich2009,Yushkevich2010,VanLeemput2009}. Table
\ref{tab:subfield-segmentation-kappa} compares segmentation accuracy from some
of these methods and \mb{}. The overlap DSC scores for \mb{} subfields are
notably lower but a direct comparison of overlap values must be done cautiously.
In the present work, our overlap scores are computed on $0.9mm$-isotropic voxel
resolution images, whereas \citet{Yushkevich2010} uses focal
$0.4\times0.5\times2.0mm$ voxel resolution images, and \citet{VanLeemput2009}
use supersampled $0.380mm$-isotropic voxel resolution images. The larger voxel
images we use necessarily entail a greater change in DSC for each incorrectly
labelled voxel. In addition, our automated segmentations are compared to manual
segmentations resampled from $0.3mm$-isotropic voxel labels; the resampling
process inevitably introduces noise which may lower overlap scores. Lastly, as
our method is aimed specifically at situations when manually produced atlases
are scarce, in our cross validation we are forced to use three rather than all
five of the Winterburn atlases (which, based on our findings with whole
hippocampal segmentation, would lead to improved overlap similarity).
Although having more atlases would be ideal in this context, these atlases are
incredibly time consuming to generate \citep{Winterburn2013}. Nevertheless, the
advantage of evaluating \mb{} on standard 3T T1-weighted resolution MR images
with a publically available atlas library is that our results reflect typical
usage scenarios of researchers and clinicians. 

One further complication common to all subfield segmentation evaluation is that,
by its nature, the Dice's Similarity Coefficient score penalizes structures with
high surface area to volume ratios. Therefore subfield DSC scores will generally
be lower than whole hippocampal segmentations. We attempted to put this
effect into perspective by comparing \mb{} subfield segmentation agreement with
the agreement of voxel-shifted manual segmentations (Table
\ref{tab:WAxval-perturb-kappa}). The results of this exercise show conclusively,
despite the very limited number of atlases we had to work with, that \mb{}
subfield segmentations are well within the bounds of error of a $0.3mm$ voxel shift. 

Our overlap DSC values demonstrates that we can reliably reproduce segmentations
for the CA1, subiculum, and CA4/dentate subfields (DSC > 0.5). That the CA2/CA3
and molecular layers are less well reproduced (DSC < 0.5) should not be
surprising as these are extremely thin and spatially convoluted regions that
originally required high-resolution MRI for identification and so it is likely
that the extents of these regions are well below the resolution and contrast
offered by standard T1-weighted images. 

\begin{table}[!tbp]
\scriptsize
\caption{\textbf{A comparison of subfield segmentation overlap similarity with
manual raters.} \label{tab:subfield-segmentation-kappa}} 
\begin{center}
\begin{tabular}{ l c c c }
\hline\hline
Subfield             & \mb{}               & \citet{VanLeemput2009} & \citet{Yushkevich2010}  \tabularnewline
\hline                                   
CA1                  &\Sexpr{mean(CA1)}    & 0.62 & 0.875                                     \tabularnewline
CA2/3                &\Sexpr{mean(CA23)}   & 0.74 & $CA2=0.538, CA3=0.618$                    \tabularnewline
CA4/DG               &\Sexpr{mean(CA4DG)}  & 0.68 & $DG=0.873$                                \tabularnewline
presubiculum         & ---                 & 0.68 & ---                                       \tabularnewline
subiculum            &\Sexpr{mean(Sub)}    & 0.74 & 0.770                                     \tabularnewline
hippocampal fissure  & ---                 & 0.53 & ---                                       \tabularnewline
SR/SL/SM             &\Sexpr{mean(SRLM)}   & ---  & ---                                       \tabularnewline
fimbria              & ---                 & 0.51 & ---                                       \tabularnewline
head                 & ---                 & ---  & 0.902                                     \tabularnewline
tail                 & ---                 & ---  & 0.863                                     \tabularnewline
\hline
\end{tabular}
\end{center}
\end{table}


This points to a larger issue of how to truly validate subfield segmentations,
both in high resolution images and in standard T1-weighted images. There are
several manual subfield segmentation methodologies, and they do not agree on
which regions can be differentiated, even on high-resolution scans. See Table
\ref{tab:subfield-segmentation-protocols} for a comparison of manual subfield
segmentation methodologies. A further complication is that different researchers
have differing operational definitions for the subfields and how they ought to
be parcellated. The disagreement in the community has led to an international
working group devoted to normalizing the ontology and segmentation rules for the
hippocampal subfields (\url{http://www.hippocampalsubfields.com/}). Both of
these disagreements suggest that direct comparison of automated methods using
``ground truth''-based overlap similarity metrics, such as Dice's Similarity
Coefficient, are not possible without carefully taking into account the
differences in underlying segmentation protocols and image characteristics. 

In conclusion, we have demonstrated the viability of leveraging a small
number of input atlases to bootstrap a large template library and thereby
improve segmentation reliability when using \multiatlas{} methods. We
demonstrated that this method works robustly over hippocampal definitions,
different disease populations, and different acquisition types. Finally, we also
demonstrate that accurate identification of the hippocampal subfields in
standard 3T T1-weighted images is possible. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                              Acknowledgements 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Acknowledgements}
We wish acknowledge support from the CAMH Foundation, thanks to Michael and
Sonja Koerner, the Kimel Family, and the Paul E. Garfinkel New Investigator
Catalyst Award. MMC is funded by the W. Garfield Weston Foundation and ANV is
funded by the Canadian Institutes of Health Research, Ontario Mental Health
Foundation, NARSAD, and the National Institute of Mental Health (R01MH099167).

Computations were performed on the gpc supercomputer at the SciNet HPC
Consortium \cite{Loken2010}. SciNet is funded by: the Canada Foundation for
Innovation under the auspices of Compute Canada; the Government of Ontario;
Ontario Research Fund - Research Excellence; and the University of Toronto.

In addition, computations were performed on the CAMH Specialized Computing 
Cluster. The SCC is funded by: The Canada Foundation for Innovation, Research 
Hospital Fund.

ADNI Acknowledgements: Data collection and sharing for this project was funded
by the Alzheimer's Disease Neuroimaging Initiative (ADNI) (National Institutes
of Health Grant U01 AG024904). ADNI is funded by the National Institute on
Aging, the National Institute of Biomedical Imaging and Bioengineering, and
through generous contributions from the following: Abbott; Alzheimer's
Association; Alzheimer's Drug Discovery Foundation; Amorfix Life Sciences Ltd.;
AstraZeneca; Bayer HealthCare; BioClinica, Inc.; Biogen Idec Inc.;
Bristol-Myers Squibb Company; Eisai Inc.; Elan Pharmaceuticals Inc.; Eli Lilly
and Company; F. Hoffmann-La Roche Ltd and its affiliated company Genentech,
Inc.; GE Healthcare; Innogenetics, N.V.; IXICO Ltd.; Janssen Alzheimer
Immunotherapy Research  Development, LLC.; Johnson \& Johnson Pharmaceutical
Research  Development LLC.; Medpace, Inc.; Merck \& Co., Inc.; Meso Scale
Diagnostics, LLC.; Novartis Pharmaceuticals Corporation; Pfizer Inc.; Servier;
Synarc Inc.; and Takeda Pharmaceutical Company. The Canadian Institutes of
Health Research is providing funds to support ADNI clinical sites in Canada.
Private sector contributions are facilitated by the Foundation for the National
Institutes of Health (www.fnih.org). The grantee organization is the Northern
California Institute for Research and Education, and the study is Rev March 26,
2012 coordinated by the Alzheimer's disease Cooperative Study at the University
of California, San Diego. ADNI data are disseminated by the Laboratory for
NeuroImaging at the University of California, Los Angeles. This research was
also supported by NIH grants P30 AG010129 and K01 AG030514.

We would also like to thank G. Clinton, E. Hazel, and B. Worrell for inspiring
this work. 

\section{Supplementary Materials}

\subsection{\snt{} Hippocampal Labels}
% The following blurb is taken (except for the first sentence) verbatim 
Semi-automated hippocampal volumetry was carried out using a commercially
available high dimensional brain mapping tool (Medtronic Surgical Navigation
Technologies, Louisville, CO), that has previously been validated and compared
to manual tracing of the hippocampus \citep{Hsu2002}. Measurement of hippocampal
volume is achieved first by placing manually 22 control points as local
landmarks for the hippocampus on the individual brain MRI data: one landmark at
the hippocampal head, one at the tail, and four per image (i.e., at the
superior, inferior, medial and lateral boundaries) on five equally spaced images
perpendicular to the long axis of the hippocampus. Second, fluid image
transformation is used to match the individual brains to a template brain
\citep{Christensen1997}. The pixels corresponding to the hippocampus are then
labeled and counted to obtain volumes. This method of hippocampal voluming has a
documented reliability of an intraclass coefficient better than .94
\citep{Hsu2002}.

%
%-------------------------------------------------------------------------------
%

\FloatBarrier
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                                                                     %%%%%
%%%%%       Experiment 5: SNT Hippocampal Subfield Cross-Validation       %%%%%
%%%%%                                                                     %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{\expadnixvalsnt{}: \expadnixvalsntdesc{}}

This experiment is a replication of \expadnixval{} using a pool of 69 images and
\snt{} semi-automated segmentations from the ADNI dataset \citep{Hsu2002}. See
\expadnixval{} for full details on the ADNI dataset, and validation process. 

\subsubsection{\expadnixvalsnt{}: Materials and Methods}
\paragraph{Dataset} 
69 1.5T images were arbitrarily selected from the baseline scans in the {\em
\adnidataset{}} standardized dataset. 23 subjects were chosen from each disease
category: cognitively normal (CN), mild cognitive impairment (MCI) and
Alzheimer's disease (AD). Demographics for this subset are shown in Table
\ref{tab:ADNI1-xvalidation-demographics}. Each image has a corresponding
semi-automated segmentation of the left and right whole hippocampus made
available with ADNI images (\snt; see Supplementary Materials). 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% ADNI1 X-Validation Dataset Demographics Table
%
<<tab:ADNI-SNT-Xval-demographics, echo=F, results="asis",cache=FALSE>>=
adni_69_RIDs = c(295,413,619,685,729,782,938,954,1018,1155,907,981,222,324,448,
                 546,553,572,602,610,814,1341,675,681,731,1130,41,68,70,101,
                 249,293,316,414,698,1206,1222,1339,751,1030,3,5,10,16,22,53,
                 168,183,241,1205,328,1095,991,213,159,337,343,642,753,1109,
                 1217,29,56,1188,1293,149,382,431,1202)

tab <- summary(DX.bl ~ AGE + PTGENDER + PTEDUCAT + CDRSB + ADAS13 +
               MMSE, data = adnimerge, subset = VISCODE == 'bl' & RID %in%
               adni_69_RIDs, method = "reverse", test=FALSE, overall=TRUE)
caption = 
  "\\textbf{\\adnidataset{} \\snt{} cross-validation subset demographics.} 
  CN     - Cognitively Normal. 
  LMCI   - Late-onset Mild Cognitive Impairment. 
  AD     - Alzheimer's Disease. 
  Hisp   - Hispanic. 
  CDR-SB - Clinical Dementia Rating-Sum of Boxes. 
  ADAS   - Alzheimer's Disease Assessment Scale. 
  MMSE   - Mini-Mental State Examination."
latex(tab, file="", size="scriptsize",landscape=FALSE, ctable=FALSE,
      caption=caption, caption.loc = c("top"),
      label="tab:ADNI1-SNT-xvalidation-demographics")
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\paragraph{Experiment details} 
A total of ten validation rounds were performed on each subject in the dataset,
for each combination of parameter settings: atlas library size (1-9), template
library size (1-20), registration method (\ants{} or \animal{}), and label
fusion method (majority vote, cross-correlation weighted majority vote, and
normalized mutual information weighted majority vote). A total of $10 \times 69
\times 9 \times 20 \times 2 \times 3 =$ \Sexpr{10*69*9*20*2*3} validation rounds
are conducted. The computed segmentations for a subject are compared to the
\snt{} labels provided by ADNI using Dice's Similarity Coefficient and the score
is averaged over the validation rounds.

% ######################
\subsubsection{\expadnixvalsnt{}: Results}

As when comparing against manual labels in \expadnixval{}, we find similar
behaviour when comparing \mb{} segmentations to \snt{} labels: similarity scores
increase with increasing numbers of atlases and templates, with diminishing
increases in improvement trending towards a plateau (Figure
\ref{fig:ADNI1-xval-k-mean}). As in \expadnixval{}, using \ants{} registration
leads to significantly increased similarity scores, and there is no significant
difference in scores from any of the label fusion methods. Mean DSC score peaks
at \Sexpr{snt.mb.kappa.best} when using 9 atlases, 19
templates, ANTS registration, and majority vote label fusion. Compared to
\multiatlas{} segmentations, we find \mb{} segmentations show increasing
improvement with larger atlas and template libraries when using more than 9
templates and 5 or fewer atlases (Figure \ref{fig:ADNI1-SNT-xval-k-diff}). Peak
improvement (+\Sexpr{round(snt.mb.diff.best, digits=3)} DSC) is found with a
single atlas and template library of 19 images. In addition to a mean increase
in similarity score over \multiatlas{}-based segmentation, \mb{} also shows more
consistency in similarity scores across all subjects and validation folds
(Figure \ref{ADNI1-SNT-xval-variability}) with a large enough template library. 

%%%%%%%%%%%%%
% ADNI1-SNT-XVAL: mean Kappa plot by settings 
%%%%%%%%%%%%%
<<fig:ADNI1-SNT-xval-k-mean,dependson='ADNI1-xval-load',fig.width=10,fig.show='hide'>>=
stderr <- function(x) sqrt(var(x)/length(x))
ggplot(subset(snt_xval_mean, (templates.mb*atlases) %% 2 == 1),
       aes(x=templates.mb,y=k.mb, colour=as.factor(atlases), linetype=reg_method)) + 
      #as.factor((atlases*templates.mb) %% 2 ))) + 
  facet_grid(.~method.mb) + 
  stat_summary(fun.y=mean,geom='line',
               aes(y=k.mb, weight=1, group=interaction(reg_method,atlases))) + 
  stat_summary(fun.y=mean,
               fun.ymin=function (x) mean(x) - stderr(x),
               fun.ymax=function (x) mean(x) + stderr(x), 
               geom='errorbar',
               aes(y=k.mb, weight=1, 
                 group=interaction(reg_method,atlases)), width=0.5) + 
  scale_y_continuous(breaks=seq(0,1,0.01)) + 
  scale_colour_hue(name="Number of Atlases") +
  scale_linetype(name="Registration Method") +
  xlab( "Number of Templates" ) + 
  ylab( "Mean similarity (DSC)" ) + 
  theme(legend.key.size = unit(0.7, 'lines'),
        legend.position = "bottom", 
        legend.box = "horizontal", 
        legend.text = element_text(size=rel(0.7)),
        axis.text = element_text(size = 8))
@

%%%%%%%%%%%%%
% ADNI1-SNT-XVAL: "increase" in mean kappa over \multiatla
s%%%%%%%%%%%%%
<<fig:ADNI1-SNT-xval-k-diff,dependson='ADNI1-xval-load',fig.show='hide'>>=
ggplot(subset(snt_xval_mean, reg_method=="ANTS" & 
                method.mb=="Majority Vote" & (templates.mb*atlases) %% 2 == 1), 
       aes(x=templates.mb, y=k_diff, colour=as.factor(atlases))) + 
  #facet_grid(reg_method~method.y) + 
  stat_summary(fun.data=mean_cl_boot,geom='errorbar',
               aes(y=k_diff,colour=as.factor(atlases), width=0.2)) +
  stat_summary(fun.y=mean, geom="point", 
               aes(y=k_diff,colour=as.factor(atlases))) + 
  stat_summary(fun.y=mean, geom="line", 
               aes(y=k_diff,colour=as.factor(atlases))) + 
  #stat_smooth(method=lm, formula=y~log(x)) + 
  geom_hline(aes(alpha=0.5, yintercept=0), linetype='dashed') + 
  scale_x_continuous(breaks=seq(1,20,2)) + scale_y_continuous(breaks=seq(-1,1,by=0.01)) + 
  scale_colour_hue(name="Number of Atlases") +
  scale_alpha_continuous(guide = "none") + 
  scale_linetype_discrete(guide = "none") + 
  xlab( "Number of Templates" ) + 
  ylab( "Increase in mean similarity (DSC)" ) +
  theme(legend.direction = "horizontal", legend.position = "bottom")
@

%%%%%%%%%%%%%
% ADNI1-SNT-XVAL: variability
%%%%%%%%%%%%%
<<fig:ADNI1-SNT-xval-variability,dependson='load',fig.show='hide'>>=
ants = subset(snt_xval_data, 
                     reg_method=="ANTS" & 
                     method.mb=="Majority Vote" &
                    templates.mb %in% seq(1,20,2))

ants.stats = ddply(ants, c("subject", "label", "atlases","templates.mb"), 
                   function (df) {
                     data.frame(
                       MA.sd  =  sd(df$k.ma),
                       MB.sd  =  sd(df$k.mb),
                       MA.var = var(df$k.ma),
                       MB.var = var(df$k.mb)
                       )
                   })

stats.tests = ddply(ants.stats, c("atlases","templates.mb"), function (df) {
  t.var = t.test(df$MA.var, df$MB.var)
  t.sd  = t.test(df$MA.sd , df$MB.sd)
  diff_mean_var = mean(df$MA.var - df$MB.var)
  diff_mean_sd  = mean(df$MA.sd -  df$MB.sd)
  
  # test statistic is positive if MA mean is larger than MB
  # i.e. that MA has a greater mean of variances/SDs
  # i.e. that MB has a smaller mean, and so is doing "better"
  data.frame(
    stat      = c("Variance", "Standard Deviation"),
    statistic = c(t.var$statistic, t.sd$statistic),
    p.value   = c(t.var$p.value, t.sd$p.value),
    direction = c(diff_mean_var, diff_mean_sd)
  )
})

ggplot(subset(stats.tests, direction > 0 & stat == "Variance"), 
  aes(x=templates.mb, y=p.value, colour=as.factor(atlases))) + 
  #facet_grid( . ~ stat) + 
  geom_line(size=0.5) +
  geom_point(size=2) + 
  geom_hline(aes(yintercept=0.05, alpha=0.5), linetype='dashed') + 
  geom_hline(aes(yintercept=0.01, alpha=0.5), linetype='dashed') + 
  scale_x_continuous(breaks=seq(1,20,by=2)) + 
  xlab( "Number of Templates" ) + 
  ylab( "Variability (p)") +
  scale_colour_hue(name="Atlases") +
  scale_alpha_continuous(guide='none') + 
  scale_linetype_discrete(guide='none') + 
  scale_size_continuous(guide='none') + 
  theme(legend.direction = "horizontal", legend.position = "bottom")
@

\begin{figure}
  \centering
  \begin{subfigure}[t]{\textwidth}
    \includegraphics[width=\textwidth]{figure/fig:ADNI1-SNT-xval-k-mean}
    \caption{DSC vs. atlas and template library size} 
    \label{fig:ADNI1-SNT-xval-k-mean}
  \end{subfigure}%
  \hfill
  \begin{subfigure}[b]{0.48\textwidth}
    \includegraphics[width=\textwidth]{figure/fig:ADNI1-SNT-xval-k-diff}
    \caption{Increase in similarity score over \multiatlas} 
    \label{fig:ADNI1-SNT-xval-k-diff}
  \end{subfigure}%
  \hfill
  \begin{subfigure}[b]{0.48\textwidth}
    \includegraphics[width=\textwidth]{figure/fig:ADNI1-SNT-xval-variability}
    \caption{Difference in variability with \multiatlas} 
    \label{fig:ADNI1-SNT-xval-variability}
  \end{subfigure}
  \caption{\textbf{Whole hippocampus segmentation cross-validation on
  ADNI subjects with \snt{} segmentations.}
(\ref{fig:ADNI1-SNT-xval-k-mean}) Average DSC score of \mb{} with \snt{} 
  segmentations for 69 ADNI subjects taken over 10 folds of cross-validation at
  each parameter setting. Error bars indicate standard error. 
(\ref{fig:ADNI1-SNT-xval-k-diff}) Increase in DSC of \mb{} over \multiatlas{}
  segmentations. 
(\ref{fig:ADNI1-SNT-xval-variability}) shows the significance of t-tests comparing
  the variability in DSC scores of \mb{} and \multiatlas{} across validation
  folds. Only points where \mb{} mean variability is lower than \multiatlas{} are
  shown. Dashed lines indicate p-values of 0.05 and 0.01.}
\end{figure}

\bibliographystyle{abbrvnat}
\bibliography{references}

% \section*{R Session Information}
% <<results = "asis">>=
% toLatex(sessionInfo(), locale=FALSE)
% @
\end{document}
