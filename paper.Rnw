%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Sweave/Knitr init
<<setup, include=FALSE, cache=FALSE>>=
library(knitr)
opts_chunk$set(echo = FALSE, 
               message = FALSE, 
               warning = FALSE, 
               fig.align = 'center', 
               tidy = FALSE, 
               comment = NA, 
               cache = TRUE,
               fig.width = 6, 
               fig.height = 6)
library(ggplot2)
library(Hmisc)
library(reshape2)
library(ADNIMERGE)
library(plyr)
options(digits=3)
theme_set(theme_bw(base_size = 12))


lm_eqn = function(m) {
  l <- list(a = format(coef(m)[1], digits = 2),
      b = format(abs(coef(m)[2]), digits = 2),
      r2 = format(summary(m)$r.squared, digits = 3));
  if (coef(m)[2] >= 0)  {
    eq <- substitute(italic(y) == a + b %.% italic(x)*","~~italic(r)^2~"="~r2,l)
  } else {
    eq <- substitute(italic(y) == a - b %.% italic(x)*","~~italic(r)^2~"="~r2,l)    
  }

  as.character(as.expression(eq))
}
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass{article}
\usepackage[margin=1in]{geometry}
\usepackage{algorithm, color, algpseudocode, amsmath, url, geometry, ctable}
\usepackage{titlesec, siunitx}
\usepackage[round,authoryear]{natbib}
\usepackage[section]{placeins}  % keep floats in their place.
\usepackage{authblk}    % Listing Author affiliations

%draft mode
\usepackage[colorinlistoftodos, textwidth=4cm, shadow]{todonotes}
\usepackage[displaymath, tightpage]{preview}
\setlength{\marginparwidth}{1.2in}

% styling
\newcommand{\subsubsubsection}[1]{\paragraph{#1}}
\renewcommand\Affilfont{\itshape\small}  %authblk

% shortcuts 
\newcommand{\mb}{MAGeT-Brain }
\newcommand{\ants}{ANTS }
\newcommand{\animal}{ANIMAL }
\newcommand{\adnidataset}{ADNI1:Complete 1Yr 1.5T }
\newcommand{\FEPdataset}{SZ-FEP }

% title and authors
\title{Bootstrapping Multi-atlas Hippocampal Segmentation with \mb}
\author[1]{Jon Pipitone}
\author[1]{Matt T. Park}
\author[1]{Julie Winterburn}
\author[1]{Tristram A. Lett}
\author[2,3]{Jason P. Lerch}
\author[4]{Jens C. Pruessner}
\author[4]{Martin Lepage}
\author[1,5]{Aristotle Voineskos}
\author[1,5,6]{M. Mallar Chakravarty}
\author[ ]{Alzheimer's Disease Neuroimaging Initiative}
\affil[1]{Kimel Family Translational Imaging-Genetics Lab, Centre for Addiction and
Mental Health, Toronto, ON, Canada}
\affil[2]{Neurosciences and Mental Health, Hospital for Sick Children, Toronto,
ON,Canada}
\affil[3]{Department of Medical Biophysics, University of Toronto, Toronto, ON,
Canada}
\affil[4]{Brain Imaging Group, Douglas Hospital Research Centre, Verdun, QC, Canada}
\affil[5]{Department of Psychiatry, University of Toronto, Toronto, ON, Canada}
\affil[6]{Institute of Biomedical Engineering, University of Toronto, Toronto,
ON, Canada}

\renewcommand\Authands{ and }

\date{}

\begin{document}
\maketitle

\begin{abstract}
%Neuroimaging research often relies on automated anatomical segmentations of MR
%images of the brain. Current multi-atlas based approaches provide accurate
%segmentations of brain images by propagating manually derived segmentations of
%specific neuroanatomical structures to unlabelled data. These approaches often
%rely on a large number of such manually segmented atlases that take significant
%time and expertise to produce. We present an algorithm for the automatic
%segmentation of the hippocampus that minimizes the number of atlases needed
%while still achieving similar accuracy to multi-atlas approaches.
\end{abstract}

\parbox{4in}{
\textbf{Contact:} \\
Jon Pipitone and M. Mallar Chakravarty \\
Kimel Family Translation Imaging-Genetics Research Laboratory \\
Research Imaging Centre \\
Centre for Addiction and Mental Health \\
250 College St. \\
Toronto, Canada   M5T 1R8 \\
jon.pipitone@camh.ca; mallar.chakravarty@camh.ca}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                               INTRODUCTION
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

The hippocampus is a neuroanatomical structure situated in the medial temporal
lobe of the brain, and has long been associated with learning and memory
\citep{DenHeijer2012,Scoville2000}.  In addition to its known functional roles,
the hippocampus is of interest to neuroscientists because it is implicated in
several forms of brain disfunction such as Alzheimer's disease
\citep{Sabuncu2011} and schizophrenia \citep{Narr2004,Karnik-Henry2012}.  In
neuroimaging experiments, magnetic resonance images (MRI) are often used for the
identification of the hippocampus.  As such, accurate segmentation of the
hippocampus and its subregions in MRI is a necessary first step to better
understand the unique neuroanatomy of subjects. Typically, the gold standard for
neuroanatomical segmentation is manual delineation by an expert human rater. However
the rapid increase in the availability of MRI data and the time and expertise
required for manual segmentation is prohibitive
\citep{Mazziotta1995,Mazziotta2001,Mazziotta,Pausova2007}.
Further, there is little agreement between researchers regarding how exactly the
hippocampus should be identified in MRI images \citep{Geuze2004} and this has
led to efforts to create an unified hippocampal segmentation protocol
\citep{Jack2011}.  

Automated segmentation techniques that are reliable, objective, and reproducible
are a necessary alternative to manual segmentation.  In the case of classical
model-based segmentation methods \citep{Haller1997,Csernansky1998}, an MRI atlas
that was previously manually labelled by an expert rater is matched to target
images using nonlinear registration methods.  The resulting nonlinear
transformation is applied to the manual labels (ie. {\em label propagation}) to
apply them to the target image.  While this methodology has been used
successfully in several contexts
\citep{Chakravarty2008,Chakravarty2009,Collins1995,Haller1997}, it is limited
in accuracy by the introduction of errors due inaccuracies in the nonlinear
transformation itself, partial volume effects in label resampling, and
irreconcilable differences between the neuroanatomy represented within the atlas
and target images.
 
One methodology that can be used to mitigate these sources of errors involves
the use of multiple manually segmented atlases and probabilistic segmentation
techniques, such as those found in the FreeSurfer package \citep{Fischl2002}.
FreeSurfer uses a probabilistic atlas of anatomical and tissue classes along
with spatial constraints for class labels encoded using a Markov random field
model to segment the entire brain.  

More recently, many groups have been using multiple atlases to improve overall
segmentation accuracy (ie. multi-atlas segmentation) over model-based approaches
\citep{Heckemann2006,Heckemann2011,Collins2010,Lotjonen2010,Aljabar2009,Leung2010,Wolz2010}.
Each atlas image is registered to a target image, and label propagation is
performed to produce several labellings of the target image (one from each
atlas). A {\it label fusion} technique, such as voxel-wise voting, is used to
merge these labels into a definitive segmentation for the target.  In addition,
weighted voting procedures that use {\em atlas selection} techniques are often
used to exclude atlases from label fusion that are dissimilar to a target image
in order to reduce error from unrepresentative anatomy \citep{Aljabar2009}.
This involves the selection of a subset of atlases using a similarity metric
such a cross-correlation \citep{Aljabar2009} or normalized mutual information.
Such selection has the added benefit of significantly reducing the number of
nonlinear registrations.  For example Collins and Pruessner \citep{Collins2010}
demonstrated that only 14 atlases, selected based on highest similarity between
medial temporal lobe neuroanatomy as evaluated by normalized mutual information
\citep{Studholme1999} from a library of 80 atlases, were required to achieve
accurate segmentations of the hippocampus.  Several methods have been explored
for label fusion including the STAPLE algorithm \citep{Warfield2004} that
computes a probabilistic segmentation using an expectation maximization
framework from an set of competing segmentations; or others where a subset of
segmentations can be estimated using metrics such as the sum of squared
differences in the regions of interest to be segmented \citep{Coupe2011}.

However, many of these methods require significant investment of time and
resources for the creation of the atlas library; ranging from atlas libraries
that require between 30 \citep{Heckemann2006} and 80 \citep{Collins2010}
manually segmented atlases.  This strategy has the main drawback of being
inflexible as it does not easily accommodate varying the definition of the
hippocampal anatomy (such as the commonly used heuristic of subdividing the
hippocampus in to head, body, and tail \citep{Poppenk2011,Pruessner2000}).
Furthermore, none of these methods have demonstrated sufficient flexibility to
accommodate atlases that are somehow exceptional such as those derived from
serial histological data \citep{Chakravarty2006,Yelnik2007} or high-resolution MRI
data that enables robust identification of hippocampal subfields
\citep{Winterburn2013,Yushkevich2009,Mueller2009,VanLeemput2009,Wisse2012}.  Due to
the recent availability of the latter, there has been increased interest in the
use of probabilistic methods for the identification of the hippocampal subfields
on standard T1-weighted images.  Our group recently demonstrated that through
use of an intermediary automated segmentation stage, robust and accurate
segmentation of the striatum, pallidum, and thalamus using a single atlas
derived from serial histological data is possible \citep{MallarChakravarty2012}.
The novelty of this manuscript is the extension our multi-atlas methodology to
the hippocampus using more than a single input atlas, while simultaneously
limiting the number of possible inputs used during segmentation, and
demonstrating that accurate identification of the hippocampal subfields is
indeed possible using this methodology.

There are few methods that have attempted to perform multi-atlas segmentation
with a limited number of input atlases. The LEAP algorithm is an elegant
modification to the basic multi-atlas strategy \citep{Wolz2010} in which the
atlas library is grown, beginning with a set of manually labelled atlases, and
successively incorporating unlabelled target images after themselves being
labelling using multi-atlas techniques. The sequence in which target images are
labelled is chosen so that the similarity between the atlas images and the
target images is minimised at each step, effectively allowing for deformations
between very dissimilar images to be broken up into sequences of smaller
deformations.  Although \citet{Wolz2010} begin with an atlas library of 30 MR
images, this method could theoretically work using a much smaller atlas library.
In their validation, LEAP was used to segment the whole hippocampus in the ADNI1
baseline dataset, achieving a mean Dice score of 0.85 with manual segmentations.

To the best of our knowledge there are two other segmentation methods that
attempt to define the hippocampal subfields using standard T1-weighted data.
The first is included with the FreeSurfer package \citep{VanLeemput2009}.  This
work is limited as it omits the tail of the hippocampus and the segmentation
protocol has yet to be fully validated.  Nonetheless, they demonstrate that the
applicability of their work using data from 10 subjects.  In the second method,
\citet{Yushkevich2009} acquired and labelled hippocampal subfields on
high-resolution MRI data from post-mortem medial temporal lobe samples. Using
nonlinear registration guided by manually derived hippocampus masks and specific
landmarks, they demonstrate accurate parcellation of hippocampal subfields in
unlabelled MRI volumes. 

Here we address the issue of limiting the number of input atlases by tuning our
algorithm, for segmentation of the entire hippocampus, using a multi-fold
experiment performed on a subset Alzheimer's Disease Neuroimaging Initiative
(ADNI) 1 dataset. Based on the parameters we find in our experiment, we validate
our algorithm using all of the data available in the ADNI Complete 1Yr sample
and compare our segmentations to the other segmentations that are available
through the ADNI informatics portal.  To ensure that we have not over-fit our
parameters to the aging or neurodegenerative brain, we also apply our
segmentations to a dataset of normal controls and individuals suffering from
first episode psychosis. Finally, we perform a leave-one-out validation
experiment to determine if the subfields can be accurately identified using our
multi-atlas framework. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                               METHODS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Methods}

%%%%%                     MAGeT Brain Algorithm                            %%%%%

\subsection{The \mb Algorithm}
In this paper, we will use the term {\em label} to mean any segmentation (manual or 
derived) of an MR image.  {\em Label propagation}, or {\em labelling}, is the 
process by which two images are registered and the resulting transformation 
is applied to the labels from one image to bring them into alignment with the 
other image. We will use the term {\em atlas} to mean a manually segmented image,
and the term {\em template} to mean an automatically segmented image (i.e. 
via label propagation). The terms {\em atlas library} and {\em template library} 
describe any set of such images.Additionally, we will use the term {\em target} 
to refer to an unlabelled image that is undergoing segmentation.

The simplest form of multi-atlas segmentation, (which we will call {\em basic 
multi-atlas segmentation}), involves three steps.  First, each labelled 
input image (i.e. atlas or template) is registered to an unlabelled target image.
Second, the labels from each image are propagated to the target image space. 
Third, the labels are combined into a single labelling by way of a label fusion method 
\citep{Heckemann2006, Heckemann2011}. This method is described in detail in other
publications \citep{Collins2010,Heckemann2011,Aljabar2009}.

\mb bootstraps the creation of a large template library given a limited input atlas 
library, and then uses the template library in basic multi-atlas segmentation. 
Images for the template library are selected from a set of input target images, 
either arbitrarily or so as to reflect the neuroanatomy or demographics of the 
target set as a whole (for instance, by sampling equally from cases and controls). 
The template library images are then labelled by each of the atlases. Basic 
multi-atlas segmentation is then conducted using the template library
to segment the entire set of target images (including the targets whose images
are used in the construction of the template library).  Since each template
library image has multiple labels (one from each atlas), the final number of 
labels to be fused for each target may be quite large (i.e. \# of atlas $\times$ 
\# of templates).

Figure \ref{alg:MAGeT} describes the \mb algorithm in pseudocode. Source code 
for \mb can be found at \url{http://github.com/pipitone/MAGeTbrain}.

\begin{algorithm}
  \scriptsize
  \caption{Pseudocode for the \mb algorithm}
  \label{alg:MAGeT}
  \begin{algorithmic}
    \Function{BasicMultiAtlasSegmentation}{Templates, Subjects}
      \ForAll{$target$}
        \ForAll{$template$}
          \State propagate all labels for template to target space
          \State store target labels
        \EndFor
        \State fuse target labels
      \EndFor
    \EndFunction
    \\
    \Function {MAGeTBrain}{Subjects, Atlases, n}
      \For{$i = 1 \to n$}
        \State choose a target to be used as a template
        \State propagate labels from each atlas to template space
        \State store the template with all of its labels
      \EndFor
      \State MultiAtlas(Templates, Subjects)
    \EndFunction
  \end{algorithmic}
\end{algorithm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                            Experiments                              %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Experiments}

The following section describes the experiments we conducted to assess the
segmentation quality of the \mb algorithm. The first two experiments assess the
validity of \mb using a cross-validation design. Experiment 1 investigates the
accuracy of \mb whole hippocampus segmentation over a wide range of parameter
settings. This enables us to choose the parameter settings offering the best
performance for use in subsequent experiments. Experiment 2 tests hippocampal
subfield segmentation quality. The last two experiments assess the validity of
the \mb algorithm when applied to different diseases: Alzheimer's disease
(Experiment 3) and first episode schizophrenia patients (Experiment 4). 

%The ADNI experiment includes comparison of volumes with other automated
%segmentation methods. Evaluation is done by correlating volumes b/c overlap
%metrics assume identical segmentation protocol. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                                                                     %%%%%
%%%%%         Experiment 1: Whole Hippocampus Cross-Validation            %%%%%
%%%%%                                                                     %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Experiment 1: Whole Hippocampus Cross-Validation}

Monte Carlo Cross-Validation (MCCV) \citep{Shao1993} was performed using a pool
of images and manual hippocampal segmentations from ADNI1 dataset.  This form of
cross-validation allows us to rigorously validate a large number of parameter
settings of \mb (atlas and template library sizes, registration algorithm, and 
label fusion method) and select the best parameters to use in subsequent 
experiments.

\paragraph{ADNI1 dataset} 

69 1.5T images were arbitrarily selected from the baseline scans in the {\em
\adnidataset} standardized dataset. 23 subjects were chosen from each disease
category: cognitively normal (CN), mild cognitive impairment (MCI) and
Alzheimer's disease (AD). Demographics for this subset are shown in Table
\ref{tab:ADNI1-xvalidation-demographics}.  Manual segmentations of the left and
right whole hippocampi are available \citep{Hsu2002}. These labels have been
generated using the SNT tool from Medtronic Surgical Navigation Technologies,
Louisville, CO (see Supplementary Materials for detailed discussion of the
manual segmentation process used).

Clinical, demographic and pre-processed T1-weighted MRI were downloaded by the
authors from the ADNI database (adni.loni.ucla.edu) between March 2012 and
August 2012. The image dataset download was the "\adnidataset"
standardized dataset available from ADNI \footnote{
\url{http://adni.loni.ucla.edu/methods/mri-analysis/adni-standardized-data/}}
\citep{Wyman2012}. This image collection contains uniformly preprocessed images
which have been designated to be the "best" after quality control.  All images
were acquired using 1.5T scanners (General Electric Healthcare, Philips Medical
Systems or Siemens Medical Solutions) at multiple sites using the protocol
described in \citep{Jack2008}.  Representative 1.5T imaging parameters were TR
= 2400ms, TI = 1000ms, TE = 3.5ms, flip angle = $8{\circ}$, field of view = 240
x 240mm, a $192 \times 192 \times 166$ matrix ($x$, $y$, and $z$ directions)
yielding a voxel resolution of $1.25 \times 1.25 \times 1.2mm^3$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% ADNI1 X-Validation Dataset Demographics Table
%
<<ADNI-Xval-demographics, echo=F, results="asis",cache=FALSE>>=
adni_69_RIDs = c(295,413,619,685,729,782,938,954,1018,1155,907,981,222,324,448,
                 546,553,572,602,610,814,1341,675,681,731,1130,41,68,70,101,
                 249,293,316,414,698,1206,1222,1339,751,1030,3,5,10,16,22,53,
                 168,183,241,1205,328,1095,991,213,159,337,343,642,753,1109,
                 1217,29,56,1188,1293,149,382,431,1202)
tab <- summary(DX.bl ~ AGE + PTGENDER + PTEDUCAT + PTETHCAT + CDRSB + ADAS13 +
               MMSE, data = adnimerge, subset = VISCODE == 'bl' & RID %in%
               adni_69_RIDs, method = "reverse", test=FALSE, overall=TRUE)

latex(tab, file="", size="scriptsize",landscape=FALSE, ctable=FALSE,
      caption="ADNI-1 cross-validation subset demographics", 
      title="tab:ADNI1-xvalidation-demographics")
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\paragraph{Experiment details} 

Monte Carlo Cross-Validation (MCCV), also known as repeated random sub-sampling
cross-validation, consists of repeated rounds of validation conducted on a fixed
dataset \citep{Shao1993}. In each round, the dataset is randomly partitioned into
a training set and a validation set. The method to be validated is then given
the training data, and its output is compared with the validation set.

In this experiment, our dataset consists of 69 1.5T images and corresponding
manual segmentations. In each validation round, the dataset is partitioned into 
a training set consisting of images and their manual labels to be used as an atlas 
library, and a validation set consisting of the remaining images segmented by both 
\mb and multi-atlas. The resulting segmentations are compared to the manual 
segmentations for the images.

A total of ten validation rounds are performed on each subject in the dataset,
over each combination of parameter settings. The parameter settings
we explore are: atlas library size (1-9), template library size (1-20),
registration method (\ants or \animal), and label fusion method (majority vote,
cross-correlation weighted majority vote, and normalized mutual information
weighted majority vote).  A total of $10 \times 69 \times 9 \times 20 \times 2
\times 3 = \num{7452000}$ validation rounds were conducted, resulting in a total
of $\num{1490400}$ segmentations analysed. 

Before registration, all images underwent preprocessing with the N3 algorithm
\citep{Sled1998} to minimize intensity nonuniformity. In this experiment we use
one of two non-linear image registration methods.

\subparagraph{Automatic Normalization and Image Matching and Anatomical
Labeling (\animal)}

The \animal algorithm carries out image registration is in two phases. In the
first, a 12-parameter linear transformation (3 translations, rotations, scales,
shears) is estimated between images using an algorithm that maximizes the
correlation between blurred MR intensities and gradient magnitude over the whole
brain \citep{Collins}. In the second phase, nonlinear registration is completed
using the \animal algorithm \citep{Collins1995}: an iterative procedure that
estimates a 3D deformation field between two MR images. At first, large
deformations are estimated using blurred version of the input data. These larger
deformations are then input to subsequent steps where the fit is refined by
estimating smaller deformations on data blurred with a Gaussian kernel with a
smaller FWHM. The final transformation is a set of local translations defined on
a bed of equally spaced nodes that were estimated through the optimization of
the correlation coefficient.  For the purposes of this work we used the
regularization parameters optimized in \citet{Robbins2004}, displayed in table
\ref{tab:ANIMAL-params}. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ANIMAL parameters                    
%                                     
\begin{table}[!tbp]
\begin{center}
\caption{\animal  registration parameters}
\begin{tabular}{l | c c c}
\hline 
Parameters        & Stage 1 & Stage 2 & Stage 3  \tabularnewline
\hline 
Model Blur (FWHM) &   8     &    8    &   4      \tabularnewline
Input Blur (FWHM) &   8     &    8    &   4      \tabularnewline
Iterations        &   30    &    30   &   10     \tabularnewline
Step              &   8x8x8 &  4x4x4  &   2x2x2  \tabularnewline
Sub-Lattice       &   6     &    6    &   6      \tabularnewline
Lattice Diameter  &24x24x24 &12x12x12 & 6x6x6    \tabularnewline
\hline
\end{tabular}
\end{center}
\label{tab:ANIMAL-params}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subparagraph{Automatic Normalization Tools (\ants)}

\ants is a diffeomorphic registration algorithm which provides great flexibility
over the choice of transformation model, objective function, and the consistency
of the final transformation \citep{Avants2008}. The transformation is estimated in a
hierarchical fashion where the MRI data is subsampled, allowing large
deformations to be estimated and successively refined at later hierarchical
stages (where the data is subsampled to a finer grid). The deformation field and
the objective function are regularized with a Gaussian kernel at each level of
the hierarchy. The \ants algorithm is freely available
\url{http://www.picsl.upenn.edu/ANTS/}. We used an implementation of the \ants
algorithm compatible with the MINC data format, mincANTS
\url{https://github.com/vfonov/mincANTS}.

We used the following command line when running \ants:
{\small
\begin{verbatim}
  mincANTS 3 -m PR[target_file.mnc,source_file.mnc,1,4] 
   --number-of-affine-iterations 10000x10000x10000x10000x10000 
   --affine-gradient-descent-option 0.5x0.95x1.e-4x1.e-4
   --use-Histogram-Matching --MI-option 32x16000
   -r Gauss[3,0] -t SyN[0.5] -i 100x100x100x20
   -o transformation.xfm
 \end{verbatim}
}
These settings were adapted from the "reasonable starting point" given in the
\ants manual 
\footnote{\url{https://sourceforge.net/projects/advants/files/Documentation/}}.

\paragraph{Label fusion methods}
Label fusion is a term given to the process of combining the information from
several candidate labellings for an intensity image into a single labelling.  In
this experiment we explore three fusion methods. 
\begin{description}
  \item[Voxel-wise Majority Vote]
  Labels are propagated from all template library images to a target.  Each
  output voxel is given the most frequent label at that voxel location amongst
  all candidate labellings.  Ties are broken arbitrarily.

  \item[Cross-correlation Weighted Majority Vote]
  An optimal combination of targets from the template library has previously been
  shown to improve segmentation accuracy \citep{Aljabar2009,Collins2010}.  In this
  method, each template library image is ranked in similarity to each unlabelled 
  image by the normalized cross-correlation (CC) of image intensities after linear
  registration, over a region of interest (ROI) generously encompassing the 
  hippocampus.  Only the top ranked template library image labels are used in a
  voxel-wise majority vote. The ROI is heuristically defined as the extent of all
  atlas labels after linear registration to the template, dilated by three voxels
  \citep{MallarChakravarty2012}.  The number of top ranked template library image labels
  is a configurable parameter and displayed as the size of the template library
  in the rest of the paper. 

  The {\tt xcorr\_vol} utility from the \animal toolkit is used to calculate the
  cross-correlation similarity measure.  
 
  \item[Normalised Mutual Information Weighted Majority Vote]
  This method is similar to cross-correlation weighted voting except that image
  similarity is calculated by the normalised mutual information score over the
  region of interest\citep{Studholme2001}.  The {\tt itk\_similarity} utility
  from the EZMinc toolkit\footnote{\url{https://github.com/vfonov/EZminc}} is
  used to calculate the normalised mutual information measure between to images.
\end{description}
\paragraph{Evaluation method}  

The Dice similarity coefficient (DSC) assesses the agreement between two
segmentations. It is one of the most widely used measures of segmentation
performance, and we use it as the basis of comparison in this experiment.
Additionally, we report the Jaccard index, another commonly used similarity
measure:

 \[\text{Dice's coefficient (DSC)} = \frac{2|A \cap B|}{|A| + |B|}\]

 \[\text{Jaccard (J)} = \frac{|A \cap B|}{|A \cup B|} = \frac{DSC}{(2-DSC)}\]

where $A$ and $B$ are the regions being compared, and the cardinality is the
volume measured in voxels. 

The manual segmentations (SNT) provided as part of the ADNI dataset are used as
the gold standard to compare with \citep{Hsu2002}.  The segmentation accuracy
reported is averaged over the ten validation rounds for each parameter setting.  

In order to investigate the performance of \mb in a real world setting in which 
only one set of atlas and template images are used, we explore the variability 
in label agreement at fixed parameter settings when the choice for atlas and 
template images is varied. This is achieved by first computing the standard 
deviation and variance of DSC scores in each block of ten validation rounds per
subject. The distribution of these statistics across all subjects is then
compared between \mb and multi-atlas using a Student's t-test. A significant
difference between distributions is taken to show either a larger or smaller
level of variability between methods. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                                                                     %%%%%
%%%%%        Experiment 2: Hippocampal Subfield Cross-Validation          %%%%%
%%%%%                                                                     %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Experiment 2: Hippocampal Subfield Cross-Validation}
In this experiment, the accuracy of the \mb algorithm on hippocampal subregion
segmentation is tested using a leave-one-out cross-validation (LOOCV) design. 
The optimal parameter settings for \mb found in Experiment 1 are used in this 
experiment.

\paragraph{Winterburn Atlases dataset} 
The Winterburn atlases \citep{Winterburn2013} are digital hippocampal
segmentations of five in-vivo $300\mu$ isotropic T1-weighted MR images. The
segmentations include subfield segmentations for the cornus ammonis (CA) 1, CA4,
dentate gyrus, subiculum, and CA 2 and 3 combined. Subjects in the Winterburn
atlases range in age from 29-57 years (mean age of 37), and include two males
and three females.  

In addition to the high-resolution scans distributed as part of the Winterburn
atlases, we also obtained additional 3T T1 BRAVO images (0.9mm-isotropic voxels)
of four of the five Winterburn atlas subjects. 

\paragraph{Experiment details} 
Leave-one-out cross-validation (LOOCV) is an approach in which the method to be
validated is given all but one item in a dataset as training data, and the
output is compared with the left-out item. This is done, in turn, for each item
in the dataset. 

In this experiment the Winterburn atlases are used as the cross-validation
dataset.  The five $300\mu$-isotropic voxel images and labels are used as
atlases, and LOOCV is conducted using the five Winterburn atlas subject images
subsampled (using trilinear interpolation) to 0.9mm-isotropic voxel resolution
(referred to as the {\em Subsampled} dataset) as input subjects. Subsampling the
subject images allows us to assess \mb in a typical segmentation scenario
(high-resolution atlases and lower-resolution subjects).  The template library
is composed of the subject images, plus an additional set of 3T T1 images
(0.9mm-isotropic voxels) of healthy subjects acquired separately (Table
\ref{table:WAval-healthy-demographics}). The optimal size of template library,
registration method, and label fusion method found in Experiment 1 are used.
Each resampled Winterburn atlas subject image is segmented by \mb with that
subject's image excluded from the atlas library.

We reproduce this experiment in a separate LOOCV run in which the resampled 
Winterburn atlas subject images are substituted for separately acquired T1 
BRAVO images of four of the subjects (referred to as the {\em BRAVO} dataset).

\paragraph{Evaluation method}  
To assess the \mb LOOCV segmentations we compute the relative percent error in 
hippocampal volume with the full resolution Winterburn atlas 
segmentations. In addition, by computing the relative error in volume of the
Winterburn atlas labels resampled (with nearest-neighbour interpolation) to
0.9mm-isotropic voxels, we obtain a baseline error to assess against.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                                                                     %%%%%
%%%%%         Experiment 3: Application of \mb to the segmentation        %%%%%
%%%%%                       of schizophrenia patients                     %%%%%
%%%%%                                                                     %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Experiment 3: Application to the segmentation first episode
schizophrenia patients}
 
To validate that \mb algorithm works effectively in the context of other
neuropsychiatric disorders, we use the Winterburn atlases with \mb to predict
the hippocampal segmentation of dataset of Schizophrenia patient MR images. The
resulting segmentations are assessed for quality by comparison with expert
manual segmentations.

\paragraph{\FEPdataset dataset}
All patients were recruited and treated through the Prevention and Early
Intervention Program for Psychoses (PEPP-Montreal), a specialized early
intervention service at the Douglas Mental Health University Institute in
Montreal, Canada. People aged 15–30 years from the local catchment area
suffering from either affective or non-affective psychosis who had not taken
antipsychotic medication for more than one month with an IQ above 70 were
consecutively admitted as either in- or out-patients. Of those treated at PEPP,
only patients aged 18 to 30 years with no previous history of neurological
disease or head trauma causing loss of consciousness were eligible for the
neuroimaging study; only those suffering from schizophrenia spectrum disorders
were considered for this analysis.  For complete program details see
\citet{Malla2003}. 

Scanning of 81 subjects was carried out at the Montreal Neurological Institute
on a 1.5-T Siemens whole body MRI system.  Structural T1 volumes were acquired
for each participant using a three-dimensional (3D) gradient echo pulse sequence
with sagittal volume excitation (repetition time=22ms, echo time=9.2ms, flip
angle=$30{\circ}$, 180 1mm contiguous sagittal slices). The rectangular
field-of-view for the images was 256mm (SI)$\times$204mm (AP).  Subject
demographics are shown in table \ref{tab:SZFEP-Demographics}. 

Each subject hippocampus is traced following a validated segmentation protocol 
\citep{Pruessner2000}. 

\paragraph{Experiment details} 
\mb is configured with an atlas library composed of the Winterburn T1 atlases
(see Experiment 2).  All images from the \FEPdataset dataset are segmented by \mb.  The 
optimal size of template library, registration method, and label fusion method 
found in Experiment 1 are used. 

\paragraph{Evaluation method}
The manual and Winterburn hippocampal segmentation protocols differ slightly in
the neuroanatomical features that are delineated.  This poses a problem for
evaluation by measuring overlap.  That is, since different protocols will
necessarily produce segmentations that do not perfectly overlap, the degree of
overlap cannot be solely used to compare segmentation methods using different
protocols. In place of an overlap metric, we can assess the degree of correlation in
average hippocampal volume of the subjects produced by each method.
Specifically, Pearson correlation is used. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% First Episode SZ Demographics Table
%
<<FEP-SZ-demographics, echo=F, results="asis",cache=FALSE>>=
fep_sz_demographics = read.csv("data/SZ_demographics.csv", na.strings=c("","."))
fep_sz_demographics = subset(fep_sz_demographics, Anon <= 81)
tab <- summary(DX ~ Age + Gender + Handedness + Education + SES + FSIQ,
               data=fep_sz_demographics, method = "reverse", test = FALSE)
latex(tab, file="", ctable=FALSE,
      caption="Schizophrenia First Episode Patient Demographics",
      title="tab:SZFEP-Demographics")
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                                                                     %%%%%
%%%%%         EXPERIMENT 4: Application of \mb to the segmentation        %%%%%
%%%%%                       of ADNI subjects                              %%%%%
%%%%%                                                                     %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Experiment 4: Application to the segmentation of Alzheimer's
disease patients}

To validate that \mb algorithm works as well as established automated methods,
\mb is applied to the ADNI1 dataset and the resulting segmentations are
compared to those produced by FreeSurfer, FSL, MAPER, and by expert manual
segmentation.

\paragraph{ADNI1 dataset revisited} 
All images from the {\em \adnidataset} standardized dataset described
in Experiment 1 are used.  Clinical and demographic data are shown in table
\ref{tab:ADNI1-1.5T-Complete-1Yr-Dataset-Demographics}. 

\paragraph{Experiment details} 
\mb is configured with an atlas library composed of the Winterburn T1 atlases
(see Experiment 2). All images from the \adnidataset dataset are
segmented. The optimal size of template library, registration method, and label
fusion method found in Experiment 1 are used. The template library is composed
of equal numbers of images from each disease class (AD, MCI, and cognitively
normal controls). 

\paragraph{Evaluation method}
As in Experiment 3, the manual (SNT) and Winterburn hippocampal segmentation
protocols differ in the neuroanatomical features delineated, and so we must
assess \mb by the degree of correlation of average hippocampal volume across all
subjects produced by \mb and by manual segmentation.  Specifically, Pearson
correlation is used.  For comparison, we also compute the correlation in
hippocampal volume between the existing, established automated segmentation
methods: FSL, FreeSurfer, and MAPER.  Additionally, we evaluate the
volume-related fixed and proportional biases in all segmentation methods using
Bland-Altman plots \citep{Bland1986}.  


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ADNI1-COMPLETE
% Prepares the data in the form needed for plotting.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
<<ADNI-volumes-prep,echo=F,cache=T>>=
means.complete   <- read.csv(gzfile('data/cache/ADNI1:means.complete.csv.gz'))
package_totals   <- read.csv(gzfile('data/cache/ADNI1:package_totals.csv.gz'))
@


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                                             
% ADNI1 Complete 1Yr Dataset Demographics Table 
%                                                                             
<<ADNI-demographics, echo=F, results="asis",cache=FALSE>>=
# RID < 2000 ensures only ADNI1 patients
yr1 = read.csv("data/ADNI_baseline_volumes/ADNI1_Complete_1Yr_1.5T_11_15_2012.csv")
yr1$VISCODE <- factor(yr1$Visit, levels = c(1,2,3,4), labels=c("bl","m03","m06","m12"))
yr1 = subset(yr1, !grepl("Scaled_2", Description))
yr1 = yr1[,c("RID","VISCODE")]
yr1 = 
adnimerge.yr1 = merge(adnimerge, yr1) 
tab <- summary(DX.bl ~ AGE + PTGENDER + PTEDUCAT + PTETHCAT + CDRSB + ADAS13 +
               MMSE, data = adnimerge.yr1, 
               #subset = RID %in% yr1$RID & VISCODE %in% c('bl','m06','m12'),   
               method = "reverse", test=FALSE, overall=TRUE)

latex(tab, file="", size="scriptsize", 
    caption="ADNI1 1.5T Complete 1Yr dataset demographics",
    label="tab:ADN1-1.5T-Complete-1Yr-Dataset-Demographics")
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                               RESULTS                                        %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Results}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                                                                     %%%%%
%%%%%     RESULTS: Experiment 1: Whole Hippocampus Cross-Validation       %%%%%
%%%%%                                                                     %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Experiment 1 Results: Whole Hippocampus Cross-Validation}

In this experiment we conducted 10 rounds of \mb and multi-atlas segmentation of
each of 69 subjects at a range of atlas and template library sizes, registration
algorithm (\ants or \animal), and three label fusion techniques.  Hippocampal
\mb-based segmentations using both \animal and \ants registration algorithm
demonstrate good overlap with SNT derived gold-standards (Figure
\ref{fig:ADNI1-xval-k-mean}). Qualitatively, both \animal and \ants-based
segmentations demonstrate trend overlap accuracy that increases with the size of
atlas library and template library. Improvement in accuracy diminishes noticeably
with template libraries larger than roughly ten images. 

No marked difference in segmentation accuracy is seen when either \animal or \ants
registration is used with any number of atlases or templates.  In every parameter 
configuration, the use of \mb with \ants registration shows a pronounced increase
in segmentation accuracy over \mb with \animal registration.  Surprisingly, the 
label fusion method used does not significantly improve label accuracy, contrary 
to the findings of \citet{Aljabar2009} when using weighted voting on much larger
atlas/template libraries. In the remainder of  this section, only results using
the \ants registration algorithm and majority vote fusion will be shown.

With an increasing number of templates, \mb shows improvement in overlap
accuracy over multi-atlas-based segmentation when using the same number of atlases
and voting method (Figure \ref{fig:ADNI1-xva-k-diff}). The magnitude of improvement over
multi-atlas-based segmentation decreases with an increasing number of atlases,
with accuracy converging with 7 atlases.  Peak improvement in \mb accuracy (~0.02
DSC) is found when one atlas is used with a template library of 20 images.

In addition to an improvement in accuracy over multi-atlas-based segmentation,
\mb also shows a decrease in the variability of segmentation accuracy 
(Figure \ref{ADNI1-xval-variability}).  The size of template library 
necessary to reach a significant ($p < 0.05$) decrease in variance and standard 
deviation grows with the size of atlas library used.  A template library of 19
images is sufficient to show significant decrease in variance and standard 
deviation for 3-7 atlases. 

We have omitted results obtained when using an even number of atlases or
templates since with this configuration we found significantly decreased
performance. We believe this is as a result of an inherent bias in the majority
vote fusion method used (see Discussion).  

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ADNI1-XVAL: prep
% Prepares the data in a the form needed for plotting.
<<ADNI1-xval-prep,dependson='ADNI1-xval-load',include=FALSE,cache=TRUE>>=
all_data  <- read.csv(gzfile('data/cache/ADNI-XVAL:all_data.csv.gz'))
all_data_mean  <- read.csv(gzfile('data/cache/ADNI-XVAL:all_data_mean.csv.gz'))
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% \begin{figure}
% <<ADN1-library-composition, cache=TRUE, dependson='ADNI1-Xval-prep'>>=
% # These composition datasheets describe the subjects and subject DX in the 
% # template and atlas libraries for each voting run
% atlas_comp = read.csv('data/a2a_ants/atlas_library_composition.csv')
% templ_comp = read.csv('data/a2a_ants/template_library_composition.csv')
% a2a.best = subset(all_data, atlases == 9 &
%                     templates.mb == 19 &
%                     reg_method=='ANTS' &
%                     method.mb =='Majority Vote')
% 
% cumulative_dist = 
%   ggplot(a2a.best, aes(x=k.mb)) + stat_ecdf() + scale_y_continuous(breaks=seq(0,1,0.1))
% 
% a2a.best = subset(a2a.best, k.mb > 0.75) # drop the guys that suck
% 
% a2a.best = merge(a2a.best, atlas_comp, by=c("timestamp","atlases"))
% a2a.best = merge(a2a.best, templ_comp, by.x=c("timestamp","templates.mb"), by.y=c("timestamp","templates"))
% a2a.best$templates_AD_percent = (a2a.best$templates_AD / 19) * 100
% a2a.best$templates_MCI_percent = (a2a.best$templates_MCI / 19) * 100
% a2a.best.melted = melt(a2a.best, measure.vars=c("templates_AD_percent", "templates_MCI_percent"))
% 
% k_by_composition = 
%   ggplot(a2a.best.melted, aes(x=value, y=k.mb, colour=DX)) + facet_grid(variable ~ DX) + 
%   geom_boxplot(aes(group=as.factor(value), colour=DX)) +  geom_smooth(method="lm") 
% 
% snt.unilateral.vols = read.csv('data/a2a_snt_volumes.csv')
% a2a.best = merge(a2a.best, snt.unilateral.vols)
% 
% # bland-altman plots
% bland_mb_overall = with(a2a.best, bland_altman_plot(volume.snt, volume.mb, DX) + 
%   geom_smooth(method="lm") + 
%   scale_y_continuous(breaks=seq(-500, 500, 50)))
% 
% bland_ma_overall = with(a2a.best, bland_altman_plot(volume.snt, volume.ma, DX) + 
%   geom_smooth(method="lm") + 
%   scale_y_continuous(breaks=seq(-500, 500, 50)))
% 
% # just the trials with a high percentage of MCI in the template library
% a2a.best.highMCI = subset(a2a.best, templates_MCI_percent > 50)
% 
% bland_mb_highMCI = with(a2a.best.highMCI, bland_altman_plot(volume.snt, volume.ma, DX) + 
%   geom_smooth(method="lm") + 
%   scale_y_continuous(breaks=seq(-500, 500, 50)))
% 
%   
% @
% \end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ADNI1-XVAL: mean Kappa plot by atlases, templates, reg and voting method. 
\begin{figure}
<<ADN1-xval-k-mean, cache=TRUE, dependson='ADNI1-Xval-prep', fig.width=7, fig.height=7>>=
stderr <- function(x) sqrt(var(x)/length(x))
ggplot(subset(all_data_mean, (templates.mb*atlases) %% 2 == 1),
       aes(x=templates.mb,y=k.mb, colour=as.factor(atlases))) + #as.factor((atlases*templates.mb) %% 2 ))) + 
  facet_grid(reg_method~method.mb) + 
  stat_summary(fun.y=mean,geom='line',
               aes(y=k.mb, weight=1, group=as.factor(atlases))) + 
  stat_summary(fun.y=mean,
               fun.ymin=function (x) mean(x) - stderr(x),
               fun.ymax=function (x) mean(x) + stderr(x), 
               geom='errorbar',
               aes(y=k.mb, weight=1, group=as.factor(atlases)), width=0.5) + 
  #stat_smooth(method='lm', formula=y~log(x)) + 
  scale_colour_hue(name="Number of Atlases") +
  xlab( "Number of Templates" ) + 
  ylab( "Mean DSC" ) + 
  theme(legend.direction = "horizontal", legend.position = "bottom", 
        axis.text = element_text(size = 8))
@
  \label{fig:ADNI1-xval-k_mean}
  \caption{Mean Dice's Similarity Coefficient of \mb segmentations with manual
  segmentations (SNT) for 69 ADNI1 subjects vs. atlas and template library size,
  registration algorithm, and label fusion method. Points above zero indicate an
  \mb parameter settings yielding a higher mean DSC score than multi-atlas
  segmentation using the same number of atlases.}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ADNI1-XVAL: "increase" in mean kappa over multi-atlas
\begin{figure}
<<ADN1-Xval-k-diff,cache=TRUE,dependson='ADNI1-Xval-prep'>>=
ggplot(subset(all_data_mean, reg_method=="ANTS" & 
                method.mb=="Majority Vote" & (templates.mb*atlases) %% 2 == 1), 
       aes(x=templates.mb, y=k_diff, colour=as.factor(atlases))) + 
  #facet_grid(reg_method~method.y) + 
  stat_summary(fun.data=mean_cl_boot,geom='errorbar',
               aes(y=k_diff,colour=as.factor(atlases), width=0.2)) +
  stat_summary(fun.y=mean, geom="point", 
               aes(y=k_diff,colour=as.factor(atlases))) + 
  stat_summary(fun.y=mean, geom="line", 
               aes(y=k_diff,colour=as.factor(atlases))) + 
  #stat_smooth(method=lm, formula=y~log(x)) + 
  geom_hline(aes(alpha=0.5, yintercept=0), linetype='dashed') + 
  scale_x_continuous(breaks=seq(1,20,2)) + scale_y_continuous(breaks=seq(-1,1,by=0.01)) + 
  scale_colour_hue(name="Number of Atlases") +
  scale_alpha_continuous(guide = "none") + 
  scale_linetype_discrete(guide = "none") + 
  xlab( "Number of Templates" ) + 
  ylab( "Difference in mean DSC" ) +
  theme(legend.direction = "horizontal", legend.position = "bottom")
@
  \caption{Difference in mean Dice's Similarity Coefficient of \mb and
  multi-atlas segmentations with manual (SNT) segmentations for a range of atlas
  and template library sizes.}
  \label{ADNI1-xval-k-diff}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ADNI1-XVAL: show variability of MAGeT over parameters
\begin{figure}
<<ADN1-Xval-variability, cache=TRUE, dependson='ADNI1-Xval-prep'>>=
ants = subset(all_data_mean, 
                     reg_method=="ANTS" & 
                     method.mb=="Majority Vote" &
                    templates.mb %in% seq(1,20,2))

ants.stats = ddply(ants, c("subject", "atlases","templates.mb"), 
                   function (df) {
                     data.frame(
                       MA.sd  =  sd(df$k.ma),
                       MB.sd  =  sd(df$k.mb),
                       MA.var = var(df$k.ma),
                       MB.var = var(df$k.mb)
                       )
                   })

stats.tests = ddply(data.stats, c("atlases","templates.mb"), function (df) {
  t.var = t.test(df$MA.var, df$MB.var)
  t.sd  = t.test(df$MA.sd , df$MB.sd)
  diff_mean_var = mean(df$MA.var - df$MB.var)
  diff_mean_sd  = mean(df$MA.sd -  df$MB.sd)
  
  # test statistic is positive if MA mean is larger than MB
  # i.e. that MA has a greater mean of variances/SDs
  # i.e. that MB has a smaller mean, and so is doing "better"
  data.frame(
    stat      = c("Variance", "Standard Deviation"),
    statistic = c(t.var$statistic, t.sd$statistic),
    p.value   = c(t.var$p.value, t.sd$p.value),
    direction = c(diff_mean_var, diff_mean_sd)
  )
})

ggplot(subset(stats.tests, direction > 0 & stat == "Variance"), 
  aes(x=templates.mb, y=p.value, colour=as.factor(atlases))) + 
  #facet_grid( . ~ stat) + 
  geom_line(size=1) +
  geom_point(size=3) + 
  geom_hline(aes(yintercept=0.05, alpha=0.5), linetype='dashed') + 
  geom_hline(aes(yintercept=0.01, alpha=0.5), linetype='dashed') + 
  scale_x_continuous(breaks=seq(1,20,by=2)) + 
  scale_y_log10(limits=c(0.001,1), breaks=c(0.01,0.05,0.1,1.0)) + 
  xlab( "Number of Templates" ) + 
  ylab( "Difference of variance during validation (p-value)" ) +
  scale_colour_hue(name="Atlases") +
  scale_alpha_continuous(guide='none') + 
  scale_linetype_discrete(guide='none') + 
  scale_size_continuous(guide='none') + 
  theme(legend.direction = "horizontal", legend.position = "bottom")
@
  \caption{{\bf Difference in variability of \mb vs. multi-atlas segmentation 
  accuracy.}
  Variance of segmentation accuracy between \mb and multi-atlas segmentation 
  is computed for each subject across all ten rounds of validation. Shown on the 
  y-axis (scaled logarithmically) is the  p-value resulting from a t-test 
  comparing the distribution of variances at each parameter setting 
  (atlas/template library size). Only points where \mb mean variability is lower 
  than multi-atlas are shown.}
  \label{ADNI1-xval-variability}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\FloatBarrier

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                                                                     %%%%%
%%%%%    RESULTS: Experiment 2: Hippocampal Subfield Cross-Validation     %%%%%
%%%%%                                                                     %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Experiment 2 Results: Winterburn Atlases Cross-Validation}
This experiment explores \mb segmentation of hippocampal subfields. To
achieve this, a leave-one-out validation is conducted in which lower-resolution
images ($0.9mm^3$ voxels) of each Winterburn atlas subject are segmented using 
the remaining Winterburn atlases. 

In general, across hippocampal subregions the percent error in volume of
\mb segmentations compares
favourably to the error resulting from image resampling (Figure
\ref{fig:WAval-vol-boxplot}). In particular, the CA1, CA4, and Dentate
subregions all show near or smaller percent errors. The Sibiculum and CA2/CA3
subregions show distinctly larger error than is found through resampling.  

Figure \ref{fig:subfield-montage} shows a qualitative comparison of \mb subfield
segmentation.  


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Winterburn-XVAL: compare resampling
\begin{figure}[h!]
<<WAval-vol-boxplot,cache=T,fig.width=6,fig.height=4>>=
data = subset(read.csv('data/WAval.csv'))
casted = dcast(melt(data, id.vars=c("file","version")), file + variable ~ version)
casted = rename(casted, c("variable"="region"))

error = ddply(casted, c("file", "region"), function(df) {
  with(df, 
  data.frame(
    resampled = (gold_0.9mm - gold_0.3mm) / gold_0.3mm * 100, 
    mb_bravo  = (mb_bravo   - gold_0.3mm) / gold_0.3mm * 100, 
    mb_0.9mm  = (mb_0.9mm   - gold_0.3mm) / gold_0.3mm * 100))})

levels(error$region) <-list("CA1"="X1", "CA1"="X101", 
                            "Subiculum"="X2","Subiculum"="X102", 
                            "CA4/DG"="X4","CA4/DG"="X104", 
                            "CA2/CA3"="X5","CA2/CA3"="X105", 
                            "SR/SL/SM"="X6","SR/SL/SM"="X106")
melted = melt(error,id.vars=c("file", "region"))
melted = rename(melted, c("variable"="measure", "value"="percenterr"))
levels(melted$measure) <- list("Subsampled"="resampled",
                               "MAGeT + Subsampled" = "mb_0.9mm",
                               "MAGeT + BRAVO"="mb_bravo")

ggplot(melted, aes(y=percenterr,x=region,colour=measure)) +
  geom_hline(aes(yintercept=0), colour="grey", size=1) + 
  geom_boxplot() +
  labs(y=expression(paste("Percent error in volume relative to 0.3", mm^3, " Winterburn Atlases")), x="Region") +
  scale_colour_discrete("") + 
  theme(legend.direction = "horizontal", legend.position = "bottom")
@
  \caption{{\bf Percent error in segmentation volume by hippocampus subregion.} 
  Percent error is measured against the volumes of of the unmodified Winterburn
  atlas segmentations.
  {\bf Subsampled} are volumes of the manual segmentations of the Winterburn
  atlases after resampling to $0.9mm^3$.  
  {\bf MAGeT + WA Subsampled} volumes are \mb segmentations of the Winterburn atlas
  images after resampling to $0.9mm^3$ voxels.
  {\bf MAGeT + WA BRAVO} volumes are \mb segmentations of T1 BRAVO images
  ($0.9mm^3$ voxels) acquired separately of four of the five Winterburn atlas
  subjects.} 
  \label{fig:WAval-vol-boxplot}
\end{figure}


\begin{figure}
  \begin{centering}
    \includegraphics[width=6in]{figure/subfield-montage.pdf}
  \end{centering}
  \caption{Sagittal slices from two subjects showing a comparison of the
  original Winterburn atlas subfield segmentations (at 0.3mm-isotropic voxel
  resolution), the subsampled Winterburn segmentations (at 0.9mm-isotropic
  voxel resolution), and the \mb labels on the subsampled atlas image.}
  \label{fig:subfield-montage}
\end{figure}

\todo[inline]{Figure \ref{fig:subfield-montage}. Show MAGeT segmentations on
BRAVO images.  Also, show coronal/transverse slices and MNI coordinates}

\FloatBarrier
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                                                                     %%%%%
%%%%%    RESULTS: Experiment 3, Application of \mb to the segmentation    %%%%%
%%%%%                       of schizophrenia patients                     %%%%%
%%%%%                                                                     %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Experiment 3 Results: Application to the segmentation of first episode
\\ \mbox{schizophrenia patients}}
 
In this experiment \mb is applied to a dataset of images of first episode
schizophrenia patients, using the Winterburn atlases and a template library of
21 subject images selected at random.  Expert manual whole hippocampal
segmentations are used as gold standards. 

\begin{figure}
<<FEP-volumes,cache=FALSE,dependson="setup">>=
SZ_volumes=read.csv("data/SZ_volumes_by_method.csv", sep="\t")
mean_sz_vols = ddply(SZ_volumes, c('Subject', 'Method'), function (df) {
  data.frame(Volume = mean(df$Volume))})
    
casted = dcast(mean_sz_vols, Subject ~ Method, value.var = "Volume")
lm = lm(MAGeT ~ Manual, casted)
ggplot(data=casted, aes(x = Manual, y = MAGeT)) + 
  geom_smooth(method="lm", formula=y~x) + 
  geom_point() + 
  geom_text(aes(x=3500, y=5000, label=lm_eqn(lm),hjust=0,size=1), parse=TRUE, data=data.frame()) +
  xlab(expression("Mean Manual hippocampus volume " (mm^3))) + 
  ylab(expression("Mean MAGeT hippocampus volume "  (mm^3))) + 
  scale_size_continuous(guide="none") 
@
  \caption{Subject mean hippocampal volumes by \mb vs. manually segmented
   volumes from the First Episode Patients with Schizophrenia dataset. A linear fit
   and standard error are shown.}
  \label{fig:SZ-volumes}
\end{figure}

<<FEP-t-test,cache=TRUE,dependson="FEP-volumes">>=
  fep.cor.test = cor.test(casted$Manual, casted$MAGeT)
@
\mb produces hippocampus segmentation volumes that are highly correlated with 
manual segmentation volumes (Pearson $r = \Sexpr{fep.cor.test$estimate}$, 
$t = \Sexpr{fep.cor.test$statistic}$, $p < \Sexpr{max(0.001,
fep.cor.test$p.value)}$; Figure \ref{fig:SZ-volumes}). 


\FloatBarrier
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                                                                     %%%%%
%%%%%                           RESULTS                                   %%%%%
%%%%%                                                                     %%%%%
%%%%%         EXPERIMENT 4: Application of \mb to the segmentation        %%%%%
%%%%%                       of ADNI subjects                              %%%%%
%%%%%                                                                     %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Experiment 4 Results: Application to the segmentation of Alzheimer's
disease patients}

Based on the results from the ADNI1 Cross-Validation experiment, in this
experiment \mb was configured with a template library of 21 randomly chosen
subject images (7 from each disease class) and used majority vote label fusion.
The entire \adnidataset dataset was segmented by \mb and we now compare the
resulting volumes with those obtained by manual segmentation (SNT), and other
automated segmentation techniques (MAPER, FreeSurfer, and FSL).  Table
\ref{tab:ADNI1-1.5T-Complete-1Yr-Dataset-Method-Totals} shows the total count of
segmentations available, including a count of those which have failed a quality
control inspection. Only those images which had segmentations from every method
are included in the following analysis (a total of
\Sexpr{length(means.complete$RID)} images).
 
We find a close relationship in total bilateral hippocampal volume between
all methods and manually segmented volumes (Figure \ref{fig:ADNI-volumes-plot}). 
Volumes are correlated with Pearson $r > 0.78$ for all methods across disease
categories.  Within disease categories (Figure \ref{fig:ADNI-volumes-boxplot}),
\mb is consistently well correlated to manual volumes (Pearson $r > 0.85$), but
appears to slightly over-estimate the volume of the AD hippocampus. 

To investigate the level of agreement with manually segmented hippocampal
volumes, we constructed Bland-Altman plots for each method (Figure
\ref{fig:ADNI-Bland-Altman}).  As \citet{Bland1986} noted, high correlation
amongst measures of the same quantity does not necessarily imply agreement (as
correlation can be driven by a large range in true values, for instance).  What
is most striking in Figure \ref{fig:ADNI-Bland-Altman} is that all methods show
an obvious proportional bias: FreeSurfer and FSL markedly under-estimate smaller
hippocampi and over-estimate large hippocampi, whereas MAPER and \mb more
conservatively show the reverse bias.  Additionally, all methods show a fixed
bias, with FreeSurfer and FSL most dramatically over-estimating hippocampal
volume by $2600 mm^3$ and $2800 mm^3$ on average, respectively, and MAPER and
\mb within $250 mm^3$ on average. 

Figure \ref{fig:ADNI-subfields} shows a qualitative comparison of \mb and 
manual (SNT) hippocampal segmentations for 10 randomly selected subjects in 
each disease category, and illustrates some of the common errors found during 
visual inspection. Mostly frequently, we find \mb improperly includes the vestigial
hippocampal sulcus and, although not anatomically incorrect, \mb under-estimates 
the hippocampal body in comparison to the manual (SNT) segmentation.  

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ADNI1 1yr Complete Dataset Package Totals & Failures
%                        
<<ADNI-seg-package-totals, echo=F, results="asis",cache=FALSE>>=
caption = paste(
  "Pass/fail quality control indicators were supplied with the FreeSurfer",
  "volumes downloaded from the ADNI website (we used the temporal lobe quality",
  "control indicator, TEMPQC). One of the authors (MP) performed visual",
  "quality inspection for MAGeT and FSL segmentations.", sep=" ")
latex(package_totals, file="", size="scriptsize", 
    caption = caption,
    title = "",
    label="tab:ADNI1-1.5T-Complete-1Yr-Dataset-Method-Totals")
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{figure}[h]
<<ADNI-volumes-boxplot,dependson='ADNI-volumes-prep',cache=T,fig.width=7,fig.height=4>>=
melted = melt(means.complete,measure.vars=c("FS", "FSL", "MAPER","MAGeT"),
              variable.name="Method", value.name="Volume")
correlations = ddply(melted, c("DX","Method"), function (df) {
  data.frame(
    pearson = cor(df$SNT, df$Volume)
  )
})
m2 = melt(means.complete,measure.vars=c("FS", "FSL", "MAPER","MAGeT","SNT"), variable.name="Method")
levels(m2$Method) = c("FS"= "FreeSurfer", "FSL" = "FSL", "MAPER" = "MAPER", "MAGeT" = "MAGeT", "SNT" = "Manual")
m2$DX = factor(m2$DX, levels(m2$DX)[c(2,3,1)])

qplot(DX,value,data=m2,
      colour=Method,geom="boxplot") + 
      #geom_text(aes(y=-Inf,x=c(.7,.85,1,1.15, 1.7,1.85,2,2.15, 2.7,2.85,3,3.15), vjust=-5, label=round(pearson,2)), 
      #          colour = 'black', size=3, data=correlations) +
      xlab("Diagnosis") + 
      ylab(expression(paste("Hippocampal volume (", mm^3, ")"))) + 
      theme(legend.direction = "horizontal", legend.position = "bottom")
@
  \caption{Subject mean hippocampal volume as measured in the \adnidataset
dataset by FreeSurfer, FSL, MAPER, \mb, and manual raters (SNT) vs. disease
category.}
  \label{fig:ADNI-volumes-boxplot}
\end{figure}

\begin{figure}[h]
<<ADNI-volumes-plot,dependson='ADNI-volumes-prep',cache=T,fig.width=6,fig.height=4>>=
melted=melt(means.complete, measure.vars=c("FS", "FSL", "MAPER","MAGeT"), 
            variable.name = "Method", value.name = "volume")

df = means.complete

ggplot(data=melted, aes(x=SNT, y=volume, colour=Method)) + 
    geom_point(size=1) + 
    geom_smooth(method="lm") + 
    xlab(expression("Manual hippocampal volume " (mm^3))) + 
    ylab(expression("Automated hippocampal volume " (mm^3))) +
    annotate("text", y = c(2000,1500,1000,500), x=Inf-100, size=2.5,
              label = c(paste("FS r =", round(cor(df$SNT, df$FS),2)),
                        paste("FSL r =", round(cor(df$SNT, df$FSL),2)),
                        paste("MAPER r =", round(cor(df$SNT, df$MAPER),2)),
                        paste("MAGeT r =", round(cor(df$SNT, df$MAGeT),2))),
              hjust=1.1,vjust=1.5) +
    theme(legend.direction = "horizontal", legend.position = "bottom")
@
  \caption{Subject mean hippocampal volume as measured in the \adnidataset
dataset by each of the four automated methods investigated (FreeSurfer (FS),
FSL, MAPER, \mb) vs. manual rating (SNT). Linear fit lines and pearson
correlations are shown for each method.}
  \label{fig:ADNI-volumes-plot}
\end{figure}
 
\begin{figure}
<<ADNI-Bland-Altman, cache=TRUE, dependson='ADNI-volumes-prep', fig.width=7, fig.height=7>>=
names(means.complete)[8] = "FreeSurfer"
melted=melt(means.complete, measure.vars=c("FreeSurfer", "FSL", "MAPER","MAGeT"), 
            variable.name = "method", value.name = "volume")

melted$diff = melted$SNT - melted$volume
melted = subset(melted, (method == "FreeSurfer") | 
                        (method == "FSL"  ) | # & diff > -5000 & diff < 900) | 
                        (method == "MAPER") | # & diff > -500 & diff < 1000) | 
                        (method == "MAGeT"))  # & diff > -1100))
#melted = subset(melted, method == "MAGeT")
melted$DX = factor(melted$DX, levels(melted$DX)[c(2,3,1)])
melted$mean = ( melted$SNT + melted$volume ) / 2
limits = ddply(melted, c("method"), function (df) { 
  data.frame(
    y = mean(df$diff) + c(-1.96,0,2) * sd(df$diff) 
)}) 

names(melted)[4] = "Diagnosis"
ggplot(melted, aes(x= mean, y = diff, colour=Diagnosis)) + 
  facet_wrap( ~ method, nrow=2, scales="fixed") + 
  geom_smooth(method="lm", formula=y~x, fullrange=T, se=F) + 
  geom_point(size=1) +  
  geom_hline(aes(yintercept = y), linetype="dashed", colour="brown",
             data=limits, size=0.3, alpha=0.5) + 
  geom_text(aes(y = y, x=Inf, label=round(y,0)), colour="black", data = limits,
            hjust=1.1,vjust=-0.8, size=2.5) + 
  xlab(expression('Mean of manual and automated hippocampal volume ' (mm^3))) + 
  ylab(expression('Difference in manual and automated hippocampal volume ' (mm^3))) + 
  scale_y_continuous(breaks=seq(-10000,4000, 1000)) + 
  scale_x_continuous(breaks=seq(0,10000, 1000)) + 
  theme(legend.direction = "horizontal", legend.position = "bottom", 
        axis.text.y = element_text(angle = 90, hjust=0.5), 
        axis.text = element_text(size = 8))
@
  \caption{Bland-Altman plots comparing subject mean hippocampal volume as
measured in the \adnidataset dataset by manual raters (SNT) and each of the four
automated methods investigated (FreeSurfer, FSL, MAPER, \mb). The overall mean
difference in volume, and limits of agreement ($\pm 1.96SD$) are shown by dashed
horizontal lines. Linear fit lines are shown for each diagnosis group. Note,
points below the mean difference indicate overestimation of the volume with
respect to the manual rating, and vice versa. }

  \label{fig:ADNI-Bland-Altman}
\end{figure}




\begin{figure}
  \begin{centering}
    \includegraphics[width=6in]{figure/ADNI1_SNT_MB_montage/montage.pdf}
  \end{centering}
  \caption{Manual and MAGeT segmentation results for 30 ADNI1 subjects (10
  subjects randomly selected from each disease category in the subject pool used
  in Experiment 1). Sagittal slices are shown for subject unlabelled T1-weighted
  anatomical image, SNT manual label (green), and \mb label (blue). Noted are
  examples of common segmentation idiosyncrasies: 
  {\em (a)} over-estimation of hippocampal head and  
  {\em (b)} translated manual segmentation by SNT; 
  {\em (c)} under-estimation of hippocampal body and
  {\em (d)} improper inclusion of the vestigial hippocampal sulcus by \mb.}
  \label{fig:ADNI-subfields}
\end{figure}

\todo[inline]{Figure \ref{fig:ADNI-subfields}. Show coronal/transverse slices
and MNI coordinates}

\FloatBarrier

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                Discussion
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Discussion}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Tabulation of segmentation accuracies of existing methods (ADNI)
%
<<ADNI1-literature, echo=F, results="asis",cache=FALSE>>=
caption = paste(
  "Survey of automated segmentation accuracy of the ADNI dataset",
  sep=" ")

tab = read.csv("data/ADNI-existing-work.csv")
tab$Notes <- NULL

adni_lit = subset(tab, Dataset=="ADNI")
adni_lit$Dataset <- NULL
other_lit = subset(tab, Dataset!="ADNI")
other_lit$Dataset <- NULL

latex(adni_lit, file="", 
      size="scriptsize",
      caption=caption, 
      rowname=NULL,
      col.just=c("p{1.5in}l","p{0.5in}","p{1.3in}","p{1.5in}"),
      title="")
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


In this manuscript we have presented the implementation and validation of the
\mb framework -- a methodology that requires very few input atlases in
order to provide accurate and reliable segmentations.  We have demonstrated that
our methodology robustly provides accurate and consistent segmentations in
populations with different ageing and neuropsychiatric characteristics.
Further, we have demonstrated that algorithmic performance is not dependent on a
single definition of the hippocampus but is effective with differing hippocampal
definitions \citep{Winterburn2013,Pruessner2000,Hsu2002}.  Finally, we also demonstrate
that \mb provides accurate automatic identification of the hippocampal
subfields despite contrast and resolution limitations in standard T1-weighted
image volumes. 

Throughout the cross validation in Experiment 1 (10-fold cross validation in the
\adnidataset dataset subsample) we find that two parameter choices improve 
segmentation accuracy: increasing the number of atlases, and the number of
templates. However, after setting the parameters to 5 atlases and 15 templates
there are diminishing returns with respect to this improvement. We were
somewhat surprised to find that cross-correlation and normalized mutual
information based weighted voting did little to improve segmentation accuracy.
This suggests that using an intermediate template library generated by accurate
nonlinear registration methods such as \ants \citep{Avants2008} sufficiently filters
sources of error such as nonlinear registration error and partial volume effects
that arise through the use of nearest neighbour resampling. From our previous
work on the \mb algorithm we have shown that these increases in error
are not simply a smoothing or averaging effect \citep{MallarChakravarty2012}.  

Although, the goal of this manuscript was to not exhaustively test or validate
multiple different voting strategies in the context of our segmentation
algorithm, it is important to note that other strategies for voting are
available.  For example, other groups have used the STAPLE algorithm
\citep{Warfield2004} (or variants of the STAPLE algorithm \citep{Duchesne2012})
which weights each segmentation based upon its estimated
performance level with respect to the other available candidate segmentations.
Further, the sensitivity and specificity parameters could also be tuned to
potentially improve segmentation accuracy and reliability.  It is rather likely
that using more sophisticated voting methods would have a positive effect on the
overall segmentation performance.  

To this end, more work is required in order to determine the source of the
slight decrease in segmentation performance when the number of templates are set
to an even number.  Our initial concern was that this dip in performance was a
by-product of the \mb algorithm itself.  However, we determined that
this pattern was also true in the analysis of multi-atlas segmentations we used
in our experiments.  We believe that our majority voting methodology is biased
towards labels with the lowest numeric values when breaking ties, thus causing
the slight bias observed when using an even number of templates. This is another
area where the voting scheme could be used to improve performance. However, it
is worth noting that this limitation was previously identified by
\citet{Heckemann2006a} and, subsequently, other groups have not even considered
the potential pitfalls of an even number of candidate labels (eg.
\citet{Leung2010}).

Another concern is the moderate-to-small improvement observed in \mb in
comparison to multi-atlas segmentation when using the same number of atlases.
The actual benefit in using \mb is consistency of the labelling regardless of
atlas or template choice. This is an important consideration that few have
touched on previously. The 10-fold Monte Carlo cross validation that we present
in Experiment 1 is amongst one of the most stringent performed in the
multi-atlas/segmentation literature.  To the best of our knowledge other groups
have only ever performed a 3-fold validation \citep{?}.  This suggests that
our results are reflective of a true average over the choice of parameter
settings and are independent of atlas or template choice (provided the input
atlases are properly segmented).  

\todo[inline]{could we be seeing a ceiling effect... reaching the limit of what
is achievable with a multi-atlas-based segmentation method}

In comparison to other methodologies in the field, it is important to note that
\mb performs quite well.  Table 6 gives a survey of some of the most recent
multi-atlas implementations with the reported kappa values used to validate the
algorithm on the ADNI dataset (many of which use the same SNT labels for
populating their template library and as gold standards for evaluation).  While
it is difficult to compare segmentation results across studies, gold-standards,
evaluation metrics, and algorithms it is worth noting that the methods
summarized in Table 6 require more atlases (between 16-55) than our \mb
implementation with the Winterburn atlases \citep{Winterburn2013}.  Amongst these
methods only method 4 yields mean Kappas that are higher than the ones that are
reported here.  

There are some important differences between our method
and these specific methods.  Others have reported the difficulty with
mis-registrations in candidate segmentation (i.e. segmentations generated that are
then input in the voxel-voting procedure \citep{Collins2010}). The work of 
\citet{Leung2010} tackles this problem by using an intensity threshold
that is estimated heuristically at the time of segmentation (this work also
reports some of the highest kappas for the segmentation of ADNI data).  While
this works for the ADNI dataset (which is partially homogenized with respect to
image acquisition and pre-processing), it is unclear if this type of heuristic
is applicable to other datasets.  In all cases, these methods require more
atlases than our implementation with the Winterburn atlases.
\citet{Lotjonen2010} achieve highly accurate segmentation but correct their
segmentations using classifications derived using an expectation maximization
framework.  In their initial work, \citet{Chupin2009} develop their
probabilistic methodology using a cohort of 8 healthy controls and 15 epilepsy
patients.  In subsequent methods, they retuned their methodology using the ADNI
sample with a hierarchical experimentation protocol that involved.  These
methods suggest that some post-processing of the final segmentations would
improve accuracy of the segmentation.  While that may be true, there is little
consensus regarding how to achieve this.  

To the best of our knowledge, no other groups have validated their work using
multiple atlas segmentation protocols, different acquisitions, and disease
populations in order to demonstrate the robustness of their technique.  This is
one of the clear strengths of this work.  Furthermore, unlike some of the
algorithms mentioned, our implementation does not require retuning for new
populations or datasets as it inherently models the variability of the dataset
through the template library.  However it should be noted that the increased
accuracy that follows increasing the number of atlases and templates comes at an
increased computational cost ($O(log(n))$), as previously mentioned in
other work \citep{Heckemann2006}. 
\todo[inline]{time complexity seems suspicious} 

In comparison to the methods that we compared and were available through the
ADNI database (FreeSurfer, MAPER) and the method that we initialized ourselves
(FSL-FIRST) we find extremely variable performance of all methods.  With the
exception of FSL all methods correlate well with the SNT volumes provided in
the ADNI database.  However, FreeSurfer and FIRST provide radically different
definitions of the size of the hippocampus in comparison to the other methods.
Further, when estimating bias of these methods relative to SNT hippocampal
volumes we see that large hippocampi are over estimated while small hippocampi
are under estimated.  By comparison, our method and MAPER are far more
conservative suggesting that these methods may be better suited for estimating
true-positives.  While this comparison with these methods using only volume,
more work is needed to better understand the differences between our method and
other methods.

Finally, we have also demonstrated that our algorithmic framework is appropriate
for the segmentation of hippocampal subfields in standard T1-weighted data.
This has started to become a burgeoning topic in the segmentation literature,
although very few methods are available for the segmentation of 3T data
\citep{Yushkevich2009,VanLeemput2009}. However, the FreeSurfer implementation of
subfield segmentation. While recent work demonstrates that subfield
segmentations can be used for classification of AD, MCI, and NC, there has been
no explicit validation of the methodology based on accuracy or precision.
Although the initial hippocampal subfield segmentations from the Yushkevich
group have been demonstrated to work on the ADNI population, there has also been
no validation of their work.  In addition, their work requires some manual
initialization to properly function.  Our work demonstrates that we can reliably
identify the CA1, subiculum, and CA4 dentate with only modest amounts of error.
The fact that CA2/CA3 and molecular layers cannot be reasonably identified
should not be surprising.  These are extremely thin and spatially convoluted
regions that originally required high-resolution MRI for identification.  It is
likely that they would be that extents of these regions are well below the
resolution offered by standard T1-weighted images.  In fact many manual
segmentation methodologies do not attempt to parse these regions either
\citep{Wisse2012, Mueller2009}

\subsection{Conclusion}
In conclusion, we have presented a flexible multi-atlas framework.  It has
considerable advantages over other methods as only a small set of atlases is
required to initialize the algorithm.  We demonstrate that our method works
robustly over hippocampal definitions, different populations, and different
acquisition types.  Finally, we also demonstrate that using this method that
accurate identification of the hippocampal subfields in also possible.



% \begin{verbatim}
% Experiment 1: 
% - address the absence of weighted-voting effects. 
%   - hypothesis: the benefits of weighted voting only outweigh the resampling
%     error effects when choosing from a large library.  In this experiment, the 
%     template library (during weighted voting) consists of only 20 templates, so
%     the most we could hope for is a "squashing" upwards of the curve towards 
%     the 20-template limit (which is the same across all cases in this experiment).
%   - we do see a slight "squashing" effect, with XCORR more strongly than NMI. 
%     Perhaps in future experiments with larger template libraries, this could be
%     explored further.
% - Why don't we use STAPLE? What would we expect from STAPLE or other fusion methods? 
%   - couldn't get STAPLE to work with our image formats
%   - Idea: expect smoothness across range of templates (no even # dips, below)
%   - perhaps more sophisticated fusion methods would boost results over majority 
%     vote based techniques.
% 
% - why does MAGeT brain show a dip in average Kappa when using an even number
%   templates. Does MA show this same pattern? (yes)
%   - Hypothesis: our voting method is biased when breaking ties to choose the 
%     label with the lowest numeric value.
%   - If we compute the total number of labels fused (atlases * templates) then 
%     both MB/MA perform worse when fusing an even number of labels. 
% 
% - we only show a +0.02 increase in mean Kappa over multi-atlas, and this is when
%   using 1 atlas (which we know from Figure 2, is when we perform worst). Why does
%   this increase justify the extra effort involved in MB? 
%   - decrease in variability
%   - we are comparing "true" averages (see above)... does this make our criteria 
%     for a worthy improvement less strict? 
%     
% 
% - how does MAGeT stack up, Kappa-wise, to other methods, in an absolute sense.
% - because of the extensive cross-validation in experiment 1, we are very likely
%   showing results that approach the true average of MB and MA on that dataset
%   (i.e. our mid 0.8 range result is a mean across 69 subjects and 10 repetitions
%   each).
% - even with this caveat, do we think we do well enough?  i.e. other than parameter 
%   tuning, to what extent does this experiment tell us about how MB would do in 
%   practice. 
% 
% - effects we are seeing is not only averaging effects (Chakravarty et al. 2012). 
% 
% - take aways: as in other studies (Aljabar, Heckemann) we find that performance
%   scales with the number of inputs (approx. log(n)), and that a large enough
%   template library can boost performance with a small number of atlases. The use 
%   of templates /can/ have a negative impact on performance (Figure 2), that is 
%   balanced by the improvement of growing the template library.  Likely the negative
%   impact on peformance is as a result of resampling/mislabelling error. In other 
%   words, tuning MAGeT brain involves balancing the tension between an improvement 
%   in peformance due to increase neuroanatomical capture and decreased peformance
%   due to resampling error. 
% 
% Experiment 2: 
% - describe resampling error during downsampling (essentially partial volume effect 
%   due to averaging/majority vote in nearest neighbour selection)
% - Why would some structures have greater downsampling error than others? (i.e. what
%   is it about a structure that would make it especially prone to resampling error)
%   - since error is discretised to whole voxels, smaller regions will show larger
%     percent error
%   - average unilateral volume (approx; mm3): 
%      region   volume   downsampling error
%      CA1      800            2%
%      CA4/DG   600          -30%
%      SR/SL/SM 700           30%
%      Sibculum 350            0%
%      CA2/3    200           15%
% 
% - observation: when downsampling error is small (<10 percent), MB error is larger, 
%   and vice versa when downsampling error is large.  Could this a case where the 
%   inevitable MAGeT resampling error outweighs the small downsampling error?
% - observation: MAGeT produces similar volumes for the downsampled and BRAVO images
%   which demonstrates reliability. Additionally, MB's error is in the same *direction*
%   as the downsampling error except for SR/SL/SM
% - for MB to show less error than resampling means that voting across templates is 
%   in aggregate performing better than local nearest neighbour fitting. presumably 
%   we'd see the same improvement with basic multiatlas as well.
% 
% - take away: MB produces subregion volumes that are comparable or better than
%   resampling error, except for the CA2/3 where error is near 25 percent (but 
%   even then resampling error is ~15%)
% 
% Experiment 3: 
% - what is an "acceptable" r^2 value? 
% - take away: MB has proven to be robust with atlases derived from three different
%   segmentation protocols (SNT, Winterburn, and now Pruessner) on three different
%   populations (older with AD progression; young and healthy; young and SZ). 
%   
% Experiment 4: 
% - address the smaller difference in mean volume across disease classes. smaller 
%   than every other method. 
%   
% - address the segmentation bias towards over-estimating smaller hippocampi, and 
%   underestimating larger HC
%   
% - visual inspection/QC reveals MB segmentations are satisfactory (failure rate 
%   is lower than the other methods (but we may be biased. :-). 
%   
% - take away: MB, with the Winterburn atlases, produces HC volumes more inline with
%   SNT than FSL/FS.  Comparable to MAPER but with far fewer atlases required. 
% 
% \end{verbatim}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                               Conclusion 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Supplementary Materials}

\subsection{ADNI Manual Labels}
% The following blurb is taken (except for the first sentence) verbatim 
Semi-automated hippocampal volumetry was carried out using a commercially
available high dimensional brain mapping tool (Medtronic Surgical Navigation
Technologies, Louisville, CO), that has previously been validated and compared
to manual tracing of the hippocampus \citep{Hsu2002}. Measurement of hippocampal
volume is achieved first by placing manually 22 control points as local
landmarks for the hippocampus on the individual brain MRI data: one landmark at
the hippocampal head, one at the tail, and four per image (i.e., at the
superior, inferior, medial and lateral boundaries) on five equally spaced images
perpendicular to the long axis of the hippocampus. Second, fluid image
transformation is used to match the individual brains to a template brain
\citep{Christensen1997}. The pixels corresponding to the hippocampus are then
labeled and counted to obtain volumes. This method of hippocampal voluming has a
documented reliability of an intraclass coefficient better than .94
\citep{Hsu2002}.

\bibliographystyle{abbrvnat}
\bibliography{references}
\end{document}
