%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Sweave/Knitr init
<<setup, include=FALSE, cache=FALSE>>=
library(knitr)
opts_chunk$set(echo = FALSE, 
               message = FALSE, 
               warning = FALSE, 
               fig.align = 'center', 
               tidy = FALSE, 
               comment = NA, 
               cache = TRUE,
               fig.width = 6, 
               fig.height = 6)
library(ggplot2)
library(Hmisc)
library(reshape2)
library(ADNIMERGE)
library(plyr)
options(digits=3)
theme_set(theme_bw())

bland_altman_plot <- function(x, y) {
  data = data.frame(x=x,y=y,diff=x-y)
  return(ggplot(data, aes(x= x, y = diff)) + 
    geom_hline(yintercept = mean(data$diff) + c(-2, 0, 2) * sd(data$diff), 
               linetype=2, color='brown') + 
    geom_point())
}

lm_eqn = function(m) {
  l <- list(a = format(coef(m)[1], digits = 2),
      b = format(abs(coef(m)[2]), digits = 2),
      r2 = format(summary(m)$r.squared, digits = 3));
  if (coef(m)[2] >= 0)  {
    eq <- substitute(italic(y) == a + b %.% italic(x)*","~~italic(r)^2~"="~r2,l)
  } else {
    eq <- substitute(italic(y) == a - b %.% italic(x)*","~~italic(r)^2~"="~r2,l)    
  }

  as.character(as.expression(eq))
}
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass{article}
\usepackage[margin=1in]{geometry}
\usepackage{algorithm, color, algpseudocode, amsmath, url, geometry, ctable}
\usepackage{titlesec, siunitx}
\usepackage[round,authoryear]{natbib}
\usepackage[section]{placeins}  % keep floats in their place.

%draft mode
\usepackage[colorinlistoftodos, textwidth=4cm, shadow]{todonotes}
\usepackage[displaymath, tightpage]{preview}
\setlength{\marginparwidth}{1.2in}

% add \subsubsubsection
% \setcounter{secnumdepth}{4}  
% \titleformat{\paragraph}
% {\normalfont\normalsize\bfseries}{\theparagraph}{1em}{}
% \titlespacing*{\paragraph}
% {0pt}{3.25ex plus 1ex minus .2ex}{1.5ex plus .2ex}
\newcommand{\subsubsubsection}[1]{\paragraph{#1}}

% shortcuts 
\newcommand{\mb}{MAGeT-Brain }
\newcommand{\ants}{ANTS }
\newcommand{\animal}{ANIMAL }
\newcommand{\adnidataset}{ADNI1:Complete 1Yr 1.5T }
%notes and TODO formatting
%\newcommand{\marginnote}[1]{\-\marginpar[\raggedleft\footnotesize #1]{\raggedright\footnotesize #1}}
%\newcommand{\comment}[1]{\begin{kframe}{\textcolor{red}{#1}}\end{kframe}}
%\newcommand{\todo}[1]{\comment{TODO #1}}
%\newcommand{\mc}[1]{\comment{MC: #1}}
\begin{document}
%\SweaveOpts{concordance=TRUE}

\title{Bootstrapping Multi-atlas Hippocampal Segmentation with \mb}
\author{Pipitone J., Winterburn J., Lett, T., Lerch J., Pruessner J., Lepage M., \\ 
Voineskos A., Chakravarty M.M., and \\ 
the Alzheimer's Disease Neuroimaging Initiative}
\maketitle

\begin{abstract}
Neuroimaging research often relies on automated anatomical segmentations of MR
images of the brain. Current multi-atlas based approaches provide accurate
segmentations of brain images by propagating manually derived segmentations of
specific neuroanatomical structures to unlabelled data. These approaches often
rely on a large number of such manually segmented atlases that take significant
time and expertise to produce. We present an algorithm for the automatic
segmentation of the hippocampus that minimizes the number of atlases needed
while still achieving similar accuracy to multi-atlas approaches.
\todo[inline]{finish}
\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                               INTRODUCTION
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

The hippocampus is a neuroanatomical structure situated in the medial temporal
lobe of the brain, and has long been associated with learning and memory
\citep{DenHeijer2012,Scoville2000}.  In addition to its known functional roles,
the hippocampus is of interest to neuroscientists because it is implicated in
several forms of brain disfunction such as Alzheimer's disease
\citep{Sabuncu2011} and schizophrenia \citep{Narr2004,Karnik-Henry2012}.  In
neuroimaging experiments, magnetic resonance images (MRI) are often used for the
identification of the hippocampus.  As such, accurate segmentation of the
hippocampus and its subregions in MRI is a necessary first step to better
understand the unique neuroanatomy of subjects. Typically, the gold standard for
neuroanatomical segmentation is manual delineation by an expert human. However
the rapid increase in the availability of MRI data and the time and expertise
required for manual segmentation is prohibitive
\citep{Mazziotta1995,Mazziotta2001,Mazziotta,Pausova2007,Weiner2013}.
Further, there is little agreement between researchers regarding how exactly the
hippocampus should be identified in MRI images \citep{Geuze2004} and this has
led to efforts to create an unified hippocampal segmentation protocol
\citep{Jack2011}.  

Automated segmentation techniques that are reliable, objective, and reproducible
are a necessary alternative to manual segmentation.  In the case of classical
model-based segmentation methods \citep{Haller1997,Csernansky1998}, an MRI atlas
that was previously manually labelled by an expert rater is matched to target
images using nonlinear registration methods.  The resulting nonlinear
transformation is applied to the manual labels (ie. {\em label propagation}) to
apply them to the target image.  While this methodology has been used
successfully in several contexts
\citep{MallarMedIA200809,MallarHBM20082009,Collins1995,Haller1997}, it is limited
in accuracy by the introduction of errors due inaccuracies in the nonlinear
transformation itself, partial volume effects in label resampling, and
irreconcilable differences between the neuroanatomy represented within the atlas
and target images.
 
One methodology that can be used to mitigate these sources of errors involves
the use of multiple manually segmented atlases and probabilistic segmentation
techniques, such as those found in the FreeSurfer package \citep{Fischl2002},
FreeSurfer uses a probabilistic atlas of anatomical and tissue classes along
with spatial constraints for class labels encoded using a Markov random field
model to segment the entire brain.  

More recently, many groups have been using multiple atlases to improve overall
segmentation accuracy (ie. multi-atlas segmentation) over model-based approaches
\citep{Heckemann2006,Heckemann2011,Collins2010,Lotjonen2010,Aljabar2009,Leung2010,Wolz2010}.
Each atlas image is registered to a target image, and label propagation is
performed to produce several labellings of the target image (one from each
atlas). A {\it label fusion} technique, such as voxel-wise voting, is used to
merge these labels into a definitive segmentation for the target.  In addition,
weighted voting procedures that use {\em atlas selection} techniques are often
used to exclude atlases from label fusion that are dissimilar to a target image
in order to reduce error from unrepresentative anatomy \citep{Aljabar2009}.
This involves the selection of a subset of atlases using a similarity metric
such a cross-correlation \citep{Aljabar2009} or normalized mutual information.
Such selection has the added benefit of significantly reducing the number of
nonlinear registrations.  For example Collins and Pruessner \citep{Collins2010}
demonstrated that only 14 atlases, selected based on highest similarity between
medial temporal lobe neuroanatomy as evaluated by normalized mutual information
\citep{Studholme1999} from a library of 80 atlases, were required to achieve
accurate segmentations of the hippocampus.  Several methods have been explored
for label fusion including the STAPLE algorithm \citep{Warfield2004} that
computes a probabilistic segmentation using an expectation maximization
framework from an set of competing segmentations; or others where a subset of
segmentations can be estimated using metrics such as the sum of squared
differences in the regions of interest to be segmented \citep{Coupe2011}.

However, many of these methods require significant investment of time and
resources for the creation of the atlas library; ranging from atlas libraries
that require between 30 \citep{Heckemann2006} and 80 \citep{Collins2010}
manually segmented atlases.  This strategy has the main drawback of being
inflexible as it does not easily accommodate varying the definition of the
hippocampal anatomy (such as the commonly used heuristic of subdividing the
hippocampus in to head, body, and tail \citep{Poppenk2011,Pruessner2000}).
Furthermore, none of these methods have demonstrated sufficient flexibility to
accommodate atlases that are somehow exceptional such as those derived from
serial histological data \citep{Chakravarty06a,Yelnik2007} or high-resolution MRI
data that enables robust identification of hippocampal subfields
\citep{Winterburn2013,Yushkevich2009,Mueller2009,VanLeemput2009,Wisse2012}.  Due to
the recent availability of the latter, there has been increased interest in the
use of probabilistic methods for the identification of the hippocampal subfields
on standard T1-weighted images.  Our group recently demonstrated that through
use of an intermediary automated segmentation stage, robust and accurate
segmentation of the striatum, pallidum, and thalamus using a single atlas
derived from serial histological data \citep{Chakravarty2013} is possible.  The
novelty of this manuscript is the extension our multi-atlas methodology to the
hippocampus using more than a single input atlas, while simultaneously limiting
the number of possible inputs used during segmentation, and demonstrating that
accurate identification of the hippocampal subfields is indeed possible using
this methodology.

There are few methods that have attempted to perform multi-atlas segmentation
with a limited number of input atlases. The LEAP algorithm is an elegant
modification to the basic multi-atlas strategy \citep{Wolz2010} in which the
atlas library is grown, beginning with a set of manually labelled atlases, and
successively incorporating unlabelled target images after themselves being
labelling using multi-atlas techniques. The sequence in which target images are
labelled is chosen so that the similarity between the atlas images and the
target images is minimised at each step, effectively allowing for deformations
between very dissimilar images to be broken up into sequences of smaller
deformations.  Although Wolz et al. begin with an atlas library of 30 MR images,
this method could theoretically work using a much smaller atlas library.  In
their validation, LEAP was used to segment the whole hippocampus in the ADNI1
baseline dataset, achieving a mean Dice score of 0.85 with manual segmentations.

To the best of our knowledge there are two other segmentation methods that
attempt to define the hippocampal subfields using standard T1-weighted data.
The first is included with the FreeSurfer package \citep{VanLeemput2009}.  This
work is limited as it omits the tail of the hippocampus and the segmentation
protocol has yet to be fully validated.  Nonetheless, they demonstrate that the
applicability of their work using data from 10 subjects.  In the second method,
Yushkevich and colleagues \citep{Yushkevich2009} acquired and labelled
hippocampal subfields on high-resolution MRI data from post-mortem medial
temporal lobe samples an demonstrate it's applicability in the segmentation of
other MRI-volumes using nonlinear registration guided using manually derived
hippocampus masks and specific landmarks. In their work they demonstrate
accurate parcellations of the subfields.

Here we address the issue of limiting the number of input atlases by tuning our
algorithm, for segmentation of the entire hippocampus, using a multi-fold
experiment performed on a subset Alzheimer's Disease Neuroimaging Initiative
(ADNI) 1 dataset.  The tuning includes \todo{complete}. Based on the parameters
we find in our experiment, we validate our algorithm using all of the data
available in the ADNI Complete 1Yr sample and compare our segmentations to the
other segmentations that are available through the ADNI informatics portal.  To
ensure that we have not over-fit our parameters to the aging or
neurodegenerative brain, we also apply our segmentations to a dataset of normal
controls and individuals suffering from first episode psychosis. Finally, we
perform a leave-one-out validation experiment to determine if the subfields can
be accurately identified using our multi-atlas framework. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                               METHODS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Methods}

%%%%%                     MAGeT Brain Algorithm                            %%%%%

\subsection{The \mb Algorithm}
In this paper, we will use the term {\em label} to mean any segmentation (manual or 
derived) of an MR image.  {\em Label propagation}, or {\em labelling}, is the 
process by which two images are registered and the resulting transformation 
is applied to the labels from one image to bring them into alignment with the 
other image. We will use the term {\em atlas} to mean a manually segmented image,
and the term {\em template} to mean an automatically segmented image (i.e. 
via label propagation). The terms {\em atlas library} and {\em template library} 
describe any set of such images.Additionally, we will use the term {\em target} 
to refer to an unlabelled image that is undergoing segmentation.

The simplest form of multi-atlas segmentation, (which we will call {\em basic 
multi-atlas segmentation}), involves three steps.  First, each labelled 
input image (i.e. atlas or template) is registered to an unlabelled target image.
Second, the labels from each image are propogated to the target image space. 
Third, the labels are combined into a single labelling by way of a label fusion method 
\citep{Heckemann2006, Heckemann2011}. This method is described in detail in other
publications \citep{Collins2010,Heckemann2011,Aljabar2009}.

\mb bootstraps the creation of a large template library given a limited input atlas 
library, and then uses the template library in basic multi-atlas segmentation. 
Images for the template library are selected from a set of input target images, 
either arbitrarily or so as to reflect the neuroanatomy or demographics of the 
target set as a whole (for instance, by sampling equally from cases and controls). 
The template library images are then labelled by each of the atlases. Basic 
multi-atlas segmentation is then conducted using the template library
to segment the entire set of target images (including the targets whose images
are used in the construction of the template library).  Since each template
library image has multiple labels (one from each atlas), the final number of 
labels to be fused for each target may be quite large (i.e. \# of atlas $\times$ 
\# of templates).

Figure \ref{alg:MAGeT} describes the \mb algorithm in pseudocode. Source code 
for \mb can be found at \url{http://github.com/pipitone/MAGeTbrain}.

\begin{algorithm}
  \scriptsize
  \caption{Pseudocode for the \mb algorithm}
  \label{alg:MAGeT}
  \begin{algorithmic}
    \Function{BasicMultiAtlasSegmentation}{Templates, Subjects}
      \ForAll{$target$}
        \ForAll{$template$}
          \State propagate all labels for template to target space
          \State store target labels
        \EndFor
        \State fuse target labels
      \EndFor
    \EndFunction
    \\
    \Function {MAGeTBrain}{Subjects, Atlases, n}
      \For{$i = 1 \to n$}
        \State choose a target to be used as a template
        \State propagate labels from each atlas to template space
        \State store the template with all of its labels
      \EndFor
      \State MultiAtlas(Templates, Subjects)
    \EndFunction
  \end{algorithmic}
\end{algorithm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                            Experiments                              %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Experiments}

The following section describes the experiments we conducted to assess the
segmentation quality of the \mb algorithm. The first two experiments assess the
validity of \mb using a cross-validation design. Experiment 1 investigates the
accuracy of \mb whole hippocampus segmentation over a wide range of parameter
settings. This enables us to choose the parameter settings offering the best
performance for use in subsequent experiments. Experiment 2 tests hippocampal
subfield segmentation quality. The last two experiments assess the validity of
the \mb algorithm when applied to different diseases: Alzheimer's disease
(Experiment 3) and first episode schizophrenia patients (Experiment 4). 

%The ADNI experiment includes comparison of volumes with other automated
%segmentation methods. Evaluation is done by correlating volumes b/c overlap
%metrics assume identical segmentation protocol. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                                                                     %%%%%
%%%%%         Experiment 1: Whole Hippocampus Cross-Validation            %%%%%
%%%%%                                                                     %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Experiment 1: Whole Hippocampus Cross-Validation}

Monte Carlo Cross-Validation (MCCV) \citep{Shao1993} was performed using a pool
of images and manual hippocampal segmentations from ADNI1 dataset.  This form of
cross-validation allows us to rigorously validate a large number of parameter
settings of \mb (atlas and template library sizes, registration algorithm, and 
label fusion method) and select the best parameters to use in subsequent 
experiments.

\paragraph{ADNI1 dataset} 

69 1.5T images were arbitrarily selected from the baseline scans in the {\em
\adnidataset} standardized dataset. 23 subjects were chosen from each
disease category: cognitively normal (CN), mild cognitive impairment (MCI) and
Alzheimer's disease (AD). Demographics for this subset are shown in Table
\ref{tab:ADNI1-xvalidation-demographics}.  Manual segmentations of the left and
right whole hippocampi are available. These labels have been generated using a
semiautomatic tool (SNT, Medtronic Surgical Navigation Technologies, Louisville,
CO; see Supplementary Materials).

Clinical, demographic and pre-processed T1-weighted MRI were downloaded by the
authors from the ADNI database (adni.loni.ucla.edu) between March 2012 and
August 2012. The image dataset download was the "\adnidataset"
standardized dataset available from ADNI \footnote{
\url{http://adni.loni.ucla.edu/methods/mri-analysis/adni-standardized-data/}}
\citep{Wyman2012}. This image collection contains uniformly preprocessed images
which have been designated to be the "best" after quality control.  All images
were acquired using 1.5T scanners (General Electric Healthcare, Philips Medical
Systems or Siemens Medical Solutions) at multiple sites using the protocol
described in \citep{Jack2008}.  Representative 1.5T imaging parameters were TR
= 2400ms, TI = 1000ms, TE = 3.5ms, flip angle = $8{\circ}$, field of view = 240
x 240mm, a $192 \times 192 \times 166$ matrix ($x$, $y$, and $z$ directions)
yielding a voxel resolution of $1.25 \times 1.25 \times 1.2mm^3$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% ADNI1 X-Validation Dataset Demographics Table
%
<<ADNI-Xval-demographics, echo=F, results="asis",cache=FALSE>>=
adni_69_RIDs = c(295,413,619,685,729,782,938,954,1018,1155,907,981,222,324,448,
                 546,553,572,602,610,814,1341,675,681,731,1130,41,68,70,101,
                 249,293,316,414,698,1206,1222,1339,751,1030,3,5,10,16,22,53,
                 168,183,241,1205,328,1095,991,213,159,337,343,642,753,1109,
                 1217,29,56,1188,1293,149,382,431,1202)
tab <- summary(DX.bl ~ AGE + PTGENDER + PTEDUCAT + PTETHCAT + CDRSB + ADAS13 +
               MMSE, data = adnimerge, subset = VISCODE == 'bl' & RID %in%
               adni_69_RIDs, method = "reverse", test=FALSE, overall=TRUE)

latex(tab, file="", size="scriptsize",landscape=FALSE, ctable=FALSE,
      caption="ADNI-1 cross-validation subset demographics", 
      title="tab:ADNI1-xvalidation-demographics")
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\paragraph{Experiment details} 

Monte Carlo Cross-Validation (MCCV), also known as repeated random sub-sampling
cross-validation, consists of repeated rounds of validation conducted on a fixed
dataset \cite{Shao1993}. In each round, the dataset is randomly partitioned into
a training set and a validation set. The method to be validated is then given
the training data, and its output is compared with the validation set.

In this experiment, our dataset consists of 69 1.5T images and corresponding
manual segmentations. In each validation round, the dataset is partitioned into 
a training set consisting of images and their manual labels to be used as an atlas 
library, and a validation set consisting of the remaining images segmented by both 
\mb and multi-atlas. The resulting segmentations are compared to the manual 
segmentations for the images.

A total of ten validation rounds are perfomed on each subject in the dataset,
over each combination of parameter settings. The parameter settings
we explore are: atlas library size (1-9), template library size (1-20),
registration method (\ants or \animal), and label fusion method (majority vote,
cross-correlation weighted majority vote, and normalized mutual information
weighted majority vote).  A total of $10 \times 69 \times 9 \times 20 \times 2
\times 3 = \num{7452000}$ validation rounds were conducted, resulting in a total
of $\num{1490400}$ segmentations analysed. 

Before registration, all images underwent preprocessing with the N3 algorithm
\citep{Sled1998} to minimize intensity nonuniformity. In this experiment we use
one of two non-linear image registration methods.

\subparagraph{Automatic Normalization and Image Matching and Anatomical
Labeling (\animal)}

The \animal algorithm carries out image registration is in two phases. In the
first, a 12-parameter linear transformation (3 translations, rotations, scales,
shears) is estimated between images using an algorithm that maximizes the
correlation between blurred MR intensities and gradient magnitude over the whole
brain \citep{Collins}. In the second phase, nonlinear registration is completed
using the \animal algorithm \citep{Collins1995}: an iterative procedure that
estimates a 3D deformation field between two MR images. At first, large
deformations are estimated using blurred version of the input data. These larger
deformations are then input to subsequent steps where the fit is refined by
estimating smaller deformations on data blurred with a Gaussian kernel with a
smaller FWHM. The final transformation is a set of local translations defined on
a bed of equally spaced nodes that were estimated through the optimization of
the correlation coefficient.  For the purposes of this work we used the
regularization parameters optimized in Robbins et al. \citep{Robbins2004},
displayed in table \ref{tab:ANIMAL-params}. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ANIMAL parameters                    
%                                     
\begin{table}[!tbp]
\begin{center}
\caption{\animal  registration parameters}
\begin{tabular}{l | c c c}
\hline 
Parameters        & Stage 1 & Stage 2 & Stage 3  \tabularnewline
\hline 
Model Blur (FWHM) &   8     &    8    &   4      \tabularnewline
Input Blur (FWHM) &   8     &    8    &   4      \tabularnewline
Iterations        &   30    &    30   &   10     \tabularnewline
Step              &   8x8x8 &  4x4x4  &   2x2x2  \tabularnewline
Sub-Lattice       &   6     &    6    &   6      \tabularnewline
Lattice Diameter  &24x24x24 &12x12x12 & 6x6x6    \tabularnewline
\hline
\end{tabular}
\end{center}
\label{tab:ANIMAL-params}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subparagraph{Automatic Normalization Tools (\ants)}

\ants is a diffeomorphic registration algorithm which provides great flexibility
over the choice of transformation model, objective function, and the consistency
of the final transformation. The transformation is estimated in a hierarchical
fashion where the MRI data is subsampled, allowing large deformations to be
estimated and successively refined at later hierarchical stages (where the data
is subsampled to a finer grid). The deformation field and the objective function
are regularized with a Gaussian kernel at each level of the hierarchy. The \ants
algorithm is freely available \url{http://www.picsl.upenn.edu/ANTS/}. We used an
implementation of the \ants algorithm compatible with the MINC data format,
mincANTS \url{https://github.com/vfonov/mincANTS}.

We used the following command line when running \ants:
{\small
\begin{verbatim}
  mincANTS 3 -m PR[target_file.mnc,source_file.mnc,1,4] 
   --number-of-affine-iterations 10000x10000x10000x10000x10000 
   --affine-gradient-descent-option 0.5x0.95x1.e-4x1.e-4
   --use-Histogram-Matching --MI-option 32x16000
   -r Gauss[3,0] -t SyN[0.5] -i 100x100x100x20
   -o transformation.xfm
 \end{verbatim}
}
These settings were adapted from the "reasonable starting point" given in the
\ants manual 
\footnote{\url{https://sourceforge.net/projects/advants/files/Documentation/}}.

\paragraph{Label fusion methods}
Label fusion is a term given to the process of combining the information from
several candidate labellings for an intensity image into a single labelling.  In
this experiment we explore three fusion methods. 

\subparagraph{Voxel-wise Majority Vote}
  Labels are propagated from all template library images to a target.  Each
  output voxel is given the most frequent label at that voxel location amongst
  all candidate labellings.  Ties are broken arbitrarily.

\subparagraph{Cross-correlation Weighted Majority Vote}
  An optimal combination of targets from the template library has previously been
  shown to improve segmentation accuracy \citep{Aljabar2009,Collins2010}.  In this
  method, each template library image is ranked in similarity to each unlabelled 
  image by the normalized cross-correlation (CC) of image intensities after linear
  registration, over a region of interest (ROI) generously encompassing the 
  hippocampus.  Only the top ranked template library image labels are used in a
  voxel-wise majority vote. The ROI is heuristically defined as the extent of all
  atlas labels after linear registration to the template, dilated by three voxels
  \citep{Chakravarty2012}.  The number of top ranked template library image labels
  is a configurable parameter.

  The {\tt xcorr\_vol} utility from the \animal toolkit is used to calculate the
  cross-correlation similarity measure.  
 
\subparagraph{Normalised Mutual Information Weighted Majority Vote}
  This method is similar to cross-correlation weighted voting except that image
  similarity is calculated by the normalised mutual information score over the
  region of interest\citep{Studholme2001}.  The {\tt itk\_similarity} utility
  from the EZMinc toolkit\footnote{\url{https://github.com/vfonov/EZminc}} is
  used to calculate the normalised mutual information measure between to images.

\paragraph{Evaluation method}  

The Dice similarity coefficient (DSC) assesses the agreement between two
segmentations. It is one of the most widely used measures of segmentation
performance, and we use it as the basis of comparison in this experiment.
Additionally, we report the Jaccard index, another commonly used similarity
measure:

 \[\text{Dice's coefficient (DSC)} = \frac{2|A \cap B|}{|A| + |B|}\]

 \[\text{Jaccard (J)} = \frac{|A \cap B|}{|A \cup B|} = \frac{DSC}{(2-DSC)}\]

where $A$ and $B$ are the regions being compared, and the cardinality is the
volume measured in voxels. 

The manual segmentations (SNT) provided as part of the ADNI dataset are used as 
the gold standard to compare with. We compare both \mb labels and multi-atlas 
labels.  The segmentation accuracy reported is averaged over the ten validation
rounds for each parameter setting.  

In order to investigate the performance of \mb in a real world setting in which 
only one set of atlas and template images are used, we explore the variability 
in label agreement at fixed parameter settings when the choice for atlas and 
template images is varied. This is achieved by first computing the standard 
deviation and variance of DSC scores in each block 
of ten validation rounds per subject. The distribution of these statistics across 
all subjects is then compared between \mb and multi-atlas using a Student's 
t-test. A significant difference between distributions is taken to show either
a larger or smaller level of variability between methods. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                                                                     %%%%%
%%%%%        Experiment 2: Hippocampal Subfield Cross-Validation          %%%%%
%%%%%                                                                     %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Experiment 2: Winterburn Atlases Cross-Validation}
In this experiment, the accuracy of the \mb algorithm on hippocampal subregion
segmentation is tested using a leave-one-out cross-validation (LOOCV) design.
The optimal parameter settings found in Experiment 1 are used.

\paragraph{Winterburn Atlases dataset} 
The Winterburn atlases \citep{Winterburn2013} are digital hippocampal
segmentations of five in-vivo $300\mu$ isotropic T1-weighted MR images. The
segmentations include subfield segmentations for the cornus ammonis (CA) 1, CA4,
dentate gyrus, subiculum, and CA 2 and 3 combined. Subjects in the Winterburn
atlases range in age from 29-57 years (mean age of 37), and include two males
and three females.  

In addition to the high-resolution scans distributed as part of the Winterburn
atlases, we also obtained additional 3T T1 BRAVO images (0.9mm-isotropic voxels)
of four of the five Winterburn atlas subjects. 

\paragraph{Experiment details} 
Leave-one-out cross-validation (LOOCV) is an approach in which the method to be
validated is given all but one item in a dataset as training data, and the
output is compared with the left-out item. This is done, in turn, for each item
in the dataset. 

In this experiment, the five $300\mu$-isotropic voxel Winterburn atlases are
used as the atlas library for \mb segmentation. LOOCV is conducted separately
for two different input datasets: the four Winterburn atlas subject T1 BRAVO
images (referred to as the {\em BRAVO} dataset), and the five
Winterburn atlas subject images resampled to 0.9mm-isotropic voxel resolution
(referred to as the {\em Resampled} dataset. Each subject in the
dataset is segmented by \mb with that subject's image excluded from the atlas
library. The template library consists of 3T T1 images (0.9mm-isotropic
voxels) of healthy subjects in addition to the images from the dataset being
evaluated.

The optimal size of template library, registration method, and label fusion
method found in Experiment 1 are used. 

\paragraph{Evaluation method}  
\mb performance is measured with respect to straight-forward nearest-neighbour
resampling of the Winterburn atlas labels to 0.9mm-isotropic voxels (i.e. no 
label propagation). The volumes of each hippocampal subregion in the downsampled
Winterburn atlas labels are compared to the volumes obtained from the full 
resolution Winterburn atlas labels, the \mb labels on the downsampled Winterburn 
atlas images, and the \mb labels on the T1 BRAVO acquisitions. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                                                                     %%%%%
%%%%%         Experiment 3: Application of \mb to the segmentation        %%%%%
%%%%%                       of schizophrenia patients                     %%%%%
%%%%%                                                                     %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Experiment 3: Application to the segmentation first episode
schizophrenia patients}
 
To validate that \mb algorithm works effectively with diseased brain images \mb
is applied to a dataset of Schizophrenia patient MR images. The resulting
segmentations are assessed for quality by comparison with expert manual
segmentations.

\paragraph{SZ-FEP dataset}
All patients were recruited and treated through the Prevention and Early
Intervention Program for Psychoses (PEPP-Montreal), a specialized early
intervention service at the Douglas Mental Health University Institute in
Montreal, Canada. People aged 15â€“30 years from the local catchment area
suffering from either affective or non-affective psychosis who had not taken
antipsychotic medication for more than one month with an IQ above 70 were
consecutively admitted as either in- or out-patients. Of those treated at PEPP,
only patients aged 18 to 30 years with no previous history of neurological
disease or head trauma causing loss of consciousness were eligible for the
neuroimaging study; only those suffering from schizophrenia spectrum disorders
were considered for this analysis.  For complete program details see Malla et
al. \citep{Malla2003}. 

Scanning of 81 subjects was carried out at the Montreal Neurological Institute
on a 1.5-T Siemens whole body MRI system.  Structural T1 volumes were acquired
for each participant using a three-dimensional (3D) gradient echo pulse sequence
with sagittal volume excitation (repetition time=22ms, echo time=9.2ms, flip
angle=$30{\circ}$, 180 1mm contiguous sagittal slices). The rectangular
field-of-view for the images was 256mm (SI)$\times$204mm (AP).  Subject
demographics are shown in table \ref{tab:SZFEP-Demographics}. 

The hippocampus were traced following a validated protocol developed by Dr Jens
Pruessner \todo{cite: (Pruessner et al., 2000)}. A recent update to this
protocol by Dr J Pruessner in 2006 allows to accurately and consistently
subdivide the hippocampus into three different subregions: head, body, and tail.

\paragraph{Experiment details} 
\mb is configured with an atlas library composed of the Winterburn T1 atlases
(see Experiment 2).  All images from the SZ-FEP dataset are segmented.  The optimal
size of template library, registration method, and label fusion method found in
Experiment 1 are used. 

\paragraph{Evaluation method}
The manual segmentation protocol used to segment the Winterburn atlases is
similar to, but different from, the protocol used to segment the SZFEP dataset.
Therefore, rather than evaluate using an overlap metric, such as DSC, which 
assumes a fixed segmentation protocol, we instead correlate whole hippocampus 
volume between \mb and manual segmentations. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% First Episode SZ Demographics Table
%
<<FEP-SZ-demographics, echo=F, results="asis",cache=FALSE>>=
fep_sz_demographics = read.csv("data/SZ_demographics.csv", na.strings=c("","."))
fep_sz_demographics = subset(fep_sz_demographics, Anon <= 81)
tab <- summary(DX ~ Age + Gender + Handedness + Education + SES + FSIQ,
               data=fep_sz_demographics, method = "reverse", test = FALSE)
latex(tab, file="", ctable=FALSE,
      caption="Schizophrenia First Episode Patient Demographics",
      title="tab:SZFEP-Demographics")
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                                                                     %%%%%
%%%%%         EXPERIMENT 4: Application of \mb to the segmentation        %%%%%
%%%%%                       of ADNI subjects                              %%%%%
%%%%%                                                                     %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Experiment 4: Application to the segmentation of Alzheimer's
disease patients}

To validate that \mb algorithm works as well as established automated methods,
\mb is applied to the ADNI1 dataset and the resulting segmentations are
compared to those produced by FreeSurfer, FSL, MAPER, and by expert manual
segmentation.

\paragraph{ADNI1 dataset revisited} 
All images from the {\em \adnidataset} standardized dataset described
in Experiment 1 are used.  Clinical and demographic data are shown in table
\ref{tab:ADNI1-1.5T-Complete-1Yr-Dataset-Demographics}. 

\paragraph{Experiment details} 
\mb is configured with an atlas library composed of the Winterburn T1 atlases
(see Experiment 2). All images from the \adnidataset dataset are
segmented. The optimal size of template library, registration method, and label
fusion method found in Experiment 1 are used. The template library is composed
of equal numbers of images from each disease class (AD, MCI, and cognitively
normal controls). 

\paragraph{Evaluation method}
Since the hippocampal segmentation protocols differ between the ADNI labels and
Winterburn atlases, this poses a problem for direct evaluation between labels
produced by \mb and the ADNI labels in terms of overlap; we would not expect
different segmentation protocols to have a high degree of overlap.  Instead, to
evaluate the performance of \mb we compare the correlation of \mb segmentation
volumes with manual segmentation (SNT) volumes. Additionally, we correlate the
hippocampal volumes of established automated segmentation methods to \mb
segmentations.  

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ADNI1-COMPLETE
% Prepares the data in a the form needed for plotting.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
<<ADNI-src-volumes-prep,echo=F,cache=T>>=
totals.complete  <- read.csv('data/cache/ADNI1:totals.complete.csv')
totals           <- read.csv('data/cache/ADNI1:totals.csv')
package_totals   <- read.csv('data/cache/ADNI1:package_totals.csv')
@


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                                             
% ADNI1 Complete 1Yr Dataset Demographics Table 
%                                                                             
<<ADNI1-scr-demographics, echo=F, results="asis",cache=FALSE>>=
# RID < 2000 ensures only ADNI1 patients
yr1 = read.csv("data/ADNI_baseline_volumes/ADNI1_Complete_1Yr_1.5T_11_15_2012.csv")
yr1$VISCODE <- factor(yr1$Visit, levels = c(1,2,3,4), labels=c("bl","m03","m06","m12"))
yr1 = subset(yr1, !grepl("Scaled_2", Description))
yr1 = yr1[,c("RID","VISCODE")]
yr1 = 
adnimerge.yr1 = merge(adnimerge, yr1) 
tab <- summary(DX.bl ~ AGE + PTGENDER + PTEDUCAT + PTETHCAT + CDRSB + ADAS13 +
               MMSE, data = adnimerge.yr1, 
               #subset = RID %in% yr1$RID & VISCODE %in% c('bl','m06','m12'),   
               method = "reverse", test=FALSE, overall=TRUE)

latex(tab, file="", size="scriptsize", 
    caption="ADNI1 1.5T Complete 1Yr dataset demographics",
    label="tab:ADN1-1.5T-Complete-1Yr-Dataset-Demographics")
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                               RESULTS                                        %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Results}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                                                                     %%%%%
%%%%%     RESULTS: Experiment 1: Whole Hippocampus Cross-Validation       %%%%%
%%%%%                                                                     %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Experiment 1 Results: Whole Hippocampus Cross-Validation}

In this experiment we conducted 10 rounds of \mb and multi-atlas segmentation of
each of 69 subjects at a range of atlas and template library sizes, registration
algorithm (\ants or \animal), and three label fusion techniques.  Hippocampal
\mb-based segmentations using both \animal and \ants registration algorithm
demonstrate good overlap with manually derived gold-standards (Figure
\ref{fig:ADNI1-xval-k-mean}). Qualitatively, both \animal and \ants-based
segmentations demonstrate trend overlap accuracy that increases with the size of
atlas library and template library. Improvement in accuracy diminishes noticeably
with template libraries larger than ten images. 

No marked difference in segmentation accuracy is seen when either \animal or \ants
registration is used with different label fusion techniques, at any atlas or
template library sizes.  In every parameter configuration, the use of \mb with
\ants registration shows a pronounced increase in segmentation accuracy over \mb with \animal
registration. In the remainder of this section, only results using the \ants
registration algorithm will be shown.

It is interesting to note that with an even number of templates, \mb shows a
small decrease in performance relative to when one fewer template image is used.
See section \todo{ref} for a discussion of this behaviour. In the remainder of
this section, only results from odd-sized template libraries will be shown. 

With an increasing number of templates, \mb-based segmentating using \ants
registration and majority vote label fusion shows improvement in overlap
accuracy over multi-atlas-based segmentation, using the same number of atlases
and voting method (Figure \ref{fig:ADNI1-xva-k-diff}). The magnitude of improvement over
multi-atlas-based segmentation decreases with an increasing number of atlases,
with accuracy converging with 7 atlases.  Peak improvement in \mb accuracy (~0.02
DSC) is found when one atlas is used with a template library of 20 images.

\todo{mention failures}

In addition to an improvement in accuracy over multi-atlas-based segmentation,
\mb also shows a decrease in the variability of segmentation accuracy 
(Figure \todo{ADNI1-xval-variability}).  The size of template library 
necessary to reach a significant (p<0.5) decrease in variance and standard 
deviation grows with the size of atlas library used.  A template library of 19
images is sufficient to show significant decrease in variance and standard 
deviation for 3-7 atlases. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ADNI1-XVAL: prep
% Prepares the data in a the form needed for plotting.
<<ADNI1-xval-prep,dependson='ADNI1-xval-load',include=FALSE,cache=TRUE>>=
all_data  <- read.csv('data/cache/ADNI-XVAL:all_data.csv')
all_data_mean  <- read.csv('data/cache/ADNI-XVAL:all_data_mean.csv')
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ADNI1-XVAL: mean Kappa plot by atlases, templates, reg and voting method. 
\begin{figure}
<<ADN1-xval-k-mean, cache=TRUE, dependson='ADNI1-Xval-prep'>>=
ggplot(all_data_mean, 
       aes(x=templates.mb,y=k.mb, colour=as.factor(atlases))) + 
  facet_grid(reg_method~method.mb) + 
  stat_summary(fun.y=mean,geom='line',
               aes(y=k.mb, weight=1)) + 
  #stat_smooth(method='lm', formula=y~log(x)) + 
  scale_colour_hue(name="Atlases") +
  xlab( "Number of Templates" ) + 
  ylab( "Mean DSC" ) + 
  opts(legend.direction = "horizontal", legend.position = "bottom")
@
  \label{fig:ADNI1-xval-k_mean}
  \caption{
  {\bf Mean DSC of \mb segmentations across 69 ADNI1 subjects, by atlas and
  template library size, registration algorithm, and label fusion method.} 
  }
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ADNI1-XVAL: "increase" in mean kappa over multi-atlas
\begin{figure}
<<ADN1-Xval-k-diff,cache=TRUE,dependson='ADNI1-Xval-prep',fig.width=6,fig.height=4>>=
ggplot(subset(all_data_mean, reg_method=="ANTS" & method.mb=="Majority Vote" &
                templates.mb %in% seq(1,20,2)), 
       aes(x=templates.mb, y=k_diff, colour=as.factor(atlases))) + 
  #facet_grid(reg_method~method.y) + 
  stat_summary(fun.data=mean_cl_boot,geom='errorbar',
               aes(y=k_diff,colour=as.factor(atlases), width=0.2)) +
  stat_summary(fun.y=mean, geom="point", 
               aes(y=k_diff,colour=as.factor(atlases))) + 
  stat_summary(fun.y=mean, geom="line", 
               aes(y=k_diff,colour=as.factor(atlases))) + 
  #stat_smooth(method=lm, formula=y~log(x)) + 
  geom_hline(aes(alpha=0.5, yintercept=0), linetype='dashed') + 
  scale_x_continuous(breaks=seq(1,20,2)) + scale_y_continuous(breaks=seq(-1,1,by=0.01)) + 
  scale_colour_hue(name="Atlases") +
  scale_alpha_continuous(legend=FALSE) + 
  scale_linetype_discrete(legend=FALSE) + 
  xlab( "Number of Templates" ) + 
  ylab( "Difference in mean DSC" ) +
  opts(legend.direction = "horizontal", legend.position = "bottom")
@
  \caption{The difference in mean DSC between \mb and multi-atlas segmentations for 
  a range of parameter settings.}
  \label{ADNI1-xval-k-diff}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ADNI1-XVAL: show variability of MAGeT over parameters
\begin{figure}
<<ADN1-Xval-variability, cache=TRUE, dependson='ADNI1-Xval-prep'>>=
ANTSmajvote = subset(all_data, 
                     reg_method=="ANTS" & 
                     method.mb=="Majority Vote" &
                    templates.mb %in% seq(1,20,2))

data.stats = ddply(ANTSmajvote, c("subject", "label","atlases","templates.mb"), function (df) {
  data.frame(
    MA.sd  =  sd(df$k.ma),
    MB.sd  =  sd(df$k.mb),
    MA.var = var(df$k.ma),
    MB.var = var(df$k.mb)
  )
})

stats.tests = ddply(data.stats, c("atlases","templates.mb"), function (df) {
  t.var = t.test(df$MA.var, df$MB.var)
  t.sd  = t.test(df$MA.sd , df$MB.sd)
  diff_mean_var = mean(df$MA.var - df$MB.var)
  diff_mean_sd  = mean(df$MA.sd -  df$MB.sd)
  
  # test statistic is positive if MA mean is larger than MB
  # i.e. that MA has a greater mean of variances/SDs
  # i.e. that MB has a smaller mean, and so is doing "better"
  data.frame(
    stat      = c("Variance", "Standard Deviation"),
    statistic = c(t.var$statistic, t.sd$statistic),
    p.value   = c(t.var$p.value, t.sd$p.value),
    direction = c(diff_mean_var, diff_mean_sd)
  )
})

ggplot(subset(stats.tests, direction > 0), 
  aes(x=templates.mb, y=p.value, colour=as.factor(atlases))) + 
  facet_grid( . ~ stat) + 
  geom_line(size=1) +
  geom_point(size=3) + 
  geom_hline(aes(yintercept=0.05, alpha=0.5), linetype='dashed') + 
  geom_hline(aes(yintercept=0.01, alpha=0.5), linetype='dashed') + 
  scale_x_continuous(breaks=seq(1,20,by=2)) + 
  scale_y_log10(limits=c(0.001,1), breaks=c(0.01,0.05,0.1,1.0)) + 
  xlab( "Number of Templates" ) + 
  ylab( "p-value" ) +
  scale_colour_hue(name="Atlases") +
  scale_alpha_continuous(guide='none') + 
  scale_linetype_discrete(guide='none') + 
  scale_size_continuous(guide='none') + 
  theme(legend.direction = "horizontal", legend.position = "bottom")
@
  \caption{{\bf Difference in variability of \mb vs. multi-atlas segmentation 
  accuracy.}
  Variability of segmentation accuracy within 10 rounds of validation per subject. 
  Standard deviation and variance is computed per subject for both \mb and 
  multi-atlas, and the distribution of these test statistics is compared with a 
  t-test. The p-value of this test, is shown on the y-axis (scaled logarithmically).
  Only points where \mb mean variability is lower multi-atlas are shown.}
  \label{ADNI1-xval-variability}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\FloatBarrier

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                                                                     %%%%%
%%%%%    RESULTS: Experiment 2: Hippocampal Subfield Cross-Validation     %%%%%
%%%%%                                                                     %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Experiment 2 Results: Winterburn Atlases Cross-Validation}
This experiment explores \mb segmentations of hippocampal subfields. To
achieve this, a leave-one-out validation is conducted in which lower-resolution
images ($0.9mm^3$ voxels) of each Winterburn atlas subject is segmented using 
the remaining Winterburn atlases. As a point of comparison, volumes of Winterburn 
atlases when downsampled to $0.9mm^3$ voxels are also computed.

In general, across hippocampal subregions the percent error in volume between 
\mb segmentations and the manual Winterburn atlas segmentations compares 
favourably to error when resampling the atlas segmentations (Figure 
\ref{fig:WAval-vol-boxplot}). In particular, the CA1, CA4, and Dentate subregions 
all show near or smaller percent errors. The Sibiculum and CA2/CA3 subregions 
show distinctly larger than resampling error. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Winterburn-XVAL: compare resampling
\begin{figure}[h!]
<<WAval-vol-boxplot,cache=T,fig.width=6,fig.height=4>>=
data = subset(read.csv('data/WAval.csv'))
casted = dcast(melt(data, id.vars=c("file","version")), file + variable ~ version)
casted = rename(casted, c("variable"="region"))

error = ddply(casted, c("file", "region"), function(df) {
  with(df, 
  data.frame(
    resampled = (gold_0.9mm - gold_0.3mm) / gold_0.3mm * 100, 
    mb_bravo  = (mb_bravo   - gold_0.3mm) / gold_0.3mm * 100, 
    mb_0.9mm  = (mb_0.9mm   - gold_0.3mm) / gold_0.3mm * 100))})

levels(error$region) <-list("CA1"="X1", "CA1"="X101", 
                            "Subiculum"="X2","Subiculum"="X102", 
                            "CA4/DG"="X4","CA4/DG"="X104", 
                            "CA2/CA3"="X5","CA2/CA3"="X105", 
                            "SR/SL/SM"="X6","SR/SL/SM"="X106")
melted = melt(error,id.vars=c("file", "region"))
melted = rename(melted, c("variable"="measure", "value"="percenterr"))
levels(melted$measure) <- list("Subsampled"="resampled",
                               "MAGeT + Subsampled" = "mb_0.9mm",
                               "MAGeT + BRAVO"="mb_bravo")

ggplot(melted, aes(y=percenterr,x=region,colour=measure)) +
  geom_boxplot() +
  labs(y="Percent error in volume", x="Region") +
  scale_colour_discrete("") + 
  theme(legend.direction = "horizontal", legend.position = "bottom")
@
  \caption{{\bf Percent error in segmentation volume by hippocampus subregion.} 
  Percent error is measured against the volumes of of the unmodified Winterburn
  atlas segmentations.
  {\bf WA Resampled} are volumes of the manual segmentations of the Winterburn
  atlases after resampling to $0.9mm^3$.  
  {\bf MAGeT + WA Resampled} volumes are \mb segmentations of the Winterburn atlas
  images after resampling to $0.9mm^3$ voxels.
  {\bf MAGeT + WA BRAVO} volumes are \mb segmentations of T1 BRAVO images
  ($0.9mm^3$ voxels) acquired separately of four of the five Winterburn atlas
  subjects. 
  } 
  \label{fig:WAval-vol-boxplot}
\end{figure}

\FloatBarrier
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                                                                     %%%%%
%%%%%    RESULTS: Experiment 3, Application of \mb to the segmentation    %%%%%
%%%%%                       of schizophrenia patients                     %%%%%
%%%%%                                                                     %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Experiment 3 Results: Application to the segmentation first episode
\\ \mbox{schizophrenia patients}}
 
In this experiment \mb is applied to a dataset of images of first episode
schizophrenia parients, using the Winterburn atlases and a template library of
21 subject images selected at random.  Expert manual whole hippocampal
segmentations are used as gold standards. 

\mb produces hippocampus segmentation volumes that are highly correlated with 
manual segmentation volumes (Figure \ref{fig:SZ-volumes}). 

\begin{figure}
<<FEP-volumes,cache=FALSE,dependson="setup">>=
SZ_volumes=read.csv("data/SZ_volumes_by_method.csv", sep="\t")
casted = dcast(SZ_volumes, Subject + Label ~ Method)
lm = lm(MAGeT ~ Manual, casted)
ggplot(data=casted, aes(x = Manual, y = MAGeT)) + 
  geom_smooth(method="lm", formula=y~x) + 
  geom_point() + 
  geom_text(aes(x=3500, y=5000, label=lm_eqn(lm),hjust=0,size=1), parse=TRUE, data=data.frame()) +
  xlab(expression("Manual unilateral whole hippocampus volume " (mm^3))) + 
  ylab(expression("MAGeT unilateral whole hippocampus volume "  (mm^3))) + 
  scale_size_continuous(guide="none") 
@
  \caption{{\bf First Episode Schizophrenic Patients.} Comparison of total
  HC volumes for \mb against manually rated Hippocampal volumes}
  \label{fig:SZ-volumes}
\end{figure}

\FloatBarrier
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                                                                     %%%%%
%%%%%                           RESULTS                                   %%%%%
%%%%%                                                                     %%%%%
%%%%%         EXPERIMENT 4: Application of \mb to the segmentation        %%%%%
%%%%%                       of ADNI subjects                              %%%%%
%%%%%                                                                     %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Experiment 4 Results: Application to the segmentation of Alzheimer's
disease patients}

Based on the results from the ADNI1 Cross-Validation experiment, in this
experiment \mb was configured with a template library of 21 randomly
chosen subject images (7 from each disease class) and used majority vote label
fusion. The entire \adnidataset dataset was segmented by \mb and we 
now compare the resulting volumes with those obtained by manual segmentation (SNT), 
and other automated segmentation techniques (MAPER, FreeSurfer, and FSL).  Table
\ref{tab:ADN1-1.5T-Complete-1yr-Dataset-Segmentations} shows the total count of 
segmentations available, including a count of those which have failed a quality 
control inspection. Only those images which had segmentations from every method
are included in the following analysis (a total of
\Sexpr{length(totals.complete$RID)} images; Table 
\ref{tab:ADNI1-1.5T-Complete-1Yr-Dataset-Method-Totals}).
 
Comparing total hippocampal volume, we find close agreement between manual
volumes, MAPER and MAGeT volumes across disease categories (Figure
\ref{fig:ADNI-scr-volumes-boxplot}, Figure \ref{fig:ADNI-scr-histogram}). FSL
and FreeSurfer both produce volumes in close agreement with each other, but
which are consistently larger than manually segmented volumes in each disease
category.  

Additionally \mb volumes show a fixed bias towards larger volumes by an 
average $-205.2mm^3$, and a proportional bias towards producing smaller 
segmentations for larger hippocampi (Figure \ref{fig:ADNI1-src-Bland-Altman}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ADNI1 1yr Complete Dataset Package Totals & Failures
%                        
<<ADNI1-scr-package-totals, echo=F, results="asis",cache=FALSE>>=
caption = paste(
  "Pass/fail quality control indicators were supplied with the FreeSurfer",
  "volumes downloaded from the ADNI website (we used the temporal lobe quality",
  "control indicator, TEMPQC). One of the authors (MP) performed visual",
  "quality inspection for MAGeT and FSL segmentations.", sep=" ")
latex(package_totals, file="", size="scriptsize", 
    caption = caption,
    title = "",
    label="tab:ADNI1-1.5T-Complete-1Yr-Dataset-Method-Totals")
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{figure}[h]
<<ADNI-scr-volumes-boxplot,dependson='ADNI-baseline-volumes-prep',cache=T,fig.width=6,fig.height=4>>=
qplot(DX,value,data=melt(totals.complete,measure.vars=c("FS", "FSL", "MAPER","MAGeT","SNT")),
      colour=variable,geom="boxplot") + 
      #geom_text(aes(y=value,x=DX, vjust=-1.4, size=1,
      #              label=paste("r==", signif(corr, digits=3))), 
      #      colour='black',parse=TRUE, data=snt.tests) +
      xlab("Diagnosis") + 
      ylab(expression(paste("Bilateral whole hippocampal volume (", mm^3, ")")))
@
  \caption{Comparison of hippocampus volumes obtained by FreeSurfer (FS), FSL, 
  MAPER, \mb (MAGeT) and manual (SNT).}
  \label{fig:ADNI-scr-volumes-boxplot}
\end{figure}

\begin{figure}[h]
<<ADNI-scr-volumes-plot,dependson='ADNI-baseline-volumes-prep',cache=T,fig.width=6,fig.height=4>>=
melted=melt(totals.complete, measure.vars=c("FS", "FSL", "MAPER","MAGeT"), 
            variable.name = "Method", value.name = "volume")

df = totals.complete
levels(melted) = c("FS" = ),
                   "FSL"= paste("FSL", round(cor(df$SNT, df$FSL),2)),
                   "MAPER"= paste("MAPER", round(cor(df$SNT, df$MAPER),2)),
                   "MAGeT"= paste("MAGeT", round(cor(df$SNT, df$FS),2)))

ggplot(data=melted, aes(x=SNT, y=volume, colour=Method)) + 
    geom_point() + 
    geom_smooth(method="lm") + 
    xlab(expression("Manual bilateral whole hippocampal volume " (mm^3))) + 
    ylab(expression("Automated bilateral whole hippocampal volume " (mm^3))) +
    annotate("text", y = c(3000,2500,2000,1500), x=Inf-100, size=3,
              label = c(paste("FS r=", round(cor(df$SNT, df$FS),2)),
                        paste("FSL r=", round(cor(df$SNT, df$FSL),2)),
                        paste("MAPER r=", round(cor(df$SNT, df$MAPER),2)),
                        paste("MAGeT r=", round(cor(df$SNT, df$MAGeT),2))),
              hjust=1.1,vjust=1.5) +
    theme(legend.direction = "horizontal", legend.position = "bottom")
@
  \caption{Comparison of hippocampus volumes obtained by FreeSurfer (FS), FSL, 
  MAPER, \mb (MAGeT) and manual (SNT).}
  \label{fig:ADNI-scr-volumes-plot}
\end{figure}
 
\begin{figure}
<<ADN1-src-Bland-Atlman, cache=TRUE, dependson='ADNI-baseline-volumes-prep', fig.width=4, fig.height=4>>=
melted=melt(totals.complete, measure.vars=c("FS", "FSL", "MAPER","MAGeT"), 
            variable.name = "method", value.name = "volume")
melted=subset(melted, method=="MAGeT")

bland_altman_plot <- function(x, y) {
  data = data.frame(x=x,y=y,diff=x-y)
  upper = mean(data$diff) + 2 * sd(data$diff)
  lower = mean(data$diff) - 2 * sd(data$diff)
  return(ggplot(data, aes(x= x, y = diff)) + 
    geom_hline(yintercept = mean(data$diff) + c(-2, 0, 2) * sd(data$diff), 
               linetype=2, color='brown') + 
    annotate("text", y = upper, x=Inf, 
              label=paste("std =",round(upper,0)), 
              hjust=1.1,vjust=1.5) + 
    annotate("text", y = lower, x=Inf, 
              label=paste("-std =",round(lower,0)), 
              hjust=1.1,vjust=1.5) + 
    geom_point())
}


melted$diff = melted$SNT - melted$volume
limits = mean(melted$diff) + c(-2, 0, 2) * sd(melted$diff)

ggplot(melted, aes(x= SNT, y = diff)) + 
  geom_hline(yintercept = limits, linetype=2, color='brown') + 
  annotate("text", y = limits, x=Inf, label=round(limits,1), 
            hjust=1.1,vjust=-0.8, size=3) + 
  geom_point() + 
  xlab('Mean of manual and MAGeT-Brain hippocampal volume') + 
  ylab('Difference between Manual and MAGeT-Brain hippocampal volume') + 
  geom_smooth(method="lm", formula = y~x)
@
  \caption{Bland-Altman plot comparing manual (SNT) and \mb hippocampal volumes 
  in the \adnidataset dataset.}
  \label{fig:ADNI-scr-Bland-Altman}
\end{figure}


\begin{figure}
<<ADN1-src-subfield, cache=TRUE, dependson='ADNI-baseline-volumes-prep', fig.width=4, fig.height=4>>=
adni_69_RIDs = c(295,413,619,685,729,782,938,954,1018,1155,907,981,222,324,448,
                 546,553,572,602,610,814,1341,675,681,731,1130,41,68,70,101,
                 249,293,316,414,698,1206,1222,1339,751,1030,3,5,10,16,22,53,
                 168,183,241,1205,328,1095,991,213,159,337,343,642,753,1109,
                 1217,29,56,1188,1293,149,382,431,1202)
mb    = read.csv("data/ADNI_baseline_volumes/ADNI1_1.5T_MAGeT_volumes.csv")

# Get subjects, and diagnoses
base = read.csv("data/ADNI_baseline_volumes/ADNI1_Screening_1.5T_11_15_2012.csv")
base = subset(base, !grepl("Scaled_2", Description)) 
base$VISCODE <- factor(base$Visit, levels = c(1,2,3,4), labels=c("bl","m03","m06","m12"))
subjects = yr1[,c("Image.Data.ID", "RID","VISCODE")]  # we only need these fields
dx = unique(adnimerge[c("DX.bl", "RID", "VISCODE")])
subjects = merge(subjects, dx) 

# Now create one data.frame with all the yr1 volume 
# data we have from each datasource
subregions = merge(subjects, mb, by.x="Image.Data.ID", by.y="SourceImageID", 
                   all.x=TRUE)
subregions = subset(subregions, VISCODE == "bl" & RID %in% adni_69_RIDs)
attach(subregions)
subregions$X1 = mean(X1, X101)
subregions$X2 = mean(X2, X102)
subregions$X4 = mean(X4, X104)
subregions$X5 = mean(X5, X105)
subregions$X6 = mean(X6, X106)
detach(subregions)
subregions = subregions[,!names(subregions) %in% c("Left_Hippo","Right_Hippo",
                                                   "X101","X102","X103","X105",
                                                   "X106")]
subregions.melted = melt(subregions, measure.vars=c("X1","X2","X4","X5","X6"),
                         variable.name="Subregion", value.name="Volume")
levels(subregions.melted$Subregion) <-list("CA1"="X1", "CA2/CA3"="X5",
                                           "CA4/DG"="X4", 
                                           "SR/SL/SM"="X6",
                                           "Subiculum"="X2")
ggplot(subregions.melted, aes(x=Subregion, y=Volume)) +
  geom_boxplot()
@
  \caption{}
  \label{fig:ADNI-scr-subfields}
\end{figure}
\FloatBarrier

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                Discussion
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Discussion}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Tabulation of segmentation accuracies of existing methods (ADNI)
%
<<ADNI1-literature, echo=F, results="asis",cache=FALSE>>=
caption = paste(
  "Survey of automated segmentation accuracy of the ADNI dataset",
  sep=" ")

tab = read.csv("data/ADNI-existing-work.csv")
tab$Notes <- NULL

adni_lit = subset(tab, Dataset=="ADNI")
adni_lit$Dataset <- NULL
other_lit = subset(tab, Dataset!="ADNI")
other_lit$Dataset <- NULL

latex(adni_lit, file="", 
      size="scriptsize",
      caption=caption, 
      rowname=NULL,
      col.just=c("p{1.5in}l","p{0.5in}","p{1.3in}","p{1.5in}"),
      title="")
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                               Conclusion 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion}

\section{Supplementary Materials}

\subsection{ADNI Manual Labels}
% The following blurb is taken (except for the first sentence) verbatim 
Semi-automated hippocampal volumetry was carried out using a commercially
available high dimensional brain mapping tool (Medtronic Surgical Navigation
Technologies, Louisville, CO), that has previously been validated and compared
to manual tracing of the hippocampus \citep{Hsu2002}. Measurement of hippocampal
volume is achieved first by placing manually 22 control points as local
landmarks for the hippocampus on the individual brain MRI data: one landmark at
the hippocampal head, one at the tail, and four per image (i.e., at the
superior, inferior, medial and lateral boundaries) on five equally spaced images
perpendicular to the long axis of the hippocampus. Second, fluid image
transformation is used to match the individual brains to a template brain
\citep{Christensen1997}. The pixels corresponding to the hippocampus are then
labeled and counted to obtain volumes. This method of hippocampal voluming has a
documented reliability of an intraclass coefficient better than .94
\citep{Hsu2002}.

\bibliographystyle{plainnat}
\bibliography{references}
\end{document}
